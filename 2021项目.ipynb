{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /home/chelinwei/anaconda3\n",
      "py37                     /home/chelinwei/anaconda3/envs/py37\n",
      "py38rasa                 /home/chelinwei/anaconda3/envs/py38rasa\n",
      "robust                *  /home/chelinwei/anaconda3/envs/robust\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0928 13:08:11.344628 37308 analysis_predictor.cc:1736] Deprecated. Please use CreatePredictor instead.\n",
      "2022-09-28 13:08:11,539\t[run_att.py-context]-[line:48]-INFO:set device gpu:0\n",
      "2022-09-28 13:08:11,540\t[run_att.py-context]-[line:53]-INFO:{\n",
      " \"model_config\": {\n",
      "  \"model_name\": \"debug\",\n",
      "  \"init_ckpt\": \"ernie-gram-zh\",\n",
      "  \"init_from_ckpt\": null,\n",
      "  \"num_labels\": 2,\n",
      "  \"rdrop_coef\": 0.0,\n",
      "  \"dropout\": 0.2\n",
      " },\n",
      " \"data_config\": {\n",
      "  \"max_seq_length\": 68,\n",
      "  \"ratio\": 70\n",
      " },\n",
      " \"train_config\": {\n",
      "  \"attack\": \"fgm\",\n",
      "  \"train_batch_size\": 128,\n",
      "  \"eval_batch_size\": 512,\n",
      "  \"max_steps\": 30000,\n",
      "  \"learning_rate\": 2e-05,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"epochs\": 5,\n",
      "  \"eval_step\": 100,\n",
      "  \"gpus\": \"0,1,2,3\",\n",
      "  \"gpu\": \"0,1,2,3\",\n",
      "  \"save_step\": 100,\n",
      "  \"warmup_proportion\": 0.2,\n",
      "  \"init_from_ckpt\": \"\",\n",
      "  \"seed\": 2022,\n",
      "  \"device\": \"gpu\",\n",
      "  \"silent\": false,\n",
      "  \"save_chkpoint\": [\n",
      "   100,\n",
      "   23700,\n",
      "   24000\n",
      "  ],\n",
      "  \"max_grad_norm\": null\n",
      " },\n",
      " \"debug\": false,\n",
      " \"logger_name\": \"debug\"\n",
      "}\n",
      "\u001b[32m[2022-09-28 13:08:15,968] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-09-28 13:08:15,978] [    INFO]\u001b[0m - tokenizer config file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-09-28 13:08:15,979] [    INFO]\u001b[0m - Special tokens file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2022-09-28 13:08:15,979] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\u001b[0m\n",
      "init data set ,lac feat!\n",
      "init data set ,lac feat!\n",
      "2022-09-28 13:09:15,973\t[train.py-do_train]-[line:135]-INFO:总步数 23525\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.589 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "global step 10, epoch: 1, batch: 10, loss: 0.8469, ce_loss: 0.8469., accu: 0.5234, speed: 1.00 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.7374, ce_loss: 0.7374., accu: 0.5129, speed: 1.22 step/s\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.8064, ce_loss: 0.8064., accu: 0.5276, speed: 1.22 step/s\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.7760, ce_loss: 0.7760., accu: 0.5266, speed: 1.22 step/s\n",
      "global step 50, epoch: 1, batch: 50, loss: 0.6859, ce_loss: 0.6859., accu: 0.5342, speed: 1.21 step/s\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.7007, ce_loss: 0.7007., accu: 0.5411, speed: 1.21 step/s\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.7536, ce_loss: 0.7536., accu: 0.5442, speed: 1.20 step/s\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.7006, ce_loss: 0.7006., accu: 0.5501, speed: 1.20 step/s\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.6825, ce_loss: 0.6825., accu: 0.5550, speed: 1.20 step/s\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.6487, ce_loss: 0.6487., accu: 0.5602, speed: 1.21 step/s\n",
      "2022-09-28 13:10:40,296\t[train.py-do_train]-[line:187]-INFO:【global step 100, epoch: 1, batch: 100】，loss: 0.6487, ce_loss: 0.6487., accu: 0.5602,\n",
      "global step 110, epoch: 1, batch: 110, loss: 0.7654, ce_loss: 0.7654., accu: 0.5653, speed: 1.19 step/s\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.6909, ce_loss: 0.6909., accu: 0.5687, speed: 1.19 step/s\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.6393, ce_loss: 0.6393., accu: 0.5728, speed: 1.19 step/s\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.5537, ce_loss: 0.5537., accu: 0.5777, speed: 1.19 step/s\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.6163, ce_loss: 0.6163., accu: 0.5809, speed: 1.19 step/s\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.5502, ce_loss: 0.5502., accu: 0.5844, speed: 1.18 step/s\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.6319, ce_loss: 0.6319., accu: 0.5891, speed: 1.18 step/s\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.5857, ce_loss: 0.5857., accu: 0.5926, speed: 1.18 step/s\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.5376, ce_loss: 0.5376., accu: 0.5968, speed: 1.20 step/s\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.6177, ce_loss: 0.6177., accu: 0.6002, speed: 1.19 step/s\n",
      "2022-09-28 13:12:04,496\t[train.py-do_train]-[line:187]-INFO:【global step 200, epoch: 1, batch: 200】，loss: 0.6177, ce_loss: 0.6177., accu: 0.6002,\n",
      "global step 210, epoch: 1, batch: 210, loss: 0.6267, ce_loss: 0.6267., accu: 0.6044, speed: 1.19 step/s\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.5940, ce_loss: 0.5940., accu: 0.6083, speed: 1.18 step/s\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.6008, ce_loss: 0.6008., accu: 0.6113, speed: 1.20 step/s\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.6097, ce_loss: 0.6097., accu: 0.6144, speed: 1.19 step/s\n",
      "global step 250, epoch: 1, batch: 250, loss: 0.6117, ce_loss: 0.6117., accu: 0.6170, speed: 1.18 step/s\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.6024, ce_loss: 0.6024., accu: 0.6201, speed: 1.20 step/s\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.5696, ce_loss: 0.5696., accu: 0.6226, speed: 1.20 step/s\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.4675, ce_loss: 0.4675., accu: 0.6258, speed: 1.19 step/s\n",
      "global step 290, epoch: 1, batch: 290, loss: 0.5279, ce_loss: 0.5279., accu: 0.6289, speed: 1.18 step/s\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.4555, ce_loss: 0.4555., accu: 0.6317, speed: 1.19 step/s\n",
      "2022-09-28 13:13:28,483\t[train.py-do_train]-[line:187]-INFO:【global step 300, epoch: 1, batch: 300】，loss: 0.4555, ce_loss: 0.4555., accu: 0.6317,\n",
      "global step 310, epoch: 1, batch: 310, loss: 0.5860, ce_loss: 0.5860., accu: 0.6343, speed: 1.19 step/s\n",
      "global step 320, epoch: 1, batch: 320, loss: 0.6033, ce_loss: 0.6033., accu: 0.6369, speed: 1.18 step/s\n",
      "global step 330, epoch: 1, batch: 330, loss: 0.5537, ce_loss: 0.5537., accu: 0.6393, speed: 1.18 step/s\n",
      "global step 340, epoch: 1, batch: 340, loss: 0.5289, ce_loss: 0.5289., accu: 0.6420, speed: 1.18 step/s\n",
      "global step 350, epoch: 1, batch: 350, loss: 0.4943, ce_loss: 0.4943., accu: 0.6444, speed: 1.18 step/s\n",
      "global step 360, epoch: 1, batch: 360, loss: 0.5339, ce_loss: 0.5339., accu: 0.6472, speed: 1.20 step/s\n",
      "global step 370, epoch: 1, batch: 370, loss: 0.4685, ce_loss: 0.4685., accu: 0.6501, speed: 1.19 step/s\n",
      "global step 380, epoch: 1, batch: 380, loss: 0.5714, ce_loss: 0.5714., accu: 0.6525, speed: 1.19 step/s\n",
      "global step 390, epoch: 1, batch: 390, loss: 0.5499, ce_loss: 0.5499., accu: 0.6546, speed: 1.19 step/s\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.5619, ce_loss: 0.5619., accu: 0.6564, speed: 1.18 step/s\n",
      "2022-09-28 13:14:52,774\t[train.py-do_train]-[line:187]-INFO:【global step 400, epoch: 1, batch: 400】，loss: 0.5619, ce_loss: 0.5619., accu: 0.6564,\n",
      "global step 410, epoch: 1, batch: 410, loss: 0.5124, ce_loss: 0.5124., accu: 0.6582, speed: 1.18 step/s\n",
      "global step 420, epoch: 1, batch: 420, loss: 0.5538, ce_loss: 0.5538., accu: 0.6604, speed: 1.19 step/s\n",
      "global step 430, epoch: 1, batch: 430, loss: 0.5215, ce_loss: 0.5215., accu: 0.6625, speed: 1.18 step/s\n",
      "global step 440, epoch: 1, batch: 440, loss: 0.5598, ce_loss: 0.5598., accu: 0.6650, speed: 1.18 step/s\n",
      "global step 450, epoch: 1, batch: 450, loss: 0.5764, ce_loss: 0.5764., accu: 0.6669, speed: 1.18 step/s\n",
      "global step 460, epoch: 1, batch: 460, loss: 0.4722, ce_loss: 0.4722., accu: 0.6684, speed: 1.18 step/s\n",
      "global step 470, epoch: 1, batch: 470, loss: 0.4449, ce_loss: 0.4449., accu: 0.6702, speed: 1.19 step/s\n",
      "global step 480, epoch: 1, batch: 480, loss: 0.5032, ce_loss: 0.5032., accu: 0.6720, speed: 1.21 step/s\n",
      "global step 490, epoch: 1, batch: 490, loss: 0.4664, ce_loss: 0.4664., accu: 0.6739, speed: 1.18 step/s\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.5323, ce_loss: 0.5323., accu: 0.6753, speed: 1.20 step/s\n",
      "2022-09-28 13:16:17,043\t[train.py-do_train]-[line:187]-INFO:【global step 500, epoch: 1, batch: 500】，loss: 0.5323, ce_loss: 0.5323., accu: 0.6753,\n",
      "global step 510, epoch: 1, batch: 510, loss: 0.4673, ce_loss: 0.4673., accu: 0.6769, speed: 1.20 step/s\n",
      "global step 520, epoch: 1, batch: 520, loss: 0.4031, ce_loss: 0.4031., accu: 0.6785, speed: 1.18 step/s\n",
      "global step 530, epoch: 1, batch: 530, loss: 0.5387, ce_loss: 0.5387., accu: 0.6805, speed: 1.18 step/s\n",
      "global step 540, epoch: 1, batch: 540, loss: 0.4433, ce_loss: 0.4433., accu: 0.6821, speed: 1.19 step/s\n",
      "global step 550, epoch: 1, batch: 550, loss: 0.4701, ce_loss: 0.4701., accu: 0.6838, speed: 1.21 step/s\n",
      "global step 560, epoch: 1, batch: 560, loss: 0.4865, ce_loss: 0.4865., accu: 0.6851, speed: 1.20 step/s\n",
      "global step 570, epoch: 1, batch: 570, loss: 0.4082, ce_loss: 0.4082., accu: 0.6868, speed: 1.20 step/s\n",
      "global step 580, epoch: 1, batch: 580, loss: 0.4070, ce_loss: 0.4070., accu: 0.6881, speed: 1.21 step/s\n",
      "global step 590, epoch: 1, batch: 590, loss: 0.4991, ce_loss: 0.4991., accu: 0.6893, speed: 1.18 step/s\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.4606, ce_loss: 0.4606., accu: 0.6908, speed: 1.18 step/s\n",
      "2022-09-28 13:17:40,932\t[train.py-do_train]-[line:187]-INFO:【global step 600, epoch: 1, batch: 600】，loss: 0.4606, ce_loss: 0.4606., accu: 0.6908,\n",
      "global step 610, epoch: 1, batch: 610, loss: 0.3811, ce_loss: 0.3811., accu: 0.6924, speed: 1.21 step/s\n",
      "global step 620, epoch: 1, batch: 620, loss: 0.4501, ce_loss: 0.4501., accu: 0.6935, speed: 1.22 step/s\n",
      "global step 630, epoch: 1, batch: 630, loss: 0.5185, ce_loss: 0.5185., accu: 0.6944, speed: 1.19 step/s\n",
      "global step 640, epoch: 1, batch: 640, loss: 0.5684, ce_loss: 0.5684., accu: 0.6955, speed: 1.19 step/s\n",
      "global step 650, epoch: 1, batch: 650, loss: 0.3762, ce_loss: 0.3762., accu: 0.6968, speed: 1.18 step/s\n",
      "global step 660, epoch: 1, batch: 660, loss: 0.4678, ce_loss: 0.4678., accu: 0.6981, speed: 1.18 step/s\n",
      "global step 670, epoch: 1, batch: 670, loss: 0.4152, ce_loss: 0.4152., accu: 0.6993, speed: 1.19 step/s\n",
      "global step 680, epoch: 1, batch: 680, loss: 0.4261, ce_loss: 0.4261., accu: 0.7005, speed: 1.20 step/s\n",
      "global step 690, epoch: 1, batch: 690, loss: 0.5154, ce_loss: 0.5154., accu: 0.7019, speed: 1.20 step/s\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.5163, ce_loss: 0.5163., accu: 0.7027, speed: 1.19 step/s\n",
      "2022-09-28 13:19:04,588\t[train.py-do_train]-[line:187]-INFO:【global step 700, epoch: 1, batch: 700】，loss: 0.5163, ce_loss: 0.5163., accu: 0.7027,\n",
      "global step 710, epoch: 1, batch: 710, loss: 0.4493, ce_loss: 0.4493., accu: 0.7036, speed: 1.20 step/s\n",
      "global step 720, epoch: 1, batch: 720, loss: 0.4854, ce_loss: 0.4854., accu: 0.7047, speed: 1.18 step/s\n",
      "global step 730, epoch: 1, batch: 730, loss: 0.4244, ce_loss: 0.4244., accu: 0.7058, speed: 1.18 step/s\n",
      "global step 740, epoch: 1, batch: 740, loss: 0.5061, ce_loss: 0.5061., accu: 0.7065, speed: 1.20 step/s\n",
      "global step 750, epoch: 1, batch: 750, loss: 0.4722, ce_loss: 0.4722., accu: 0.7079, speed: 1.21 step/s\n",
      "global step 760, epoch: 1, batch: 760, loss: 0.5302, ce_loss: 0.5302., accu: 0.7086, speed: 1.18 step/s\n",
      "global step 770, epoch: 1, batch: 770, loss: 0.4551, ce_loss: 0.4551., accu: 0.7093, speed: 1.20 step/s\n",
      "global step 780, epoch: 1, batch: 780, loss: 0.4359, ce_loss: 0.4359., accu: 0.7103, speed: 1.19 step/s\n",
      "global step 790, epoch: 1, batch: 790, loss: 0.4273, ce_loss: 0.4273., accu: 0.7112, speed: 1.19 step/s\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.4750, ce_loss: 0.4750., accu: 0.7122, speed: 1.18 step/s\n",
      "2022-09-28 13:20:28,622\t[train.py-do_train]-[line:187]-INFO:【global step 800, epoch: 1, batch: 800】，loss: 0.4750, ce_loss: 0.4750., accu: 0.7122,\n",
      "global step 810, epoch: 1, batch: 810, loss: 0.5464, ce_loss: 0.5464., accu: 0.7129, speed: 1.18 step/s\n",
      "global step 820, epoch: 1, batch: 820, loss: 0.3982, ce_loss: 0.3982., accu: 0.7137, speed: 1.18 step/s\n",
      "global step 830, epoch: 1, batch: 830, loss: 0.5517, ce_loss: 0.5517., accu: 0.7148, speed: 1.20 step/s\n",
      "global step 840, epoch: 1, batch: 840, loss: 0.3724, ce_loss: 0.3724., accu: 0.7156, speed: 1.19 step/s\n",
      "global step 850, epoch: 1, batch: 850, loss: 0.3805, ce_loss: 0.3805., accu: 0.7164, speed: 1.18 step/s\n",
      "global step 860, epoch: 1, batch: 860, loss: 0.4362, ce_loss: 0.4362., accu: 0.7173, speed: 1.20 step/s\n",
      "global step 870, epoch: 1, batch: 870, loss: 0.4506, ce_loss: 0.4506., accu: 0.7182, speed: 1.19 step/s\n",
      "global step 880, epoch: 1, batch: 880, loss: 0.3899, ce_loss: 0.3899., accu: 0.7190, speed: 1.18 step/s\n",
      "global step 890, epoch: 1, batch: 890, loss: 0.5338, ce_loss: 0.5338., accu: 0.7196, speed: 1.18 step/s\n",
      "global step 900, epoch: 1, batch: 900, loss: 0.4152, ce_loss: 0.4152., accu: 0.7204, speed: 1.19 step/s\n",
      "2022-09-28 13:21:52,804\t[train.py-do_train]-[line:187]-INFO:【global step 900, epoch: 1, batch: 900】，loss: 0.4152, ce_loss: 0.4152., accu: 0.7204,\n",
      "global step 910, epoch: 1, batch: 910, loss: 0.5325, ce_loss: 0.5325., accu: 0.7210, speed: 1.21 step/s\n",
      "global step 920, epoch: 1, batch: 920, loss: 0.4055, ce_loss: 0.4055., accu: 0.7219, speed: 1.19 step/s\n",
      "global step 930, epoch: 1, batch: 930, loss: 0.4495, ce_loss: 0.4495., accu: 0.7228, speed: 1.19 step/s\n",
      "global step 940, epoch: 1, batch: 940, loss: 0.3773, ce_loss: 0.3773., accu: 0.7235, speed: 1.18 step/s\n",
      "global step 950, epoch: 1, batch: 950, loss: 0.4201, ce_loss: 0.4201., accu: 0.7242, speed: 1.19 step/s\n",
      "global step 960, epoch: 1, batch: 960, loss: 0.4346, ce_loss: 0.4346., accu: 0.7249, speed: 1.20 step/s\n",
      "global step 970, epoch: 1, batch: 970, loss: 0.4326, ce_loss: 0.4326., accu: 0.7257, speed: 1.21 step/s\n",
      "global step 980, epoch: 1, batch: 980, loss: 0.4032, ce_loss: 0.4032., accu: 0.7265, speed: 1.20 step/s\n",
      "global step 990, epoch: 1, batch: 990, loss: 0.5607, ce_loss: 0.5607., accu: 0.7272, speed: 1.18 step/s\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.3870, ce_loss: 0.3870., accu: 0.7277, speed: 1.22 step/s\n",
      "2022-09-28 13:23:16,438\t[train.py-do_train]-[line:187]-INFO:【global step 1000, epoch: 1, batch: 1000】，loss: 0.3870, ce_loss: 0.3870., accu: 0.7277,\n",
      "global step 1010, epoch: 1, batch: 1010, loss: 0.4444, ce_loss: 0.4444., accu: 0.7283, speed: 1.18 step/s\n",
      "global step 1020, epoch: 1, batch: 1020, loss: 0.5478, ce_loss: 0.5478., accu: 0.7288, speed: 1.20 step/s\n",
      "global step 1030, epoch: 1, batch: 1030, loss: 0.4363, ce_loss: 0.4363., accu: 0.7295, speed: 1.18 step/s\n",
      "global step 1040, epoch: 1, batch: 1040, loss: 0.4447, ce_loss: 0.4447., accu: 0.7301, speed: 1.18 step/s\n",
      "global step 1050, epoch: 1, batch: 1050, loss: 0.4482, ce_loss: 0.4482., accu: 0.7308, speed: 1.19 step/s\n",
      "global step 1060, epoch: 1, batch: 1060, loss: 0.3572, ce_loss: 0.3572., accu: 0.7316, speed: 1.18 step/s\n",
      "global step 1070, epoch: 1, batch: 1070, loss: 0.5438, ce_loss: 0.5438., accu: 0.7321, speed: 1.18 step/s\n",
      "global step 1080, epoch: 1, batch: 1080, loss: 0.3937, ce_loss: 0.3937., accu: 0.7328, speed: 1.19 step/s\n",
      "global step 1090, epoch: 1, batch: 1090, loss: 0.3853, ce_loss: 0.3853., accu: 0.7334, speed: 1.18 step/s\n",
      "global step 1100, epoch: 1, batch: 1100, loss: 0.4455, ce_loss: 0.4455., accu: 0.7341, speed: 1.18 step/s\n",
      "2022-09-28 13:24:40,887\t[train.py-do_train]-[line:187]-INFO:【global step 1100, epoch: 1, batch: 1100】，loss: 0.4455, ce_loss: 0.4455., accu: 0.7341,\n",
      "global step 1110, epoch: 1, batch: 1110, loss: 0.5292, ce_loss: 0.5292., accu: 0.7345, speed: 1.18 step/s\n",
      "global step 1120, epoch: 1, batch: 1120, loss: 0.4070, ce_loss: 0.4070., accu: 0.7352, speed: 1.18 step/s\n",
      "global step 1130, epoch: 1, batch: 1130, loss: 0.3529, ce_loss: 0.3529., accu: 0.7360, speed: 1.18 step/s\n",
      "global step 1140, epoch: 1, batch: 1140, loss: 0.3555, ce_loss: 0.3555., accu: 0.7367, speed: 1.19 step/s\n",
      "global step 1150, epoch: 1, batch: 1150, loss: 0.3440, ce_loss: 0.3440., accu: 0.7372, speed: 1.18 step/s\n",
      "global step 1160, epoch: 1, batch: 1160, loss: 0.4483, ce_loss: 0.4483., accu: 0.7377, speed: 1.18 step/s\n",
      "global step 1170, epoch: 1, batch: 1170, loss: 0.5389, ce_loss: 0.5389., accu: 0.7382, speed: 1.18 step/s\n",
      "global step 1180, epoch: 1, batch: 1180, loss: 0.4085, ce_loss: 0.4085., accu: 0.7389, speed: 1.18 step/s\n",
      "global step 1190, epoch: 1, batch: 1190, loss: 0.4858, ce_loss: 0.4858., accu: 0.7394, speed: 1.18 step/s\n",
      "global step 1200, epoch: 1, batch: 1200, loss: 0.4840, ce_loss: 0.4840., accu: 0.7400, speed: 1.19 step/s\n",
      "2022-09-28 13:26:05,393\t[train.py-do_train]-[line:187]-INFO:【global step 1200, epoch: 1, batch: 1200】，loss: 0.4840, ce_loss: 0.4840., accu: 0.7400,\n",
      "global step 1210, epoch: 1, batch: 1210, loss: 0.3819, ce_loss: 0.3819., accu: 0.7405, speed: 1.20 step/s\n",
      "global step 1220, epoch: 1, batch: 1220, loss: 0.4076, ce_loss: 0.4076., accu: 0.7411, speed: 1.18 step/s\n",
      "global step 1230, epoch: 1, batch: 1230, loss: 0.4345, ce_loss: 0.4345., accu: 0.7416, speed: 1.18 step/s\n",
      "global step 1240, epoch: 1, batch: 1240, loss: 0.4306, ce_loss: 0.4306., accu: 0.7422, speed: 1.18 step/s\n",
      "global step 1250, epoch: 1, batch: 1250, loss: 0.3759, ce_loss: 0.3759., accu: 0.7428, speed: 1.18 step/s\n",
      "global step 1260, epoch: 1, batch: 1260, loss: 0.4233, ce_loss: 0.4233., accu: 0.7434, speed: 1.18 step/s\n",
      "global step 1270, epoch: 1, batch: 1270, loss: 0.4493, ce_loss: 0.4493., accu: 0.7440, speed: 1.18 step/s\n",
      "global step 1280, epoch: 1, batch: 1280, loss: 0.3631, ce_loss: 0.3631., accu: 0.7443, speed: 1.18 step/s\n",
      "global step 1290, epoch: 1, batch: 1290, loss: 0.3004, ce_loss: 0.3004., accu: 0.7449, speed: 1.18 step/s\n",
      "global step 1300, epoch: 1, batch: 1300, loss: 0.4322, ce_loss: 0.4322., accu: 0.7454, speed: 1.18 step/s\n",
      "2022-09-28 13:27:29,967\t[train.py-do_train]-[line:187]-INFO:【global step 1300, epoch: 1, batch: 1300】，loss: 0.4322, ce_loss: 0.4322., accu: 0.7454,\n",
      "global step 1310, epoch: 1, batch: 1310, loss: 0.3891, ce_loss: 0.3891., accu: 0.7458, speed: 1.19 step/s\n",
      "global step 1320, epoch: 1, batch: 1320, loss: 0.3768, ce_loss: 0.3768., accu: 0.7464, speed: 1.19 step/s\n",
      "global step 1330, epoch: 1, batch: 1330, loss: 0.4316, ce_loss: 0.4316., accu: 0.7467, speed: 1.18 step/s\n",
      "global step 1340, epoch: 1, batch: 1340, loss: 0.3747, ce_loss: 0.3747., accu: 0.7471, speed: 1.18 step/s\n",
      "global step 1350, epoch: 1, batch: 1350, loss: 0.3884, ce_loss: 0.3884., accu: 0.7476, speed: 1.18 step/s\n",
      "global step 1360, epoch: 1, batch: 1360, loss: 0.4421, ce_loss: 0.4421., accu: 0.7480, speed: 1.19 step/s\n",
      "global step 1370, epoch: 1, batch: 1370, loss: 0.4144, ce_loss: 0.4144., accu: 0.7484, speed: 1.18 step/s\n",
      "global step 1380, epoch: 1, batch: 1380, loss: 0.3822, ce_loss: 0.3822., accu: 0.7489, speed: 1.18 step/s\n",
      "global step 1390, epoch: 1, batch: 1390, loss: 0.4884, ce_loss: 0.4884., accu: 0.7495, speed: 1.18 step/s\n",
      "global step 1400, epoch: 1, batch: 1400, loss: 0.3571, ce_loss: 0.3571., accu: 0.7499, speed: 1.18 step/s\n",
      "2022-09-28 13:28:54,666\t[train.py-do_train]-[line:187]-INFO:【global step 1400, epoch: 1, batch: 1400】，loss: 0.3571, ce_loss: 0.3571., accu: 0.7499,\n",
      "global step 1410, epoch: 1, batch: 1410, loss: 0.4175, ce_loss: 0.4175., accu: 0.7504, speed: 1.18 step/s\n",
      "global step 1420, epoch: 1, batch: 1420, loss: 0.4861, ce_loss: 0.4861., accu: 0.7508, speed: 1.18 step/s\n",
      "global step 1430, epoch: 1, batch: 1430, loss: 0.3812, ce_loss: 0.3812., accu: 0.7513, speed: 1.18 step/s\n",
      "global step 1440, epoch: 1, batch: 1440, loss: 0.3287, ce_loss: 0.3287., accu: 0.7517, speed: 1.19 step/s\n",
      "global step 1450, epoch: 1, batch: 1450, loss: 0.3389, ce_loss: 0.3389., accu: 0.7521, speed: 1.18 step/s\n",
      "global step 1460, epoch: 1, batch: 1460, loss: 0.4371, ce_loss: 0.4371., accu: 0.7524, speed: 1.18 step/s\n",
      "global step 1470, epoch: 1, batch: 1470, loss: 0.4648, ce_loss: 0.4648., accu: 0.7529, speed: 1.18 step/s\n",
      "global step 1480, epoch: 1, batch: 1480, loss: 0.3718, ce_loss: 0.3718., accu: 0.7533, speed: 1.18 step/s\n",
      "global step 1490, epoch: 1, batch: 1490, loss: 0.2847, ce_loss: 0.2847., accu: 0.7538, speed: 1.20 step/s\n",
      "global step 1500, epoch: 1, batch: 1500, loss: 0.4002, ce_loss: 0.4002., accu: 0.7541, speed: 1.20 step/s\n",
      "2022-09-28 13:30:19,134\t[train.py-do_train]-[line:187]-INFO:【global step 1500, epoch: 1, batch: 1500】，loss: 0.4002, ce_loss: 0.4002., accu: 0.7541,\n",
      "global step 1510, epoch: 1, batch: 1510, loss: 0.3842, ce_loss: 0.3842., accu: 0.7545, speed: 1.18 step/s\n",
      "global step 1520, epoch: 1, batch: 1520, loss: 0.3627, ce_loss: 0.3627., accu: 0.7549, speed: 1.18 step/s\n",
      "global step 1530, epoch: 1, batch: 1530, loss: 0.3581, ce_loss: 0.3581., accu: 0.7554, speed: 1.19 step/s\n",
      "global step 1540, epoch: 1, batch: 1540, loss: 0.3573, ce_loss: 0.3573., accu: 0.7559, speed: 1.19 step/s\n",
      "global step 1550, epoch: 1, batch: 1550, loss: 0.3416, ce_loss: 0.3416., accu: 0.7564, speed: 1.18 step/s\n",
      "global step 1560, epoch: 1, batch: 1560, loss: 0.3874, ce_loss: 0.3874., accu: 0.7568, speed: 1.19 step/s\n",
      "global step 1570, epoch: 1, batch: 1570, loss: 0.3972, ce_loss: 0.3972., accu: 0.7572, speed: 1.18 step/s\n",
      "global step 1580, epoch: 1, batch: 1580, loss: 0.3701, ce_loss: 0.3701., accu: 0.7575, speed: 1.21 step/s\n",
      "global step 1590, epoch: 1, batch: 1590, loss: 0.4686, ce_loss: 0.4686., accu: 0.7577, speed: 1.20 step/s\n",
      "global step 1600, epoch: 1, batch: 1600, loss: 0.4188, ce_loss: 0.4188., accu: 0.7580, speed: 1.18 step/s\n",
      "2022-09-28 13:31:43,448\t[train.py-do_train]-[line:187]-INFO:【global step 1600, epoch: 1, batch: 1600】，loss: 0.4188, ce_loss: 0.4188., accu: 0.7580,\n",
      "global step 1610, epoch: 1, batch: 1610, loss: 0.4083, ce_loss: 0.4083., accu: 0.7585, speed: 1.19 step/s\n",
      "global step 1620, epoch: 1, batch: 1620, loss: 0.3632, ce_loss: 0.3632., accu: 0.7589, speed: 1.18 step/s\n",
      "global step 1630, epoch: 1, batch: 1630, loss: 0.4154, ce_loss: 0.4154., accu: 0.7593, speed: 1.19 step/s\n",
      "global step 1640, epoch: 1, batch: 1640, loss: 0.3803, ce_loss: 0.3803., accu: 0.7596, speed: 1.20 step/s\n",
      "global step 1650, epoch: 1, batch: 1650, loss: 0.5442, ce_loss: 0.5442., accu: 0.7600, speed: 1.19 step/s\n",
      "global step 1660, epoch: 1, batch: 1660, loss: 0.2867, ce_loss: 0.2867., accu: 0.7605, speed: 1.18 step/s\n",
      "global step 1670, epoch: 1, batch: 1670, loss: 0.3383, ce_loss: 0.3383., accu: 0.7608, speed: 1.20 step/s\n",
      "global step 1680, epoch: 1, batch: 1680, loss: 0.4262, ce_loss: 0.4262., accu: 0.7612, speed: 1.18 step/s\n",
      "global step 1690, epoch: 1, batch: 1690, loss: 0.4584, ce_loss: 0.4584., accu: 0.7615, speed: 1.18 step/s\n",
      "global step 1700, epoch: 1, batch: 1700, loss: 0.2876, ce_loss: 0.2876., accu: 0.7619, speed: 1.20 step/s\n",
      "2022-09-28 13:33:07,538\t[train.py-do_train]-[line:187]-INFO:【global step 1700, epoch: 1, batch: 1700】，loss: 0.2876, ce_loss: 0.2876., accu: 0.7619,\n",
      "global step 1710, epoch: 1, batch: 1710, loss: 0.4242, ce_loss: 0.4242., accu: 0.7623, speed: 1.18 step/s\n",
      "global step 1720, epoch: 1, batch: 1720, loss: 0.3673, ce_loss: 0.3673., accu: 0.7626, speed: 1.18 step/s\n",
      "global step 1730, epoch: 1, batch: 1730, loss: 0.3570, ce_loss: 0.3570., accu: 0.7630, speed: 1.18 step/s\n",
      "global step 1740, epoch: 1, batch: 1740, loss: 0.3862, ce_loss: 0.3862., accu: 0.7633, speed: 1.19 step/s\n",
      "global step 1750, epoch: 1, batch: 1750, loss: 0.4020, ce_loss: 0.4020., accu: 0.7636, speed: 1.18 step/s\n",
      "global step 1760, epoch: 1, batch: 1760, loss: 0.3092, ce_loss: 0.3092., accu: 0.7640, speed: 1.18 step/s\n",
      "global step 1770, epoch: 1, batch: 1770, loss: 0.3350, ce_loss: 0.3350., accu: 0.7644, speed: 1.19 step/s\n",
      "global step 1780, epoch: 1, batch: 1780, loss: 0.3301, ce_loss: 0.3301., accu: 0.7647, speed: 1.18 step/s\n",
      "global step 1790, epoch: 1, batch: 1790, loss: 0.4122, ce_loss: 0.4122., accu: 0.7649, speed: 1.20 step/s\n",
      "global step 1800, epoch: 1, batch: 1800, loss: 0.4667, ce_loss: 0.4667., accu: 0.7653, speed: 1.20 step/s\n",
      "2022-09-28 13:34:31,782\t[train.py-do_train]-[line:187]-INFO:【global step 1800, epoch: 1, batch: 1800】，loss: 0.4667, ce_loss: 0.4667., accu: 0.7653,\n",
      "global step 1810, epoch: 1, batch: 1810, loss: 0.4216, ce_loss: 0.4216., accu: 0.7656, speed: 1.18 step/s\n",
      "global step 1820, epoch: 1, batch: 1820, loss: 0.3175, ce_loss: 0.3175., accu: 0.7659, speed: 1.18 step/s\n",
      "global step 1830, epoch: 1, batch: 1830, loss: 0.2991, ce_loss: 0.2991., accu: 0.7663, speed: 1.18 step/s\n",
      "global step 1840, epoch: 1, batch: 1840, loss: 0.3415, ce_loss: 0.3415., accu: 0.7666, speed: 1.18 step/s\n",
      "global step 1850, epoch: 1, batch: 1850, loss: 0.4234, ce_loss: 0.4234., accu: 0.7670, speed: 1.20 step/s\n",
      "global step 1860, epoch: 1, batch: 1860, loss: 0.4691, ce_loss: 0.4691., accu: 0.7673, speed: 1.18 step/s\n",
      "global step 1870, epoch: 1, batch: 1870, loss: 0.4078, ce_loss: 0.4078., accu: 0.7676, speed: 1.18 step/s\n",
      "global step 1880, epoch: 1, batch: 1880, loss: 0.3752, ce_loss: 0.3752., accu: 0.7679, speed: 1.19 step/s\n",
      "global step 1890, epoch: 1, batch: 1890, loss: 0.4186, ce_loss: 0.4186., accu: 0.7683, speed: 1.18 step/s\n",
      "global step 1900, epoch: 1, batch: 1900, loss: 0.3127, ce_loss: 0.3127., accu: 0.7686, speed: 1.20 step/s\n",
      "2022-09-28 13:35:56,094\t[train.py-do_train]-[line:187]-INFO:【global step 1900, epoch: 1, batch: 1900】，loss: 0.3127, ce_loss: 0.3127., accu: 0.7686,\n",
      "global step 1910, epoch: 1, batch: 1910, loss: 0.4811, ce_loss: 0.4811., accu: 0.7689, speed: 1.18 step/s\n",
      "global step 1920, epoch: 1, batch: 1920, loss: 0.3454, ce_loss: 0.3454., accu: 0.7692, speed: 1.20 step/s\n",
      "global step 1930, epoch: 1, batch: 1930, loss: 0.4123, ce_loss: 0.4123., accu: 0.7695, speed: 1.20 step/s\n",
      "global step 1940, epoch: 1, batch: 1940, loss: 0.5007, ce_loss: 0.5007., accu: 0.7697, speed: 1.18 step/s\n",
      "global step 1950, epoch: 1, batch: 1950, loss: 0.4267, ce_loss: 0.4267., accu: 0.7700, speed: 1.19 step/s\n",
      "global step 1960, epoch: 1, batch: 1960, loss: 0.5099, ce_loss: 0.5099., accu: 0.7702, speed: 1.18 step/s\n",
      "global step 1970, epoch: 1, batch: 1970, loss: 0.3687, ce_loss: 0.3687., accu: 0.7706, speed: 1.18 step/s\n",
      "global step 1980, epoch: 1, batch: 1980, loss: 0.3328, ce_loss: 0.3328., accu: 0.7709, speed: 1.18 step/s\n",
      "global step 1990, epoch: 1, batch: 1990, loss: 0.2924, ce_loss: 0.2924., accu: 0.7712, speed: 1.18 step/s\n",
      "global step 2000, epoch: 1, batch: 2000, loss: 0.3378, ce_loss: 0.3378., accu: 0.7715, speed: 1.18 step/s\n",
      "2022-09-28 13:37:20,508\t[train.py-do_train]-[line:187]-INFO:【global step 2000, epoch: 1, batch: 2000】，loss: 0.3378, ce_loss: 0.3378., accu: 0.7715,\n",
      "global step 2010, epoch: 1, batch: 2010, loss: 0.3733, ce_loss: 0.3733., accu: 0.7718, speed: 1.19 step/s\n",
      "global step 2020, epoch: 1, batch: 2020, loss: 0.4225, ce_loss: 0.4225., accu: 0.7722, speed: 1.20 step/s\n",
      "global step 2030, epoch: 1, batch: 2030, loss: 0.3065, ce_loss: 0.3065., accu: 0.7724, speed: 1.18 step/s\n",
      "global step 2040, epoch: 1, batch: 2040, loss: 0.3206, ce_loss: 0.3206., accu: 0.7726, speed: 1.21 step/s\n",
      "global step 2050, epoch: 1, batch: 2050, loss: 0.3466, ce_loss: 0.3466., accu: 0.7729, speed: 1.18 step/s\n",
      "global step 2060, epoch: 1, batch: 2060, loss: 0.3812, ce_loss: 0.3812., accu: 0.7731, speed: 1.19 step/s\n",
      "global step 2070, epoch: 1, batch: 2070, loss: 0.4101, ce_loss: 0.4101., accu: 0.7734, speed: 1.19 step/s\n",
      "global step 2080, epoch: 1, batch: 2080, loss: 0.3437, ce_loss: 0.3437., accu: 0.7737, speed: 1.18 step/s\n",
      "global step 2090, epoch: 1, batch: 2090, loss: 0.3338, ce_loss: 0.3338., accu: 0.7740, speed: 1.18 step/s\n",
      "global step 2100, epoch: 1, batch: 2100, loss: 0.2899, ce_loss: 0.2899., accu: 0.7743, speed: 1.19 step/s\n",
      "2022-09-28 13:38:44,708\t[train.py-do_train]-[line:187]-INFO:【global step 2100, epoch: 1, batch: 2100】，loss: 0.2899, ce_loss: 0.2899., accu: 0.7743,\n",
      "global step 2110, epoch: 1, batch: 2110, loss: 0.4371, ce_loss: 0.4371., accu: 0.7746, speed: 1.20 step/s\n",
      "global step 2120, epoch: 1, batch: 2120, loss: 0.3961, ce_loss: 0.3961., accu: 0.7748, speed: 1.19 step/s\n",
      "global step 2130, epoch: 1, batch: 2130, loss: 0.3057, ce_loss: 0.3057., accu: 0.7751, speed: 1.19 step/s\n",
      "global step 2140, epoch: 1, batch: 2140, loss: 0.4095, ce_loss: 0.4095., accu: 0.7753, speed: 1.19 step/s\n",
      "global step 2150, epoch: 1, batch: 2150, loss: 0.4082, ce_loss: 0.4082., accu: 0.7756, speed: 1.20 step/s\n",
      "global step 2160, epoch: 1, batch: 2160, loss: 0.4476, ce_loss: 0.4476., accu: 0.7758, speed: 1.19 step/s\n",
      "global step 2170, epoch: 1, batch: 2170, loss: 0.3599, ce_loss: 0.3599., accu: 0.7761, speed: 1.19 step/s\n",
      "global step 2180, epoch: 1, batch: 2180, loss: 0.3635, ce_loss: 0.3635., accu: 0.7764, speed: 1.20 step/s\n",
      "global step 2190, epoch: 1, batch: 2190, loss: 0.2763, ce_loss: 0.2763., accu: 0.7766, speed: 1.18 step/s\n",
      "global step 2200, epoch: 1, batch: 2200, loss: 0.4207, ce_loss: 0.4207., accu: 0.7769, speed: 1.18 step/s\n",
      "2022-09-28 13:40:08,667\t[train.py-do_train]-[line:187]-INFO:【global step 2200, epoch: 1, batch: 2200】，loss: 0.4207, ce_loss: 0.4207., accu: 0.7769,\n",
      "global step 2210, epoch: 1, batch: 2210, loss: 0.3537, ce_loss: 0.3537., accu: 0.7771, speed: 1.18 step/s\n",
      "global step 2220, epoch: 1, batch: 2220, loss: 0.3453, ce_loss: 0.3453., accu: 0.7774, speed: 1.19 step/s\n",
      "global step 2230, epoch: 1, batch: 2230, loss: 0.2879, ce_loss: 0.2879., accu: 0.7776, speed: 1.18 step/s\n",
      "global step 2240, epoch: 1, batch: 2240, loss: 0.4100, ce_loss: 0.4100., accu: 0.7779, speed: 1.21 step/s\n",
      "global step 2250, epoch: 1, batch: 2250, loss: 0.4440, ce_loss: 0.4440., accu: 0.7781, speed: 1.18 step/s\n",
      "global step 2260, epoch: 1, batch: 2260, loss: 0.3439, ce_loss: 0.3439., accu: 0.7783, speed: 1.19 step/s\n",
      "global step 2270, epoch: 1, batch: 2270, loss: 0.3310, ce_loss: 0.3310., accu: 0.7787, speed: 1.19 step/s\n",
      "global step 2280, epoch: 1, batch: 2280, loss: 0.2990, ce_loss: 0.2990., accu: 0.7789, speed: 1.18 step/s\n",
      "global step 2290, epoch: 1, batch: 2290, loss: 0.2698, ce_loss: 0.2698., accu: 0.7791, speed: 1.18 step/s\n",
      "global step 2300, epoch: 1, batch: 2300, loss: 0.4562, ce_loss: 0.4562., accu: 0.7793, speed: 1.19 step/s\n",
      "2022-09-28 13:41:32,887\t[train.py-do_train]-[line:187]-INFO:【global step 2300, epoch: 1, batch: 2300】，loss: 0.4562, ce_loss: 0.4562., accu: 0.7793,\n",
      "global step 2310, epoch: 1, batch: 2310, loss: 0.3780, ce_loss: 0.3780., accu: 0.7795, speed: 1.22 step/s\n",
      "global step 2320, epoch: 1, batch: 2320, loss: 0.3642, ce_loss: 0.3642., accu: 0.7798, speed: 1.20 step/s\n",
      "global step 2330, epoch: 1, batch: 2330, loss: 0.3809, ce_loss: 0.3809., accu: 0.7801, speed: 1.18 step/s\n",
      "global step 2340, epoch: 1, batch: 2340, loss: 0.2698, ce_loss: 0.2698., accu: 0.7804, speed: 1.19 step/s\n",
      "global step 2350, epoch: 1, batch: 2350, loss: 0.4019, ce_loss: 0.4019., accu: 0.7806, speed: 1.21 step/s\n",
      "global step 2360, epoch: 1, batch: 2360, loss: 0.4090, ce_loss: 0.4090., accu: 0.7807, speed: 1.20 step/s\n",
      "global step 2370, epoch: 1, batch: 2370, loss: 0.3582, ce_loss: 0.3582., accu: 0.7810, speed: 1.21 step/s\n",
      "global step 2380, epoch: 1, batch: 2380, loss: 0.3827, ce_loss: 0.3827., accu: 0.7812, speed: 1.20 step/s\n",
      "global step 2390, epoch: 1, batch: 2390, loss: 0.2712, ce_loss: 0.2712., accu: 0.7815, speed: 1.19 step/s\n",
      "global step 2400, epoch: 1, batch: 2400, loss: 0.3056, ce_loss: 0.3056., accu: 0.7817, speed: 1.19 step/s\n",
      "2022-09-28 13:42:56,299\t[train.py-do_train]-[line:187]-INFO:【global step 2400, epoch: 1, batch: 2400】，loss: 0.3056, ce_loss: 0.3056., accu: 0.7817,\n",
      "global step 2410, epoch: 1, batch: 2410, loss: 0.2919, ce_loss: 0.2919., accu: 0.7819, speed: 1.18 step/s\n",
      "global step 2420, epoch: 1, batch: 2420, loss: 0.3410, ce_loss: 0.3410., accu: 0.7821, speed: 1.21 step/s\n",
      "global step 2430, epoch: 1, batch: 2430, loss: 0.3807, ce_loss: 0.3807., accu: 0.7824, speed: 1.18 step/s\n",
      "global step 2440, epoch: 1, batch: 2440, loss: 0.3258, ce_loss: 0.3258., accu: 0.7827, speed: 1.20 step/s\n",
      "global step 2450, epoch: 1, batch: 2450, loss: 0.2573, ce_loss: 0.2573., accu: 0.7829, speed: 1.18 step/s\n",
      "global step 2460, epoch: 1, batch: 2460, loss: 0.4364, ce_loss: 0.4364., accu: 0.7830, speed: 1.18 step/s\n",
      "global step 2470, epoch: 1, batch: 2470, loss: 0.4264, ce_loss: 0.4264., accu: 0.7832, speed: 1.21 step/s\n",
      "global step 2480, epoch: 1, batch: 2480, loss: 0.2976, ce_loss: 0.2976., accu: 0.7834, speed: 1.18 step/s\n",
      "global step 2490, epoch: 1, batch: 2490, loss: 0.3465, ce_loss: 0.3465., accu: 0.7836, speed: 1.18 step/s\n",
      "global step 2500, epoch: 1, batch: 2500, loss: 0.3622, ce_loss: 0.3622., accu: 0.7838, speed: 1.18 step/s\n",
      "2022-09-28 13:44:20,438\t[train.py-do_train]-[line:187]-INFO:【global step 2500, epoch: 1, batch: 2500】，loss: 0.3622, ce_loss: 0.3622., accu: 0.7838,\n",
      "global step 2510, epoch: 1, batch: 2510, loss: 0.3933, ce_loss: 0.3933., accu: 0.7839, speed: 1.18 step/s\n",
      "global step 2520, epoch: 1, batch: 2520, loss: 0.3307, ce_loss: 0.3307., accu: 0.7842, speed: 1.18 step/s\n",
      "global step 2530, epoch: 1, batch: 2530, loss: 0.4631, ce_loss: 0.4631., accu: 0.7843, speed: 1.20 step/s\n",
      "global step 2540, epoch: 1, batch: 2540, loss: 0.3712, ce_loss: 0.3712., accu: 0.7845, speed: 1.18 step/s\n",
      "global step 2550, epoch: 1, batch: 2550, loss: 0.3472, ce_loss: 0.3472., accu: 0.7846, speed: 1.21 step/s\n",
      "global step 2560, epoch: 1, batch: 2560, loss: 0.3469, ce_loss: 0.3469., accu: 0.7849, speed: 1.18 step/s\n",
      "global step 2570, epoch: 1, batch: 2570, loss: 0.3039, ce_loss: 0.3039., accu: 0.7851, speed: 1.19 step/s\n",
      "global step 2580, epoch: 1, batch: 2580, loss: 0.4482, ce_loss: 0.4482., accu: 0.7852, speed: 1.18 step/s\n",
      "global step 2590, epoch: 1, batch: 2590, loss: 0.3513, ce_loss: 0.3513., accu: 0.7854, speed: 1.19 step/s\n",
      "global step 2600, epoch: 1, batch: 2600, loss: 0.3012, ce_loss: 0.3012., accu: 0.7855, speed: 1.20 step/s\n",
      "2022-09-28 13:45:44,546\t[train.py-do_train]-[line:187]-INFO:【global step 2600, epoch: 1, batch: 2600】，loss: 0.3012, ce_loss: 0.3012., accu: 0.7855,\n",
      "global step 2610, epoch: 1, batch: 2610, loss: 0.4289, ce_loss: 0.4289., accu: 0.7858, speed: 1.20 step/s\n",
      "global step 2620, epoch: 1, batch: 2620, loss: 0.3291, ce_loss: 0.3291., accu: 0.7860, speed: 1.18 step/s\n",
      "global step 2630, epoch: 1, batch: 2630, loss: 0.3434, ce_loss: 0.3434., accu: 0.7862, speed: 1.18 step/s\n",
      "global step 2640, epoch: 1, batch: 2640, loss: 0.4213, ce_loss: 0.4213., accu: 0.7864, speed: 1.18 step/s\n",
      "global step 2650, epoch: 1, batch: 2650, loss: 0.3571, ce_loss: 0.3571., accu: 0.7865, speed: 1.18 step/s\n",
      "global step 2660, epoch: 1, batch: 2660, loss: 0.3327, ce_loss: 0.3327., accu: 0.7867, speed: 1.19 step/s\n",
      "global step 2670, epoch: 1, batch: 2670, loss: 0.2837, ce_loss: 0.2837., accu: 0.7869, speed: 1.21 step/s\n",
      "global step 2680, epoch: 1, batch: 2680, loss: 0.3997, ce_loss: 0.3997., accu: 0.7871, speed: 1.19 step/s\n",
      "global step 2690, epoch: 1, batch: 2690, loss: 0.2429, ce_loss: 0.2429., accu: 0.7873, speed: 1.18 step/s\n",
      "global step 2700, epoch: 1, batch: 2700, loss: 0.3319, ce_loss: 0.3319., accu: 0.7876, speed: 1.18 step/s\n",
      "2022-09-28 13:47:08,779\t[train.py-do_train]-[line:187]-INFO:【global step 2700, epoch: 1, batch: 2700】，loss: 0.3319, ce_loss: 0.3319., accu: 0.7876,\n",
      "global step 2710, epoch: 1, batch: 2710, loss: 0.3980, ce_loss: 0.3980., accu: 0.7878, speed: 1.19 step/s\n",
      "global step 2720, epoch: 1, batch: 2720, loss: 0.2830, ce_loss: 0.2830., accu: 0.7880, speed: 1.19 step/s\n",
      "global step 2730, epoch: 1, batch: 2730, loss: 0.3376, ce_loss: 0.3376., accu: 0.7881, speed: 1.20 step/s\n",
      "global step 2740, epoch: 1, batch: 2740, loss: 0.3695, ce_loss: 0.3695., accu: 0.7883, speed: 1.20 step/s\n",
      "global step 2750, epoch: 1, batch: 2750, loss: 0.3026, ce_loss: 0.3026., accu: 0.7884, speed: 1.19 step/s\n",
      "global step 2760, epoch: 1, batch: 2760, loss: 0.3809, ce_loss: 0.3809., accu: 0.7886, speed: 1.19 step/s\n",
      "global step 2770, epoch: 1, batch: 2770, loss: 0.4166, ce_loss: 0.4166., accu: 0.7888, speed: 1.19 step/s\n",
      "global step 2780, epoch: 1, batch: 2780, loss: 0.3204, ce_loss: 0.3204., accu: 0.7889, speed: 1.18 step/s\n",
      "global step 2790, epoch: 1, batch: 2790, loss: 0.2998, ce_loss: 0.2998., accu: 0.7891, speed: 1.18 step/s\n",
      "global step 2800, epoch: 1, batch: 2800, loss: 0.2626, ce_loss: 0.2626., accu: 0.7893, speed: 1.18 step/s\n",
      "2022-09-28 13:48:32,961\t[train.py-do_train]-[line:187]-INFO:【global step 2800, epoch: 1, batch: 2800】，loss: 0.2626, ce_loss: 0.2626., accu: 0.7893,\n",
      "global step 2810, epoch: 1, batch: 2810, loss: 0.3884, ce_loss: 0.3884., accu: 0.7895, speed: 1.18 step/s\n",
      "global step 2820, epoch: 1, batch: 2820, loss: 0.3766, ce_loss: 0.3766., accu: 0.7897, speed: 1.18 step/s\n",
      "global step 2830, epoch: 1, batch: 2830, loss: 0.3446, ce_loss: 0.3446., accu: 0.7898, speed: 1.19 step/s\n",
      "global step 2840, epoch: 1, batch: 2840, loss: 0.3449, ce_loss: 0.3449., accu: 0.7900, speed: 1.18 step/s\n",
      "global step 2850, epoch: 1, batch: 2850, loss: 0.3663, ce_loss: 0.3663., accu: 0.7901, speed: 1.19 step/s\n",
      "global step 2860, epoch: 1, batch: 2860, loss: 0.3774, ce_loss: 0.3774., accu: 0.7904, speed: 1.19 step/s\n",
      "global step 2870, epoch: 1, batch: 2870, loss: 0.2908, ce_loss: 0.2908., accu: 0.7905, speed: 1.17 step/s\n",
      "global step 2880, epoch: 1, batch: 2880, loss: 0.3964, ce_loss: 0.3964., accu: 0.7907, speed: 1.18 step/s\n",
      "global step 2890, epoch: 1, batch: 2890, loss: 0.3006, ce_loss: 0.3006., accu: 0.7909, speed: 1.18 step/s\n",
      "global step 2900, epoch: 1, batch: 2900, loss: 0.2994, ce_loss: 0.2994., accu: 0.7910, speed: 1.20 step/s\n",
      "2022-09-28 13:49:57,525\t[train.py-do_train]-[line:187]-INFO:【global step 2900, epoch: 1, batch: 2900】，loss: 0.2994, ce_loss: 0.2994., accu: 0.7910,\n",
      "global step 2910, epoch: 1, batch: 2910, loss: 0.3907, ce_loss: 0.3907., accu: 0.7911, speed: 1.18 step/s\n",
      "global step 2920, epoch: 1, batch: 2920, loss: 0.4648, ce_loss: 0.4648., accu: 0.7913, speed: 1.18 step/s\n",
      "global step 2930, epoch: 1, batch: 2930, loss: 0.3593, ce_loss: 0.3593., accu: 0.7914, speed: 1.20 step/s\n",
      "global step 2940, epoch: 1, batch: 2940, loss: 0.3478, ce_loss: 0.3478., accu: 0.7915, speed: 1.19 step/s\n",
      "global step 2950, epoch: 1, batch: 2950, loss: 0.3530, ce_loss: 0.3530., accu: 0.7917, speed: 1.20 step/s\n",
      "global step 2960, epoch: 1, batch: 2960, loss: 0.3431, ce_loss: 0.3431., accu: 0.7918, speed: 1.18 step/s\n",
      "global step 2970, epoch: 1, batch: 2970, loss: 0.2904, ce_loss: 0.2904., accu: 0.7920, speed: 1.19 step/s\n",
      "global step 2980, epoch: 1, batch: 2980, loss: 0.3879, ce_loss: 0.3879., accu: 0.7921, speed: 1.18 step/s\n",
      "global step 2990, epoch: 1, batch: 2990, loss: 0.3341, ce_loss: 0.3341., accu: 0.7924, speed: 1.18 step/s\n",
      "global step 3000, epoch: 1, batch: 3000, loss: 0.3207, ce_loss: 0.3207., accu: 0.7925, speed: 1.20 step/s\n",
      "2022-09-28 13:51:21,751\t[train.py-do_train]-[line:187]-INFO:【global step 3000, epoch: 1, batch: 3000】，loss: 0.3207, ce_loss: 0.3207., accu: 0.7925,\n",
      "global step 3010, epoch: 1, batch: 3010, loss: 0.3563, ce_loss: 0.3563., accu: 0.7927, speed: 1.19 step/s\n",
      "global step 3020, epoch: 1, batch: 3020, loss: 0.3204, ce_loss: 0.3204., accu: 0.7928, speed: 1.18 step/s\n",
      "global step 3030, epoch: 1, batch: 3030, loss: 0.4628, ce_loss: 0.4628., accu: 0.7929, speed: 1.19 step/s\n",
      "global step 3040, epoch: 1, batch: 3040, loss: 0.3123, ce_loss: 0.3123., accu: 0.7931, speed: 1.18 step/s\n",
      "global step 3050, epoch: 1, batch: 3050, loss: 0.3706, ce_loss: 0.3706., accu: 0.7932, speed: 1.19 step/s\n",
      "global step 3060, epoch: 1, batch: 3060, loss: 0.3292, ce_loss: 0.3292., accu: 0.7934, speed: 1.18 step/s\n",
      "global step 3070, epoch: 1, batch: 3070, loss: 0.3191, ce_loss: 0.3191., accu: 0.7936, speed: 1.18 step/s\n",
      "global step 3080, epoch: 1, batch: 3080, loss: 0.4208, ce_loss: 0.4208., accu: 0.7937, speed: 1.19 step/s\n",
      "global step 3090, epoch: 1, batch: 3090, loss: 0.3409, ce_loss: 0.3409., accu: 0.7939, speed: 1.19 step/s\n",
      "global step 3100, epoch: 1, batch: 3100, loss: 0.3225, ce_loss: 0.3225., accu: 0.7940, speed: 1.18 step/s\n",
      "2022-09-28 13:52:46,149\t[train.py-do_train]-[line:187]-INFO:【global step 3100, epoch: 1, batch: 3100】，loss: 0.3225, ce_loss: 0.3225., accu: 0.7940,\n",
      "global step 3110, epoch: 1, batch: 3110, loss: 0.3301, ce_loss: 0.3301., accu: 0.7942, speed: 1.18 step/s\n",
      "global step 3120, epoch: 1, batch: 3120, loss: 0.3944, ce_loss: 0.3944., accu: 0.7944, speed: 1.19 step/s\n",
      "global step 3130, epoch: 1, batch: 3130, loss: 0.2491, ce_loss: 0.2491., accu: 0.7946, speed: 1.18 step/s\n",
      "global step 3140, epoch: 1, batch: 3140, loss: 0.2444, ce_loss: 0.2444., accu: 0.7948, speed: 1.20 step/s\n",
      "global step 3150, epoch: 1, batch: 3150, loss: 0.2873, ce_loss: 0.2873., accu: 0.7949, speed: 1.18 step/s\n",
      "global step 3160, epoch: 1, batch: 3160, loss: 0.3647, ce_loss: 0.3647., accu: 0.7950, speed: 1.20 step/s\n",
      "global step 3170, epoch: 1, batch: 3170, loss: 0.3344, ce_loss: 0.3344., accu: 0.7952, speed: 1.21 step/s\n",
      "global step 3180, epoch: 1, batch: 3180, loss: 0.3116, ce_loss: 0.3116., accu: 0.7953, speed: 1.20 step/s\n",
      "global step 3190, epoch: 1, batch: 3190, loss: 0.3187, ce_loss: 0.3187., accu: 0.7954, speed: 1.19 step/s\n",
      "global step 3200, epoch: 1, batch: 3200, loss: 0.3821, ce_loss: 0.3821., accu: 0.7955, speed: 1.18 step/s\n",
      "2022-09-28 13:54:10,160\t[train.py-do_train]-[line:187]-INFO:【global step 3200, epoch: 1, batch: 3200】，loss: 0.3821, ce_loss: 0.3821., accu: 0.7955,\n",
      "global step 3210, epoch: 1, batch: 3210, loss: 0.3380, ce_loss: 0.3380., accu: 0.7957, speed: 1.18 step/s\n",
      "global step 3220, epoch: 1, batch: 3220, loss: 0.3310, ce_loss: 0.3310., accu: 0.7958, speed: 1.19 step/s\n",
      "global step 3230, epoch: 1, batch: 3230, loss: 0.2880, ce_loss: 0.2880., accu: 0.7959, speed: 1.18 step/s\n",
      "global step 3240, epoch: 1, batch: 3240, loss: 0.2761, ce_loss: 0.2761., accu: 0.7961, speed: 1.18 step/s\n",
      "global step 3250, epoch: 1, batch: 3250, loss: 0.3042, ce_loss: 0.3042., accu: 0.7963, speed: 1.19 step/s\n",
      "global step 3260, epoch: 1, batch: 3260, loss: 0.2776, ce_loss: 0.2776., accu: 0.7964, speed: 1.19 step/s\n",
      "global step 3270, epoch: 1, batch: 3270, loss: 0.3542, ce_loss: 0.3542., accu: 0.7965, speed: 1.18 step/s\n",
      "global step 3280, epoch: 1, batch: 3280, loss: 0.3315, ce_loss: 0.3315., accu: 0.7967, speed: 1.19 step/s\n",
      "global step 3290, epoch: 1, batch: 3290, loss: 0.3020, ce_loss: 0.3020., accu: 0.7968, speed: 1.18 step/s\n",
      "global step 3300, epoch: 1, batch: 3300, loss: 0.3250, ce_loss: 0.3250., accu: 0.7969, speed: 1.19 step/s\n",
      "2022-09-28 13:55:34,596\t[train.py-do_train]-[line:187]-INFO:【global step 3300, epoch: 1, batch: 3300】，loss: 0.3250, ce_loss: 0.3250., accu: 0.7969,\n",
      "global step 3310, epoch: 1, batch: 3310, loss: 0.3386, ce_loss: 0.3386., accu: 0.7970, speed: 1.19 step/s\n",
      "global step 3320, epoch: 1, batch: 3320, loss: 0.3570, ce_loss: 0.3570., accu: 0.7972, speed: 1.18 step/s\n",
      "global step 3330, epoch: 1, batch: 3330, loss: 0.3406, ce_loss: 0.3406., accu: 0.7973, speed: 1.19 step/s\n",
      "global step 3340, epoch: 1, batch: 3340, loss: 0.3387, ce_loss: 0.3387., accu: 0.7974, speed: 1.18 step/s\n",
      "global step 3350, epoch: 1, batch: 3350, loss: 0.3373, ce_loss: 0.3373., accu: 0.7975, speed: 1.18 step/s\n",
      "global step 3360, epoch: 1, batch: 3360, loss: 0.2997, ce_loss: 0.2997., accu: 0.7977, speed: 1.21 step/s\n",
      "global step 3370, epoch: 1, batch: 3370, loss: 0.3099, ce_loss: 0.3099., accu: 0.7979, speed: 1.20 step/s\n",
      "global step 3380, epoch: 1, batch: 3380, loss: 0.3516, ce_loss: 0.3516., accu: 0.7981, speed: 1.19 step/s\n",
      "global step 3390, epoch: 1, batch: 3390, loss: 0.2871, ce_loss: 0.2871., accu: 0.7982, speed: 1.18 step/s\n",
      "global step 3400, epoch: 1, batch: 3400, loss: 0.4007, ce_loss: 0.4007., accu: 0.7983, speed: 1.20 step/s\n",
      "2022-09-28 13:56:58,734\t[train.py-do_train]-[line:187]-INFO:【global step 3400, epoch: 1, batch: 3400】，loss: 0.4007, ce_loss: 0.4007., accu: 0.7983,\n",
      "global step 3410, epoch: 1, batch: 3410, loss: 0.4098, ce_loss: 0.4098., accu: 0.7984, speed: 1.18 step/s\n",
      "global step 3420, epoch: 1, batch: 3420, loss: 0.2927, ce_loss: 0.2927., accu: 0.7986, speed: 1.19 step/s\n",
      "global step 3430, epoch: 1, batch: 3430, loss: 0.4246, ce_loss: 0.4246., accu: 0.7987, speed: 1.19 step/s\n",
      "global step 3440, epoch: 1, batch: 3440, loss: 0.3137, ce_loss: 0.3137., accu: 0.7988, speed: 1.18 step/s\n",
      "global step 3450, epoch: 1, batch: 3450, loss: 0.3196, ce_loss: 0.3196., accu: 0.7989, speed: 1.18 step/s\n",
      "global step 3460, epoch: 1, batch: 3460, loss: 0.3627, ce_loss: 0.3627., accu: 0.7990, speed: 1.20 step/s\n",
      "global step 3470, epoch: 1, batch: 3470, loss: 0.3291, ce_loss: 0.3291., accu: 0.7992, speed: 1.20 step/s\n",
      "global step 3480, epoch: 1, batch: 3480, loss: 0.3064, ce_loss: 0.3064., accu: 0.7993, speed: 1.18 step/s\n",
      "global step 3490, epoch: 1, batch: 3490, loss: 0.3253, ce_loss: 0.3253., accu: 0.7995, speed: 1.18 step/s\n",
      "global step 3500, epoch: 1, batch: 3500, loss: 0.3942, ce_loss: 0.3942., accu: 0.7996, speed: 1.18 step/s\n",
      "2022-09-28 13:58:23,015\t[train.py-do_train]-[line:187]-INFO:【global step 3500, epoch: 1, batch: 3500】，loss: 0.3942, ce_loss: 0.3942., accu: 0.7996,\n",
      "global step 3510, epoch: 1, batch: 3510, loss: 0.3764, ce_loss: 0.3764., accu: 0.7997, speed: 1.18 step/s\n",
      "global step 3520, epoch: 1, batch: 3520, loss: 0.2760, ce_loss: 0.2760., accu: 0.7999, speed: 1.19 step/s\n",
      "global step 3530, epoch: 1, batch: 3530, loss: 0.3144, ce_loss: 0.3144., accu: 0.8000, speed: 1.19 step/s\n",
      "global step 3540, epoch: 1, batch: 3540, loss: 0.2949, ce_loss: 0.2949., accu: 0.8000, speed: 1.18 step/s\n",
      "global step 3550, epoch: 1, batch: 3550, loss: 0.3169, ce_loss: 0.3169., accu: 0.8001, speed: 1.18 step/s\n",
      "global step 3560, epoch: 1, batch: 3560, loss: 0.3476, ce_loss: 0.3476., accu: 0.8003, speed: 1.20 step/s\n",
      "global step 3570, epoch: 1, batch: 3570, loss: 0.3508, ce_loss: 0.3508., accu: 0.8003, speed: 1.18 step/s\n",
      "global step 3580, epoch: 1, batch: 3580, loss: 0.3855, ce_loss: 0.3855., accu: 0.8005, speed: 1.18 step/s\n",
      "global step 3590, epoch: 1, batch: 3590, loss: 0.3191, ce_loss: 0.3191., accu: 0.8006, speed: 1.18 step/s\n",
      "global step 3600, epoch: 1, batch: 3600, loss: 0.3642, ce_loss: 0.3642., accu: 0.8008, speed: 1.18 step/s\n",
      "2022-09-28 13:59:47,411\t[train.py-do_train]-[line:187]-INFO:【global step 3600, epoch: 1, batch: 3600】，loss: 0.3642, ce_loss: 0.3642., accu: 0.8008,\n",
      "global step 3610, epoch: 1, batch: 3610, loss: 0.3162, ce_loss: 0.3162., accu: 0.8009, speed: 1.18 step/s\n",
      "global step 3620, epoch: 1, batch: 3620, loss: 0.4373, ce_loss: 0.4373., accu: 0.8011, speed: 1.18 step/s\n",
      "global step 3630, epoch: 1, batch: 3630, loss: 0.3280, ce_loss: 0.3280., accu: 0.8012, speed: 1.18 step/s\n",
      "global step 3640, epoch: 1, batch: 3640, loss: 0.2807, ce_loss: 0.2807., accu: 0.8014, speed: 1.18 step/s\n",
      "global step 3650, epoch: 1, batch: 3650, loss: 0.2860, ce_loss: 0.2860., accu: 0.8015, speed: 1.19 step/s\n",
      "global step 3660, epoch: 1, batch: 3660, loss: 0.3457, ce_loss: 0.3457., accu: 0.8016, speed: 1.19 step/s\n",
      "global step 3670, epoch: 1, batch: 3670, loss: 0.2815, ce_loss: 0.2815., accu: 0.8017, speed: 1.18 step/s\n",
      "global step 3680, epoch: 1, batch: 3680, loss: 0.3696, ce_loss: 0.3696., accu: 0.8019, speed: 1.18 step/s\n",
      "global step 3690, epoch: 1, batch: 3690, loss: 0.2502, ce_loss: 0.2502., accu: 0.8020, speed: 1.19 step/s\n",
      "global step 3700, epoch: 1, batch: 3700, loss: 0.3274, ce_loss: 0.3274., accu: 0.8021, speed: 1.19 step/s\n",
      "2022-09-28 14:01:11,842\t[train.py-do_train]-[line:187]-INFO:【global step 3700, epoch: 1, batch: 3700】，loss: 0.3274, ce_loss: 0.3274., accu: 0.8021,\n",
      "global step 3710, epoch: 1, batch: 3710, loss: 0.4044, ce_loss: 0.4044., accu: 0.8022, speed: 1.18 step/s\n",
      "global step 3720, epoch: 1, batch: 3720, loss: 0.2731, ce_loss: 0.2731., accu: 0.8023, speed: 1.21 step/s\n",
      "global step 3730, epoch: 1, batch: 3730, loss: 0.2722, ce_loss: 0.2722., accu: 0.8025, speed: 1.21 step/s\n",
      "global step 3740, epoch: 1, batch: 3740, loss: 0.3897, ce_loss: 0.3897., accu: 0.8026, speed: 1.18 step/s\n",
      "global step 3750, epoch: 1, batch: 3750, loss: 0.3307, ce_loss: 0.3307., accu: 0.8027, speed: 1.19 step/s\n",
      "global step 3760, epoch: 1, batch: 3760, loss: 0.3634, ce_loss: 0.3634., accu: 0.8028, speed: 1.18 step/s\n",
      "global step 3770, epoch: 1, batch: 3770, loss: 0.3821, ce_loss: 0.3821., accu: 0.8029, speed: 1.18 step/s\n",
      "global step 3780, epoch: 1, batch: 3780, loss: 0.3072, ce_loss: 0.3072., accu: 0.8030, speed: 1.18 step/s\n",
      "global step 3790, epoch: 1, batch: 3790, loss: 0.2824, ce_loss: 0.2824., accu: 0.8031, speed: 1.19 step/s\n",
      "global step 3800, epoch: 1, batch: 3800, loss: 0.3553, ce_loss: 0.3553., accu: 0.8032, speed: 1.18 step/s\n",
      "2022-09-28 14:02:35,901\t[train.py-do_train]-[line:187]-INFO:【global step 3800, epoch: 1, batch: 3800】，loss: 0.3553, ce_loss: 0.3553., accu: 0.8032,\n",
      "global step 3810, epoch: 1, batch: 3810, loss: 0.4097, ce_loss: 0.4097., accu: 0.8033, speed: 1.19 step/s\n",
      "global step 3820, epoch: 1, batch: 3820, loss: 0.3013, ce_loss: 0.3013., accu: 0.8034, speed: 1.19 step/s\n",
      "global step 3830, epoch: 1, batch: 3830, loss: 0.3305, ce_loss: 0.3305., accu: 0.8035, speed: 1.20 step/s\n",
      "global step 3840, epoch: 1, batch: 3840, loss: 0.1874, ce_loss: 0.1874., accu: 0.8037, speed: 1.18 step/s\n",
      "global step 3850, epoch: 1, batch: 3850, loss: 0.3696, ce_loss: 0.3696., accu: 0.8037, speed: 1.19 step/s\n",
      "global step 3860, epoch: 1, batch: 3860, loss: 0.3312, ce_loss: 0.3312., accu: 0.8038, speed: 1.18 step/s\n",
      "global step 3870, epoch: 1, batch: 3870, loss: 0.3486, ce_loss: 0.3486., accu: 0.8039, speed: 1.19 step/s\n",
      "global step 3880, epoch: 1, batch: 3880, loss: 0.3438, ce_loss: 0.3438., accu: 0.8040, speed: 1.18 step/s\n",
      "global step 3890, epoch: 1, batch: 3890, loss: 0.2896, ce_loss: 0.2896., accu: 0.8041, speed: 1.18 step/s\n",
      "global step 3900, epoch: 1, batch: 3900, loss: 0.3164, ce_loss: 0.3164., accu: 0.8042, speed: 1.20 step/s\n",
      "2022-09-28 14:04:00,099\t[train.py-do_train]-[line:187]-INFO:【global step 3900, epoch: 1, batch: 3900】，loss: 0.3164, ce_loss: 0.3164., accu: 0.8042,\n",
      "global step 3910, epoch: 1, batch: 3910, loss: 0.3503, ce_loss: 0.3503., accu: 0.8043, speed: 1.20 step/s\n",
      "global step 3920, epoch: 1, batch: 3920, loss: 0.3163, ce_loss: 0.3163., accu: 0.8045, speed: 1.18 step/s\n",
      "global step 3930, epoch: 1, batch: 3930, loss: 0.3827, ce_loss: 0.3827., accu: 0.8046, speed: 1.18 step/s\n",
      "global step 3940, epoch: 1, batch: 3940, loss: 0.2687, ce_loss: 0.2687., accu: 0.8047, speed: 1.19 step/s\n",
      "global step 3950, epoch: 1, batch: 3950, loss: 0.2936, ce_loss: 0.2936., accu: 0.8048, speed: 1.18 step/s\n",
      "global step 3960, epoch: 1, batch: 3960, loss: 0.3045, ce_loss: 0.3045., accu: 0.8050, speed: 1.19 step/s\n",
      "global step 3970, epoch: 1, batch: 3970, loss: 0.3263, ce_loss: 0.3263., accu: 0.8051, speed: 1.19 step/s\n",
      "global step 3980, epoch: 1, batch: 3980, loss: 0.3374, ce_loss: 0.3374., accu: 0.8052, speed: 1.20 step/s\n",
      "global step 3990, epoch: 1, batch: 3990, loss: 0.3684, ce_loss: 0.3684., accu: 0.8053, speed: 1.19 step/s\n",
      "global step 4000, epoch: 1, batch: 4000, loss: 0.3978, ce_loss: 0.3978., accu: 0.8054, speed: 1.18 step/s\n",
      "2022-09-28 14:05:24,306\t[train.py-do_train]-[line:187]-INFO:【global step 4000, epoch: 1, batch: 4000】，loss: 0.3978, ce_loss: 0.3978., accu: 0.8054,\n",
      "global step 4010, epoch: 1, batch: 4010, loss: 0.3304, ce_loss: 0.3304., accu: 0.8055, speed: 1.18 step/s\n",
      "global step 4020, epoch: 1, batch: 4020, loss: 0.2847, ce_loss: 0.2847., accu: 0.8056, speed: 1.18 step/s\n",
      "global step 4030, epoch: 1, batch: 4030, loss: 0.3260, ce_loss: 0.3260., accu: 0.8057, speed: 1.18 step/s\n",
      "global step 4040, epoch: 1, batch: 4040, loss: 0.2591, ce_loss: 0.2591., accu: 0.8058, speed: 1.18 step/s\n",
      "global step 4050, epoch: 1, batch: 4050, loss: 0.4503, ce_loss: 0.4503., accu: 0.8059, speed: 1.18 step/s\n",
      "global step 4060, epoch: 1, batch: 4060, loss: 0.3345, ce_loss: 0.3345., accu: 0.8060, speed: 1.17 step/s\n",
      "global step 4070, epoch: 1, batch: 4070, loss: 0.2932, ce_loss: 0.2932., accu: 0.8061, speed: 1.18 step/s\n",
      "global step 4080, epoch: 1, batch: 4080, loss: 0.3286, ce_loss: 0.3286., accu: 0.8062, speed: 1.19 step/s\n",
      "global step 4090, epoch: 1, batch: 4090, loss: 0.4557, ce_loss: 0.4557., accu: 0.8062, speed: 1.18 step/s\n",
      "global step 4100, epoch: 1, batch: 4100, loss: 0.3459, ce_loss: 0.3459., accu: 0.8063, speed: 1.19 step/s\n",
      "2022-09-28 14:06:48,896\t[train.py-do_train]-[line:187]-INFO:【global step 4100, epoch: 1, batch: 4100】，loss: 0.3459, ce_loss: 0.3459., accu: 0.8063,\n",
      "global step 4110, epoch: 1, batch: 4110, loss: 0.3640, ce_loss: 0.3640., accu: 0.8064, speed: 1.18 step/s\n",
      "global step 4120, epoch: 1, batch: 4120, loss: 0.3513, ce_loss: 0.3513., accu: 0.8065, speed: 1.18 step/s\n",
      "global step 4130, epoch: 1, batch: 4130, loss: 0.3065, ce_loss: 0.3065., accu: 0.8066, speed: 1.19 step/s\n",
      "global step 4140, epoch: 1, batch: 4140, loss: 0.3758, ce_loss: 0.3758., accu: 0.8067, speed: 1.21 step/s\n",
      "global step 4150, epoch: 1, batch: 4150, loss: 0.3308, ce_loss: 0.3308., accu: 0.8068, speed: 1.19 step/s\n",
      "global step 4160, epoch: 1, batch: 4160, loss: 0.3025, ce_loss: 0.3025., accu: 0.8069, speed: 1.18 step/s\n",
      "global step 4170, epoch: 1, batch: 4170, loss: 0.3552, ce_loss: 0.3552., accu: 0.8071, speed: 1.18 step/s\n",
      "global step 4180, epoch: 1, batch: 4180, loss: 0.3050, ce_loss: 0.3050., accu: 0.8072, speed: 1.18 step/s\n",
      "global step 4190, epoch: 1, batch: 4190, loss: 0.3791, ce_loss: 0.3791., accu: 0.8073, speed: 1.19 step/s\n",
      "global step 4200, epoch: 1, batch: 4200, loss: 0.3974, ce_loss: 0.3974., accu: 0.8074, speed: 1.19 step/s\n",
      "2022-09-28 14:08:13,135\t[train.py-do_train]-[line:187]-INFO:【global step 4200, epoch: 1, batch: 4200】，loss: 0.3974, ce_loss: 0.3974., accu: 0.8074,\n",
      "global step 4210, epoch: 1, batch: 4210, loss: 0.2620, ce_loss: 0.2620., accu: 0.8075, speed: 1.19 step/s\n",
      "global step 4220, epoch: 1, batch: 4220, loss: 0.3300, ce_loss: 0.3300., accu: 0.8076, speed: 1.19 step/s\n",
      "global step 4230, epoch: 1, batch: 4230, loss: 0.3463, ce_loss: 0.3463., accu: 0.8076, speed: 1.18 step/s\n",
      "global step 4240, epoch: 1, batch: 4240, loss: 0.2708, ce_loss: 0.2708., accu: 0.8078, speed: 1.18 step/s\n",
      "global step 4250, epoch: 1, batch: 4250, loss: 0.2923, ce_loss: 0.2923., accu: 0.8079, speed: 1.21 step/s\n",
      "global step 4260, epoch: 1, batch: 4260, loss: 0.3835, ce_loss: 0.3835., accu: 0.8080, speed: 1.20 step/s\n",
      "global step 4270, epoch: 1, batch: 4270, loss: 0.3087, ce_loss: 0.3087., accu: 0.8081, speed: 1.18 step/s\n",
      "global step 4280, epoch: 1, batch: 4280, loss: 0.2283, ce_loss: 0.2283., accu: 0.8082, speed: 1.19 step/s\n",
      "global step 4290, epoch: 1, batch: 4290, loss: 0.3413, ce_loss: 0.3413., accu: 0.8083, speed: 1.19 step/s\n",
      "global step 4300, epoch: 1, batch: 4300, loss: 0.3092, ce_loss: 0.3092., accu: 0.8083, speed: 1.20 step/s\n",
      "2022-09-28 14:09:37,110\t[train.py-do_train]-[line:187]-INFO:【global step 4300, epoch: 1, batch: 4300】，loss: 0.3092, ce_loss: 0.3092., accu: 0.8083,\n",
      "global step 4310, epoch: 1, batch: 4310, loss: 0.3755, ce_loss: 0.3755., accu: 0.8085, speed: 1.19 step/s\n",
      "global step 4320, epoch: 1, batch: 4320, loss: 0.3622, ce_loss: 0.3622., accu: 0.8086, speed: 1.18 step/s\n",
      "global step 4330, epoch: 1, batch: 4330, loss: 0.4088, ce_loss: 0.4088., accu: 0.8087, speed: 1.18 step/s\n",
      "global step 4340, epoch: 1, batch: 4340, loss: 0.3468, ce_loss: 0.3468., accu: 0.8087, speed: 1.17 step/s\n",
      "global step 4350, epoch: 1, batch: 4350, loss: 0.3105, ce_loss: 0.3105., accu: 0.8088, speed: 1.17 step/s\n",
      "global step 4360, epoch: 1, batch: 4360, loss: 0.3646, ce_loss: 0.3646., accu: 0.8089, speed: 1.19 step/s\n",
      "global step 4370, epoch: 1, batch: 4370, loss: 0.2233, ce_loss: 0.2233., accu: 0.8090, speed: 1.18 step/s\n",
      "global step 4380, epoch: 1, batch: 4380, loss: 0.3179, ce_loss: 0.3179., accu: 0.8091, speed: 1.18 step/s\n",
      "global step 4390, epoch: 1, batch: 4390, loss: 0.3348, ce_loss: 0.3348., accu: 0.8092, speed: 1.19 step/s\n",
      "global step 4400, epoch: 1, batch: 4400, loss: 0.2411, ce_loss: 0.2411., accu: 0.8092, speed: 1.18 step/s\n",
      "2022-09-28 14:11:01,784\t[train.py-do_train]-[line:187]-INFO:【global step 4400, epoch: 1, batch: 4400】，loss: 0.2411, ce_loss: 0.2411., accu: 0.8092,\n",
      "global step 4410, epoch: 1, batch: 4410, loss: 0.3282, ce_loss: 0.3282., accu: 0.8093, speed: 1.19 step/s\n",
      "global step 4420, epoch: 1, batch: 4420, loss: 0.3304, ce_loss: 0.3304., accu: 0.8093, speed: 1.18 step/s\n",
      "global step 4430, epoch: 1, batch: 4430, loss: 0.3308, ce_loss: 0.3308., accu: 0.8094, speed: 1.22 step/s\n",
      "global step 4440, epoch: 1, batch: 4440, loss: 0.2641, ce_loss: 0.2641., accu: 0.8096, speed: 1.19 step/s\n",
      "global step 4450, epoch: 1, batch: 4450, loss: 0.3509, ce_loss: 0.3509., accu: 0.8097, speed: 1.20 step/s\n",
      "global step 4460, epoch: 1, batch: 4460, loss: 0.3117, ce_loss: 0.3117., accu: 0.8098, speed: 1.19 step/s\n",
      "global step 4470, epoch: 1, batch: 4470, loss: 0.3531, ce_loss: 0.3531., accu: 0.8099, speed: 1.23 step/s\n",
      "global step 4480, epoch: 1, batch: 4480, loss: 0.4013, ce_loss: 0.4013., accu: 0.8099, speed: 1.18 step/s\n",
      "global step 4490, epoch: 1, batch: 4490, loss: 0.3315, ce_loss: 0.3315., accu: 0.8100, speed: 1.20 step/s\n",
      "global step 4500, epoch: 1, batch: 4500, loss: 0.2764, ce_loss: 0.2764., accu: 0.8101, speed: 1.20 step/s\n",
      "2022-09-28 14:12:25,359\t[train.py-do_train]-[line:187]-INFO:【global step 4500, epoch: 1, batch: 4500】，loss: 0.2764, ce_loss: 0.2764., accu: 0.8101,\n",
      "global step 4510, epoch: 1, batch: 4510, loss: 0.3487, ce_loss: 0.3487., accu: 0.8102, speed: 1.18 step/s\n",
      "global step 4520, epoch: 1, batch: 4520, loss: 0.3024, ce_loss: 0.3024., accu: 0.8103, speed: 1.21 step/s\n",
      "global step 4530, epoch: 1, batch: 4530, loss: 0.2566, ce_loss: 0.2566., accu: 0.8104, speed: 1.18 step/s\n",
      "global step 4540, epoch: 1, batch: 4540, loss: 0.3231, ce_loss: 0.3231., accu: 0.8105, speed: 1.19 step/s\n",
      "global step 4550, epoch: 1, batch: 4550, loss: 0.3223, ce_loss: 0.3223., accu: 0.8106, speed: 1.22 step/s\n",
      "global step 4560, epoch: 1, batch: 4560, loss: 0.3060, ce_loss: 0.3060., accu: 0.8107, speed: 1.18 step/s\n",
      "global step 4570, epoch: 1, batch: 4570, loss: 0.3841, ce_loss: 0.3841., accu: 0.8108, speed: 1.19 step/s\n",
      "global step 4580, epoch: 1, batch: 4580, loss: 0.4067, ce_loss: 0.4067., accu: 0.8108, speed: 1.19 step/s\n",
      "global step 4590, epoch: 1, batch: 4590, loss: 0.2842, ce_loss: 0.2842., accu: 0.8110, speed: 1.18 step/s\n",
      "global step 4600, epoch: 1, batch: 4600, loss: 0.3514, ce_loss: 0.3514., accu: 0.8111, speed: 1.18 step/s\n",
      "2022-09-28 14:13:49,398\t[train.py-do_train]-[line:187]-INFO:【global step 4600, epoch: 1, batch: 4600】，loss: 0.3514, ce_loss: 0.3514., accu: 0.8111,\n",
      "global step 4610, epoch: 1, batch: 4610, loss: 0.3664, ce_loss: 0.3664., accu: 0.8111, speed: 1.18 step/s\n",
      "global step 4620, epoch: 1, batch: 4620, loss: 0.4298, ce_loss: 0.4298., accu: 0.8112, speed: 1.19 step/s\n",
      "global step 4630, epoch: 1, batch: 4630, loss: 0.3755, ce_loss: 0.3755., accu: 0.8113, speed: 1.19 step/s\n",
      "global step 4640, epoch: 1, batch: 4640, loss: 0.3565, ce_loss: 0.3565., accu: 0.8113, speed: 1.18 step/s\n",
      "global step 4650, epoch: 1, batch: 4650, loss: 0.3618, ce_loss: 0.3618., accu: 0.8114, speed: 1.18 step/s\n",
      "global step 4660, epoch: 1, batch: 4660, loss: 0.3306, ce_loss: 0.3306., accu: 0.8115, speed: 1.18 step/s\n",
      "global step 4670, epoch: 1, batch: 4670, loss: 0.3561, ce_loss: 0.3561., accu: 0.8116, speed: 1.18 step/s\n",
      "global step 4680, epoch: 1, batch: 4680, loss: 0.2672, ce_loss: 0.2672., accu: 0.8117, speed: 1.18 step/s\n",
      "global step 4690, epoch: 1, batch: 4690, loss: 0.2871, ce_loss: 0.2871., accu: 0.8118, speed: 1.18 step/s\n",
      "global step 4700, epoch: 1, batch: 4700, loss: 0.3240, ce_loss: 0.3240., accu: 0.8119, speed: 1.18 step/s\n",
      "2022-09-28 14:15:14,016\t[train.py-do_train]-[line:187]-INFO:【global step 4700, epoch: 1, batch: 4700】，loss: 0.3240, ce_loss: 0.3240., accu: 0.8119,\n",
      " 20%|███████▊                               | 1/5 [1:06:01<4:24:06, 3961.61s/it]global step 4710, epoch: 2, batch: 5, loss: 0.4369, ce_loss: 0.4369., accu: 0.8120, speed: 1.25 step/s\n",
      "global step 4720, epoch: 2, batch: 15, loss: 0.3548, ce_loss: 0.3548., accu: 0.8121, speed: 1.20 step/s\n",
      "global step 4730, epoch: 2, batch: 25, loss: 0.3076, ce_loss: 0.3076., accu: 0.8122, speed: 1.20 step/s\n",
      "global step 4740, epoch: 2, batch: 35, loss: 0.3416, ce_loss: 0.3416., accu: 0.8123, speed: 1.18 step/s\n",
      "global step 4750, epoch: 2, batch: 45, loss: 0.3263, ce_loss: 0.3263., accu: 0.8123, speed: 1.18 step/s\n",
      "global step 4760, epoch: 2, batch: 55, loss: 0.3252, ce_loss: 0.3252., accu: 0.8124, speed: 1.18 step/s\n",
      "global step 4770, epoch: 2, batch: 65, loss: 0.2202, ce_loss: 0.2202., accu: 0.8125, speed: 1.18 step/s\n",
      "global step 4780, epoch: 2, batch: 75, loss: 0.3485, ce_loss: 0.3485., accu: 0.8126, speed: 1.18 step/s\n",
      "global step 4790, epoch: 2, batch: 85, loss: 0.2818, ce_loss: 0.2818., accu: 0.8127, speed: 1.18 step/s\n",
      "global step 4800, epoch: 2, batch: 95, loss: 0.2782, ce_loss: 0.2782., accu: 0.8128, speed: 1.18 step/s\n",
      "2022-09-28 14:16:38,060\t[train.py-do_train]-[line:187]-INFO:【global step 4800, epoch: 2, batch: 95】，loss: 0.2782, ce_loss: 0.2782., accu: 0.8128,\n",
      "global step 4810, epoch: 2, batch: 105, loss: 0.3228, ce_loss: 0.3228., accu: 0.8129, speed: 1.18 step/s\n",
      "global step 4820, epoch: 2, batch: 115, loss: 0.3279, ce_loss: 0.3279., accu: 0.8130, speed: 1.19 step/s\n",
      "global step 4830, epoch: 2, batch: 125, loss: 0.3883, ce_loss: 0.3883., accu: 0.8131, speed: 1.24 step/s\n",
      "global step 4840, epoch: 2, batch: 135, loss: 0.3843, ce_loss: 0.3843., accu: 0.8132, speed: 1.20 step/s\n",
      "global step 4850, epoch: 2, batch: 145, loss: 0.2797, ce_loss: 0.2797., accu: 0.8133, speed: 1.21 step/s\n",
      "global step 4860, epoch: 2, batch: 155, loss: 0.3400, ce_loss: 0.3400., accu: 0.8134, speed: 1.19 step/s\n",
      "global step 4870, epoch: 2, batch: 165, loss: 0.3392, ce_loss: 0.3392., accu: 0.8135, speed: 1.18 step/s\n",
      "global step 4880, epoch: 2, batch: 175, loss: 0.2935, ce_loss: 0.2935., accu: 0.8136, speed: 1.19 step/s\n",
      "global step 4890, epoch: 2, batch: 185, loss: 0.3196, ce_loss: 0.3196., accu: 0.8138, speed: 1.19 step/s\n",
      "global step 4900, epoch: 2, batch: 195, loss: 0.2615, ce_loss: 0.2615., accu: 0.8139, speed: 1.19 step/s\n",
      "2022-09-28 14:18:01,837\t[train.py-do_train]-[line:187]-INFO:【global step 4900, epoch: 2, batch: 195】，loss: 0.2615, ce_loss: 0.2615., accu: 0.8139,\n",
      "global step 4910, epoch: 2, batch: 205, loss: 0.2513, ce_loss: 0.2513., accu: 0.8140, speed: 1.18 step/s\n",
      "global step 4920, epoch: 2, batch: 215, loss: 0.2626, ce_loss: 0.2626., accu: 0.8140, speed: 1.18 step/s\n",
      "global step 4930, epoch: 2, batch: 225, loss: 0.2652, ce_loss: 0.2652., accu: 0.8142, speed: 1.18 step/s\n",
      "global step 4940, epoch: 2, batch: 235, loss: 0.2960, ce_loss: 0.2960., accu: 0.8143, speed: 1.19 step/s\n",
      "global step 4950, epoch: 2, batch: 245, loss: 0.3062, ce_loss: 0.3062., accu: 0.8144, speed: 1.18 step/s\n",
      "global step 4960, epoch: 2, batch: 255, loss: 0.2586, ce_loss: 0.2586., accu: 0.8145, speed: 1.18 step/s\n",
      "global step 4970, epoch: 2, batch: 265, loss: 0.2555, ce_loss: 0.2555., accu: 0.8146, speed: 1.18 step/s\n",
      "global step 4980, epoch: 2, batch: 275, loss: 0.2275, ce_loss: 0.2275., accu: 0.8147, speed: 1.19 step/s\n",
      "global step 4990, epoch: 2, batch: 285, loss: 0.3286, ce_loss: 0.3286., accu: 0.8148, speed: 1.18 step/s\n",
      "global step 5000, epoch: 2, batch: 295, loss: 0.3550, ce_loss: 0.3550., accu: 0.8149, speed: 1.18 step/s\n",
      "2022-09-28 14:19:26,507\t[train.py-do_train]-[line:187]-INFO:【global step 5000, epoch: 2, batch: 295】，loss: 0.3550, ce_loss: 0.3550., accu: 0.8149,\n",
      "global step 5010, epoch: 2, batch: 305, loss: 0.3362, ce_loss: 0.3362., accu: 0.8150, speed: 1.18 step/s\n",
      "global step 5020, epoch: 2, batch: 315, loss: 0.3131, ce_loss: 0.3131., accu: 0.8151, speed: 1.18 step/s\n",
      "global step 5030, epoch: 2, batch: 325, loss: 0.4017, ce_loss: 0.4017., accu: 0.8152, speed: 1.19 step/s\n",
      "global step 5040, epoch: 2, batch: 335, loss: 0.2407, ce_loss: 0.2407., accu: 0.8153, speed: 1.18 step/s\n",
      "global step 5050, epoch: 2, batch: 345, loss: 0.3487, ce_loss: 0.3487., accu: 0.8154, speed: 1.19 step/s\n",
      "global step 5060, epoch: 2, batch: 355, loss: 0.3150, ce_loss: 0.3150., accu: 0.8155, speed: 1.18 step/s\n",
      "global step 5070, epoch: 2, batch: 365, loss: 0.2839, ce_loss: 0.2839., accu: 0.8156, speed: 1.19 step/s\n",
      "global step 5080, epoch: 2, batch: 375, loss: 0.2998, ce_loss: 0.2998., accu: 0.8157, speed: 1.18 step/s\n",
      "global step 5090, epoch: 2, batch: 385, loss: 0.2476, ce_loss: 0.2476., accu: 0.8158, speed: 1.20 step/s\n",
      "global step 5100, epoch: 2, batch: 395, loss: 0.2937, ce_loss: 0.2937., accu: 0.8159, speed: 1.20 step/s\n",
      "2022-09-28 14:20:50,851\t[train.py-do_train]-[line:187]-INFO:【global step 5100, epoch: 2, batch: 395】，loss: 0.2937, ce_loss: 0.2937., accu: 0.8159,\n",
      "global step 5110, epoch: 2, batch: 405, loss: 0.2994, ce_loss: 0.2994., accu: 0.8159, speed: 1.18 step/s\n",
      "global step 5120, epoch: 2, batch: 415, loss: 0.2997, ce_loss: 0.2997., accu: 0.8160, speed: 1.18 step/s\n",
      "global step 5130, epoch: 2, batch: 425, loss: 0.2297, ce_loss: 0.2297., accu: 0.8161, speed: 1.19 step/s\n",
      "global step 5140, epoch: 2, batch: 435, loss: 0.2618, ce_loss: 0.2618., accu: 0.8162, speed: 1.19 step/s\n",
      "global step 5150, epoch: 2, batch: 445, loss: 0.2764, ce_loss: 0.2764., accu: 0.8163, speed: 1.18 step/s\n",
      "global step 5160, epoch: 2, batch: 455, loss: 0.3323, ce_loss: 0.3323., accu: 0.8164, speed: 1.18 step/s\n",
      "global step 5170, epoch: 2, batch: 465, loss: 0.2704, ce_loss: 0.2704., accu: 0.8164, speed: 1.20 step/s\n",
      "global step 5180, epoch: 2, batch: 475, loss: 0.3036, ce_loss: 0.3036., accu: 0.8166, speed: 1.19 step/s\n",
      "global step 5190, epoch: 2, batch: 485, loss: 0.3537, ce_loss: 0.3537., accu: 0.8166, speed: 1.18 step/s\n",
      "global step 5200, epoch: 2, batch: 495, loss: 0.3219, ce_loss: 0.3219., accu: 0.8167, speed: 1.18 step/s\n",
      "2022-09-28 14:22:15,229\t[train.py-do_train]-[line:187]-INFO:【global step 5200, epoch: 2, batch: 495】，loss: 0.3219, ce_loss: 0.3219., accu: 0.8167,\n",
      "global step 5210, epoch: 2, batch: 505, loss: 0.3471, ce_loss: 0.3471., accu: 0.8168, speed: 1.18 step/s\n",
      "global step 5220, epoch: 2, batch: 515, loss: 0.3665, ce_loss: 0.3665., accu: 0.8169, speed: 1.19 step/s\n",
      "global step 5230, epoch: 2, batch: 525, loss: 0.3594, ce_loss: 0.3594., accu: 0.8170, speed: 1.19 step/s\n",
      "global step 5240, epoch: 2, batch: 535, loss: 0.4425, ce_loss: 0.4425., accu: 0.8171, speed: 1.18 step/s\n",
      "global step 5250, epoch: 2, batch: 545, loss: 0.3364, ce_loss: 0.3364., accu: 0.8171, speed: 1.19 step/s\n",
      "global step 5260, epoch: 2, batch: 555, loss: 0.3001, ce_loss: 0.3001., accu: 0.8172, speed: 1.20 step/s\n",
      "global step 5270, epoch: 2, batch: 565, loss: 0.2243, ce_loss: 0.2243., accu: 0.8173, speed: 1.18 step/s\n",
      "global step 5280, epoch: 2, batch: 575, loss: 0.1911, ce_loss: 0.1911., accu: 0.8174, speed: 1.18 step/s\n",
      "global step 5290, epoch: 2, batch: 585, loss: 0.2050, ce_loss: 0.2050., accu: 0.8175, speed: 1.19 step/s\n",
      "global step 5300, epoch: 2, batch: 595, loss: 0.3057, ce_loss: 0.3057., accu: 0.8176, speed: 1.19 step/s\n",
      "2022-09-28 14:23:39,393\t[train.py-do_train]-[line:187]-INFO:【global step 5300, epoch: 2, batch: 595】，loss: 0.3057, ce_loss: 0.3057., accu: 0.8176,\n",
      "global step 5310, epoch: 2, batch: 605, loss: 0.3176, ce_loss: 0.3176., accu: 0.8177, speed: 1.18 step/s\n",
      "global step 5320, epoch: 2, batch: 615, loss: 0.2718, ce_loss: 0.2718., accu: 0.8178, speed: 1.18 step/s\n",
      "global step 5330, epoch: 2, batch: 625, loss: 0.2927, ce_loss: 0.2927., accu: 0.8179, speed: 1.19 step/s\n",
      "global step 5340, epoch: 2, batch: 635, loss: 0.3253, ce_loss: 0.3253., accu: 0.8180, speed: 1.18 step/s\n",
      "global step 5350, epoch: 2, batch: 645, loss: 0.3399, ce_loss: 0.3399., accu: 0.8180, speed: 1.19 step/s\n",
      "global step 5360, epoch: 2, batch: 655, loss: 0.3608, ce_loss: 0.3608., accu: 0.8181, speed: 1.18 step/s\n",
      "global step 5370, epoch: 2, batch: 665, loss: 0.3030, ce_loss: 0.3030., accu: 0.8182, speed: 1.19 step/s\n",
      "global step 5380, epoch: 2, batch: 675, loss: 0.3842, ce_loss: 0.3842., accu: 0.8183, speed: 1.19 step/s\n",
      "global step 5390, epoch: 2, batch: 685, loss: 0.3303, ce_loss: 0.3303., accu: 0.8184, speed: 1.19 step/s\n",
      "global step 5400, epoch: 2, batch: 695, loss: 0.2902, ce_loss: 0.2902., accu: 0.8185, speed: 1.18 step/s\n",
      "2022-09-28 14:25:03,819\t[train.py-do_train]-[line:187]-INFO:【global step 5400, epoch: 2, batch: 695】，loss: 0.2902, ce_loss: 0.2902., accu: 0.8185,\n",
      "global step 5410, epoch: 2, batch: 705, loss: 0.2958, ce_loss: 0.2958., accu: 0.8185, speed: 1.18 step/s\n",
      "global step 5420, epoch: 2, batch: 715, loss: 0.2758, ce_loss: 0.2758., accu: 0.8186, speed: 1.18 step/s\n",
      "global step 5430, epoch: 2, batch: 725, loss: 0.2864, ce_loss: 0.2864., accu: 0.8187, speed: 1.19 step/s\n",
      "global step 5440, epoch: 2, batch: 735, loss: 0.3253, ce_loss: 0.3253., accu: 0.8188, speed: 1.18 step/s\n",
      "global step 5450, epoch: 2, batch: 745, loss: 0.3750, ce_loss: 0.3750., accu: 0.8189, speed: 1.18 step/s\n",
      "global step 5460, epoch: 2, batch: 755, loss: 0.2107, ce_loss: 0.2107., accu: 0.8189, speed: 1.19 step/s\n",
      "global step 5470, epoch: 2, batch: 765, loss: 0.2736, ce_loss: 0.2736., accu: 0.8190, speed: 1.18 step/s\n",
      "global step 5480, epoch: 2, batch: 775, loss: 0.2527, ce_loss: 0.2527., accu: 0.8191, speed: 1.20 step/s\n",
      "global step 5490, epoch: 2, batch: 785, loss: 0.3531, ce_loss: 0.3531., accu: 0.8191, speed: 1.18 step/s\n",
      "global step 5500, epoch: 2, batch: 795, loss: 0.2996, ce_loss: 0.2996., accu: 0.8192, speed: 1.18 step/s\n",
      "2022-09-28 14:26:28,264\t[train.py-do_train]-[line:187]-INFO:【global step 5500, epoch: 2, batch: 795】，loss: 0.2996, ce_loss: 0.2996., accu: 0.8192,\n",
      "global step 5510, epoch: 2, batch: 805, loss: 0.4505, ce_loss: 0.4505., accu: 0.8194, speed: 1.19 step/s\n",
      "global step 5520, epoch: 2, batch: 815, loss: 0.3200, ce_loss: 0.3200., accu: 0.8195, speed: 1.19 step/s\n",
      "global step 5530, epoch: 2, batch: 825, loss: 0.2674, ce_loss: 0.2674., accu: 0.8196, speed: 1.18 step/s\n",
      "global step 5540, epoch: 2, batch: 835, loss: 0.2541, ce_loss: 0.2541., accu: 0.8196, speed: 1.19 step/s\n",
      "global step 5550, epoch: 2, batch: 845, loss: 0.3137, ce_loss: 0.3137., accu: 0.8197, speed: 1.18 step/s\n",
      "global step 5560, epoch: 2, batch: 855, loss: 0.2791, ce_loss: 0.2791., accu: 0.8198, speed: 1.18 step/s\n",
      "global step 5570, epoch: 2, batch: 865, loss: 0.2524, ce_loss: 0.2524., accu: 0.8199, speed: 1.20 step/s\n",
      "global step 5580, epoch: 2, batch: 875, loss: 0.3131, ce_loss: 0.3131., accu: 0.8199, speed: 1.18 step/s\n",
      "global step 5590, epoch: 2, batch: 885, loss: 0.2752, ce_loss: 0.2752., accu: 0.8200, speed: 1.18 step/s\n",
      "global step 5600, epoch: 2, batch: 895, loss: 0.2687, ce_loss: 0.2687., accu: 0.8200, speed: 1.20 step/s\n",
      "2022-09-28 14:27:52,493\t[train.py-do_train]-[line:187]-INFO:【global step 5600, epoch: 2, batch: 895】，loss: 0.2687, ce_loss: 0.2687., accu: 0.8200,\n",
      "global step 5610, epoch: 2, batch: 905, loss: 0.2522, ce_loss: 0.2522., accu: 0.8201, speed: 1.19 step/s\n",
      "global step 5620, epoch: 2, batch: 915, loss: 0.2546, ce_loss: 0.2546., accu: 0.8202, speed: 1.22 step/s\n",
      "global step 5630, epoch: 2, batch: 925, loss: 0.2596, ce_loss: 0.2596., accu: 0.8203, speed: 1.18 step/s\n",
      "global step 5640, epoch: 2, batch: 935, loss: 0.3685, ce_loss: 0.3685., accu: 0.8203, speed: 1.18 step/s\n",
      "global step 5650, epoch: 2, batch: 945, loss: 0.2471, ce_loss: 0.2471., accu: 0.8204, speed: 1.19 step/s\n",
      "global step 5660, epoch: 2, batch: 955, loss: 0.2513, ce_loss: 0.2513., accu: 0.8205, speed: 1.19 step/s\n",
      "global step 5670, epoch: 2, batch: 965, loss: 0.2428, ce_loss: 0.2428., accu: 0.8206, speed: 1.18 step/s\n",
      "global step 5680, epoch: 2, batch: 975, loss: 0.2480, ce_loss: 0.2480., accu: 0.8207, speed: 1.18 step/s\n",
      "global step 5690, epoch: 2, batch: 985, loss: 0.2237, ce_loss: 0.2237., accu: 0.8208, speed: 1.19 step/s\n",
      "global step 5700, epoch: 2, batch: 995, loss: 0.3288, ce_loss: 0.3288., accu: 0.8208, speed: 1.18 step/s\n",
      "2022-09-28 14:29:16,656\t[train.py-do_train]-[line:187]-INFO:【global step 5700, epoch: 2, batch: 995】，loss: 0.3288, ce_loss: 0.3288., accu: 0.8208,\n",
      "global step 5710, epoch: 2, batch: 1005, loss: 0.2871, ce_loss: 0.2871., accu: 0.8209, speed: 1.20 step/s\n",
      "global step 5720, epoch: 2, batch: 1015, loss: 0.2942, ce_loss: 0.2942., accu: 0.8210, speed: 1.19 step/s\n",
      "global step 5730, epoch: 2, batch: 1025, loss: 0.3666, ce_loss: 0.3666., accu: 0.8210, speed: 1.18 step/s\n",
      "global step 5740, epoch: 2, batch: 1035, loss: 0.2780, ce_loss: 0.2780., accu: 0.8211, speed: 1.18 step/s\n",
      "global step 5750, epoch: 2, batch: 1045, loss: 0.2678, ce_loss: 0.2678., accu: 0.8212, speed: 1.19 step/s\n",
      "global step 5760, epoch: 2, batch: 1055, loss: 0.2541, ce_loss: 0.2541., accu: 0.8212, speed: 1.19 step/s\n",
      "global step 5770, epoch: 2, batch: 1065, loss: 0.2893, ce_loss: 0.2893., accu: 0.8213, speed: 1.19 step/s\n",
      "global step 5780, epoch: 2, batch: 1075, loss: 0.3482, ce_loss: 0.3482., accu: 0.8214, speed: 1.19 step/s\n",
      "global step 5790, epoch: 2, batch: 1085, loss: 0.3548, ce_loss: 0.3548., accu: 0.8215, speed: 1.18 step/s\n",
      "global step 5800, epoch: 2, batch: 1095, loss: 0.3181, ce_loss: 0.3181., accu: 0.8216, speed: 1.19 step/s\n",
      "2022-09-28 14:30:40,749\t[train.py-do_train]-[line:187]-INFO:【global step 5800, epoch: 2, batch: 1095】，loss: 0.3181, ce_loss: 0.3181., accu: 0.8216,\n",
      "global step 5810, epoch: 2, batch: 1105, loss: 0.3071, ce_loss: 0.3071., accu: 0.8216, speed: 1.18 step/s\n",
      "global step 5820, epoch: 2, batch: 1115, loss: 0.2550, ce_loss: 0.2550., accu: 0.8217, speed: 1.18 step/s\n",
      "global step 5830, epoch: 2, batch: 1125, loss: 0.2668, ce_loss: 0.2668., accu: 0.8217, speed: 1.19 step/s\n",
      "global step 5840, epoch: 2, batch: 1135, loss: 0.2419, ce_loss: 0.2419., accu: 0.8218, speed: 1.18 step/s\n",
      "global step 5850, epoch: 2, batch: 1145, loss: 0.2645, ce_loss: 0.2645., accu: 0.8219, speed: 1.19 step/s\n",
      "global step 5860, epoch: 2, batch: 1155, loss: 0.2992, ce_loss: 0.2992., accu: 0.8220, speed: 1.18 step/s\n",
      "global step 5870, epoch: 2, batch: 1165, loss: 0.2622, ce_loss: 0.2622., accu: 0.8221, speed: 1.20 step/s\n",
      "global step 5880, epoch: 2, batch: 1175, loss: 0.3013, ce_loss: 0.3013., accu: 0.8221, speed: 1.18 step/s\n",
      "global step 5890, epoch: 2, batch: 1185, loss: 0.1776, ce_loss: 0.1776., accu: 0.8222, speed: 1.20 step/s\n",
      "global step 5900, epoch: 2, batch: 1195, loss: 0.3010, ce_loss: 0.3010., accu: 0.8223, speed: 1.18 step/s\n",
      "2022-09-28 14:32:05,013\t[train.py-do_train]-[line:187]-INFO:【global step 5900, epoch: 2, batch: 1195】，loss: 0.3010, ce_loss: 0.3010., accu: 0.8223,\n",
      "global step 5910, epoch: 2, batch: 1205, loss: 0.2822, ce_loss: 0.2822., accu: 0.8223, speed: 1.18 step/s\n",
      "global step 5920, epoch: 2, batch: 1215, loss: 0.2561, ce_loss: 0.2561., accu: 0.8224, speed: 1.20 step/s\n",
      "global step 5930, epoch: 2, batch: 1225, loss: 0.3000, ce_loss: 0.3000., accu: 0.8225, speed: 1.19 step/s\n",
      "global step 5940, epoch: 2, batch: 1235, loss: 0.2958, ce_loss: 0.2958., accu: 0.8225, speed: 1.18 step/s\n",
      "global step 5950, epoch: 2, batch: 1245, loss: 0.2903, ce_loss: 0.2903., accu: 0.8226, speed: 1.18 step/s\n",
      "global step 5960, epoch: 2, batch: 1255, loss: 0.4073, ce_loss: 0.4073., accu: 0.8226, speed: 1.19 step/s\n",
      "global step 5970, epoch: 2, batch: 1265, loss: 0.3592, ce_loss: 0.3592., accu: 0.8227, speed: 1.18 step/s\n",
      "global step 5980, epoch: 2, batch: 1275, loss: 0.3032, ce_loss: 0.3032., accu: 0.8228, speed: 1.18 step/s\n",
      "global step 5990, epoch: 2, batch: 1285, loss: 0.3254, ce_loss: 0.3254., accu: 0.8229, speed: 1.19 step/s\n",
      "global step 6000, epoch: 2, batch: 1295, loss: 0.3715, ce_loss: 0.3715., accu: 0.8229, speed: 1.19 step/s\n",
      "2022-09-28 14:33:29,382\t[train.py-do_train]-[line:187]-INFO:【global step 6000, epoch: 2, batch: 1295】，loss: 0.3715, ce_loss: 0.3715., accu: 0.8229,\n",
      "global step 6010, epoch: 2, batch: 1305, loss: 0.2489, ce_loss: 0.2489., accu: 0.8230, speed: 1.18 step/s\n",
      "global step 6020, epoch: 2, batch: 1315, loss: 0.2740, ce_loss: 0.2740., accu: 0.8231, speed: 1.18 step/s\n",
      "global step 6030, epoch: 2, batch: 1325, loss: 0.2495, ce_loss: 0.2495., accu: 0.8231, speed: 1.18 step/s\n",
      "global step 6040, epoch: 2, batch: 1335, loss: 0.3488, ce_loss: 0.3488., accu: 0.8232, speed: 1.18 step/s\n",
      "global step 6050, epoch: 2, batch: 1345, loss: 0.3464, ce_loss: 0.3464., accu: 0.8233, speed: 1.18 step/s\n",
      "global step 6060, epoch: 2, batch: 1355, loss: 0.3032, ce_loss: 0.3032., accu: 0.8233, speed: 1.18 step/s\n",
      "global step 6070, epoch: 2, batch: 1365, loss: 0.4739, ce_loss: 0.4739., accu: 0.8234, speed: 1.20 step/s\n",
      "global step 6080, epoch: 2, batch: 1375, loss: 0.3040, ce_loss: 0.3040., accu: 0.8235, speed: 1.19 step/s\n",
      "global step 6090, epoch: 2, batch: 1385, loss: 0.3294, ce_loss: 0.3294., accu: 0.8236, speed: 1.18 step/s\n",
      "global step 6100, epoch: 2, batch: 1395, loss: 0.2506, ce_loss: 0.2506., accu: 0.8236, speed: 1.19 step/s\n",
      "2022-09-28 14:34:53,883\t[train.py-do_train]-[line:187]-INFO:【global step 6100, epoch: 2, batch: 1395】，loss: 0.2506, ce_loss: 0.2506., accu: 0.8236,\n",
      "global step 6110, epoch: 2, batch: 1405, loss: 0.3178, ce_loss: 0.3178., accu: 0.8237, speed: 1.18 step/s\n",
      "global step 6120, epoch: 2, batch: 1415, loss: 0.2945, ce_loss: 0.2945., accu: 0.8238, speed: 1.18 step/s\n",
      "global step 6130, epoch: 2, batch: 1425, loss: 0.3023, ce_loss: 0.3023., accu: 0.8239, speed: 1.18 step/s\n",
      "global step 6140, epoch: 2, batch: 1435, loss: 0.4122, ce_loss: 0.4122., accu: 0.8239, speed: 1.19 step/s\n",
      "global step 6150, epoch: 2, batch: 1445, loss: 0.2919, ce_loss: 0.2919., accu: 0.8239, speed: 1.19 step/s\n",
      "global step 6160, epoch: 2, batch: 1455, loss: 0.3158, ce_loss: 0.3158., accu: 0.8240, speed: 1.19 step/s\n",
      "global step 6170, epoch: 2, batch: 1465, loss: 0.3304, ce_loss: 0.3304., accu: 0.8241, speed: 1.18 step/s\n",
      "global step 6180, epoch: 2, batch: 1475, loss: 0.4895, ce_loss: 0.4895., accu: 0.8241, speed: 1.20 step/s\n",
      "global step 6190, epoch: 2, batch: 1485, loss: 0.3583, ce_loss: 0.3583., accu: 0.8242, speed: 1.18 step/s\n",
      "global step 6200, epoch: 2, batch: 1495, loss: 0.3252, ce_loss: 0.3252., accu: 0.8243, speed: 1.18 step/s\n",
      "2022-09-28 14:36:18,330\t[train.py-do_train]-[line:187]-INFO:【global step 6200, epoch: 2, batch: 1495】，loss: 0.3252, ce_loss: 0.3252., accu: 0.8243,\n",
      "global step 6210, epoch: 2, batch: 1505, loss: 0.3482, ce_loss: 0.3482., accu: 0.8243, speed: 1.18 step/s\n",
      "global step 6220, epoch: 2, batch: 1515, loss: 0.2653, ce_loss: 0.2653., accu: 0.8244, speed: 1.20 step/s\n",
      "global step 6230, epoch: 2, batch: 1525, loss: 0.2839, ce_loss: 0.2839., accu: 0.8245, speed: 1.19 step/s\n",
      "global step 6240, epoch: 2, batch: 1535, loss: 0.2649, ce_loss: 0.2649., accu: 0.8246, speed: 1.19 step/s\n",
      "global step 6250, epoch: 2, batch: 1545, loss: 0.2173, ce_loss: 0.2173., accu: 0.8247, speed: 1.18 step/s\n",
      "global step 6260, epoch: 2, batch: 1555, loss: 0.2792, ce_loss: 0.2792., accu: 0.8248, speed: 1.21 step/s\n",
      "global step 6270, epoch: 2, batch: 1565, loss: 0.2789, ce_loss: 0.2789., accu: 0.8249, speed: 1.19 step/s\n",
      "global step 6280, epoch: 2, batch: 1575, loss: 0.3693, ce_loss: 0.3693., accu: 0.8249, speed: 1.18 step/s\n",
      "global step 6290, epoch: 2, batch: 1585, loss: 0.2398, ce_loss: 0.2398., accu: 0.8250, speed: 1.20 step/s\n",
      "global step 6300, epoch: 2, batch: 1595, loss: 0.2625, ce_loss: 0.2625., accu: 0.8251, speed: 1.19 step/s\n",
      "2022-09-28 14:37:42,356\t[train.py-do_train]-[line:187]-INFO:【global step 6300, epoch: 2, batch: 1595】，loss: 0.2625, ce_loss: 0.2625., accu: 0.8251,\n",
      "global step 6310, epoch: 2, batch: 1605, loss: 0.3643, ce_loss: 0.3643., accu: 0.8252, speed: 1.19 step/s\n",
      "global step 6320, epoch: 2, batch: 1615, loss: 0.2834, ce_loss: 0.2834., accu: 0.8252, speed: 1.18 step/s\n",
      "global step 6330, epoch: 2, batch: 1625, loss: 0.2977, ce_loss: 0.2977., accu: 0.8253, speed: 1.18 step/s\n",
      "global step 6340, epoch: 2, batch: 1635, loss: 0.2780, ce_loss: 0.2780., accu: 0.8254, speed: 1.19 step/s\n",
      "global step 6350, epoch: 2, batch: 1645, loss: 0.2635, ce_loss: 0.2635., accu: 0.8254, speed: 1.19 step/s\n",
      "global step 6360, epoch: 2, batch: 1655, loss: 0.3075, ce_loss: 0.3075., accu: 0.8255, speed: 1.19 step/s\n",
      "global step 6370, epoch: 2, batch: 1665, loss: 0.2677, ce_loss: 0.2677., accu: 0.8256, speed: 1.19 step/s\n",
      "global step 6380, epoch: 2, batch: 1675, loss: 0.3339, ce_loss: 0.3339., accu: 0.8256, speed: 1.20 step/s\n",
      "global step 6390, epoch: 2, batch: 1685, loss: 0.3114, ce_loss: 0.3114., accu: 0.8257, speed: 1.19 step/s\n",
      "global step 6400, epoch: 2, batch: 1695, loss: 0.3413, ce_loss: 0.3413., accu: 0.8258, speed: 1.20 step/s\n",
      "2022-09-28 14:39:06,356\t[train.py-do_train]-[line:187]-INFO:【global step 6400, epoch: 2, batch: 1695】，loss: 0.3413, ce_loss: 0.3413., accu: 0.8258,\n",
      "global step 6410, epoch: 2, batch: 1705, loss: 0.3366, ce_loss: 0.3366., accu: 0.8258, speed: 1.18 step/s\n",
      "global step 6420, epoch: 2, batch: 1715, loss: 0.3178, ce_loss: 0.3178., accu: 0.8259, speed: 1.19 step/s\n",
      "global step 6430, epoch: 2, batch: 1725, loss: 0.3439, ce_loss: 0.3439., accu: 0.8259, speed: 1.18 step/s\n",
      "global step 6440, epoch: 2, batch: 1735, loss: 0.2614, ce_loss: 0.2614., accu: 0.8260, speed: 1.21 step/s\n",
      "global step 6450, epoch: 2, batch: 1745, loss: 0.2519, ce_loss: 0.2519., accu: 0.8260, speed: 1.19 step/s\n",
      "global step 6460, epoch: 2, batch: 1755, loss: 0.3365, ce_loss: 0.3365., accu: 0.8261, speed: 1.18 step/s\n",
      "global step 6470, epoch: 2, batch: 1765, loss: 0.3031, ce_loss: 0.3031., accu: 0.8262, speed: 1.19 step/s\n",
      "global step 6480, epoch: 2, batch: 1775, loss: 0.2409, ce_loss: 0.2409., accu: 0.8263, speed: 1.19 step/s\n",
      "global step 6490, epoch: 2, batch: 1785, loss: 0.3174, ce_loss: 0.3174., accu: 0.8263, speed: 1.18 step/s\n",
      "global step 6500, epoch: 2, batch: 1795, loss: 0.3578, ce_loss: 0.3578., accu: 0.8264, speed: 1.19 step/s\n",
      "2022-09-28 14:40:30,572\t[train.py-do_train]-[line:187]-INFO:【global step 6500, epoch: 2, batch: 1795】，loss: 0.3578, ce_loss: 0.3578., accu: 0.8264,\n",
      "global step 6510, epoch: 2, batch: 1805, loss: 0.2687, ce_loss: 0.2687., accu: 0.8264, speed: 1.18 step/s\n",
      "global step 6520, epoch: 2, batch: 1815, loss: 0.2400, ce_loss: 0.2400., accu: 0.8265, speed: 1.18 step/s\n",
      "global step 6530, epoch: 2, batch: 1825, loss: 0.2407, ce_loss: 0.2407., accu: 0.8266, speed: 1.18 step/s\n",
      "global step 6540, epoch: 2, batch: 1835, loss: 0.2653, ce_loss: 0.2653., accu: 0.8266, speed: 1.21 step/s\n",
      "global step 6550, epoch: 2, batch: 1845, loss: 0.1948, ce_loss: 0.1948., accu: 0.8267, speed: 1.18 step/s\n",
      "global step 6560, epoch: 2, batch: 1855, loss: 0.3634, ce_loss: 0.3634., accu: 0.8267, speed: 1.18 step/s\n",
      "global step 6570, epoch: 2, batch: 1865, loss: 0.3041, ce_loss: 0.3041., accu: 0.8268, speed: 1.18 step/s\n",
      "global step 6580, epoch: 2, batch: 1875, loss: 0.4174, ce_loss: 0.4174., accu: 0.8269, speed: 1.18 step/s\n",
      "global step 6590, epoch: 2, batch: 1885, loss: 0.2859, ce_loss: 0.2859., accu: 0.8269, speed: 1.18 step/s\n",
      "global step 6600, epoch: 2, batch: 1895, loss: 0.2428, ce_loss: 0.2428., accu: 0.8270, speed: 1.18 step/s\n",
      "2022-09-28 14:41:55,089\t[train.py-do_train]-[line:187]-INFO:【global step 6600, epoch: 2, batch: 1895】，loss: 0.2428, ce_loss: 0.2428., accu: 0.8270,\n",
      "global step 6610, epoch: 2, batch: 1905, loss: 0.3429, ce_loss: 0.3429., accu: 0.8270, speed: 1.18 step/s\n",
      "global step 6620, epoch: 2, batch: 1915, loss: 0.2244, ce_loss: 0.2244., accu: 0.8271, speed: 1.18 step/s\n",
      "global step 6630, epoch: 2, batch: 1925, loss: 0.2558, ce_loss: 0.2558., accu: 0.8272, speed: 1.18 step/s\n",
      "global step 6640, epoch: 2, batch: 1935, loss: 0.3133, ce_loss: 0.3133., accu: 0.8272, speed: 1.18 step/s\n",
      "global step 6650, epoch: 2, batch: 1945, loss: 0.3110, ce_loss: 0.3110., accu: 0.8273, speed: 1.18 step/s\n",
      "global step 6660, epoch: 2, batch: 1955, loss: 0.3500, ce_loss: 0.3500., accu: 0.8273, speed: 1.18 step/s\n",
      "global step 6670, epoch: 2, batch: 1965, loss: 0.2421, ce_loss: 0.2421., accu: 0.8274, speed: 1.18 step/s\n",
      "global step 6680, epoch: 2, batch: 1975, loss: 0.3445, ce_loss: 0.3445., accu: 0.8274, speed: 1.18 step/s\n",
      "global step 6690, epoch: 2, batch: 1985, loss: 0.3398, ce_loss: 0.3398., accu: 0.8275, speed: 1.19 step/s\n",
      "global step 6700, epoch: 2, batch: 1995, loss: 0.3521, ce_loss: 0.3521., accu: 0.8276, speed: 1.18 step/s\n",
      "2022-09-28 14:43:19,666\t[train.py-do_train]-[line:187]-INFO:【global step 6700, epoch: 2, batch: 1995】，loss: 0.3521, ce_loss: 0.3521., accu: 0.8276,\n",
      "global step 6710, epoch: 2, batch: 2005, loss: 0.2972, ce_loss: 0.2972., accu: 0.8276, speed: 1.21 step/s\n",
      "global step 6720, epoch: 2, batch: 2015, loss: 0.3235, ce_loss: 0.3235., accu: 0.8276, speed: 1.18 step/s\n",
      "global step 6730, epoch: 2, batch: 2025, loss: 0.3360, ce_loss: 0.3360., accu: 0.8277, speed: 1.18 step/s\n",
      "global step 6740, epoch: 2, batch: 2035, loss: 0.3482, ce_loss: 0.3482., accu: 0.8277, speed: 1.18 step/s\n",
      "global step 6750, epoch: 2, batch: 2045, loss: 0.3446, ce_loss: 0.3446., accu: 0.8278, speed: 1.19 step/s\n",
      "global step 6760, epoch: 2, batch: 2055, loss: 0.3829, ce_loss: 0.3829., accu: 0.8278, speed: 1.18 step/s\n",
      "global step 6770, epoch: 2, batch: 2065, loss: 0.3134, ce_loss: 0.3134., accu: 0.8279, speed: 1.18 step/s\n",
      "global step 6780, epoch: 2, batch: 2075, loss: 0.3336, ce_loss: 0.3336., accu: 0.8280, speed: 1.18 step/s\n",
      "global step 6790, epoch: 2, batch: 2085, loss: 0.2469, ce_loss: 0.2469., accu: 0.8280, speed: 1.19 step/s\n",
      "global step 6800, epoch: 2, batch: 2095, loss: 0.2805, ce_loss: 0.2805., accu: 0.8281, speed: 1.18 step/s\n",
      "2022-09-28 14:44:44,173\t[train.py-do_train]-[line:187]-INFO:【global step 6800, epoch: 2, batch: 2095】，loss: 0.2805, ce_loss: 0.2805., accu: 0.8281,\n",
      "global step 6810, epoch: 2, batch: 2105, loss: 0.3028, ce_loss: 0.3028., accu: 0.8282, speed: 1.19 step/s\n",
      "global step 6820, epoch: 2, batch: 2115, loss: 0.2658, ce_loss: 0.2658., accu: 0.8282, speed: 1.18 step/s\n",
      "global step 6830, epoch: 2, batch: 2125, loss: 0.3146, ce_loss: 0.3146., accu: 0.8282, speed: 1.19 step/s\n",
      "global step 6840, epoch: 2, batch: 2135, loss: 0.2314, ce_loss: 0.2314., accu: 0.8283, speed: 1.19 step/s\n",
      "global step 6850, epoch: 2, batch: 2145, loss: 0.3310, ce_loss: 0.3310., accu: 0.8284, speed: 1.19 step/s\n",
      "global step 6860, epoch: 2, batch: 2155, loss: 0.2695, ce_loss: 0.2695., accu: 0.8285, speed: 1.19 step/s\n",
      "global step 6870, epoch: 2, batch: 2165, loss: 0.2978, ce_loss: 0.2978., accu: 0.8285, speed: 1.18 step/s\n",
      "global step 6880, epoch: 2, batch: 2175, loss: 0.2959, ce_loss: 0.2959., accu: 0.8286, speed: 1.19 step/s\n",
      "global step 6890, epoch: 2, batch: 2185, loss: 0.2862, ce_loss: 0.2862., accu: 0.8286, speed: 1.20 step/s\n",
      "global step 6900, epoch: 2, batch: 2195, loss: 0.3088, ce_loss: 0.3088., accu: 0.8287, speed: 1.18 step/s\n",
      "2022-09-28 14:46:08,520\t[train.py-do_train]-[line:187]-INFO:【global step 6900, epoch: 2, batch: 2195】，loss: 0.3088, ce_loss: 0.3088., accu: 0.8287,\n",
      "global step 6910, epoch: 2, batch: 2205, loss: 0.2623, ce_loss: 0.2623., accu: 0.8288, speed: 1.19 step/s\n",
      "global step 6920, epoch: 2, batch: 2215, loss: 0.2753, ce_loss: 0.2753., accu: 0.8288, speed: 1.18 step/s\n",
      "global step 6930, epoch: 2, batch: 2225, loss: 0.3915, ce_loss: 0.3915., accu: 0.8288, speed: 1.18 step/s\n",
      "global step 6940, epoch: 2, batch: 2235, loss: 0.2911, ce_loss: 0.2911., accu: 0.8289, speed: 1.18 step/s\n",
      "global step 6950, epoch: 2, batch: 2245, loss: 0.3088, ce_loss: 0.3088., accu: 0.8290, speed: 1.19 step/s\n",
      "global step 6960, epoch: 2, batch: 2255, loss: 0.3615, ce_loss: 0.3615., accu: 0.8290, speed: 1.19 step/s\n",
      "global step 6970, epoch: 2, batch: 2265, loss: 0.2398, ce_loss: 0.2398., accu: 0.8291, speed: 1.18 step/s\n",
      "global step 6980, epoch: 2, batch: 2275, loss: 0.2255, ce_loss: 0.2255., accu: 0.8292, speed: 1.18 step/s\n",
      "global step 6990, epoch: 2, batch: 2285, loss: 0.2281, ce_loss: 0.2281., accu: 0.8292, speed: 1.18 step/s\n",
      "global step 7000, epoch: 2, batch: 2295, loss: 0.2847, ce_loss: 0.2847., accu: 0.8293, speed: 1.18 step/s\n",
      "2022-09-28 14:47:33,098\t[train.py-do_train]-[line:187]-INFO:【global step 7000, epoch: 2, batch: 2295】，loss: 0.2847, ce_loss: 0.2847., accu: 0.8293,\n",
      "global step 7010, epoch: 2, batch: 2305, loss: 0.3389, ce_loss: 0.3389., accu: 0.8293, speed: 1.20 step/s\n",
      "global step 7020, epoch: 2, batch: 2315, loss: 0.2079, ce_loss: 0.2079., accu: 0.8294, speed: 1.18 step/s\n",
      "global step 7030, epoch: 2, batch: 2325, loss: 0.2685, ce_loss: 0.2685., accu: 0.8295, speed: 1.19 step/s\n",
      "global step 7040, epoch: 2, batch: 2335, loss: 0.2631, ce_loss: 0.2631., accu: 0.8295, speed: 1.19 step/s\n",
      "global step 7050, epoch: 2, batch: 2345, loss: 0.2687, ce_loss: 0.2687., accu: 0.8296, speed: 1.18 step/s\n",
      "global step 7060, epoch: 2, batch: 2355, loss: 0.3343, ce_loss: 0.3343., accu: 0.8296, speed: 1.18 step/s\n",
      "global step 7070, epoch: 2, batch: 2365, loss: 0.2789, ce_loss: 0.2789., accu: 0.8297, speed: 1.19 step/s\n",
      "global step 7080, epoch: 2, batch: 2375, loss: 0.3499, ce_loss: 0.3499., accu: 0.8297, speed: 1.20 step/s\n",
      "global step 7090, epoch: 2, batch: 2385, loss: 0.3202, ce_loss: 0.3202., accu: 0.8298, speed: 1.19 step/s\n",
      "global step 7100, epoch: 2, batch: 2395, loss: 0.2755, ce_loss: 0.2755., accu: 0.8298, speed: 1.19 step/s\n",
      "2022-09-28 14:48:57,307\t[train.py-do_train]-[line:187]-INFO:【global step 7100, epoch: 2, batch: 2395】，loss: 0.2755, ce_loss: 0.2755., accu: 0.8298,\n",
      "global step 7110, epoch: 2, batch: 2405, loss: 0.2322, ce_loss: 0.2322., accu: 0.8299, speed: 1.18 step/s\n",
      "global step 7120, epoch: 2, batch: 2415, loss: 0.3008, ce_loss: 0.3008., accu: 0.8299, speed: 1.18 step/s\n",
      "global step 7130, epoch: 2, batch: 2425, loss: 0.2710, ce_loss: 0.2710., accu: 0.8300, speed: 1.18 step/s\n",
      "global step 7140, epoch: 2, batch: 2435, loss: 0.4339, ce_loss: 0.4339., accu: 0.8301, speed: 1.18 step/s\n",
      "global step 7150, epoch: 2, batch: 2445, loss: 0.3122, ce_loss: 0.3122., accu: 0.8301, speed: 1.18 step/s\n",
      "global step 7160, epoch: 2, batch: 2455, loss: 0.3104, ce_loss: 0.3104., accu: 0.8302, speed: 1.18 step/s\n",
      "global step 7170, epoch: 2, batch: 2465, loss: 0.2864, ce_loss: 0.2864., accu: 0.8302, speed: 1.19 step/s\n",
      "global step 7180, epoch: 2, batch: 2475, loss: 0.3011, ce_loss: 0.3011., accu: 0.8303, speed: 1.20 step/s\n",
      "global step 7190, epoch: 2, batch: 2485, loss: 0.2134, ce_loss: 0.2134., accu: 0.8304, speed: 1.18 step/s\n",
      "global step 7200, epoch: 2, batch: 2495, loss: 0.3271, ce_loss: 0.3271., accu: 0.8304, speed: 1.18 step/s\n",
      "2022-09-28 14:50:21,981\t[train.py-do_train]-[line:187]-INFO:【global step 7200, epoch: 2, batch: 2495】，loss: 0.3271, ce_loss: 0.3271., accu: 0.8304,\n",
      "global step 7210, epoch: 2, batch: 2505, loss: 0.1929, ce_loss: 0.1929., accu: 0.8305, speed: 1.18 step/s\n",
      "global step 7220, epoch: 2, batch: 2515, loss: 0.3506, ce_loss: 0.3506., accu: 0.8305, speed: 1.19 step/s\n",
      "global step 7230, epoch: 2, batch: 2525, loss: 0.2658, ce_loss: 0.2658., accu: 0.8306, speed: 1.20 step/s\n",
      "global step 7240, epoch: 2, batch: 2535, loss: 0.3218, ce_loss: 0.3218., accu: 0.8306, speed: 1.18 step/s\n",
      "global step 7250, epoch: 2, batch: 2545, loss: 0.3138, ce_loss: 0.3138., accu: 0.8307, speed: 1.19 step/s\n",
      "global step 7260, epoch: 2, batch: 2555, loss: 0.3378, ce_loss: 0.3378., accu: 0.8307, speed: 1.19 step/s\n",
      "global step 7270, epoch: 2, batch: 2565, loss: 0.2600, ce_loss: 0.2600., accu: 0.8308, speed: 1.18 step/s\n",
      "global step 7280, epoch: 2, batch: 2575, loss: 0.1915, ce_loss: 0.1915., accu: 0.8308, speed: 1.19 step/s\n",
      "global step 7290, epoch: 2, batch: 2585, loss: 0.2646, ce_loss: 0.2646., accu: 0.8309, speed: 1.19 step/s\n",
      "global step 7300, epoch: 2, batch: 2595, loss: 0.2687, ce_loss: 0.2687., accu: 0.8309, speed: 1.18 step/s\n",
      "2022-09-28 14:51:46,274\t[train.py-do_train]-[line:187]-INFO:【global step 7300, epoch: 2, batch: 2595】，loss: 0.2687, ce_loss: 0.2687., accu: 0.8309,\n",
      "global step 7310, epoch: 2, batch: 2605, loss: 0.3275, ce_loss: 0.3275., accu: 0.8310, speed: 1.21 step/s\n",
      "global step 7320, epoch: 2, batch: 2615, loss: 0.4273, ce_loss: 0.4273., accu: 0.8310, speed: 1.18 step/s\n",
      "global step 7330, epoch: 2, batch: 2625, loss: 0.3337, ce_loss: 0.3337., accu: 0.8311, speed: 1.18 step/s\n",
      "global step 7340, epoch: 2, batch: 2635, loss: 0.2470, ce_loss: 0.2470., accu: 0.8311, speed: 1.20 step/s\n",
      "global step 7350, epoch: 2, batch: 2645, loss: 0.2743, ce_loss: 0.2743., accu: 0.8312, speed: 1.20 step/s\n",
      "global step 7360, epoch: 2, batch: 2655, loss: 0.3126, ce_loss: 0.3126., accu: 0.8313, speed: 1.18 step/s\n",
      "global step 7370, epoch: 2, batch: 2665, loss: 0.2987, ce_loss: 0.2987., accu: 0.8313, speed: 1.19 step/s\n",
      "global step 7380, epoch: 2, batch: 2675, loss: 0.3137, ce_loss: 0.3137., accu: 0.8313, speed: 1.18 step/s\n",
      "global step 7390, epoch: 2, batch: 2685, loss: 0.3311, ce_loss: 0.3311., accu: 0.8314, speed: 1.19 step/s\n",
      "global step 7400, epoch: 2, batch: 2695, loss: 0.3380, ce_loss: 0.3380., accu: 0.8315, speed: 1.19 step/s\n",
      "2022-09-28 14:53:10,366\t[train.py-do_train]-[line:187]-INFO:【global step 7400, epoch: 2, batch: 2695】，loss: 0.3380, ce_loss: 0.3380., accu: 0.8315,\n",
      "global step 7410, epoch: 2, batch: 2705, loss: 0.3122, ce_loss: 0.3122., accu: 0.8315, speed: 1.18 step/s\n",
      "global step 7420, epoch: 2, batch: 2715, loss: 0.2713, ce_loss: 0.2713., accu: 0.8316, speed: 1.21 step/s\n",
      "global step 7430, epoch: 2, batch: 2725, loss: 0.3238, ce_loss: 0.3238., accu: 0.8316, speed: 1.20 step/s\n",
      "global step 7440, epoch: 2, batch: 2735, loss: 0.2148, ce_loss: 0.2148., accu: 0.8317, speed: 1.18 step/s\n",
      "global step 7450, epoch: 2, batch: 2745, loss: 0.2594, ce_loss: 0.2594., accu: 0.8317, speed: 1.18 step/s\n",
      "global step 7460, epoch: 2, batch: 2755, loss: 0.2583, ce_loss: 0.2583., accu: 0.8318, speed: 1.19 step/s\n",
      "global step 7470, epoch: 2, batch: 2765, loss: 0.2904, ce_loss: 0.2904., accu: 0.8319, speed: 1.19 step/s\n",
      "global step 7480, epoch: 2, batch: 2775, loss: 0.3309, ce_loss: 0.3309., accu: 0.8319, speed: 1.18 step/s\n",
      "global step 7490, epoch: 2, batch: 2785, loss: 0.2207, ce_loss: 0.2207., accu: 0.8319, speed: 1.19 step/s\n",
      "global step 7500, epoch: 2, batch: 2795, loss: 0.2699, ce_loss: 0.2699., accu: 0.8320, speed: 1.19 step/s\n",
      "2022-09-28 14:54:34,543\t[train.py-do_train]-[line:187]-INFO:【global step 7500, epoch: 2, batch: 2795】，loss: 0.2699, ce_loss: 0.2699., accu: 0.8320,\n",
      "global step 7510, epoch: 2, batch: 2805, loss: 0.3324, ce_loss: 0.3324., accu: 0.8321, speed: 1.18 step/s\n",
      "global step 7520, epoch: 2, batch: 2815, loss: 0.3035, ce_loss: 0.3035., accu: 0.8321, speed: 1.20 step/s\n",
      "global step 7530, epoch: 2, batch: 2825, loss: 0.2396, ce_loss: 0.2396., accu: 0.8322, speed: 1.20 step/s\n",
      "global step 7540, epoch: 2, batch: 2835, loss: 0.3033, ce_loss: 0.3033., accu: 0.8322, speed: 1.21 step/s\n",
      "global step 7550, epoch: 2, batch: 2845, loss: 0.3538, ce_loss: 0.3538., accu: 0.8323, speed: 1.18 step/s\n",
      "global step 7560, epoch: 2, batch: 2855, loss: 0.2807, ce_loss: 0.2807., accu: 0.8324, speed: 1.18 step/s\n",
      "global step 7570, epoch: 2, batch: 2865, loss: 0.3637, ce_loss: 0.3637., accu: 0.8324, speed: 1.19 step/s\n",
      "global step 7580, epoch: 2, batch: 2875, loss: 0.2819, ce_loss: 0.2819., accu: 0.8325, speed: 1.19 step/s\n",
      "global step 7590, epoch: 2, batch: 2885, loss: 0.2105, ce_loss: 0.2105., accu: 0.8325, speed: 1.18 step/s\n",
      "global step 7600, epoch: 2, batch: 2895, loss: 0.3733, ce_loss: 0.3733., accu: 0.8326, speed: 1.19 step/s\n",
      "2022-09-28 14:55:58,677\t[train.py-do_train]-[line:187]-INFO:【global step 7600, epoch: 2, batch: 2895】，loss: 0.3733, ce_loss: 0.3733., accu: 0.8326,\n",
      "global step 7610, epoch: 2, batch: 2905, loss: 0.2695, ce_loss: 0.2695., accu: 0.8326, speed: 1.18 step/s\n",
      "global step 7620, epoch: 2, batch: 2915, loss: 0.2498, ce_loss: 0.2498., accu: 0.8327, speed: 1.19 step/s\n",
      "global step 7630, epoch: 2, batch: 2925, loss: 0.2414, ce_loss: 0.2414., accu: 0.8327, speed: 1.20 step/s\n",
      "global step 7640, epoch: 2, batch: 2935, loss: 0.2540, ce_loss: 0.2540., accu: 0.8328, speed: 1.18 step/s\n",
      "global step 7650, epoch: 2, batch: 2945, loss: 0.4219, ce_loss: 0.4219., accu: 0.8329, speed: 1.18 step/s\n",
      "global step 7660, epoch: 2, batch: 2955, loss: 0.2501, ce_loss: 0.2501., accu: 0.8329, speed: 1.19 step/s\n",
      "global step 7670, epoch: 2, batch: 2965, loss: 0.3443, ce_loss: 0.3443., accu: 0.8330, speed: 1.19 step/s\n",
      "global step 7680, epoch: 2, batch: 2975, loss: 0.2714, ce_loss: 0.2714., accu: 0.8330, speed: 1.19 step/s\n",
      "global step 7690, epoch: 2, batch: 2985, loss: 0.2077, ce_loss: 0.2077., accu: 0.8331, speed: 1.19 step/s\n",
      "global step 7700, epoch: 2, batch: 2995, loss: 0.2746, ce_loss: 0.2746., accu: 0.8331, speed: 1.20 step/s\n",
      "2022-09-28 14:57:22,787\t[train.py-do_train]-[line:187]-INFO:【global step 7700, epoch: 2, batch: 2995】，loss: 0.2746, ce_loss: 0.2746., accu: 0.8331,\n",
      "global step 7710, epoch: 2, batch: 3005, loss: 0.3122, ce_loss: 0.3122., accu: 0.8332, speed: 1.18 step/s\n",
      "global step 7720, epoch: 2, batch: 3015, loss: 0.2825, ce_loss: 0.2825., accu: 0.8332, speed: 1.19 step/s\n",
      "global step 7730, epoch: 2, batch: 3025, loss: 0.2159, ce_loss: 0.2159., accu: 0.8333, speed: 1.18 step/s\n",
      "global step 7740, epoch: 2, batch: 3035, loss: 0.3174, ce_loss: 0.3174., accu: 0.8333, speed: 1.19 step/s\n",
      "global step 7750, epoch: 2, batch: 3045, loss: 0.3183, ce_loss: 0.3183., accu: 0.8334, speed: 1.19 step/s\n",
      "global step 7760, epoch: 2, batch: 3055, loss: 0.3104, ce_loss: 0.3104., accu: 0.8334, speed: 1.20 step/s\n",
      "global step 7770, epoch: 2, batch: 3065, loss: 0.2920, ce_loss: 0.2920., accu: 0.8335, speed: 1.18 step/s\n",
      "global step 7780, epoch: 2, batch: 3075, loss: 0.3004, ce_loss: 0.3004., accu: 0.8335, speed: 1.18 step/s\n",
      "global step 7790, epoch: 2, batch: 3085, loss: 0.2648, ce_loss: 0.2648., accu: 0.8336, speed: 1.18 step/s\n",
      "global step 7800, epoch: 2, batch: 3095, loss: 0.2647, ce_loss: 0.2647., accu: 0.8336, speed: 1.19 step/s\n",
      "2022-09-28 14:58:47,197\t[train.py-do_train]-[line:187]-INFO:【global step 7800, epoch: 2, batch: 3095】，loss: 0.2647, ce_loss: 0.2647., accu: 0.8336,\n",
      "global step 7810, epoch: 2, batch: 3105, loss: 0.2417, ce_loss: 0.2417., accu: 0.8337, speed: 1.18 step/s\n",
      "global step 7820, epoch: 2, batch: 3115, loss: 0.3025, ce_loss: 0.3025., accu: 0.8337, speed: 1.19 step/s\n",
      "global step 7830, epoch: 2, batch: 3125, loss: 0.3214, ce_loss: 0.3214., accu: 0.8338, speed: 1.21 step/s\n",
      "global step 7840, epoch: 2, batch: 3135, loss: 0.2546, ce_loss: 0.2546., accu: 0.8338, speed: 1.19 step/s\n",
      "global step 7850, epoch: 2, batch: 3145, loss: 0.3281, ce_loss: 0.3281., accu: 0.8339, speed: 1.19 step/s\n",
      "global step 7860, epoch: 2, batch: 3155, loss: 0.2782, ce_loss: 0.2782., accu: 0.8339, speed: 1.20 step/s\n",
      "global step 7870, epoch: 2, batch: 3165, loss: 0.2731, ce_loss: 0.2731., accu: 0.8340, speed: 1.18 step/s\n",
      "global step 7880, epoch: 2, batch: 3175, loss: 0.2877, ce_loss: 0.2877., accu: 0.8340, speed: 1.18 step/s\n",
      "global step 7890, epoch: 2, batch: 3185, loss: 0.3718, ce_loss: 0.3718., accu: 0.8341, speed: 1.18 step/s\n",
      "global step 7900, epoch: 2, batch: 3195, loss: 0.2222, ce_loss: 0.2222., accu: 0.8341, speed: 1.20 step/s\n",
      "2022-09-28 15:00:11,263\t[train.py-do_train]-[line:187]-INFO:【global step 7900, epoch: 2, batch: 3195】，loss: 0.2222, ce_loss: 0.2222., accu: 0.8341,\n",
      "global step 7910, epoch: 2, batch: 3205, loss: 0.2511, ce_loss: 0.2511., accu: 0.8342, speed: 1.18 step/s\n",
      "global step 7920, epoch: 2, batch: 3215, loss: 0.2263, ce_loss: 0.2263., accu: 0.8342, speed: 1.20 step/s\n",
      "global step 7930, epoch: 2, batch: 3225, loss: 0.2321, ce_loss: 0.2321., accu: 0.8343, speed: 1.19 step/s\n",
      "global step 7940, epoch: 2, batch: 3235, loss: 0.3633, ce_loss: 0.3633., accu: 0.8343, speed: 1.19 step/s\n",
      "global step 7950, epoch: 2, batch: 3245, loss: 0.1756, ce_loss: 0.1756., accu: 0.8344, speed: 1.20 step/s\n",
      "global step 7960, epoch: 2, batch: 3255, loss: 0.2344, ce_loss: 0.2344., accu: 0.8344, speed: 1.18 step/s\n",
      "global step 7970, epoch: 2, batch: 3265, loss: 0.2357, ce_loss: 0.2357., accu: 0.8345, speed: 1.19 step/s\n",
      "global step 7980, epoch: 2, batch: 3275, loss: 0.2913, ce_loss: 0.2913., accu: 0.8345, speed: 1.18 step/s\n",
      "global step 7990, epoch: 2, batch: 3285, loss: 0.2802, ce_loss: 0.2802., accu: 0.8346, speed: 1.20 step/s\n",
      "global step 8000, epoch: 2, batch: 3295, loss: 0.2482, ce_loss: 0.2482., accu: 0.8346, speed: 1.19 step/s\n",
      "2022-09-28 15:01:35,301\t[train.py-do_train]-[line:187]-INFO:【global step 8000, epoch: 2, batch: 3295】，loss: 0.2482, ce_loss: 0.2482., accu: 0.8346,\n",
      "global step 8010, epoch: 2, batch: 3305, loss: 0.2985, ce_loss: 0.2985., accu: 0.8347, speed: 1.19 step/s\n",
      "global step 8020, epoch: 2, batch: 3315, loss: 0.2801, ce_loss: 0.2801., accu: 0.8347, speed: 1.21 step/s\n",
      "global step 8030, epoch: 2, batch: 3325, loss: 0.3055, ce_loss: 0.3055., accu: 0.8348, speed: 1.20 step/s\n",
      "global step 8040, epoch: 2, batch: 3335, loss: 0.2939, ce_loss: 0.2939., accu: 0.8348, speed: 1.19 step/s\n",
      "global step 8050, epoch: 2, batch: 3345, loss: 0.2527, ce_loss: 0.2527., accu: 0.8349, speed: 1.19 step/s\n",
      "global step 8060, epoch: 2, batch: 3355, loss: 0.3235, ce_loss: 0.3235., accu: 0.8349, speed: 1.19 step/s\n",
      "global step 8070, epoch: 2, batch: 3365, loss: 0.2729, ce_loss: 0.2729., accu: 0.8350, speed: 1.19 step/s\n",
      "global step 8080, epoch: 2, batch: 3375, loss: 0.3427, ce_loss: 0.3427., accu: 0.8350, speed: 1.19 step/s\n",
      "global step 8090, epoch: 2, batch: 3385, loss: 0.2440, ce_loss: 0.2440., accu: 0.8351, speed: 1.18 step/s\n",
      "global step 8100, epoch: 2, batch: 3395, loss: 0.2678, ce_loss: 0.2678., accu: 0.8351, speed: 1.20 step/s\n",
      "2022-09-28 15:02:59,266\t[train.py-do_train]-[line:187]-INFO:【global step 8100, epoch: 2, batch: 3395】，loss: 0.2678, ce_loss: 0.2678., accu: 0.8351,\n",
      "global step 8110, epoch: 2, batch: 3405, loss: 0.1943, ce_loss: 0.1943., accu: 0.8352, speed: 1.18 step/s\n",
      "global step 8120, epoch: 2, batch: 3415, loss: 0.3243, ce_loss: 0.3243., accu: 0.8352, speed: 1.18 step/s\n",
      "global step 8130, epoch: 2, batch: 3425, loss: 0.2154, ce_loss: 0.2154., accu: 0.8353, speed: 1.19 step/s\n",
      "global step 8140, epoch: 2, batch: 3435, loss: 0.2645, ce_loss: 0.2645., accu: 0.8353, speed: 1.19 step/s\n",
      "global step 8150, epoch: 2, batch: 3445, loss: 0.2748, ce_loss: 0.2748., accu: 0.8354, speed: 1.20 step/s\n",
      "global step 8160, epoch: 2, batch: 3455, loss: 0.2384, ce_loss: 0.2384., accu: 0.8354, speed: 1.19 step/s\n",
      "global step 8170, epoch: 2, batch: 3465, loss: 0.3194, ce_loss: 0.3194., accu: 0.8355, speed: 1.18 step/s\n",
      "global step 8180, epoch: 2, batch: 3475, loss: 0.3148, ce_loss: 0.3148., accu: 0.8355, speed: 1.19 step/s\n",
      "global step 8190, epoch: 2, batch: 3485, loss: 0.3067, ce_loss: 0.3067., accu: 0.8356, speed: 1.18 step/s\n",
      "global step 8200, epoch: 2, batch: 3495, loss: 0.2311, ce_loss: 0.2311., accu: 0.8356, speed: 1.19 step/s\n",
      "2022-09-28 15:04:23,506\t[train.py-do_train]-[line:187]-INFO:【global step 8200, epoch: 2, batch: 3495】，loss: 0.2311, ce_loss: 0.2311., accu: 0.8356,\n",
      "global step 8210, epoch: 2, batch: 3505, loss: 0.2476, ce_loss: 0.2476., accu: 0.8357, speed: 1.18 step/s\n",
      "global step 8220, epoch: 2, batch: 3515, loss: 0.2848, ce_loss: 0.2848., accu: 0.8357, speed: 1.19 step/s\n",
      "global step 8230, epoch: 2, batch: 3525, loss: 0.3531, ce_loss: 0.3531., accu: 0.8358, speed: 1.18 step/s\n",
      "global step 8240, epoch: 2, batch: 3535, loss: 0.3161, ce_loss: 0.3161., accu: 0.8358, speed: 1.20 step/s\n",
      "global step 8250, epoch: 2, batch: 3545, loss: 0.2634, ce_loss: 0.2634., accu: 0.8359, speed: 1.18 step/s\n",
      "global step 8260, epoch: 2, batch: 3555, loss: 0.2820, ce_loss: 0.2820., accu: 0.8359, speed: 1.18 step/s\n",
      "global step 8270, epoch: 2, batch: 3565, loss: 0.3598, ce_loss: 0.3598., accu: 0.8360, speed: 1.19 step/s\n",
      "global step 8280, epoch: 2, batch: 3575, loss: 0.3211, ce_loss: 0.3211., accu: 0.8360, speed: 1.18 step/s\n",
      "global step 8290, epoch: 2, batch: 3585, loss: 0.2836, ce_loss: 0.2836., accu: 0.8360, speed: 1.19 step/s\n",
      "global step 8300, epoch: 2, batch: 3595, loss: 0.2918, ce_loss: 0.2918., accu: 0.8361, speed: 1.19 step/s\n",
      "2022-09-28 15:05:47,840\t[train.py-do_train]-[line:187]-INFO:【global step 8300, epoch: 2, batch: 3595】，loss: 0.2918, ce_loss: 0.2918., accu: 0.8361,\n",
      "global step 8310, epoch: 2, batch: 3605, loss: 0.2788, ce_loss: 0.2788., accu: 0.8361, speed: 1.19 step/s\n",
      "global step 8320, epoch: 2, batch: 3615, loss: 0.2988, ce_loss: 0.2988., accu: 0.8362, speed: 1.20 step/s\n",
      "global step 8330, epoch: 2, batch: 3625, loss: 0.3534, ce_loss: 0.3534., accu: 0.8362, speed: 1.20 step/s\n",
      "global step 8340, epoch: 2, batch: 3635, loss: 0.3011, ce_loss: 0.3011., accu: 0.8362, speed: 1.18 step/s\n",
      "global step 8350, epoch: 2, batch: 3645, loss: 0.2798, ce_loss: 0.2798., accu: 0.8363, speed: 1.18 step/s\n",
      "global step 8360, epoch: 2, batch: 3655, loss: 0.2582, ce_loss: 0.2582., accu: 0.8363, speed: 1.19 step/s\n",
      "global step 8370, epoch: 2, batch: 3665, loss: 0.2459, ce_loss: 0.2459., accu: 0.8364, speed: 1.21 step/s\n",
      "global step 8380, epoch: 2, batch: 3675, loss: 0.2859, ce_loss: 0.2859., accu: 0.8364, speed: 1.18 step/s\n",
      "global step 8390, epoch: 2, batch: 3685, loss: 0.3012, ce_loss: 0.3012., accu: 0.8365, speed: 1.18 step/s\n",
      "global step 8400, epoch: 2, batch: 3695, loss: 0.3201, ce_loss: 0.3201., accu: 0.8365, speed: 1.19 step/s\n",
      "2022-09-28 15:07:11,830\t[train.py-do_train]-[line:187]-INFO:【global step 8400, epoch: 2, batch: 3695】，loss: 0.3201, ce_loss: 0.3201., accu: 0.8365,\n",
      "global step 8410, epoch: 2, batch: 3705, loss: 0.2361, ce_loss: 0.2361., accu: 0.8366, speed: 1.20 step/s\n",
      "global step 8420, epoch: 2, batch: 3715, loss: 0.3029, ce_loss: 0.3029., accu: 0.8366, speed: 1.18 step/s\n",
      "global step 8430, epoch: 2, batch: 3725, loss: 0.3374, ce_loss: 0.3374., accu: 0.8367, speed: 1.18 step/s\n",
      "global step 8440, epoch: 2, batch: 3735, loss: 0.2815, ce_loss: 0.2815., accu: 0.8367, speed: 1.18 step/s\n",
      "global step 8450, epoch: 2, batch: 3745, loss: 0.3376, ce_loss: 0.3376., accu: 0.8367, speed: 1.18 step/s\n",
      "global step 8460, epoch: 2, batch: 3755, loss: 0.2209, ce_loss: 0.2209., accu: 0.8368, speed: 1.19 step/s\n",
      "global step 8470, epoch: 2, batch: 3765, loss: 0.3012, ce_loss: 0.3012., accu: 0.8369, speed: 1.20 step/s\n",
      "global step 8480, epoch: 2, batch: 3775, loss: 0.3575, ce_loss: 0.3575., accu: 0.8369, speed: 1.19 step/s\n",
      "global step 8490, epoch: 2, batch: 3785, loss: 0.2822, ce_loss: 0.2822., accu: 0.8369, speed: 1.19 step/s\n",
      "global step 8500, epoch: 2, batch: 3795, loss: 0.2346, ce_loss: 0.2346., accu: 0.8370, speed: 1.19 step/s\n",
      "2022-09-28 15:08:36,000\t[train.py-do_train]-[line:187]-INFO:【global step 8500, epoch: 2, batch: 3795】，loss: 0.2346, ce_loss: 0.2346., accu: 0.8370,\n",
      "global step 8510, epoch: 2, batch: 3805, loss: 0.3615, ce_loss: 0.3615., accu: 0.8370, speed: 1.18 step/s\n",
      "global step 8520, epoch: 2, batch: 3815, loss: 0.2208, ce_loss: 0.2208., accu: 0.8371, speed: 1.19 step/s\n",
      "global step 8530, epoch: 2, batch: 3825, loss: 0.3154, ce_loss: 0.3154., accu: 0.8371, speed: 1.18 step/s\n",
      "global step 8540, epoch: 2, batch: 3835, loss: 0.3705, ce_loss: 0.3705., accu: 0.8372, speed: 1.20 step/s\n",
      "global step 8550, epoch: 2, batch: 3845, loss: 0.2420, ce_loss: 0.2420., accu: 0.8372, speed: 1.18 step/s\n",
      "global step 8560, epoch: 2, batch: 3855, loss: 0.2423, ce_loss: 0.2423., accu: 0.8372, speed: 1.18 step/s\n",
      "global step 8570, epoch: 2, batch: 3865, loss: 0.3424, ce_loss: 0.3424., accu: 0.8373, speed: 1.20 step/s\n",
      "global step 8580, epoch: 2, batch: 3875, loss: 0.2267, ce_loss: 0.2267., accu: 0.8373, speed: 1.18 step/s\n",
      "global step 8590, epoch: 2, batch: 3885, loss: 0.2812, ce_loss: 0.2812., accu: 0.8374, speed: 1.18 step/s\n",
      "global step 8600, epoch: 2, batch: 3895, loss: 0.2958, ce_loss: 0.2958., accu: 0.8374, speed: 1.19 step/s\n",
      "2022-09-28 15:10:00,302\t[train.py-do_train]-[line:187]-INFO:【global step 8600, epoch: 2, batch: 3895】，loss: 0.2958, ce_loss: 0.2958., accu: 0.8374,\n",
      "global step 8610, epoch: 2, batch: 3905, loss: 0.2503, ce_loss: 0.2503., accu: 0.8375, speed: 1.20 step/s\n",
      "global step 8620, epoch: 2, batch: 3915, loss: 0.2928, ce_loss: 0.2928., accu: 0.8375, speed: 1.19 step/s\n",
      "global step 8630, epoch: 2, batch: 3925, loss: 0.2502, ce_loss: 0.2502., accu: 0.8376, speed: 1.19 step/s\n",
      "global step 8640, epoch: 2, batch: 3935, loss: 0.3957, ce_loss: 0.3957., accu: 0.8376, speed: 1.21 step/s\n",
      "global step 8650, epoch: 2, batch: 3945, loss: 0.3142, ce_loss: 0.3142., accu: 0.8377, speed: 1.20 step/s\n",
      "global step 8660, epoch: 2, batch: 3955, loss: 0.4135, ce_loss: 0.4135., accu: 0.8377, speed: 1.18 step/s\n",
      "global step 8670, epoch: 2, batch: 3965, loss: 0.2755, ce_loss: 0.2755., accu: 0.8378, speed: 1.20 step/s\n",
      "global step 8680, epoch: 2, batch: 3975, loss: 0.2637, ce_loss: 0.2637., accu: 0.8378, speed: 1.20 step/s\n",
      "global step 8690, epoch: 2, batch: 3985, loss: 0.2880, ce_loss: 0.2880., accu: 0.8379, speed: 1.18 step/s\n",
      "global step 8700, epoch: 2, batch: 3995, loss: 0.2347, ce_loss: 0.2347., accu: 0.8379, speed: 1.18 step/s\n",
      "2022-09-28 15:11:24,050\t[train.py-do_train]-[line:187]-INFO:【global step 8700, epoch: 2, batch: 3995】，loss: 0.2347, ce_loss: 0.2347., accu: 0.8379,\n",
      "global step 8710, epoch: 2, batch: 4005, loss: 0.2631, ce_loss: 0.2631., accu: 0.8380, speed: 1.18 step/s\n",
      "global step 8720, epoch: 2, batch: 4015, loss: 0.2865, ce_loss: 0.2865., accu: 0.8380, speed: 1.19 step/s\n",
      "global step 8730, epoch: 2, batch: 4025, loss: 0.2967, ce_loss: 0.2967., accu: 0.8380, speed: 1.18 step/s\n",
      "global step 8740, epoch: 2, batch: 4035, loss: 0.2883, ce_loss: 0.2883., accu: 0.8381, speed: 1.18 step/s\n",
      "global step 8750, epoch: 2, batch: 4045, loss: 0.2645, ce_loss: 0.2645., accu: 0.8381, speed: 1.19 step/s\n",
      "global step 8760, epoch: 2, batch: 4055, loss: 0.2359, ce_loss: 0.2359., accu: 0.8382, speed: 1.19 step/s\n",
      "global step 8770, epoch: 2, batch: 4065, loss: 0.2871, ce_loss: 0.2871., accu: 0.8382, speed: 1.18 step/s\n",
      "global step 8780, epoch: 2, batch: 4075, loss: 0.2865, ce_loss: 0.2865., accu: 0.8383, speed: 1.18 step/s\n",
      "global step 8790, epoch: 2, batch: 4085, loss: 0.3131, ce_loss: 0.3131., accu: 0.8383, speed: 1.19 step/s\n",
      "global step 8800, epoch: 2, batch: 4095, loss: 0.2855, ce_loss: 0.2855., accu: 0.8384, speed: 1.18 step/s\n",
      "2022-09-28 15:12:48,541\t[train.py-do_train]-[line:187]-INFO:【global step 8800, epoch: 2, batch: 4095】，loss: 0.2855, ce_loss: 0.2855., accu: 0.8384,\n",
      "global step 8810, epoch: 2, batch: 4105, loss: 0.2987, ce_loss: 0.2987., accu: 0.8384, speed: 1.19 step/s\n",
      "global step 8820, epoch: 2, batch: 4115, loss: 0.2095, ce_loss: 0.2095., accu: 0.8384, speed: 1.22 step/s\n",
      "global step 8830, epoch: 2, batch: 4125, loss: 0.3712, ce_loss: 0.3712., accu: 0.8385, speed: 1.19 step/s\n",
      "global step 8840, epoch: 2, batch: 4135, loss: 0.2466, ce_loss: 0.2466., accu: 0.8385, speed: 1.19 step/s\n",
      "global step 8850, epoch: 2, batch: 4145, loss: 0.2623, ce_loss: 0.2623., accu: 0.8385, speed: 1.18 step/s\n",
      "global step 8860, epoch: 2, batch: 4155, loss: 0.3356, ce_loss: 0.3356., accu: 0.8386, speed: 1.18 step/s\n",
      "global step 8870, epoch: 2, batch: 4165, loss: 0.2811, ce_loss: 0.2811., accu: 0.8386, speed: 1.18 step/s\n",
      "global step 8880, epoch: 2, batch: 4175, loss: 0.2188, ce_loss: 0.2188., accu: 0.8387, speed: 1.18 step/s\n",
      "global step 8890, epoch: 2, batch: 4185, loss: 0.2980, ce_loss: 0.2980., accu: 0.8387, speed: 1.18 step/s\n",
      "global step 8900, epoch: 2, batch: 4195, loss: 0.2721, ce_loss: 0.2721., accu: 0.8388, speed: 1.18 step/s\n",
      "2022-09-28 15:14:12,788\t[train.py-do_train]-[line:187]-INFO:【global step 8900, epoch: 2, batch: 4195】，loss: 0.2721, ce_loss: 0.2721., accu: 0.8388,\n",
      "global step 8910, epoch: 2, batch: 4205, loss: 0.2898, ce_loss: 0.2898., accu: 0.8388, speed: 1.18 step/s\n",
      "global step 8920, epoch: 2, batch: 4215, loss: 0.2608, ce_loss: 0.2608., accu: 0.8389, speed: 1.19 step/s\n",
      "global step 8930, epoch: 2, batch: 4225, loss: 0.2366, ce_loss: 0.2366., accu: 0.8389, speed: 1.18 step/s\n",
      "global step 8940, epoch: 2, batch: 4235, loss: 0.2102, ce_loss: 0.2102., accu: 0.8389, speed: 1.20 step/s\n",
      "global step 8950, epoch: 2, batch: 4245, loss: 0.3001, ce_loss: 0.3001., accu: 0.8390, speed: 1.20 step/s\n",
      "global step 8960, epoch: 2, batch: 4255, loss: 0.3131, ce_loss: 0.3131., accu: 0.8390, speed: 1.20 step/s\n",
      "global step 8970, epoch: 2, batch: 4265, loss: 0.2774, ce_loss: 0.2774., accu: 0.8391, speed: 1.19 step/s\n",
      "global step 8980, epoch: 2, batch: 4275, loss: 0.2976, ce_loss: 0.2976., accu: 0.8391, speed: 1.19 step/s\n",
      "global step 8990, epoch: 2, batch: 4285, loss: 0.3650, ce_loss: 0.3650., accu: 0.8392, speed: 1.18 step/s\n",
      "global step 9000, epoch: 2, batch: 4295, loss: 0.3106, ce_loss: 0.3106., accu: 0.8392, speed: 1.19 step/s\n",
      "2022-09-28 15:15:36,895\t[train.py-do_train]-[line:187]-INFO:【global step 9000, epoch: 2, batch: 4295】，loss: 0.3106, ce_loss: 0.3106., accu: 0.8392,\n",
      "global step 9010, epoch: 2, batch: 4305, loss: 0.2469, ce_loss: 0.2469., accu: 0.8392, speed: 1.18 step/s\n",
      "global step 9020, epoch: 2, batch: 4315, loss: 0.2185, ce_loss: 0.2185., accu: 0.8393, speed: 1.18 step/s\n",
      "global step 9030, epoch: 2, batch: 4325, loss: 0.3356, ce_loss: 0.3356., accu: 0.8393, speed: 1.18 step/s\n",
      "global step 9040, epoch: 2, batch: 4335, loss: 0.2403, ce_loss: 0.2403., accu: 0.8394, speed: 1.19 step/s\n",
      "global step 9050, epoch: 2, batch: 4345, loss: 0.1959, ce_loss: 0.1959., accu: 0.8394, speed: 1.19 step/s\n",
      "global step 9060, epoch: 2, batch: 4355, loss: 0.2458, ce_loss: 0.2458., accu: 0.8394, speed: 1.18 step/s\n",
      "global step 9070, epoch: 2, batch: 4365, loss: 0.3329, ce_loss: 0.3329., accu: 0.8395, speed: 1.18 step/s\n",
      "global step 9080, epoch: 2, batch: 4375, loss: 0.4126, ce_loss: 0.4126., accu: 0.8395, speed: 1.18 step/s\n",
      "global step 9090, epoch: 2, batch: 4385, loss: 0.4015, ce_loss: 0.4015., accu: 0.8396, speed: 1.18 step/s\n",
      "global step 9100, epoch: 2, batch: 4395, loss: 0.2800, ce_loss: 0.2800., accu: 0.8396, speed: 1.18 step/s\n",
      "2022-09-28 15:17:01,441\t[train.py-do_train]-[line:187]-INFO:【global step 9100, epoch: 2, batch: 4395】，loss: 0.2800, ce_loss: 0.2800., accu: 0.8396,\n",
      "global step 9110, epoch: 2, batch: 4405, loss: 0.2593, ce_loss: 0.2593., accu: 0.8396, speed: 1.18 step/s\n",
      "global step 9120, epoch: 2, batch: 4415, loss: 0.3097, ce_loss: 0.3097., accu: 0.8397, speed: 1.18 step/s\n",
      "global step 9130, epoch: 2, batch: 4425, loss: 0.1873, ce_loss: 0.1873., accu: 0.8397, speed: 1.19 step/s\n",
      "global step 9140, epoch: 2, batch: 4435, loss: 0.2226, ce_loss: 0.2226., accu: 0.8398, speed: 1.18 step/s\n",
      "global step 9150, epoch: 2, batch: 4445, loss: 0.2238, ce_loss: 0.2238., accu: 0.8398, speed: 1.21 step/s\n",
      "global step 9160, epoch: 2, batch: 4455, loss: 0.3220, ce_loss: 0.3220., accu: 0.8399, speed: 1.20 step/s\n",
      "global step 9170, epoch: 2, batch: 4465, loss: 0.3403, ce_loss: 0.3403., accu: 0.8399, speed: 1.19 step/s\n",
      "global step 9180, epoch: 2, batch: 4475, loss: 0.3196, ce_loss: 0.3196., accu: 0.8399, speed: 1.18 step/s\n",
      "global step 9190, epoch: 2, batch: 4485, loss: 0.3022, ce_loss: 0.3022., accu: 0.8400, speed: 1.19 step/s\n",
      "global step 9200, epoch: 2, batch: 4495, loss: 0.3031, ce_loss: 0.3031., accu: 0.8400, speed: 1.18 step/s\n",
      "2022-09-28 15:18:25,666\t[train.py-do_train]-[line:187]-INFO:【global step 9200, epoch: 2, batch: 4495】，loss: 0.3031, ce_loss: 0.3031., accu: 0.8400,\n",
      "global step 9210, epoch: 2, batch: 4505, loss: 0.2464, ce_loss: 0.2464., accu: 0.8400, speed: 1.19 step/s\n",
      "global step 9220, epoch: 2, batch: 4515, loss: 0.2778, ce_loss: 0.2778., accu: 0.8401, speed: 1.18 step/s\n",
      "global step 9230, epoch: 2, batch: 4525, loss: 0.2312, ce_loss: 0.2312., accu: 0.8401, speed: 1.19 step/s\n",
      "global step 9240, epoch: 2, batch: 4535, loss: 0.2778, ce_loss: 0.2778., accu: 0.8402, speed: 1.20 step/s\n",
      "global step 9250, epoch: 2, batch: 4545, loss: 0.2539, ce_loss: 0.2539., accu: 0.8402, speed: 1.18 step/s\n",
      "global step 9260, epoch: 2, batch: 4555, loss: 0.3674, ce_loss: 0.3674., accu: 0.8402, speed: 1.20 step/s\n",
      "global step 9270, epoch: 2, batch: 4565, loss: 0.2431, ce_loss: 0.2431., accu: 0.8403, speed: 1.19 step/s\n",
      "global step 9280, epoch: 2, batch: 4575, loss: 0.3451, ce_loss: 0.3451., accu: 0.8403, speed: 1.18 step/s\n",
      "global step 9290, epoch: 2, batch: 4585, loss: 0.1878, ce_loss: 0.1878., accu: 0.8404, speed: 1.19 step/s\n",
      "global step 9300, epoch: 2, batch: 4595, loss: 0.2438, ce_loss: 0.2438., accu: 0.8404, speed: 1.20 step/s\n",
      "2022-09-28 15:19:49,741\t[train.py-do_train]-[line:187]-INFO:【global step 9300, epoch: 2, batch: 4595】，loss: 0.2438, ce_loss: 0.2438., accu: 0.8404,\n",
      "global step 9310, epoch: 2, batch: 4605, loss: 0.2681, ce_loss: 0.2681., accu: 0.8404, speed: 1.19 step/s\n",
      "global step 9320, epoch: 2, batch: 4615, loss: 0.2484, ce_loss: 0.2484., accu: 0.8405, speed: 1.19 step/s\n",
      "global step 9330, epoch: 2, batch: 4625, loss: 0.2321, ce_loss: 0.2321., accu: 0.8405, speed: 1.19 step/s\n",
      "global step 9340, epoch: 2, batch: 4635, loss: 0.2290, ce_loss: 0.2290., accu: 0.8406, speed: 1.18 step/s\n",
      "global step 9350, epoch: 2, batch: 4645, loss: 0.2257, ce_loss: 0.2257., accu: 0.8406, speed: 1.20 step/s\n",
      "global step 9360, epoch: 2, batch: 4655, loss: 0.2676, ce_loss: 0.2676., accu: 0.8406, speed: 1.19 step/s\n",
      "global step 9370, epoch: 2, batch: 4665, loss: 0.2777, ce_loss: 0.2777., accu: 0.8407, speed: 1.22 step/s\n",
      "global step 9380, epoch: 2, batch: 4675, loss: 0.2671, ce_loss: 0.2671., accu: 0.8407, speed: 1.18 step/s\n",
      "global step 9390, epoch: 2, batch: 4685, loss: 0.3093, ce_loss: 0.3093., accu: 0.8408, speed: 1.19 step/s\n",
      "global step 9400, epoch: 2, batch: 4695, loss: 0.2832, ce_loss: 0.2832., accu: 0.8408, speed: 1.18 step/s\n",
      "2022-09-28 15:21:13,792\t[train.py-do_train]-[line:187]-INFO:【global step 9400, epoch: 2, batch: 4695】，loss: 0.2832, ce_loss: 0.2832., accu: 0.8408,\n",
      "global step 9410, epoch: 2, batch: 4705, loss: 0.5084, ce_loss: 0.5084., accu: 0.8408, speed: 1.28 step/s\n",
      " 40%|███████████████▌                       | 2/5 [2:12:05<3:18:09, 3963.02s/it]global step 9420, epoch: 3, batch: 10, loss: 0.2886, ce_loss: 0.2886., accu: 0.8409, speed: 1.15 step/s\n",
      "global step 9430, epoch: 3, batch: 20, loss: 0.3128, ce_loss: 0.3128., accu: 0.8409, speed: 1.19 step/s\n",
      "global step 9440, epoch: 3, batch: 30, loss: 0.2821, ce_loss: 0.2821., accu: 0.8409, speed: 1.18 step/s\n",
      "global step 9450, epoch: 3, batch: 40, loss: 0.2058, ce_loss: 0.2058., accu: 0.8410, speed: 1.19 step/s\n",
      "global step 9460, epoch: 3, batch: 50, loss: 0.2725, ce_loss: 0.2725., accu: 0.8410, speed: 1.18 step/s\n",
      "global step 9470, epoch: 3, batch: 60, loss: 0.2266, ce_loss: 0.2266., accu: 0.8411, speed: 1.19 step/s\n",
      "global step 9480, epoch: 3, batch: 70, loss: 0.2263, ce_loss: 0.2263., accu: 0.8411, speed: 1.18 step/s\n",
      "global step 9490, epoch: 3, batch: 80, loss: 0.2364, ce_loss: 0.2364., accu: 0.8412, speed: 1.18 step/s\n",
      "global step 9500, epoch: 3, batch: 90, loss: 0.1872, ce_loss: 0.1872., accu: 0.8412, speed: 1.18 step/s\n",
      "2022-09-28 15:22:37,879\t[train.py-do_train]-[line:187]-INFO:【global step 9500, epoch: 3, batch: 90】，loss: 0.1872, ce_loss: 0.1872., accu: 0.8412,\n",
      "global step 9510, epoch: 3, batch: 100, loss: 0.2325, ce_loss: 0.2325., accu: 0.8413, speed: 1.19 step/s\n",
      "global step 9520, epoch: 3, batch: 110, loss: 0.2677, ce_loss: 0.2677., accu: 0.8413, speed: 1.18 step/s\n",
      "global step 9530, epoch: 3, batch: 120, loss: 0.2080, ce_loss: 0.2080., accu: 0.8414, speed: 1.18 step/s\n",
      "global step 9540, epoch: 3, batch: 130, loss: 0.2143, ce_loss: 0.2143., accu: 0.8415, speed: 1.18 step/s\n",
      "global step 9550, epoch: 3, batch: 140, loss: 0.2392, ce_loss: 0.2392., accu: 0.8415, speed: 1.18 step/s\n",
      "global step 9560, epoch: 3, batch: 150, loss: 0.2713, ce_loss: 0.2713., accu: 0.8416, speed: 1.19 step/s\n",
      "global step 9570, epoch: 3, batch: 160, loss: 0.2349, ce_loss: 0.2349., accu: 0.8416, speed: 1.18 step/s\n",
      "global step 9580, epoch: 3, batch: 170, loss: 0.2836, ce_loss: 0.2836., accu: 0.8417, speed: 1.19 step/s\n",
      "global step 9590, epoch: 3, batch: 180, loss: 0.2834, ce_loss: 0.2834., accu: 0.8417, speed: 1.19 step/s\n",
      "global step 9600, epoch: 3, batch: 190, loss: 0.3235, ce_loss: 0.3235., accu: 0.8418, speed: 1.18 step/s\n",
      "2022-09-28 15:24:02,368\t[train.py-do_train]-[line:187]-INFO:【global step 9600, epoch: 3, batch: 190】，loss: 0.3235, ce_loss: 0.3235., accu: 0.8418,\n",
      "global step 9610, epoch: 3, batch: 200, loss: 0.2604, ce_loss: 0.2604., accu: 0.8418, speed: 1.19 step/s\n",
      "global step 9620, epoch: 3, batch: 210, loss: 0.2069, ce_loss: 0.2069., accu: 0.8419, speed: 1.20 step/s\n",
      "global step 9630, epoch: 3, batch: 220, loss: 0.2134, ce_loss: 0.2134., accu: 0.8419, speed: 1.18 step/s\n",
      "global step 9640, epoch: 3, batch: 230, loss: 0.1480, ce_loss: 0.1480., accu: 0.8420, speed: 1.18 step/s\n",
      "global step 9650, epoch: 3, batch: 240, loss: 0.1947, ce_loss: 0.1947., accu: 0.8420, speed: 1.18 step/s\n",
      "global step 9660, epoch: 3, batch: 250, loss: 0.2545, ce_loss: 0.2545., accu: 0.8421, speed: 1.18 step/s\n",
      "global step 9670, epoch: 3, batch: 260, loss: 0.3098, ce_loss: 0.3098., accu: 0.8422, speed: 1.18 step/s\n",
      "global step 9680, epoch: 3, batch: 270, loss: 0.2662, ce_loss: 0.2662., accu: 0.8422, speed: 1.20 step/s\n",
      "global step 9690, epoch: 3, batch: 280, loss: 0.3102, ce_loss: 0.3102., accu: 0.8423, speed: 1.18 step/s\n",
      "global step 9700, epoch: 3, batch: 290, loss: 0.2051, ce_loss: 0.2051., accu: 0.8423, speed: 1.18 step/s\n",
      "2022-09-28 15:25:26,755\t[train.py-do_train]-[line:187]-INFO:【global step 9700, epoch: 3, batch: 290】，loss: 0.2051, ce_loss: 0.2051., accu: 0.8423,\n",
      "global step 9710, epoch: 3, batch: 300, loss: 0.2415, ce_loss: 0.2415., accu: 0.8424, speed: 1.20 step/s\n",
      "global step 9720, epoch: 3, batch: 310, loss: 0.2390, ce_loss: 0.2390., accu: 0.8424, speed: 1.19 step/s\n",
      "global step 9730, epoch: 3, batch: 320, loss: 0.1960, ce_loss: 0.1960., accu: 0.8425, speed: 1.19 step/s\n",
      "global step 9740, epoch: 3, batch: 330, loss: 0.2296, ce_loss: 0.2296., accu: 0.8425, speed: 1.20 step/s\n",
      "global step 9750, epoch: 3, batch: 340, loss: 0.2644, ce_loss: 0.2644., accu: 0.8426, speed: 1.20 step/s\n",
      "global step 9760, epoch: 3, batch: 350, loss: 0.2894, ce_loss: 0.2894., accu: 0.8426, speed: 1.19 step/s\n",
      "global step 9770, epoch: 3, batch: 360, loss: 0.1964, ce_loss: 0.1964., accu: 0.8427, speed: 1.19 step/s\n",
      "global step 9780, epoch: 3, batch: 370, loss: 0.2101, ce_loss: 0.2101., accu: 0.8427, speed: 1.18 step/s\n",
      "global step 9790, epoch: 3, batch: 380, loss: 0.2379, ce_loss: 0.2379., accu: 0.8428, speed: 1.18 step/s\n",
      "global step 9800, epoch: 3, batch: 390, loss: 0.2626, ce_loss: 0.2626., accu: 0.8428, speed: 1.18 step/s\n",
      "2022-09-28 15:26:50,856\t[train.py-do_train]-[line:187]-INFO:【global step 9800, epoch: 3, batch: 390】，loss: 0.2626, ce_loss: 0.2626., accu: 0.8428,\n",
      "global step 9810, epoch: 3, batch: 400, loss: 0.2981, ce_loss: 0.2981., accu: 0.8429, speed: 1.22 step/s\n",
      "global step 9820, epoch: 3, batch: 410, loss: 0.2547, ce_loss: 0.2547., accu: 0.8429, speed: 1.18 step/s\n",
      "global step 9830, epoch: 3, batch: 420, loss: 0.2116, ce_loss: 0.2116., accu: 0.8429, speed: 1.19 step/s\n",
      "global step 9840, epoch: 3, batch: 430, loss: 0.3228, ce_loss: 0.3228., accu: 0.8430, speed: 1.18 step/s\n",
      "global step 9850, epoch: 3, batch: 440, loss: 0.1929, ce_loss: 0.1929., accu: 0.8430, speed: 1.19 step/s\n",
      "global step 9860, epoch: 3, batch: 450, loss: 0.2870, ce_loss: 0.2870., accu: 0.8431, speed: 1.18 step/s\n",
      "global step 9870, epoch: 3, batch: 460, loss: 0.3541, ce_loss: 0.3541., accu: 0.8431, speed: 1.18 step/s\n",
      "global step 9880, epoch: 3, batch: 470, loss: 0.2040, ce_loss: 0.2040., accu: 0.8432, speed: 1.18 step/s\n",
      "global step 9890, epoch: 3, batch: 480, loss: 0.2708, ce_loss: 0.2708., accu: 0.8432, speed: 1.19 step/s\n",
      "global step 9900, epoch: 3, batch: 490, loss: 0.3482, ce_loss: 0.3482., accu: 0.8433, speed: 1.19 step/s\n",
      "2022-09-28 15:28:15,060\t[train.py-do_train]-[line:187]-INFO:【global step 9900, epoch: 3, batch: 490】，loss: 0.3482, ce_loss: 0.3482., accu: 0.8433,\n",
      "global step 9910, epoch: 3, batch: 500, loss: 0.1764, ce_loss: 0.1764., accu: 0.8434, speed: 1.19 step/s\n",
      "global step 9920, epoch: 3, batch: 510, loss: 0.1629, ce_loss: 0.1629., accu: 0.8434, speed: 1.18 step/s\n",
      "global step 9930, epoch: 3, batch: 520, loss: 0.2432, ce_loss: 0.2432., accu: 0.8435, speed: 1.18 step/s\n",
      "global step 9940, epoch: 3, batch: 530, loss: 0.3177, ce_loss: 0.3177., accu: 0.8435, speed: 1.19 step/s\n",
      "global step 9950, epoch: 3, batch: 540, loss: 0.3516, ce_loss: 0.3516., accu: 0.8435, speed: 1.18 step/s\n",
      "global step 9960, epoch: 3, batch: 550, loss: 0.2083, ce_loss: 0.2083., accu: 0.8436, speed: 1.20 step/s\n",
      "global step 9970, epoch: 3, batch: 560, loss: 0.2882, ce_loss: 0.2882., accu: 0.8436, speed: 1.18 step/s\n",
      "global step 9980, epoch: 3, batch: 570, loss: 0.3025, ce_loss: 0.3025., accu: 0.8437, speed: 1.18 step/s\n",
      "global step 9990, epoch: 3, batch: 580, loss: 0.2481, ce_loss: 0.2481., accu: 0.8438, speed: 1.18 step/s\n",
      "global step 10000, epoch: 3, batch: 590, loss: 0.3486, ce_loss: 0.3486., accu: 0.8438, speed: 1.18 step/s\n",
      "2022-09-28 15:29:39,553\t[train.py-do_train]-[line:187]-INFO:【global step 10000, epoch: 3, batch: 590】，loss: 0.3486, ce_loss: 0.3486., accu: 0.8438,\n",
      "global step 10010, epoch: 3, batch: 600, loss: 0.2249, ce_loss: 0.2249., accu: 0.8438, speed: 1.19 step/s\n",
      "global step 10020, epoch: 3, batch: 610, loss: 0.2419, ce_loss: 0.2419., accu: 0.8439, speed: 1.19 step/s\n",
      "global step 10030, epoch: 3, batch: 620, loss: 0.3068, ce_loss: 0.3068., accu: 0.8439, speed: 1.19 step/s\n",
      "global step 10040, epoch: 3, batch: 630, loss: 0.2387, ce_loss: 0.2387., accu: 0.8440, speed: 1.22 step/s\n",
      "global step 10050, epoch: 3, batch: 640, loss: 0.3267, ce_loss: 0.3267., accu: 0.8440, speed: 1.18 step/s\n",
      "global step 10060, epoch: 3, batch: 650, loss: 0.3057, ce_loss: 0.3057., accu: 0.8441, speed: 1.18 step/s\n",
      "global step 10070, epoch: 3, batch: 660, loss: 0.2143, ce_loss: 0.2143., accu: 0.8441, speed: 1.17 step/s\n",
      "global step 10080, epoch: 3, batch: 670, loss: 0.2582, ce_loss: 0.2582., accu: 0.8441, speed: 1.21 step/s\n",
      "global step 10090, epoch: 3, batch: 680, loss: 0.1720, ce_loss: 0.1720., accu: 0.8442, speed: 1.17 step/s\n",
      "global step 10100, epoch: 3, batch: 690, loss: 0.2527, ce_loss: 0.2527., accu: 0.8442, speed: 1.20 step/s\n",
      "2022-09-28 15:31:03,625\t[train.py-do_train]-[line:187]-INFO:【global step 10100, epoch: 3, batch: 690】，loss: 0.2527, ce_loss: 0.2527., accu: 0.8442,\n",
      "global step 10110, epoch: 3, batch: 700, loss: 0.2356, ce_loss: 0.2356., accu: 0.8443, speed: 1.18 step/s\n",
      "global step 10120, epoch: 3, batch: 710, loss: 0.3189, ce_loss: 0.3189., accu: 0.8443, speed: 1.18 step/s\n",
      "global step 10130, epoch: 3, batch: 720, loss: 0.3077, ce_loss: 0.3077., accu: 0.8444, speed: 1.17 step/s\n",
      "global step 10140, epoch: 3, batch: 730, loss: 0.2081, ce_loss: 0.2081., accu: 0.8444, speed: 1.18 step/s\n",
      "global step 10150, epoch: 3, batch: 740, loss: 0.2587, ce_loss: 0.2587., accu: 0.8445, speed: 1.18 step/s\n",
      "global step 10160, epoch: 3, batch: 750, loss: 0.2082, ce_loss: 0.2082., accu: 0.8445, speed: 1.18 step/s\n",
      "global step 10170, epoch: 3, batch: 760, loss: 0.2473, ce_loss: 0.2473., accu: 0.8446, speed: 1.18 step/s\n",
      "global step 10180, epoch: 3, batch: 770, loss: 0.2520, ce_loss: 0.2520., accu: 0.8446, speed: 1.18 step/s\n",
      "global step 10190, epoch: 3, batch: 780, loss: 0.2340, ce_loss: 0.2340., accu: 0.8446, speed: 1.18 step/s\n",
      "global step 10200, epoch: 3, batch: 790, loss: 0.2882, ce_loss: 0.2882., accu: 0.8447, speed: 1.21 step/s\n",
      "2022-09-28 15:32:28,117\t[train.py-do_train]-[line:187]-INFO:【global step 10200, epoch: 3, batch: 790】，loss: 0.2882, ce_loss: 0.2882., accu: 0.8447,\n",
      "global step 10210, epoch: 3, batch: 800, loss: 0.2086, ce_loss: 0.2086., accu: 0.8447, speed: 1.18 step/s\n",
      "global step 10220, epoch: 3, batch: 810, loss: 0.2149, ce_loss: 0.2149., accu: 0.8448, speed: 1.19 step/s\n",
      "global step 10230, epoch: 3, batch: 820, loss: 0.2054, ce_loss: 0.2054., accu: 0.8448, speed: 1.20 step/s\n",
      "global step 10240, epoch: 3, batch: 830, loss: 0.2552, ce_loss: 0.2552., accu: 0.8449, speed: 1.18 step/s\n",
      "global step 10250, epoch: 3, batch: 840, loss: 0.2746, ce_loss: 0.2746., accu: 0.8449, speed: 1.18 step/s\n",
      "global step 10260, epoch: 3, batch: 850, loss: 0.2520, ce_loss: 0.2520., accu: 0.8450, speed: 1.19 step/s\n",
      "global step 10270, epoch: 3, batch: 860, loss: 0.2639, ce_loss: 0.2639., accu: 0.8450, speed: 1.18 step/s\n",
      "global step 10280, epoch: 3, batch: 870, loss: 0.2354, ce_loss: 0.2354., accu: 0.8451, speed: 1.18 step/s\n",
      "global step 10290, epoch: 3, batch: 880, loss: 0.2818, ce_loss: 0.2818., accu: 0.8451, speed: 1.19 step/s\n",
      "global step 10300, epoch: 3, batch: 890, loss: 0.2298, ce_loss: 0.2298., accu: 0.8452, speed: 1.19 step/s\n",
      "2022-09-28 15:33:52,401\t[train.py-do_train]-[line:187]-INFO:【global step 10300, epoch: 3, batch: 890】，loss: 0.2298, ce_loss: 0.2298., accu: 0.8452,\n",
      "global step 10310, epoch: 3, batch: 900, loss: 0.2927, ce_loss: 0.2927., accu: 0.8452, speed: 1.18 step/s\n",
      "global step 10320, epoch: 3, batch: 910, loss: 0.2461, ce_loss: 0.2461., accu: 0.8452, speed: 1.18 step/s\n",
      "global step 10330, epoch: 3, batch: 920, loss: 0.2026, ce_loss: 0.2026., accu: 0.8453, speed: 1.18 step/s\n",
      "global step 10340, epoch: 3, batch: 930, loss: 0.2249, ce_loss: 0.2249., accu: 0.8453, speed: 1.18 step/s\n",
      "global step 10350, epoch: 3, batch: 940, loss: 0.2787, ce_loss: 0.2787., accu: 0.8454, speed: 1.19 step/s\n",
      "global step 10360, epoch: 3, batch: 950, loss: 0.3563, ce_loss: 0.3563., accu: 0.8454, speed: 1.18 step/s\n",
      "global step 10370, epoch: 3, batch: 960, loss: 0.1658, ce_loss: 0.1658., accu: 0.8454, speed: 1.18 step/s\n",
      "global step 10380, epoch: 3, batch: 970, loss: 0.2412, ce_loss: 0.2412., accu: 0.8455, speed: 1.18 step/s\n",
      "global step 10390, epoch: 3, batch: 980, loss: 0.2740, ce_loss: 0.2740., accu: 0.8455, speed: 1.18 step/s\n",
      "global step 10400, epoch: 3, batch: 990, loss: 0.2221, ce_loss: 0.2221., accu: 0.8455, speed: 1.20 step/s\n",
      "2022-09-28 15:35:16,898\t[train.py-do_train]-[line:187]-INFO:【global step 10400, epoch: 3, batch: 990】，loss: 0.2221, ce_loss: 0.2221., accu: 0.8455,\n",
      "global step 10410, epoch: 3, batch: 1000, loss: 0.2398, ce_loss: 0.2398., accu: 0.8456, speed: 1.19 step/s\n",
      "global step 10420, epoch: 3, batch: 1010, loss: 0.2695, ce_loss: 0.2695., accu: 0.8456, speed: 1.19 step/s\n",
      "global step 10430, epoch: 3, batch: 1020, loss: 0.1772, ce_loss: 0.1772., accu: 0.8457, speed: 1.18 step/s\n",
      "global step 10440, epoch: 3, batch: 1030, loss: 0.1625, ce_loss: 0.1625., accu: 0.8457, speed: 1.18 step/s\n",
      "global step 10450, epoch: 3, batch: 1040, loss: 0.3659, ce_loss: 0.3659., accu: 0.8457, speed: 1.19 step/s\n",
      "global step 10460, epoch: 3, batch: 1050, loss: 0.2464, ce_loss: 0.2464., accu: 0.8458, speed: 1.18 step/s\n",
      "global step 10470, epoch: 3, batch: 1060, loss: 0.2071, ce_loss: 0.2071., accu: 0.8458, speed: 1.19 step/s\n",
      "global step 10480, epoch: 3, batch: 1070, loss: 0.3150, ce_loss: 0.3150., accu: 0.8459, speed: 1.19 step/s\n",
      "global step 10490, epoch: 3, batch: 1080, loss: 0.4402, ce_loss: 0.4402., accu: 0.8459, speed: 1.18 step/s\n",
      "global step 10500, epoch: 3, batch: 1090, loss: 0.3163, ce_loss: 0.3163., accu: 0.8460, speed: 1.18 step/s\n",
      "2022-09-28 15:36:41,322\t[train.py-do_train]-[line:187]-INFO:【global step 10500, epoch: 3, batch: 1090】，loss: 0.3163, ce_loss: 0.3163., accu: 0.8460,\n",
      "global step 10510, epoch: 3, batch: 1100, loss: 0.1914, ce_loss: 0.1914., accu: 0.8460, speed: 1.18 step/s\n",
      "global step 10520, epoch: 3, batch: 1110, loss: 0.1881, ce_loss: 0.1881., accu: 0.8461, speed: 1.19 step/s\n",
      "global step 10530, epoch: 3, batch: 1120, loss: 0.1601, ce_loss: 0.1601., accu: 0.8461, speed: 1.19 step/s\n",
      "global step 10540, epoch: 3, batch: 1130, loss: 0.1782, ce_loss: 0.1782., accu: 0.8462, speed: 1.18 step/s\n",
      "global step 10550, epoch: 3, batch: 1140, loss: 0.2821, ce_loss: 0.2821., accu: 0.8462, speed: 1.19 step/s\n",
      "global step 10560, epoch: 3, batch: 1150, loss: 0.2125, ce_loss: 0.2125., accu: 0.8463, speed: 1.18 step/s\n",
      "global step 10570, epoch: 3, batch: 1160, loss: 0.2958, ce_loss: 0.2958., accu: 0.8463, speed: 1.17 step/s\n",
      "global step 10580, epoch: 3, batch: 1170, loss: 0.2361, ce_loss: 0.2361., accu: 0.8463, speed: 1.19 step/s\n",
      "global step 10590, epoch: 3, batch: 1180, loss: 0.2144, ce_loss: 0.2144., accu: 0.8464, speed: 1.18 step/s\n",
      "global step 10600, epoch: 3, batch: 1190, loss: 0.2071, ce_loss: 0.2071., accu: 0.8464, speed: 1.18 step/s\n",
      "2022-09-28 15:38:05,898\t[train.py-do_train]-[line:187]-INFO:【global step 10600, epoch: 3, batch: 1190】，loss: 0.2071, ce_loss: 0.2071., accu: 0.8464,\n",
      "global step 10610, epoch: 3, batch: 1200, loss: 0.2232, ce_loss: 0.2232., accu: 0.8465, speed: 1.20 step/s\n",
      "global step 10620, epoch: 3, batch: 1210, loss: 0.2091, ce_loss: 0.2091., accu: 0.8465, speed: 1.20 step/s\n",
      "global step 10630, epoch: 3, batch: 1220, loss: 0.2562, ce_loss: 0.2562., accu: 0.8466, speed: 1.21 step/s\n",
      "global step 10640, epoch: 3, batch: 1230, loss: 0.2301, ce_loss: 0.2301., accu: 0.8466, speed: 1.20 step/s\n",
      "global step 10650, epoch: 3, batch: 1240, loss: 0.2145, ce_loss: 0.2145., accu: 0.8467, speed: 1.19 step/s\n",
      "global step 10660, epoch: 3, batch: 1250, loss: 0.3321, ce_loss: 0.3321., accu: 0.8467, speed: 1.18 step/s\n",
      "global step 10670, epoch: 3, batch: 1260, loss: 0.1840, ce_loss: 0.1840., accu: 0.8468, speed: 1.21 step/s\n",
      "global step 10680, epoch: 3, batch: 1270, loss: 0.1591, ce_loss: 0.1591., accu: 0.8468, speed: 1.18 step/s\n",
      "global step 10690, epoch: 3, batch: 1280, loss: 0.3789, ce_loss: 0.3789., accu: 0.8469, speed: 1.18 step/s\n",
      "global step 10700, epoch: 3, batch: 1290, loss: 0.1770, ce_loss: 0.1770., accu: 0.8469, speed: 1.18 step/s\n",
      "2022-09-28 15:39:29,899\t[train.py-do_train]-[line:187]-INFO:【global step 10700, epoch: 3, batch: 1290】，loss: 0.1770, ce_loss: 0.1770., accu: 0.8469,\n",
      "global step 10710, epoch: 3, batch: 1300, loss: 0.2502, ce_loss: 0.2502., accu: 0.8469, speed: 1.18 step/s\n",
      "global step 10720, epoch: 3, batch: 1310, loss: 0.2208, ce_loss: 0.2208., accu: 0.8470, speed: 1.19 step/s\n",
      "global step 10730, epoch: 3, batch: 1320, loss: 0.2253, ce_loss: 0.2253., accu: 0.8470, speed: 1.19 step/s\n",
      "global step 10740, epoch: 3, batch: 1330, loss: 0.1868, ce_loss: 0.1868., accu: 0.8471, speed: 1.18 step/s\n",
      "global step 10750, epoch: 3, batch: 1340, loss: 0.1720, ce_loss: 0.1720., accu: 0.8471, speed: 1.18 step/s\n",
      "global step 10760, epoch: 3, batch: 1350, loss: 0.2737, ce_loss: 0.2737., accu: 0.8472, speed: 1.19 step/s\n",
      "global step 10770, epoch: 3, batch: 1360, loss: 0.3312, ce_loss: 0.3312., accu: 0.8472, speed: 1.18 step/s\n",
      "global step 10780, epoch: 3, batch: 1370, loss: 0.2645, ce_loss: 0.2645., accu: 0.8473, speed: 1.18 step/s\n",
      "global step 10790, epoch: 3, batch: 1380, loss: 0.3005, ce_loss: 0.3005., accu: 0.8473, speed: 1.19 step/s\n",
      "global step 10800, epoch: 3, batch: 1390, loss: 0.2221, ce_loss: 0.2221., accu: 0.8474, speed: 1.18 step/s\n",
      "2022-09-28 15:40:54,385\t[train.py-do_train]-[line:187]-INFO:【global step 10800, epoch: 3, batch: 1390】，loss: 0.2221, ce_loss: 0.2221., accu: 0.8474,\n",
      "global step 10810, epoch: 3, batch: 1400, loss: 0.2665, ce_loss: 0.2665., accu: 0.8474, speed: 1.20 step/s\n",
      "global step 10820, epoch: 3, batch: 1410, loss: 0.1857, ce_loss: 0.1857., accu: 0.8474, speed: 1.19 step/s\n",
      "global step 10830, epoch: 3, batch: 1420, loss: 0.3050, ce_loss: 0.3050., accu: 0.8475, speed: 1.18 step/s\n",
      "global step 10840, epoch: 3, batch: 1430, loss: 0.2367, ce_loss: 0.2367., accu: 0.8475, speed: 1.18 step/s\n",
      "global step 10850, epoch: 3, batch: 1440, loss: 0.2537, ce_loss: 0.2537., accu: 0.8476, speed: 1.19 step/s\n",
      "global step 10860, epoch: 3, batch: 1450, loss: 0.2719, ce_loss: 0.2719., accu: 0.8476, speed: 1.18 step/s\n",
      "global step 10870, epoch: 3, batch: 1460, loss: 0.2116, ce_loss: 0.2116., accu: 0.8477, speed: 1.20 step/s\n",
      "global step 10880, epoch: 3, batch: 1470, loss: 0.2311, ce_loss: 0.2311., accu: 0.8477, speed: 1.18 step/s\n",
      "global step 10890, epoch: 3, batch: 1480, loss: 0.1873, ce_loss: 0.1873., accu: 0.8477, speed: 1.19 step/s\n",
      "global step 10900, epoch: 3, batch: 1490, loss: 0.2758, ce_loss: 0.2758., accu: 0.8478, speed: 1.19 step/s\n",
      "2022-09-28 15:42:18,587\t[train.py-do_train]-[line:187]-INFO:【global step 10900, epoch: 3, batch: 1490】，loss: 0.2758, ce_loss: 0.2758., accu: 0.8478,\n",
      "global step 10910, epoch: 3, batch: 1500, loss: 0.2956, ce_loss: 0.2956., accu: 0.8478, speed: 1.19 step/s\n",
      "global step 10920, epoch: 3, batch: 1510, loss: 0.3187, ce_loss: 0.3187., accu: 0.8479, speed: 1.18 step/s\n",
      "global step 10930, epoch: 3, batch: 1520, loss: 0.2657, ce_loss: 0.2657., accu: 0.8479, speed: 1.18 step/s\n",
      "global step 10940, epoch: 3, batch: 1530, loss: 0.2423, ce_loss: 0.2423., accu: 0.8479, speed: 1.19 step/s\n",
      "global step 10950, epoch: 3, batch: 1540, loss: 0.2386, ce_loss: 0.2386., accu: 0.8480, speed: 1.19 step/s\n",
      "global step 10960, epoch: 3, batch: 1550, loss: 0.3182, ce_loss: 0.3182., accu: 0.8480, speed: 1.19 step/s\n",
      "global step 10970, epoch: 3, batch: 1560, loss: 0.2173, ce_loss: 0.2173., accu: 0.8480, speed: 1.18 step/s\n",
      "global step 10980, epoch: 3, batch: 1570, loss: 0.2863, ce_loss: 0.2863., accu: 0.8481, speed: 1.19 step/s\n",
      "global step 10990, epoch: 3, batch: 1580, loss: 0.2259, ce_loss: 0.2259., accu: 0.8481, speed: 1.19 step/s\n",
      "global step 11000, epoch: 3, batch: 1590, loss: 0.2094, ce_loss: 0.2094., accu: 0.8482, speed: 1.19 step/s\n",
      "2022-09-28 15:43:42,951\t[train.py-do_train]-[line:187]-INFO:【global step 11000, epoch: 3, batch: 1590】，loss: 0.2094, ce_loss: 0.2094., accu: 0.8482,\n",
      "global step 11010, epoch: 3, batch: 1600, loss: 0.1908, ce_loss: 0.1908., accu: 0.8482, speed: 1.20 step/s\n",
      "global step 11020, epoch: 3, batch: 1610, loss: 0.2865, ce_loss: 0.2865., accu: 0.8482, speed: 1.19 step/s\n",
      "global step 11030, epoch: 3, batch: 1620, loss: 0.2072, ce_loss: 0.2072., accu: 0.8483, speed: 1.18 step/s\n",
      "global step 11040, epoch: 3, batch: 1630, loss: 0.2246, ce_loss: 0.2246., accu: 0.8483, speed: 1.20 step/s\n",
      "global step 11050, epoch: 3, batch: 1640, loss: 0.2399, ce_loss: 0.2399., accu: 0.8484, speed: 1.18 step/s\n",
      "global step 11060, epoch: 3, batch: 1650, loss: 0.2661, ce_loss: 0.2661., accu: 0.8484, speed: 1.18 step/s\n",
      "global step 11070, epoch: 3, batch: 1660, loss: 0.2559, ce_loss: 0.2559., accu: 0.8484, speed: 1.20 step/s\n",
      "global step 11080, epoch: 3, batch: 1670, loss: 0.2739, ce_loss: 0.2739., accu: 0.8485, speed: 1.18 step/s\n",
      "global step 11090, epoch: 3, batch: 1680, loss: 0.2601, ce_loss: 0.2601., accu: 0.8485, speed: 1.18 step/s\n",
      "global step 11100, epoch: 3, batch: 1690, loss: 0.2976, ce_loss: 0.2976., accu: 0.8485, speed: 1.18 step/s\n",
      "2022-09-28 15:45:07,192\t[train.py-do_train]-[line:187]-INFO:【global step 11100, epoch: 3, batch: 1690】，loss: 0.2976, ce_loss: 0.2976., accu: 0.8485,\n",
      "global step 11110, epoch: 3, batch: 1700, loss: 0.2175, ce_loss: 0.2175., accu: 0.8486, speed: 1.20 step/s\n",
      "global step 11120, epoch: 3, batch: 1710, loss: 0.2144, ce_loss: 0.2144., accu: 0.8486, speed: 1.20 step/s\n",
      "global step 11130, epoch: 3, batch: 1720, loss: 0.3005, ce_loss: 0.3005., accu: 0.8487, speed: 1.19 step/s\n",
      "global step 11140, epoch: 3, batch: 1730, loss: 0.1760, ce_loss: 0.1760., accu: 0.8487, speed: 1.19 step/s\n",
      "global step 11150, epoch: 3, batch: 1740, loss: 0.2363, ce_loss: 0.2363., accu: 0.8488, speed: 1.18 step/s\n",
      "global step 11160, epoch: 3, batch: 1750, loss: 0.1936, ce_loss: 0.1936., accu: 0.8488, speed: 1.19 step/s\n",
      "global step 11170, epoch: 3, batch: 1760, loss: 0.2333, ce_loss: 0.2333., accu: 0.8488, speed: 1.18 step/s\n",
      "global step 11180, epoch: 3, batch: 1770, loss: 0.2364, ce_loss: 0.2364., accu: 0.8489, speed: 1.18 step/s\n",
      "global step 11190, epoch: 3, batch: 1780, loss: 0.2294, ce_loss: 0.2294., accu: 0.8489, speed: 1.21 step/s\n",
      "global step 11200, epoch: 3, batch: 1790, loss: 0.3037, ce_loss: 0.3037., accu: 0.8489, speed: 1.18 step/s\n",
      "2022-09-28 15:46:31,213\t[train.py-do_train]-[line:187]-INFO:【global step 11200, epoch: 3, batch: 1790】，loss: 0.3037, ce_loss: 0.3037., accu: 0.8489,\n",
      "global step 11210, epoch: 3, batch: 1800, loss: 0.2437, ce_loss: 0.2437., accu: 0.8490, speed: 1.18 step/s\n",
      "global step 11220, epoch: 3, batch: 1810, loss: 0.2500, ce_loss: 0.2500., accu: 0.8490, speed: 1.19 step/s\n",
      "global step 11230, epoch: 3, batch: 1820, loss: 0.2216, ce_loss: 0.2216., accu: 0.8491, speed: 1.18 step/s\n",
      "global step 11240, epoch: 3, batch: 1830, loss: 0.2406, ce_loss: 0.2406., accu: 0.8491, speed: 1.20 step/s\n",
      "global step 11250, epoch: 3, batch: 1840, loss: 0.2184, ce_loss: 0.2184., accu: 0.8492, speed: 1.18 step/s\n",
      "global step 11260, epoch: 3, batch: 1850, loss: 0.2755, ce_loss: 0.2755., accu: 0.8492, speed: 1.18 step/s\n",
      "global step 11270, epoch: 3, batch: 1860, loss: 0.2149, ce_loss: 0.2149., accu: 0.8492, speed: 1.19 step/s\n",
      "global step 11280, epoch: 3, batch: 1870, loss: 0.2479, ce_loss: 0.2479., accu: 0.8493, speed: 1.19 step/s\n",
      "global step 11290, epoch: 3, batch: 1880, loss: 0.2751, ce_loss: 0.2751., accu: 0.8493, speed: 1.19 step/s\n",
      "global step 11300, epoch: 3, batch: 1890, loss: 0.2265, ce_loss: 0.2265., accu: 0.8493, speed: 1.20 step/s\n",
      "2022-09-28 15:47:55,408\t[train.py-do_train]-[line:187]-INFO:【global step 11300, epoch: 3, batch: 1890】，loss: 0.2265, ce_loss: 0.2265., accu: 0.8493,\n",
      "global step 11310, epoch: 3, batch: 1900, loss: 0.3368, ce_loss: 0.3368., accu: 0.8494, speed: 1.19 step/s\n",
      "global step 11320, epoch: 3, batch: 1910, loss: 0.2476, ce_loss: 0.2476., accu: 0.8494, speed: 1.18 step/s\n",
      "global step 11330, epoch: 3, batch: 1920, loss: 0.2107, ce_loss: 0.2107., accu: 0.8495, speed: 1.19 step/s\n",
      "global step 11340, epoch: 3, batch: 1930, loss: 0.2838, ce_loss: 0.2838., accu: 0.8495, speed: 1.18 step/s\n",
      "global step 11350, epoch: 3, batch: 1940, loss: 0.2067, ce_loss: 0.2067., accu: 0.8495, speed: 1.18 step/s\n",
      "global step 11360, epoch: 3, batch: 1950, loss: 0.2649, ce_loss: 0.2649., accu: 0.8496, speed: 1.18 step/s\n",
      "global step 11370, epoch: 3, batch: 1960, loss: 0.3405, ce_loss: 0.3405., accu: 0.8496, speed: 1.19 step/s\n",
      "global step 11380, epoch: 3, batch: 1970, loss: 0.2858, ce_loss: 0.2858., accu: 0.8496, speed: 1.18 step/s\n",
      "global step 11390, epoch: 3, batch: 1980, loss: 0.2488, ce_loss: 0.2488., accu: 0.8497, speed: 1.19 step/s\n",
      "global step 11400, epoch: 3, batch: 1990, loss: 0.3079, ce_loss: 0.3079., accu: 0.8497, speed: 1.20 step/s\n",
      "2022-09-28 15:49:19,788\t[train.py-do_train]-[line:187]-INFO:【global step 11400, epoch: 3, batch: 1990】，loss: 0.3079, ce_loss: 0.3079., accu: 0.8497,\n",
      "global step 11410, epoch: 3, batch: 2000, loss: 0.1804, ce_loss: 0.1804., accu: 0.8497, speed: 1.20 step/s\n",
      "global step 11420, epoch: 3, batch: 2010, loss: 0.2581, ce_loss: 0.2581., accu: 0.8498, speed: 1.18 step/s\n",
      "global step 11430, epoch: 3, batch: 2020, loss: 0.2524, ce_loss: 0.2524., accu: 0.8498, speed: 1.21 step/s\n",
      "global step 11440, epoch: 3, batch: 2030, loss: 0.2701, ce_loss: 0.2701., accu: 0.8498, speed: 1.19 step/s\n",
      "global step 11450, epoch: 3, batch: 2040, loss: 0.2447, ce_loss: 0.2447., accu: 0.8499, speed: 1.18 step/s\n",
      "global step 11460, epoch: 3, batch: 2050, loss: 0.1816, ce_loss: 0.1816., accu: 0.8499, speed: 1.19 step/s\n",
      "global step 11470, epoch: 3, batch: 2060, loss: 0.2451, ce_loss: 0.2451., accu: 0.8500, speed: 1.20 step/s\n",
      "global step 11480, epoch: 3, batch: 2070, loss: 0.2033, ce_loss: 0.2033., accu: 0.8500, speed: 1.20 step/s\n",
      "global step 11490, epoch: 3, batch: 2080, loss: 0.3001, ce_loss: 0.3001., accu: 0.8500, speed: 1.19 step/s\n",
      "global step 11500, epoch: 3, batch: 2090, loss: 0.2538, ce_loss: 0.2538., accu: 0.8501, speed: 1.19 step/s\n",
      "2022-09-28 15:50:43,637\t[train.py-do_train]-[line:187]-INFO:【global step 11500, epoch: 3, batch: 2090】，loss: 0.2538, ce_loss: 0.2538., accu: 0.8501,\n",
      "global step 11510, epoch: 3, batch: 2100, loss: 0.2501, ce_loss: 0.2501., accu: 0.8501, speed: 1.19 step/s\n",
      "global step 11520, epoch: 3, batch: 2110, loss: 0.2414, ce_loss: 0.2414., accu: 0.8501, speed: 1.18 step/s\n",
      "global step 11530, epoch: 3, batch: 2120, loss: 0.2170, ce_loss: 0.2170., accu: 0.8502, speed: 1.18 step/s\n",
      "global step 11540, epoch: 3, batch: 2130, loss: 0.1974, ce_loss: 0.1974., accu: 0.8502, speed: 1.18 step/s\n",
      "global step 11550, epoch: 3, batch: 2140, loss: 0.2345, ce_loss: 0.2345., accu: 0.8502, speed: 1.19 step/s\n",
      "global step 11560, epoch: 3, batch: 2150, loss: 0.2358, ce_loss: 0.2358., accu: 0.8503, speed: 1.18 step/s\n",
      "global step 11570, epoch: 3, batch: 2160, loss: 0.2261, ce_loss: 0.2261., accu: 0.8503, speed: 1.18 step/s\n",
      "global step 11580, epoch: 3, batch: 2170, loss: 0.2521, ce_loss: 0.2521., accu: 0.8503, speed: 1.18 step/s\n",
      "global step 11590, epoch: 3, batch: 2180, loss: 0.3110, ce_loss: 0.3110., accu: 0.8504, speed: 1.19 step/s\n",
      "global step 11600, epoch: 3, batch: 2190, loss: 0.2807, ce_loss: 0.2807., accu: 0.8504, speed: 1.17 step/s\n",
      "2022-09-28 15:52:08,274\t[train.py-do_train]-[line:187]-INFO:【global step 11600, epoch: 3, batch: 2190】，loss: 0.2807, ce_loss: 0.2807., accu: 0.8504,\n",
      "global step 11610, epoch: 3, batch: 2200, loss: 0.2249, ce_loss: 0.2249., accu: 0.8505, speed: 1.19 step/s\n",
      "global step 11620, epoch: 3, batch: 2210, loss: 0.2733, ce_loss: 0.2733., accu: 0.8505, speed: 1.18 step/s\n",
      "global step 11630, epoch: 3, batch: 2220, loss: 0.2353, ce_loss: 0.2353., accu: 0.8505, speed: 1.18 step/s\n",
      "global step 11640, epoch: 3, batch: 2230, loss: 0.2204, ce_loss: 0.2204., accu: 0.8506, speed: 1.18 step/s\n",
      "global step 11650, epoch: 3, batch: 2240, loss: 0.2105, ce_loss: 0.2105., accu: 0.8506, speed: 1.18 step/s\n",
      "global step 11660, epoch: 3, batch: 2250, loss: 0.2510, ce_loss: 0.2510., accu: 0.8507, speed: 1.18 step/s\n",
      "global step 11670, epoch: 3, batch: 2260, loss: 0.2340, ce_loss: 0.2340., accu: 0.8507, speed: 1.21 step/s\n",
      "global step 11680, epoch: 3, batch: 2270, loss: 0.2022, ce_loss: 0.2022., accu: 0.8507, speed: 1.20 step/s\n",
      "global step 11690, epoch: 3, batch: 2280, loss: 0.2269, ce_loss: 0.2269., accu: 0.8508, speed: 1.18 step/s\n",
      "global step 11700, epoch: 3, batch: 2290, loss: 0.1949, ce_loss: 0.1949., accu: 0.8508, speed: 1.18 step/s\n",
      "2022-09-28 15:53:32,687\t[train.py-do_train]-[line:187]-INFO:【global step 11700, epoch: 3, batch: 2290】，loss: 0.1949, ce_loss: 0.1949., accu: 0.8508,\n",
      "global step 11710, epoch: 3, batch: 2300, loss: 0.2750, ce_loss: 0.2750., accu: 0.8508, speed: 1.20 step/s\n",
      "global step 11720, epoch: 3, batch: 2310, loss: 0.2411, ce_loss: 0.2411., accu: 0.8509, speed: 1.19 step/s\n",
      "global step 11730, epoch: 3, batch: 2320, loss: 0.2743, ce_loss: 0.2743., accu: 0.8509, speed: 1.18 step/s\n",
      "global step 11740, epoch: 3, batch: 2330, loss: 0.2348, ce_loss: 0.2348., accu: 0.8509, speed: 1.20 step/s\n",
      "global step 11750, epoch: 3, batch: 2340, loss: 0.3301, ce_loss: 0.3301., accu: 0.8510, speed: 1.20 step/s\n",
      "global step 11760, epoch: 3, batch: 2350, loss: 0.2217, ce_loss: 0.2217., accu: 0.8510, speed: 1.19 step/s\n",
      "global step 11770, epoch: 3, batch: 2360, loss: 0.1782, ce_loss: 0.1782., accu: 0.8510, speed: 1.18 step/s\n",
      "global step 11780, epoch: 3, batch: 2370, loss: 0.2356, ce_loss: 0.2356., accu: 0.8511, speed: 1.18 step/s\n",
      "global step 11790, epoch: 3, batch: 2380, loss: 0.2491, ce_loss: 0.2491., accu: 0.8511, speed: 1.18 step/s\n",
      "global step 11800, epoch: 3, batch: 2390, loss: 0.2747, ce_loss: 0.2747., accu: 0.8511, speed: 1.18 step/s\n",
      "2022-09-28 15:54:56,902\t[train.py-do_train]-[line:187]-INFO:【global step 11800, epoch: 3, batch: 2390】，loss: 0.2747, ce_loss: 0.2747., accu: 0.8511,\n",
      "global step 11810, epoch: 3, batch: 2400, loss: 0.2466, ce_loss: 0.2466., accu: 0.8512, speed: 1.19 step/s\n",
      "global step 11820, epoch: 3, batch: 2410, loss: 0.3292, ce_loss: 0.3292., accu: 0.8512, speed: 1.19 step/s\n",
      "global step 11830, epoch: 3, batch: 2420, loss: 0.2529, ce_loss: 0.2529., accu: 0.8512, speed: 1.20 step/s\n",
      "global step 11840, epoch: 3, batch: 2430, loss: 0.2625, ce_loss: 0.2625., accu: 0.8513, speed: 1.18 step/s\n",
      "global step 11850, epoch: 3, batch: 2440, loss: 0.2138, ce_loss: 0.2138., accu: 0.8513, speed: 1.18 step/s\n",
      "global step 11860, epoch: 3, batch: 2450, loss: 0.2300, ce_loss: 0.2300., accu: 0.8514, speed: 1.19 step/s\n",
      "global step 11870, epoch: 3, batch: 2460, loss: 0.2915, ce_loss: 0.2915., accu: 0.8514, speed: 1.19 step/s\n",
      "global step 11880, epoch: 3, batch: 2470, loss: 0.2943, ce_loss: 0.2943., accu: 0.8514, speed: 1.20 step/s\n",
      "global step 11890, epoch: 3, batch: 2480, loss: 0.2277, ce_loss: 0.2277., accu: 0.8515, speed: 1.19 step/s\n",
      "global step 11900, epoch: 3, batch: 2490, loss: 0.1892, ce_loss: 0.1892., accu: 0.8515, speed: 1.19 step/s\n",
      "2022-09-28 15:56:20,955\t[train.py-do_train]-[line:187]-INFO:【global step 11900, epoch: 3, batch: 2490】，loss: 0.1892, ce_loss: 0.1892., accu: 0.8515,\n",
      "global step 11910, epoch: 3, batch: 2500, loss: 0.2311, ce_loss: 0.2311., accu: 0.8516, speed: 1.19 step/s\n",
      "global step 11920, epoch: 3, batch: 2510, loss: 0.2328, ce_loss: 0.2328., accu: 0.8516, speed: 1.19 step/s\n",
      "global step 11930, epoch: 3, batch: 2520, loss: 0.2176, ce_loss: 0.2176., accu: 0.8516, speed: 1.19 step/s\n",
      "global step 11940, epoch: 3, batch: 2530, loss: 0.2677, ce_loss: 0.2677., accu: 0.8517, speed: 1.18 step/s\n",
      "global step 11950, epoch: 3, batch: 2540, loss: 0.2286, ce_loss: 0.2286., accu: 0.8517, speed: 1.19 step/s\n",
      "global step 11960, epoch: 3, batch: 2550, loss: 0.2246, ce_loss: 0.2246., accu: 0.8517, speed: 1.19 step/s\n",
      "global step 11970, epoch: 3, batch: 2560, loss: 0.3000, ce_loss: 0.3000., accu: 0.8518, speed: 1.18 step/s\n",
      "global step 11980, epoch: 3, batch: 2570, loss: 0.2843, ce_loss: 0.2843., accu: 0.8518, speed: 1.18 step/s\n",
      "global step 11990, epoch: 3, batch: 2580, loss: 0.2308, ce_loss: 0.2308., accu: 0.8519, speed: 1.18 step/s\n",
      "global step 12000, epoch: 3, batch: 2590, loss: 0.2119, ce_loss: 0.2119., accu: 0.8519, speed: 1.18 step/s\n",
      "2022-09-28 15:57:45,251\t[train.py-do_train]-[line:187]-INFO:【global step 12000, epoch: 3, batch: 2590】，loss: 0.2119, ce_loss: 0.2119., accu: 0.8519,\n",
      "global step 12010, epoch: 3, batch: 2600, loss: 0.2158, ce_loss: 0.2158., accu: 0.8519, speed: 1.19 step/s\n",
      "global step 12020, epoch: 3, batch: 2610, loss: 0.1812, ce_loss: 0.1812., accu: 0.8520, speed: 1.19 step/s\n",
      "global step 12030, epoch: 3, batch: 2620, loss: 0.2132, ce_loss: 0.2132., accu: 0.8520, speed: 1.18 step/s\n",
      "global step 12040, epoch: 3, batch: 2630, loss: 0.2346, ce_loss: 0.2346., accu: 0.8520, speed: 1.18 step/s\n",
      "global step 12050, epoch: 3, batch: 2640, loss: 0.2799, ce_loss: 0.2799., accu: 0.8521, speed: 1.18 step/s\n",
      "global step 12060, epoch: 3, batch: 2650, loss: 0.2138, ce_loss: 0.2138., accu: 0.8521, speed: 1.21 step/s\n",
      "global step 12070, epoch: 3, batch: 2660, loss: 0.2618, ce_loss: 0.2618., accu: 0.8521, speed: 1.18 step/s\n",
      "global step 12080, epoch: 3, batch: 2670, loss: 0.2108, ce_loss: 0.2108., accu: 0.8521, speed: 1.19 step/s\n",
      "global step 12090, epoch: 3, batch: 2680, loss: 0.2728, ce_loss: 0.2728., accu: 0.8522, speed: 1.18 step/s\n",
      "global step 12100, epoch: 3, batch: 2690, loss: 0.1649, ce_loss: 0.1649., accu: 0.8522, speed: 1.20 step/s\n",
      "2022-09-28 15:59:09,409\t[train.py-do_train]-[line:187]-INFO:【global step 12100, epoch: 3, batch: 2690】，loss: 0.1649, ce_loss: 0.1649., accu: 0.8522,\n",
      "global step 12110, epoch: 3, batch: 2700, loss: 0.2444, ce_loss: 0.2444., accu: 0.8523, speed: 1.19 step/s\n",
      "global step 12120, epoch: 3, batch: 2710, loss: 0.1561, ce_loss: 0.1561., accu: 0.8523, speed: 1.18 step/s\n",
      "global step 12130, epoch: 3, batch: 2720, loss: 0.2475, ce_loss: 0.2475., accu: 0.8523, speed: 1.18 step/s\n",
      "global step 12140, epoch: 3, batch: 2730, loss: 0.2052, ce_loss: 0.2052., accu: 0.8524, speed: 1.20 step/s\n",
      "global step 12150, epoch: 3, batch: 2740, loss: 0.1835, ce_loss: 0.1835., accu: 0.8524, speed: 1.20 step/s\n",
      "global step 12160, epoch: 3, batch: 2750, loss: 0.2207, ce_loss: 0.2207., accu: 0.8524, speed: 1.19 step/s\n",
      "global step 12170, epoch: 3, batch: 2760, loss: 0.2559, ce_loss: 0.2559., accu: 0.8525, speed: 1.19 step/s\n",
      "global step 12180, epoch: 3, batch: 2770, loss: 0.2386, ce_loss: 0.2386., accu: 0.8525, speed: 1.18 step/s\n",
      "global step 12190, epoch: 3, batch: 2780, loss: 0.2074, ce_loss: 0.2074., accu: 0.8526, speed: 1.20 step/s\n",
      "global step 12200, epoch: 3, batch: 2790, loss: 0.2022, ce_loss: 0.2022., accu: 0.8526, speed: 1.19 step/s\n",
      "2022-09-28 16:00:33,489\t[train.py-do_train]-[line:187]-INFO:【global step 12200, epoch: 3, batch: 2790】，loss: 0.2022, ce_loss: 0.2022., accu: 0.8526,\n",
      "global step 12210, epoch: 3, batch: 2800, loss: 0.2986, ce_loss: 0.2986., accu: 0.8526, speed: 1.19 step/s\n",
      "global step 12220, epoch: 3, batch: 2810, loss: 0.1927, ce_loss: 0.1927., accu: 0.8527, speed: 1.19 step/s\n",
      "global step 12230, epoch: 3, batch: 2820, loss: 0.2509, ce_loss: 0.2509., accu: 0.8527, speed: 1.19 step/s\n",
      "global step 12240, epoch: 3, batch: 2830, loss: 0.2819, ce_loss: 0.2819., accu: 0.8527, speed: 1.18 step/s\n",
      "global step 12250, epoch: 3, batch: 2840, loss: 0.1978, ce_loss: 0.1978., accu: 0.8528, speed: 1.18 step/s\n",
      "global step 12260, epoch: 3, batch: 2850, loss: 0.2664, ce_loss: 0.2664., accu: 0.8528, speed: 1.18 step/s\n",
      "global step 12270, epoch: 3, batch: 2860, loss: 0.2092, ce_loss: 0.2092., accu: 0.8528, speed: 1.19 step/s\n",
      "global step 12280, epoch: 3, batch: 2870, loss: 0.2826, ce_loss: 0.2826., accu: 0.8528, speed: 1.19 step/s\n",
      "global step 12290, epoch: 3, batch: 2880, loss: 0.2155, ce_loss: 0.2155., accu: 0.8529, speed: 1.18 step/s\n",
      "global step 12300, epoch: 3, batch: 2890, loss: 0.2496, ce_loss: 0.2496., accu: 0.8529, speed: 1.18 step/s\n",
      "2022-09-28 16:01:57,955\t[train.py-do_train]-[line:187]-INFO:【global step 12300, epoch: 3, batch: 2890】，loss: 0.2496, ce_loss: 0.2496., accu: 0.8529,\n",
      "global step 12310, epoch: 3, batch: 2900, loss: 0.3717, ce_loss: 0.3717., accu: 0.8529, speed: 1.20 step/s\n",
      "global step 12320, epoch: 3, batch: 2910, loss: 0.2755, ce_loss: 0.2755., accu: 0.8530, speed: 1.18 step/s\n",
      "global step 12330, epoch: 3, batch: 2920, loss: 0.2616, ce_loss: 0.2616., accu: 0.8530, speed: 1.18 step/s\n",
      "global step 12340, epoch: 3, batch: 2930, loss: 0.2483, ce_loss: 0.2483., accu: 0.8530, speed: 1.21 step/s\n",
      "global step 12350, epoch: 3, batch: 2940, loss: 0.2573, ce_loss: 0.2573., accu: 0.8530, speed: 1.20 step/s\n",
      "global step 12360, epoch: 3, batch: 2950, loss: 0.2157, ce_loss: 0.2157., accu: 0.8531, speed: 1.19 step/s\n",
      "global step 12370, epoch: 3, batch: 2960, loss: 0.1965, ce_loss: 0.1965., accu: 0.8531, speed: 1.18 step/s\n",
      "global step 12380, epoch: 3, batch: 2970, loss: 0.1857, ce_loss: 0.1857., accu: 0.8532, speed: 1.18 step/s\n",
      "global step 12390, epoch: 3, batch: 2980, loss: 0.2495, ce_loss: 0.2495., accu: 0.8532, speed: 1.18 step/s\n",
      "global step 12400, epoch: 3, batch: 2990, loss: 0.3201, ce_loss: 0.3201., accu: 0.8532, speed: 1.18 step/s\n",
      "2022-09-28 16:03:22,139\t[train.py-do_train]-[line:187]-INFO:【global step 12400, epoch: 3, batch: 2990】，loss: 0.3201, ce_loss: 0.3201., accu: 0.8532,\n",
      "global step 12410, epoch: 3, batch: 3000, loss: 0.3090, ce_loss: 0.3090., accu: 0.8533, speed: 1.21 step/s\n",
      "global step 12420, epoch: 3, batch: 3010, loss: 0.2390, ce_loss: 0.2390., accu: 0.8533, speed: 1.18 step/s\n",
      "global step 12430, epoch: 3, batch: 3020, loss: 0.2333, ce_loss: 0.2333., accu: 0.8533, speed: 1.19 step/s\n",
      "global step 12440, epoch: 3, batch: 3030, loss: 0.2276, ce_loss: 0.2276., accu: 0.8533, speed: 1.20 step/s\n",
      "global step 12450, epoch: 3, batch: 3040, loss: 0.1942, ce_loss: 0.1942., accu: 0.8534, speed: 1.21 step/s\n",
      "global step 12460, epoch: 3, batch: 3050, loss: 0.1824, ce_loss: 0.1824., accu: 0.8534, speed: 1.18 step/s\n",
      "global step 12470, epoch: 3, batch: 3060, loss: 0.2049, ce_loss: 0.2049., accu: 0.8534, speed: 1.20 step/s\n",
      "global step 12480, epoch: 3, batch: 3070, loss: 0.3583, ce_loss: 0.3583., accu: 0.8535, speed: 1.20 step/s\n",
      "global step 12490, epoch: 3, batch: 3080, loss: 0.2694, ce_loss: 0.2694., accu: 0.8535, speed: 1.19 step/s\n",
      "global step 12500, epoch: 3, batch: 3090, loss: 0.3113, ce_loss: 0.3113., accu: 0.8535, speed: 1.18 step/s\n",
      "2022-09-28 16:04:45,952\t[train.py-do_train]-[line:187]-INFO:【global step 12500, epoch: 3, batch: 3090】，loss: 0.3113, ce_loss: 0.3113., accu: 0.8535,\n",
      "global step 12510, epoch: 3, batch: 3100, loss: 0.1786, ce_loss: 0.1786., accu: 0.8536, speed: 1.18 step/s\n",
      "global step 12520, epoch: 3, batch: 3110, loss: 0.3400, ce_loss: 0.3400., accu: 0.8536, speed: 1.20 step/s\n",
      "global step 12530, epoch: 3, batch: 3120, loss: 0.3083, ce_loss: 0.3083., accu: 0.8536, speed: 1.20 step/s\n",
      "global step 12540, epoch: 3, batch: 3130, loss: 0.2528, ce_loss: 0.2528., accu: 0.8537, speed: 1.18 step/s\n",
      "global step 12550, epoch: 3, batch: 3140, loss: 0.2833, ce_loss: 0.2833., accu: 0.8537, speed: 1.20 step/s\n",
      "global step 12560, epoch: 3, batch: 3150, loss: 0.2310, ce_loss: 0.2310., accu: 0.8537, speed: 1.19 step/s\n",
      "global step 12570, epoch: 3, batch: 3160, loss: 0.2245, ce_loss: 0.2245., accu: 0.8537, speed: 1.18 step/s\n",
      "global step 12580, epoch: 3, batch: 3170, loss: 0.2717, ce_loss: 0.2717., accu: 0.8538, speed: 1.19 step/s\n",
      "global step 12590, epoch: 3, batch: 3180, loss: 0.2832, ce_loss: 0.2832., accu: 0.8538, speed: 1.20 step/s\n",
      "global step 12600, epoch: 3, batch: 3190, loss: 0.2313, ce_loss: 0.2313., accu: 0.8538, speed: 1.18 step/s\n",
      "2022-09-28 16:06:09,939\t[train.py-do_train]-[line:187]-INFO:【global step 12600, epoch: 3, batch: 3190】，loss: 0.2313, ce_loss: 0.2313., accu: 0.8538,\n",
      "global step 12610, epoch: 3, batch: 3200, loss: 0.1657, ce_loss: 0.1657., accu: 0.8539, speed: 1.18 step/s\n",
      "global step 12620, epoch: 3, batch: 3210, loss: 0.2757, ce_loss: 0.2757., accu: 0.8539, speed: 1.18 step/s\n",
      "global step 12630, epoch: 3, batch: 3220, loss: 0.1692, ce_loss: 0.1692., accu: 0.8539, speed: 1.21 step/s\n",
      "global step 12640, epoch: 3, batch: 3230, loss: 0.2948, ce_loss: 0.2948., accu: 0.8540, speed: 1.18 step/s\n",
      "global step 12650, epoch: 3, batch: 3240, loss: 0.2465, ce_loss: 0.2465., accu: 0.8540, speed: 1.18 step/s\n",
      "global step 12660, epoch: 3, batch: 3250, loss: 0.2733, ce_loss: 0.2733., accu: 0.8540, speed: 1.19 step/s\n",
      "global step 12670, epoch: 3, batch: 3260, loss: 0.2558, ce_loss: 0.2558., accu: 0.8541, speed: 1.20 step/s\n",
      "global step 12680, epoch: 3, batch: 3270, loss: 0.1969, ce_loss: 0.1969., accu: 0.8541, speed: 1.18 step/s\n",
      "global step 12690, epoch: 3, batch: 3280, loss: 0.2893, ce_loss: 0.2893., accu: 0.8541, speed: 1.18 step/s\n",
      "global step 12700, epoch: 3, batch: 3290, loss: 0.2656, ce_loss: 0.2656., accu: 0.8542, speed: 1.19 step/s\n",
      "2022-09-28 16:07:34,134\t[train.py-do_train]-[line:187]-INFO:【global step 12700, epoch: 3, batch: 3290】，loss: 0.2656, ce_loss: 0.2656., accu: 0.8542,\n",
      "global step 12710, epoch: 3, batch: 3300, loss: 0.2551, ce_loss: 0.2551., accu: 0.8542, speed: 1.18 step/s\n",
      "global step 12720, epoch: 3, batch: 3310, loss: 0.1664, ce_loss: 0.1664., accu: 0.8542, speed: 1.20 step/s\n",
      "global step 12730, epoch: 3, batch: 3320, loss: 0.1807, ce_loss: 0.1807., accu: 0.8543, speed: 1.19 step/s\n",
      "global step 12740, epoch: 3, batch: 3330, loss: 0.2698, ce_loss: 0.2698., accu: 0.8543, speed: 1.20 step/s\n",
      "global step 12750, epoch: 3, batch: 3340, loss: 0.2824, ce_loss: 0.2824., accu: 0.8543, speed: 1.20 step/s\n",
      "global step 12760, epoch: 3, batch: 3350, loss: 0.2015, ce_loss: 0.2015., accu: 0.8543, speed: 1.18 step/s\n",
      "global step 12770, epoch: 3, batch: 3360, loss: 0.2919, ce_loss: 0.2919., accu: 0.8544, speed: 1.20 step/s\n",
      "global step 12780, epoch: 3, batch: 3370, loss: 0.2581, ce_loss: 0.2581., accu: 0.8544, speed: 1.18 step/s\n",
      "global step 12790, epoch: 3, batch: 3380, loss: 0.2651, ce_loss: 0.2651., accu: 0.8544, speed: 1.18 step/s\n",
      "global step 12800, epoch: 3, batch: 3390, loss: 0.2737, ce_loss: 0.2737., accu: 0.8545, speed: 1.18 step/s\n",
      "2022-09-28 16:08:58,176\t[train.py-do_train]-[line:187]-INFO:【global step 12800, epoch: 3, batch: 3390】，loss: 0.2737, ce_loss: 0.2737., accu: 0.8545,\n",
      "global step 12810, epoch: 3, batch: 3400, loss: 0.2365, ce_loss: 0.2365., accu: 0.8545, speed: 1.21 step/s\n",
      "global step 12820, epoch: 3, batch: 3410, loss: 0.2243, ce_loss: 0.2243., accu: 0.8545, speed: 1.18 step/s\n",
      "global step 12830, epoch: 3, batch: 3420, loss: 0.3129, ce_loss: 0.3129., accu: 0.8546, speed: 1.18 step/s\n",
      "global step 12840, epoch: 3, batch: 3430, loss: 0.3267, ce_loss: 0.3267., accu: 0.8546, speed: 1.18 step/s\n",
      "global step 12850, epoch: 3, batch: 3440, loss: 0.2912, ce_loss: 0.2912., accu: 0.8546, speed: 1.18 step/s\n",
      "global step 12860, epoch: 3, batch: 3450, loss: 0.2157, ce_loss: 0.2157., accu: 0.8547, speed: 1.19 step/s\n",
      "global step 12870, epoch: 3, batch: 3460, loss: 0.1860, ce_loss: 0.1860., accu: 0.8547, speed: 1.18 step/s\n",
      "global step 12880, epoch: 3, batch: 3470, loss: 0.2454, ce_loss: 0.2454., accu: 0.8547, speed: 1.19 step/s\n",
      "global step 12890, epoch: 3, batch: 3480, loss: 0.2774, ce_loss: 0.2774., accu: 0.8547, speed: 1.19 step/s\n",
      "global step 12900, epoch: 3, batch: 3490, loss: 0.2925, ce_loss: 0.2925., accu: 0.8548, speed: 1.19 step/s\n",
      "2022-09-28 16:10:22,426\t[train.py-do_train]-[line:187]-INFO:【global step 12900, epoch: 3, batch: 3490】，loss: 0.2925, ce_loss: 0.2925., accu: 0.8548,\n",
      "global step 12910, epoch: 3, batch: 3500, loss: 0.2613, ce_loss: 0.2613., accu: 0.8548, speed: 1.18 step/s\n",
      "global step 12920, epoch: 3, batch: 3510, loss: 0.2632, ce_loss: 0.2632., accu: 0.8548, speed: 1.18 step/s\n",
      "global step 12930, epoch: 3, batch: 3520, loss: 0.2838, ce_loss: 0.2838., accu: 0.8549, speed: 1.18 step/s\n",
      "global step 12940, epoch: 3, batch: 3530, loss: 0.2215, ce_loss: 0.2215., accu: 0.8549, speed: 1.19 step/s\n",
      "global step 12950, epoch: 3, batch: 3540, loss: 0.2810, ce_loss: 0.2810., accu: 0.8550, speed: 1.20 step/s\n",
      "global step 12960, epoch: 3, batch: 3550, loss: 0.3051, ce_loss: 0.3051., accu: 0.8550, speed: 1.20 step/s\n",
      "global step 12970, epoch: 3, batch: 3560, loss: 0.2656, ce_loss: 0.2656., accu: 0.8550, speed: 1.18 step/s\n",
      "global step 12980, epoch: 3, batch: 3570, loss: 0.2143, ce_loss: 0.2143., accu: 0.8551, speed: 1.18 step/s\n",
      "global step 12990, epoch: 3, batch: 3580, loss: 0.2097, ce_loss: 0.2097., accu: 0.8551, speed: 1.19 step/s\n",
      "global step 13000, epoch: 3, batch: 3590, loss: 0.2027, ce_loss: 0.2027., accu: 0.8551, speed: 1.19 step/s\n",
      "2022-09-28 16:11:46,691\t[train.py-do_train]-[line:187]-INFO:【global step 13000, epoch: 3, batch: 3590】，loss: 0.2027, ce_loss: 0.2027., accu: 0.8551,\n",
      "global step 13010, epoch: 3, batch: 3600, loss: 0.2155, ce_loss: 0.2155., accu: 0.8552, speed: 1.18 step/s\n",
      "global step 13020, epoch: 3, batch: 3610, loss: 0.2971, ce_loss: 0.2971., accu: 0.8552, speed: 1.20 step/s\n",
      "global step 13030, epoch: 3, batch: 3620, loss: 0.1500, ce_loss: 0.1500., accu: 0.8552, speed: 1.19 step/s\n",
      "global step 13040, epoch: 3, batch: 3630, loss: 0.2624, ce_loss: 0.2624., accu: 0.8553, speed: 1.19 step/s\n",
      "global step 13050, epoch: 3, batch: 3640, loss: 0.2807, ce_loss: 0.2807., accu: 0.8553, speed: 1.18 step/s\n",
      "global step 13060, epoch: 3, batch: 3650, loss: 0.3491, ce_loss: 0.3491., accu: 0.8553, speed: 1.18 step/s\n",
      "global step 13070, epoch: 3, batch: 3660, loss: 0.2521, ce_loss: 0.2521., accu: 0.8553, speed: 1.18 step/s\n",
      "global step 13080, epoch: 3, batch: 3670, loss: 0.2881, ce_loss: 0.2881., accu: 0.8554, speed: 1.18 step/s\n",
      "global step 13090, epoch: 3, batch: 3680, loss: 0.2342, ce_loss: 0.2342., accu: 0.8554, speed: 1.20 step/s\n",
      "global step 13100, epoch: 3, batch: 3690, loss: 0.2116, ce_loss: 0.2116., accu: 0.8554, speed: 1.18 step/s\n",
      "2022-09-28 16:13:10,982\t[train.py-do_train]-[line:187]-INFO:【global step 13100, epoch: 3, batch: 3690】，loss: 0.2116, ce_loss: 0.2116., accu: 0.8554,\n",
      "global step 13110, epoch: 3, batch: 3700, loss: 0.2369, ce_loss: 0.2369., accu: 0.8555, speed: 1.18 step/s\n",
      "global step 13120, epoch: 3, batch: 3710, loss: 0.2177, ce_loss: 0.2177., accu: 0.8555, speed: 1.18 step/s\n",
      "global step 13130, epoch: 3, batch: 3720, loss: 0.2438, ce_loss: 0.2438., accu: 0.8555, speed: 1.19 step/s\n",
      "global step 13140, epoch: 3, batch: 3730, loss: 0.2868, ce_loss: 0.2868., accu: 0.8556, speed: 1.19 step/s\n",
      "global step 13150, epoch: 3, batch: 3740, loss: 0.2149, ce_loss: 0.2149., accu: 0.8556, speed: 1.19 step/s\n",
      "global step 13160, epoch: 3, batch: 3750, loss: 0.2333, ce_loss: 0.2333., accu: 0.8556, speed: 1.18 step/s\n",
      "global step 13170, epoch: 3, batch: 3760, loss: 0.2758, ce_loss: 0.2758., accu: 0.8557, speed: 1.18 step/s\n",
      "global step 13180, epoch: 3, batch: 3770, loss: 0.2580, ce_loss: 0.2580., accu: 0.8557, speed: 1.18 step/s\n",
      "global step 13190, epoch: 3, batch: 3780, loss: 0.1963, ce_loss: 0.1963., accu: 0.8557, speed: 1.18 step/s\n",
      "global step 13200, epoch: 3, batch: 3790, loss: 0.2823, ce_loss: 0.2823., accu: 0.8557, speed: 1.18 step/s\n",
      "2022-09-28 16:14:35,520\t[train.py-do_train]-[line:187]-INFO:【global step 13200, epoch: 3, batch: 3790】，loss: 0.2823, ce_loss: 0.2823., accu: 0.8557,\n",
      "global step 13210, epoch: 3, batch: 3800, loss: 0.2686, ce_loss: 0.2686., accu: 0.8558, speed: 1.18 step/s\n",
      "global step 13220, epoch: 3, batch: 3810, loss: 0.3177, ce_loss: 0.3177., accu: 0.8558, speed: 1.17 step/s\n",
      "global step 13230, epoch: 3, batch: 3820, loss: 0.2806, ce_loss: 0.2806., accu: 0.8558, speed: 1.18 step/s\n",
      "global step 13240, epoch: 3, batch: 3830, loss: 0.2441, ce_loss: 0.2441., accu: 0.8558, speed: 1.20 step/s\n",
      "global step 13250, epoch: 3, batch: 3840, loss: 0.1827, ce_loss: 0.1827., accu: 0.8559, speed: 1.18 step/s\n",
      "global step 13260, epoch: 3, batch: 3850, loss: 0.2236, ce_loss: 0.2236., accu: 0.8559, speed: 1.18 step/s\n",
      "global step 13270, epoch: 3, batch: 3860, loss: 0.1740, ce_loss: 0.1740., accu: 0.8559, speed: 1.18 step/s\n",
      "global step 13280, epoch: 3, batch: 3870, loss: 0.2189, ce_loss: 0.2189., accu: 0.8560, speed: 1.18 step/s\n",
      "global step 13290, epoch: 3, batch: 3880, loss: 0.2172, ce_loss: 0.2172., accu: 0.8560, speed: 1.19 step/s\n",
      "global step 13300, epoch: 3, batch: 3890, loss: 0.2535, ce_loss: 0.2535., accu: 0.8560, speed: 1.19 step/s\n",
      "2022-09-28 16:16:00,002\t[train.py-do_train]-[line:187]-INFO:【global step 13300, epoch: 3, batch: 3890】，loss: 0.2535, ce_loss: 0.2535., accu: 0.8560,\n",
      "global step 13310, epoch: 3, batch: 3900, loss: 0.2394, ce_loss: 0.2394., accu: 0.8561, speed: 1.19 step/s\n",
      "global step 13320, epoch: 3, batch: 3910, loss: 0.1729, ce_loss: 0.1729., accu: 0.8561, speed: 1.18 step/s\n",
      "global step 13330, epoch: 3, batch: 3920, loss: 0.2129, ce_loss: 0.2129., accu: 0.8561, speed: 1.18 step/s\n",
      "global step 13340, epoch: 3, batch: 3930, loss: 0.2099, ce_loss: 0.2099., accu: 0.8561, speed: 1.18 step/s\n",
      "global step 13350, epoch: 3, batch: 3940, loss: 0.2365, ce_loss: 0.2365., accu: 0.8562, speed: 1.18 step/s\n",
      "global step 13360, epoch: 3, batch: 3950, loss: 0.2339, ce_loss: 0.2339., accu: 0.8562, speed: 1.18 step/s\n",
      "global step 13370, epoch: 3, batch: 3960, loss: 0.2355, ce_loss: 0.2355., accu: 0.8562, speed: 1.19 step/s\n",
      "global step 13380, epoch: 3, batch: 3970, loss: 0.3420, ce_loss: 0.3420., accu: 0.8563, speed: 1.21 step/s\n",
      "global step 13390, epoch: 3, batch: 3980, loss: 0.2746, ce_loss: 0.2746., accu: 0.8563, speed: 1.20 step/s\n",
      "global step 13400, epoch: 3, batch: 3990, loss: 0.2189, ce_loss: 0.2189., accu: 0.8563, speed: 1.18 step/s\n",
      "2022-09-28 16:17:24,194\t[train.py-do_train]-[line:187]-INFO:【global step 13400, epoch: 3, batch: 3990】，loss: 0.2189, ce_loss: 0.2189., accu: 0.8563,\n",
      "global step 13410, epoch: 3, batch: 4000, loss: 0.2765, ce_loss: 0.2765., accu: 0.8564, speed: 1.18 step/s\n",
      "global step 13420, epoch: 3, batch: 4010, loss: 0.2343, ce_loss: 0.2343., accu: 0.8564, speed: 1.18 step/s\n",
      "global step 13430, epoch: 3, batch: 4020, loss: 0.1993, ce_loss: 0.1993., accu: 0.8564, speed: 1.18 step/s\n",
      "global step 13440, epoch: 3, batch: 4030, loss: 0.2445, ce_loss: 0.2445., accu: 0.8564, speed: 1.18 step/s\n",
      "global step 13450, epoch: 3, batch: 4040, loss: 0.2718, ce_loss: 0.2718., accu: 0.8565, speed: 1.18 step/s\n",
      "global step 13460, epoch: 3, batch: 4050, loss: 0.3186, ce_loss: 0.3186., accu: 0.8565, speed: 1.18 step/s\n",
      "global step 13470, epoch: 3, batch: 4060, loss: 0.3004, ce_loss: 0.3004., accu: 0.8565, speed: 1.20 step/s\n",
      "global step 13480, epoch: 3, batch: 4070, loss: 0.1979, ce_loss: 0.1979., accu: 0.8566, speed: 1.22 step/s\n",
      "global step 13490, epoch: 3, batch: 4080, loss: 0.1934, ce_loss: 0.1934., accu: 0.8566, speed: 1.18 step/s\n",
      "global step 13500, epoch: 3, batch: 4090, loss: 0.2735, ce_loss: 0.2735., accu: 0.8566, speed: 1.18 step/s\n",
      "2022-09-28 16:18:48,615\t[train.py-do_train]-[line:187]-INFO:【global step 13500, epoch: 3, batch: 4090】，loss: 0.2735, ce_loss: 0.2735., accu: 0.8566,\n",
      "global step 13510, epoch: 3, batch: 4100, loss: 0.2200, ce_loss: 0.2200., accu: 0.8566, speed: 1.20 step/s\n",
      "global step 13520, epoch: 3, batch: 4110, loss: 0.2076, ce_loss: 0.2076., accu: 0.8567, speed: 1.18 step/s\n",
      "global step 13530, epoch: 3, batch: 4120, loss: 0.3265, ce_loss: 0.3265., accu: 0.8567, speed: 1.18 step/s\n",
      "global step 13540, epoch: 3, batch: 4130, loss: 0.2295, ce_loss: 0.2295., accu: 0.8567, speed: 1.19 step/s\n",
      "global step 13550, epoch: 3, batch: 4140, loss: 0.2763, ce_loss: 0.2763., accu: 0.8568, speed: 1.19 step/s\n",
      "global step 13560, epoch: 3, batch: 4150, loss: 0.2801, ce_loss: 0.2801., accu: 0.8568, speed: 1.18 step/s\n",
      "global step 13570, epoch: 3, batch: 4160, loss: 0.2767, ce_loss: 0.2767., accu: 0.8568, speed: 1.18 step/s\n",
      "global step 13580, epoch: 3, batch: 4170, loss: 0.2682, ce_loss: 0.2682., accu: 0.8568, speed: 1.19 step/s\n",
      "global step 13590, epoch: 3, batch: 4180, loss: 0.2391, ce_loss: 0.2391., accu: 0.8569, speed: 1.18 step/s\n",
      "global step 13600, epoch: 3, batch: 4190, loss: 0.1882, ce_loss: 0.1882., accu: 0.8569, speed: 1.18 step/s\n",
      "2022-09-28 16:20:12,916\t[train.py-do_train]-[line:187]-INFO:【global step 13600, epoch: 3, batch: 4190】，loss: 0.1882, ce_loss: 0.1882., accu: 0.8569,\n",
      "global step 13610, epoch: 3, batch: 4200, loss: 0.2629, ce_loss: 0.2629., accu: 0.8569, speed: 1.18 step/s\n",
      "global step 13620, epoch: 3, batch: 4210, loss: 0.2564, ce_loss: 0.2564., accu: 0.8569, speed: 1.18 step/s\n",
      "global step 13630, epoch: 3, batch: 4220, loss: 0.2090, ce_loss: 0.2090., accu: 0.8570, speed: 1.19 step/s\n",
      "global step 13640, epoch: 3, batch: 4230, loss: 0.2524, ce_loss: 0.2524., accu: 0.8570, speed: 1.17 step/s\n",
      "global step 13650, epoch: 3, batch: 4240, loss: 0.2671, ce_loss: 0.2671., accu: 0.8570, speed: 1.20 step/s\n",
      "global step 13660, epoch: 3, batch: 4250, loss: 0.2537, ce_loss: 0.2537., accu: 0.8571, speed: 1.18 step/s\n",
      "global step 13670, epoch: 3, batch: 4260, loss: 0.2544, ce_loss: 0.2544., accu: 0.8571, speed: 1.17 step/s\n",
      "global step 13680, epoch: 3, batch: 4270, loss: 0.3000, ce_loss: 0.3000., accu: 0.8571, speed: 1.18 step/s\n",
      "global step 13690, epoch: 3, batch: 4280, loss: 0.2777, ce_loss: 0.2777., accu: 0.8572, speed: 1.17 step/s\n",
      "global step 13700, epoch: 3, batch: 4290, loss: 0.2194, ce_loss: 0.2194., accu: 0.8572, speed: 1.19 step/s\n",
      "2022-09-28 16:21:37,435\t[train.py-do_train]-[line:187]-INFO:【global step 13700, epoch: 3, batch: 4290】，loss: 0.2194, ce_loss: 0.2194., accu: 0.8572,\n",
      "global step 13710, epoch: 3, batch: 4300, loss: 0.2152, ce_loss: 0.2152., accu: 0.8572, speed: 1.18 step/s\n",
      "global step 13720, epoch: 3, batch: 4310, loss: 0.2058, ce_loss: 0.2058., accu: 0.8573, speed: 1.18 step/s\n",
      "global step 13730, epoch: 3, batch: 4320, loss: 0.3781, ce_loss: 0.3781., accu: 0.8573, speed: 1.18 step/s\n",
      "global step 13740, epoch: 3, batch: 4330, loss: 0.3145, ce_loss: 0.3145., accu: 0.8573, speed: 1.18 step/s\n",
      "global step 13750, epoch: 3, batch: 4340, loss: 0.2487, ce_loss: 0.2487., accu: 0.8573, speed: 1.17 step/s\n",
      "global step 13760, epoch: 3, batch: 4350, loss: 0.2339, ce_loss: 0.2339., accu: 0.8574, speed: 1.17 step/s\n",
      "global step 13770, epoch: 3, batch: 4360, loss: 0.1745, ce_loss: 0.1745., accu: 0.8574, speed: 1.19 step/s\n",
      "global step 13780, epoch: 3, batch: 4370, loss: 0.2050, ce_loss: 0.2050., accu: 0.8574, speed: 1.19 step/s\n",
      "global step 13790, epoch: 3, batch: 4380, loss: 0.2695, ce_loss: 0.2695., accu: 0.8575, speed: 1.20 step/s\n",
      "global step 13800, epoch: 3, batch: 4390, loss: 0.2392, ce_loss: 0.2392., accu: 0.8575, speed: 1.18 step/s\n",
      "2022-09-28 16:23:02,112\t[train.py-do_train]-[line:187]-INFO:【global step 13800, epoch: 3, batch: 4390】，loss: 0.2392, ce_loss: 0.2392., accu: 0.8575,\n",
      "global step 13810, epoch: 3, batch: 4400, loss: 0.1913, ce_loss: 0.1913., accu: 0.8575, speed: 1.18 step/s\n",
      "global step 13820, epoch: 3, batch: 4410, loss: 0.1982, ce_loss: 0.1982., accu: 0.8575, speed: 1.18 step/s\n",
      "global step 13830, epoch: 3, batch: 4420, loss: 0.1955, ce_loss: 0.1955., accu: 0.8576, speed: 1.18 step/s\n",
      "global step 13840, epoch: 3, batch: 4430, loss: 0.2640, ce_loss: 0.2640., accu: 0.8576, speed: 1.18 step/s\n",
      "global step 13850, epoch: 3, batch: 4440, loss: 0.2342, ce_loss: 0.2342., accu: 0.8576, speed: 1.18 step/s\n",
      "global step 13860, epoch: 3, batch: 4450, loss: 0.3799, ce_loss: 0.3799., accu: 0.8576, speed: 1.19 step/s\n",
      "global step 13870, epoch: 3, batch: 4460, loss: 0.2298, ce_loss: 0.2298., accu: 0.8577, speed: 1.19 step/s\n",
      "global step 13880, epoch: 3, batch: 4470, loss: 0.2416, ce_loss: 0.2416., accu: 0.8577, speed: 1.18 step/s\n",
      "global step 13890, epoch: 3, batch: 4480, loss: 0.1750, ce_loss: 0.1750., accu: 0.8577, speed: 1.18 step/s\n",
      "global step 13900, epoch: 3, batch: 4490, loss: 0.1917, ce_loss: 0.1917., accu: 0.8577, speed: 1.20 step/s\n",
      "2022-09-28 16:24:26,588\t[train.py-do_train]-[line:187]-INFO:【global step 13900, epoch: 3, batch: 4490】，loss: 0.1917, ce_loss: 0.1917., accu: 0.8577,\n",
      "global step 13910, epoch: 3, batch: 4500, loss: 0.2444, ce_loss: 0.2444., accu: 0.8578, speed: 1.18 step/s\n",
      "global step 13920, epoch: 3, batch: 4510, loss: 0.1671, ce_loss: 0.1671., accu: 0.8578, speed: 1.19 step/s\n",
      "global step 13930, epoch: 3, batch: 4520, loss: 0.3223, ce_loss: 0.3223., accu: 0.8578, speed: 1.19 step/s\n",
      "global step 13940, epoch: 3, batch: 4530, loss: 0.1740, ce_loss: 0.1740., accu: 0.8579, speed: 1.19 step/s\n",
      "global step 13950, epoch: 3, batch: 4540, loss: 0.3389, ce_loss: 0.3389., accu: 0.8579, speed: 1.18 step/s\n",
      "global step 13960, epoch: 3, batch: 4550, loss: 0.2016, ce_loss: 0.2016., accu: 0.8579, speed: 1.19 step/s\n",
      "global step 13970, epoch: 3, batch: 4560, loss: 0.3434, ce_loss: 0.3434., accu: 0.8579, speed: 1.18 step/s\n",
      "global step 13980, epoch: 3, batch: 4570, loss: 0.1904, ce_loss: 0.1904., accu: 0.8580, speed: 1.19 step/s\n",
      "global step 13990, epoch: 3, batch: 4580, loss: 0.1785, ce_loss: 0.1785., accu: 0.8580, speed: 1.20 step/s\n",
      "global step 14000, epoch: 3, batch: 4590, loss: 0.2233, ce_loss: 0.2233., accu: 0.8580, speed: 1.18 step/s\n",
      "2022-09-28 16:25:50,997\t[train.py-do_train]-[line:187]-INFO:【global step 14000, epoch: 3, batch: 4590】，loss: 0.2233, ce_loss: 0.2233., accu: 0.8580,\n",
      "global step 14010, epoch: 3, batch: 4600, loss: 0.1576, ce_loss: 0.1576., accu: 0.8581, speed: 1.19 step/s\n",
      "global step 14020, epoch: 3, batch: 4610, loss: 0.2314, ce_loss: 0.2314., accu: 0.8581, speed: 1.20 step/s\n",
      "global step 14030, epoch: 3, batch: 4620, loss: 0.2423, ce_loss: 0.2423., accu: 0.8581, speed: 1.18 step/s\n",
      "global step 14040, epoch: 3, batch: 4630, loss: 0.1784, ce_loss: 0.1784., accu: 0.8581, speed: 1.19 step/s\n",
      "global step 14050, epoch: 3, batch: 4640, loss: 0.2441, ce_loss: 0.2441., accu: 0.8582, speed: 1.20 step/s\n",
      "global step 14060, epoch: 3, batch: 4650, loss: 0.2059, ce_loss: 0.2059., accu: 0.8582, speed: 1.19 step/s\n",
      "global step 14070, epoch: 3, batch: 4660, loss: 0.1717, ce_loss: 0.1717., accu: 0.8582, speed: 1.19 step/s\n",
      "global step 14080, epoch: 3, batch: 4670, loss: 0.1918, ce_loss: 0.1918., accu: 0.8583, speed: 1.18 step/s\n",
      "global step 14090, epoch: 3, batch: 4680, loss: 0.1815, ce_loss: 0.1815., accu: 0.8583, speed: 1.19 step/s\n",
      "global step 14100, epoch: 3, batch: 4690, loss: 0.2824, ce_loss: 0.2824., accu: 0.8583, speed: 1.18 step/s\n",
      "2022-09-28 16:27:15,199\t[train.py-do_train]-[line:187]-INFO:【global step 14100, epoch: 3, batch: 4690】，loss: 0.2824, ce_loss: 0.2824., accu: 0.8583,\n",
      "global step 14110, epoch: 3, batch: 4700, loss: 0.2519, ce_loss: 0.2519., accu: 0.8584, speed: 1.20 step/s\n",
      " 60%|███████████████████████▍               | 3/5 [3:18:11<2:12:08, 3964.16s/it]global step 14120, epoch: 4, batch: 5, loss: 0.1971, ce_loss: 0.1971., accu: 0.8584, speed: 1.26 step/s\n",
      "global step 14130, epoch: 4, batch: 15, loss: 0.1531, ce_loss: 0.1531., accu: 0.8584, speed: 1.18 step/s\n",
      "global step 14140, epoch: 4, batch: 25, loss: 0.2906, ce_loss: 0.2906., accu: 0.8585, speed: 1.21 step/s\n",
      "global step 14150, epoch: 4, batch: 35, loss: 0.1920, ce_loss: 0.1920., accu: 0.8585, speed: 1.20 step/s\n",
      "global step 14160, epoch: 4, batch: 45, loss: 0.1725, ce_loss: 0.1725., accu: 0.8585, speed: 1.20 step/s\n",
      "global step 14170, epoch: 4, batch: 55, loss: 0.1144, ce_loss: 0.1144., accu: 0.8586, speed: 1.18 step/s\n",
      "global step 14180, epoch: 4, batch: 65, loss: 0.2145, ce_loss: 0.2145., accu: 0.8586, speed: 1.18 step/s\n",
      "global step 14190, epoch: 4, batch: 75, loss: 0.2251, ce_loss: 0.2251., accu: 0.8586, speed: 1.18 step/s\n",
      "global step 14200, epoch: 4, batch: 85, loss: 0.2139, ce_loss: 0.2139., accu: 0.8587, speed: 1.17 step/s\n",
      "2022-09-28 16:28:38,851\t[train.py-do_train]-[line:187]-INFO:【global step 14200, epoch: 4, batch: 85】，loss: 0.2139, ce_loss: 0.2139., accu: 0.8587,\n",
      "global step 14210, epoch: 4, batch: 95, loss: 0.1882, ce_loss: 0.1882., accu: 0.8587, speed: 1.18 step/s\n",
      "global step 14220, epoch: 4, batch: 105, loss: 0.1735, ce_loss: 0.1735., accu: 0.8588, speed: 1.20 step/s\n",
      "global step 14230, epoch: 4, batch: 115, loss: 0.2469, ce_loss: 0.2469., accu: 0.8588, speed: 1.20 step/s\n",
      "global step 14240, epoch: 4, batch: 125, loss: 0.2061, ce_loss: 0.2061., accu: 0.8588, speed: 1.18 step/s\n",
      "global step 14250, epoch: 4, batch: 135, loss: 0.2697, ce_loss: 0.2697., accu: 0.8589, speed: 1.18 step/s\n",
      "global step 14260, epoch: 4, batch: 145, loss: 0.1914, ce_loss: 0.1914., accu: 0.8589, speed: 1.18 step/s\n",
      "global step 14270, epoch: 4, batch: 155, loss: 0.1238, ce_loss: 0.1238., accu: 0.8590, speed: 1.19 step/s\n",
      "global step 14280, epoch: 4, batch: 165, loss: 0.2816, ce_loss: 0.2816., accu: 0.8590, speed: 1.18 step/s\n",
      "global step 14290, epoch: 4, batch: 175, loss: 0.2423, ce_loss: 0.2423., accu: 0.8590, speed: 1.18 step/s\n",
      "global step 14300, epoch: 4, batch: 185, loss: 0.1726, ce_loss: 0.1726., accu: 0.8591, speed: 1.19 step/s\n",
      "2022-09-28 16:30:03,215\t[train.py-do_train]-[line:187]-INFO:【global step 14300, epoch: 4, batch: 185】，loss: 0.1726, ce_loss: 0.1726., accu: 0.8591,\n",
      "global step 14310, epoch: 4, batch: 195, loss: 0.2645, ce_loss: 0.2645., accu: 0.8591, speed: 1.19 step/s\n",
      "global step 14320, epoch: 4, batch: 205, loss: 0.1936, ce_loss: 0.1936., accu: 0.8591, speed: 1.19 step/s\n",
      "global step 14330, epoch: 4, batch: 215, loss: 0.2649, ce_loss: 0.2649., accu: 0.8591, speed: 1.19 step/s\n",
      "global step 14340, epoch: 4, batch: 225, loss: 0.2110, ce_loss: 0.2110., accu: 0.8592, speed: 1.19 step/s\n",
      "global step 14350, epoch: 4, batch: 235, loss: 0.1805, ce_loss: 0.1805., accu: 0.8592, speed: 1.19 step/s\n",
      "global step 14360, epoch: 4, batch: 245, loss: 0.1951, ce_loss: 0.1951., accu: 0.8593, speed: 1.18 step/s\n",
      "global step 14370, epoch: 4, batch: 255, loss: 0.2295, ce_loss: 0.2295., accu: 0.8593, speed: 1.18 step/s\n",
      "global step 14380, epoch: 4, batch: 265, loss: 0.1705, ce_loss: 0.1705., accu: 0.8593, speed: 1.17 step/s\n",
      "global step 14390, epoch: 4, batch: 275, loss: 0.2003, ce_loss: 0.2003., accu: 0.8594, speed: 1.18 step/s\n",
      "global step 14400, epoch: 4, batch: 285, loss: 0.2053, ce_loss: 0.2053., accu: 0.8594, speed: 1.19 step/s\n",
      "2022-09-28 16:31:27,669\t[train.py-do_train]-[line:187]-INFO:【global step 14400, epoch: 4, batch: 285】，loss: 0.2053, ce_loss: 0.2053., accu: 0.8594,\n",
      "global step 14410, epoch: 4, batch: 295, loss: 0.2630, ce_loss: 0.2630., accu: 0.8594, speed: 1.17 step/s\n",
      "global step 14420, epoch: 4, batch: 305, loss: 0.1543, ce_loss: 0.1543., accu: 0.8595, speed: 1.20 step/s\n",
      "global step 14430, epoch: 4, batch: 315, loss: 0.1766, ce_loss: 0.1766., accu: 0.8595, speed: 1.19 step/s\n",
      "global step 14440, epoch: 4, batch: 325, loss: 0.2037, ce_loss: 0.2037., accu: 0.8595, speed: 1.17 step/s\n",
      "global step 14450, epoch: 4, batch: 335, loss: 0.1487, ce_loss: 0.1487., accu: 0.8596, speed: 1.18 step/s\n",
      "global step 14460, epoch: 4, batch: 345, loss: 0.1456, ce_loss: 0.1456., accu: 0.8596, speed: 1.19 step/s\n",
      "global step 14470, epoch: 4, batch: 355, loss: 0.1995, ce_loss: 0.1995., accu: 0.8596, speed: 1.20 step/s\n",
      "global step 14480, epoch: 4, batch: 365, loss: 0.1959, ce_loss: 0.1959., accu: 0.8596, speed: 1.19 step/s\n",
      "global step 14490, epoch: 4, batch: 375, loss: 0.1913, ce_loss: 0.1913., accu: 0.8597, speed: 1.18 step/s\n",
      "global step 14500, epoch: 4, batch: 385, loss: 0.1840, ce_loss: 0.1840., accu: 0.8597, speed: 1.18 step/s\n",
      "2022-09-28 16:32:52,126\t[train.py-do_train]-[line:187]-INFO:【global step 14500, epoch: 4, batch: 385】，loss: 0.1840, ce_loss: 0.1840., accu: 0.8597,\n",
      "global step 14510, epoch: 4, batch: 395, loss: 0.3778, ce_loss: 0.3778., accu: 0.8597, speed: 1.19 step/s\n",
      "global step 14520, epoch: 4, batch: 405, loss: 0.2109, ce_loss: 0.2109., accu: 0.8598, speed: 1.18 step/s\n",
      "global step 14530, epoch: 4, batch: 415, loss: 0.2090, ce_loss: 0.2090., accu: 0.8598, speed: 1.17 step/s\n",
      "global step 14540, epoch: 4, batch: 425, loss: 0.1916, ce_loss: 0.1916., accu: 0.8598, speed: 1.18 step/s\n",
      "global step 14550, epoch: 4, batch: 435, loss: 0.2237, ce_loss: 0.2237., accu: 0.8599, speed: 1.18 step/s\n",
      "global step 14560, epoch: 4, batch: 445, loss: 0.1757, ce_loss: 0.1757., accu: 0.8599, speed: 1.18 step/s\n",
      "global step 14570, epoch: 4, batch: 455, loss: 0.1823, ce_loss: 0.1823., accu: 0.8599, speed: 1.18 step/s\n",
      "global step 14580, epoch: 4, batch: 465, loss: 0.2439, ce_loss: 0.2439., accu: 0.8600, speed: 1.20 step/s\n",
      "global step 14590, epoch: 4, batch: 475, loss: 0.2237, ce_loss: 0.2237., accu: 0.8600, speed: 1.18 step/s\n",
      "global step 14600, epoch: 4, batch: 485, loss: 0.1449, ce_loss: 0.1449., accu: 0.8600, speed: 1.18 step/s\n",
      "2022-09-28 16:34:16,710\t[train.py-do_train]-[line:187]-INFO:【global step 14600, epoch: 4, batch: 485】，loss: 0.1449, ce_loss: 0.1449., accu: 0.8600,\n",
      "global step 14610, epoch: 4, batch: 495, loss: 0.2677, ce_loss: 0.2677., accu: 0.8601, speed: 1.18 step/s\n",
      "global step 14620, epoch: 4, batch: 505, loss: 0.2085, ce_loss: 0.2085., accu: 0.8601, speed: 1.19 step/s\n",
      "global step 14630, epoch: 4, batch: 515, loss: 0.2250, ce_loss: 0.2250., accu: 0.8601, speed: 1.20 step/s\n",
      "global step 14640, epoch: 4, batch: 525, loss: 0.1422, ce_loss: 0.1422., accu: 0.8602, speed: 1.19 step/s\n",
      "global step 14650, epoch: 4, batch: 535, loss: 0.1580, ce_loss: 0.1580., accu: 0.8602, speed: 1.19 step/s\n",
      "global step 14660, epoch: 4, batch: 545, loss: 0.1590, ce_loss: 0.1590., accu: 0.8602, speed: 1.18 step/s\n",
      "global step 14670, epoch: 4, batch: 555, loss: 0.2433, ce_loss: 0.2433., accu: 0.8603, speed: 1.19 step/s\n",
      "global step 14680, epoch: 4, batch: 565, loss: 0.1813, ce_loss: 0.1813., accu: 0.8603, speed: 1.19 step/s\n",
      "global step 14690, epoch: 4, batch: 575, loss: 0.2466, ce_loss: 0.2466., accu: 0.8604, speed: 1.18 step/s\n",
      "global step 14700, epoch: 4, batch: 585, loss: 0.1498, ce_loss: 0.1498., accu: 0.8604, speed: 1.20 step/s\n",
      "2022-09-28 16:35:40,882\t[train.py-do_train]-[line:187]-INFO:【global step 14700, epoch: 4, batch: 585】，loss: 0.1498, ce_loss: 0.1498., accu: 0.8604,\n",
      "global step 14710, epoch: 4, batch: 595, loss: 0.1546, ce_loss: 0.1546., accu: 0.8604, speed: 1.20 step/s\n",
      "global step 14720, epoch: 4, batch: 605, loss: 0.1790, ce_loss: 0.1790., accu: 0.8604, speed: 1.19 step/s\n",
      "global step 14730, epoch: 4, batch: 615, loss: 0.1942, ce_loss: 0.1942., accu: 0.8605, speed: 1.18 step/s\n",
      "global step 14740, epoch: 4, batch: 625, loss: 0.1844, ce_loss: 0.1844., accu: 0.8605, speed: 1.19 step/s\n",
      "global step 14750, epoch: 4, batch: 635, loss: 0.2254, ce_loss: 0.2254., accu: 0.8605, speed: 1.18 step/s\n",
      "global step 14760, epoch: 4, batch: 645, loss: 0.1511, ce_loss: 0.1511., accu: 0.8606, speed: 1.18 step/s\n",
      "global step 14770, epoch: 4, batch: 655, loss: 0.2342, ce_loss: 0.2342., accu: 0.8606, speed: 1.19 step/s\n",
      "global step 14780, epoch: 4, batch: 665, loss: 0.2206, ce_loss: 0.2206., accu: 0.8606, speed: 1.19 step/s\n",
      "global step 14790, epoch: 4, batch: 675, loss: 0.1926, ce_loss: 0.1926., accu: 0.8607, speed: 1.18 step/s\n",
      "global step 14800, epoch: 4, batch: 685, loss: 0.1658, ce_loss: 0.1658., accu: 0.8607, speed: 1.19 step/s\n",
      "2022-09-28 16:37:05,155\t[train.py-do_train]-[line:187]-INFO:【global step 14800, epoch: 4, batch: 685】，loss: 0.1658, ce_loss: 0.1658., accu: 0.8607,\n",
      "global step 14810, epoch: 4, batch: 695, loss: 0.2212, ce_loss: 0.2212., accu: 0.8607, speed: 1.20 step/s\n",
      "global step 14820, epoch: 4, batch: 705, loss: 0.2316, ce_loss: 0.2316., accu: 0.8608, speed: 1.19 step/s\n",
      "global step 14830, epoch: 4, batch: 715, loss: 0.2161, ce_loss: 0.2161., accu: 0.8608, speed: 1.18 step/s\n",
      "global step 14840, epoch: 4, batch: 725, loss: 0.2538, ce_loss: 0.2538., accu: 0.8608, speed: 1.18 step/s\n",
      "global step 14850, epoch: 4, batch: 735, loss: 0.2236, ce_loss: 0.2236., accu: 0.8609, speed: 1.18 step/s\n",
      "global step 14860, epoch: 4, batch: 745, loss: 0.1419, ce_loss: 0.1419., accu: 0.8609, speed: 1.17 step/s\n",
      "global step 14870, epoch: 4, batch: 755, loss: 0.1835, ce_loss: 0.1835., accu: 0.8609, speed: 1.17 step/s\n",
      "global step 14880, epoch: 4, batch: 765, loss: 0.1753, ce_loss: 0.1753., accu: 0.8610, speed: 1.20 step/s\n",
      "global step 14890, epoch: 4, batch: 775, loss: 0.1624, ce_loss: 0.1624., accu: 0.8610, speed: 1.19 step/s\n",
      "global step 14900, epoch: 4, batch: 785, loss: 0.2324, ce_loss: 0.2324., accu: 0.8611, speed: 1.18 step/s\n",
      "2022-09-28 16:38:29,513\t[train.py-do_train]-[line:187]-INFO:【global step 14900, epoch: 4, batch: 785】，loss: 0.2324, ce_loss: 0.2324., accu: 0.8611,\n",
      "global step 14910, epoch: 4, batch: 795, loss: 0.2021, ce_loss: 0.2021., accu: 0.8611, speed: 1.20 step/s\n",
      "global step 14920, epoch: 4, batch: 805, loss: 0.1838, ce_loss: 0.1838., accu: 0.8611, speed: 1.20 step/s\n",
      "global step 14930, epoch: 4, batch: 815, loss: 0.2016, ce_loss: 0.2016., accu: 0.8611, speed: 1.19 step/s\n",
      "global step 14940, epoch: 4, batch: 825, loss: 0.2191, ce_loss: 0.2191., accu: 0.8612, speed: 1.20 step/s\n",
      "global step 14950, epoch: 4, batch: 835, loss: 0.2175, ce_loss: 0.2175., accu: 0.8612, speed: 1.19 step/s\n",
      "global step 14960, epoch: 4, batch: 845, loss: 0.1637, ce_loss: 0.1637., accu: 0.8612, speed: 1.18 step/s\n",
      "global step 14970, epoch: 4, batch: 855, loss: 0.2211, ce_loss: 0.2211., accu: 0.8613, speed: 1.19 step/s\n",
      "global step 14980, epoch: 4, batch: 865, loss: 0.2381, ce_loss: 0.2381., accu: 0.8613, speed: 1.18 step/s\n",
      "global step 14990, epoch: 4, batch: 875, loss: 0.2176, ce_loss: 0.2176., accu: 0.8613, speed: 1.19 step/s\n",
      "global step 15000, epoch: 4, batch: 885, loss: 0.1702, ce_loss: 0.1702., accu: 0.8613, speed: 1.19 step/s\n",
      "2022-09-28 16:39:53,580\t[train.py-do_train]-[line:187]-INFO:【global step 15000, epoch: 4, batch: 885】，loss: 0.1702, ce_loss: 0.1702., accu: 0.8613,\n",
      "global step 15010, epoch: 4, batch: 895, loss: 0.2511, ce_loss: 0.2511., accu: 0.8614, speed: 1.19 step/s\n",
      "global step 15020, epoch: 4, batch: 905, loss: 0.1942, ce_loss: 0.1942., accu: 0.8614, speed: 1.19 step/s\n",
      "global step 15030, epoch: 4, batch: 915, loss: 0.2753, ce_loss: 0.2753., accu: 0.8614, speed: 1.17 step/s\n",
      "global step 15040, epoch: 4, batch: 925, loss: 0.2293, ce_loss: 0.2293., accu: 0.8615, speed: 1.18 step/s\n",
      "global step 15050, epoch: 4, batch: 935, loss: 0.1671, ce_loss: 0.1671., accu: 0.8615, speed: 1.20 step/s\n",
      "global step 15060, epoch: 4, batch: 945, loss: 0.2115, ce_loss: 0.2115., accu: 0.8615, speed: 1.18 step/s\n",
      "global step 15070, epoch: 4, batch: 955, loss: 0.2610, ce_loss: 0.2610., accu: 0.8616, speed: 1.18 step/s\n",
      "global step 15080, epoch: 4, batch: 965, loss: 0.2801, ce_loss: 0.2801., accu: 0.8616, speed: 1.19 step/s\n",
      "global step 15090, epoch: 4, batch: 975, loss: 0.2657, ce_loss: 0.2657., accu: 0.8616, speed: 1.19 step/s\n",
      "global step 15100, epoch: 4, batch: 985, loss: 0.1766, ce_loss: 0.1766., accu: 0.8617, speed: 1.18 step/s\n",
      "2022-09-28 16:41:17,887\t[train.py-do_train]-[line:187]-INFO:【global step 15100, epoch: 4, batch: 985】，loss: 0.1766, ce_loss: 0.1766., accu: 0.8617,\n",
      "global step 15110, epoch: 4, batch: 995, loss: 0.2263, ce_loss: 0.2263., accu: 0.8617, speed: 1.19 step/s\n",
      "global step 15120, epoch: 4, batch: 1005, loss: 0.1600, ce_loss: 0.1600., accu: 0.8617, speed: 1.18 step/s\n",
      "global step 15130, epoch: 4, batch: 1015, loss: 0.2637, ce_loss: 0.2637., accu: 0.8618, speed: 1.19 step/s\n",
      "global step 15140, epoch: 4, batch: 1025, loss: 0.2011, ce_loss: 0.2011., accu: 0.8618, speed: 1.20 step/s\n",
      "global step 15150, epoch: 4, batch: 1035, loss: 0.2632, ce_loss: 0.2632., accu: 0.8618, speed: 1.18 step/s\n",
      "global step 15160, epoch: 4, batch: 1045, loss: 0.1815, ce_loss: 0.1815., accu: 0.8619, speed: 1.19 step/s\n",
      "global step 15170, epoch: 4, batch: 1055, loss: 0.1259, ce_loss: 0.1259., accu: 0.8619, speed: 1.18 step/s\n",
      "global step 15180, epoch: 4, batch: 1065, loss: 0.1931, ce_loss: 0.1931., accu: 0.8619, speed: 1.18 step/s\n",
      "global step 15190, epoch: 4, batch: 1075, loss: 0.3227, ce_loss: 0.3227., accu: 0.8620, speed: 1.18 step/s\n",
      "global step 15200, epoch: 4, batch: 1085, loss: 0.1975, ce_loss: 0.1975., accu: 0.8620, speed: 1.18 step/s\n",
      "2022-09-28 16:42:42,354\t[train.py-do_train]-[line:187]-INFO:【global step 15200, epoch: 4, batch: 1085】，loss: 0.1975, ce_loss: 0.1975., accu: 0.8620,\n",
      "global step 15210, epoch: 4, batch: 1095, loss: 0.1642, ce_loss: 0.1642., accu: 0.8620, speed: 1.18 step/s\n",
      "global step 15220, epoch: 4, batch: 1105, loss: 0.2120, ce_loss: 0.2120., accu: 0.8620, speed: 1.18 step/s\n",
      "global step 15230, epoch: 4, batch: 1115, loss: 0.1810, ce_loss: 0.1810., accu: 0.8621, speed: 1.19 step/s\n",
      "global step 15240, epoch: 4, batch: 1125, loss: 0.2498, ce_loss: 0.2498., accu: 0.8621, speed: 1.18 step/s\n",
      "global step 15250, epoch: 4, batch: 1135, loss: 0.2099, ce_loss: 0.2099., accu: 0.8621, speed: 1.18 step/s\n",
      "global step 15260, epoch: 4, batch: 1145, loss: 0.1757, ce_loss: 0.1757., accu: 0.8622, speed: 1.19 step/s\n",
      "global step 15270, epoch: 4, batch: 1155, loss: 0.2014, ce_loss: 0.2014., accu: 0.8622, speed: 1.18 step/s\n",
      "global step 15280, epoch: 4, batch: 1165, loss: 0.1931, ce_loss: 0.1931., accu: 0.8622, speed: 1.19 step/s\n",
      "global step 15290, epoch: 4, batch: 1175, loss: 0.2075, ce_loss: 0.2075., accu: 0.8623, speed: 1.18 step/s\n",
      "global step 15300, epoch: 4, batch: 1185, loss: 0.2232, ce_loss: 0.2232., accu: 0.8623, speed: 1.20 step/s\n",
      "2022-09-28 16:44:06,784\t[train.py-do_train]-[line:187]-INFO:【global step 15300, epoch: 4, batch: 1185】，loss: 0.2232, ce_loss: 0.2232., accu: 0.8623,\n",
      "global step 15310, epoch: 4, batch: 1195, loss: 0.2421, ce_loss: 0.2421., accu: 0.8623, speed: 1.18 step/s\n",
      "global step 15320, epoch: 4, batch: 1205, loss: 0.2477, ce_loss: 0.2477., accu: 0.8623, speed: 1.18 step/s\n",
      "global step 15330, epoch: 4, batch: 1215, loss: 0.2073, ce_loss: 0.2073., accu: 0.8624, speed: 1.19 step/s\n",
      "global step 15340, epoch: 4, batch: 1225, loss: 0.2394, ce_loss: 0.2394., accu: 0.8624, speed: 1.18 step/s\n",
      "global step 15350, epoch: 4, batch: 1235, loss: 0.2027, ce_loss: 0.2027., accu: 0.8624, speed: 1.20 step/s\n",
      "global step 15360, epoch: 4, batch: 1245, loss: 0.2031, ce_loss: 0.2031., accu: 0.8625, speed: 1.20 step/s\n",
      "global step 15370, epoch: 4, batch: 1255, loss: 0.2302, ce_loss: 0.2302., accu: 0.8625, speed: 1.20 step/s\n",
      "global step 15380, epoch: 4, batch: 1265, loss: 0.1511, ce_loss: 0.1511., accu: 0.8625, speed: 1.18 step/s\n",
      "global step 15390, epoch: 4, batch: 1275, loss: 0.1378, ce_loss: 0.1378., accu: 0.8625, speed: 1.18 step/s\n",
      "global step 15400, epoch: 4, batch: 1285, loss: 0.1801, ce_loss: 0.1801., accu: 0.8626, speed: 1.18 step/s\n",
      "2022-09-28 16:45:31,026\t[train.py-do_train]-[line:187]-INFO:【global step 15400, epoch: 4, batch: 1285】，loss: 0.1801, ce_loss: 0.1801., accu: 0.8626,\n",
      "global step 15410, epoch: 4, batch: 1295, loss: 0.1431, ce_loss: 0.1431., accu: 0.8626, speed: 1.19 step/s\n",
      "global step 15420, epoch: 4, batch: 1305, loss: 0.1896, ce_loss: 0.1896., accu: 0.8626, speed: 1.21 step/s\n",
      "global step 15430, epoch: 4, batch: 1315, loss: 0.1692, ce_loss: 0.1692., accu: 0.8627, speed: 1.20 step/s\n",
      "global step 15440, epoch: 4, batch: 1325, loss: 0.1625, ce_loss: 0.1625., accu: 0.8627, speed: 1.20 step/s\n",
      "global step 15450, epoch: 4, batch: 1335, loss: 0.2059, ce_loss: 0.2059., accu: 0.8627, speed: 1.18 step/s\n",
      "global step 15460, epoch: 4, batch: 1345, loss: 0.2137, ce_loss: 0.2137., accu: 0.8628, speed: 1.18 step/s\n",
      "global step 15470, epoch: 4, batch: 1355, loss: 0.1824, ce_loss: 0.1824., accu: 0.8628, speed: 1.18 step/s\n",
      "global step 15480, epoch: 4, batch: 1365, loss: 0.2497, ce_loss: 0.2497., accu: 0.8628, speed: 1.20 step/s\n",
      "global step 15490, epoch: 4, batch: 1375, loss: 0.2137, ce_loss: 0.2137., accu: 0.8629, speed: 1.19 step/s\n",
      "global step 15500, epoch: 4, batch: 1385, loss: 0.2178, ce_loss: 0.2178., accu: 0.8629, speed: 1.21 step/s\n",
      "2022-09-28 16:46:54,823\t[train.py-do_train]-[line:187]-INFO:【global step 15500, epoch: 4, batch: 1385】，loss: 0.2178, ce_loss: 0.2178., accu: 0.8629,\n",
      "global step 15510, epoch: 4, batch: 1395, loss: 0.1970, ce_loss: 0.1970., accu: 0.8629, speed: 1.20 step/s\n",
      "global step 15520, epoch: 4, batch: 1405, loss: 0.2315, ce_loss: 0.2315., accu: 0.8630, speed: 1.19 step/s\n",
      "global step 15530, epoch: 4, batch: 1415, loss: 0.2621, ce_loss: 0.2621., accu: 0.8630, speed: 1.20 step/s\n",
      "global step 15540, epoch: 4, batch: 1425, loss: 0.2140, ce_loss: 0.2140., accu: 0.8630, speed: 1.19 step/s\n",
      "global step 15550, epoch: 4, batch: 1435, loss: 0.2102, ce_loss: 0.2102., accu: 0.8630, speed: 1.19 step/s\n",
      "global step 15560, epoch: 4, batch: 1445, loss: 0.1731, ce_loss: 0.1731., accu: 0.8631, speed: 1.18 step/s\n",
      "global step 15570, epoch: 4, batch: 1455, loss: 0.2197, ce_loss: 0.2197., accu: 0.8631, speed: 1.18 step/s\n",
      "global step 15580, epoch: 4, batch: 1465, loss: 0.2202, ce_loss: 0.2202., accu: 0.8631, speed: 1.18 step/s\n",
      "global step 15590, epoch: 4, batch: 1475, loss: 0.2083, ce_loss: 0.2083., accu: 0.8632, speed: 1.18 step/s\n",
      "global step 15600, epoch: 4, batch: 1485, loss: 0.1836, ce_loss: 0.1836., accu: 0.8632, speed: 1.20 step/s\n",
      "2022-09-28 16:48:18,932\t[train.py-do_train]-[line:187]-INFO:【global step 15600, epoch: 4, batch: 1485】，loss: 0.1836, ce_loss: 0.1836., accu: 0.8632,\n",
      "global step 15610, epoch: 4, batch: 1495, loss: 0.2306, ce_loss: 0.2306., accu: 0.8632, speed: 1.20 step/s\n",
      "global step 15620, epoch: 4, batch: 1505, loss: 0.1890, ce_loss: 0.1890., accu: 0.8632, speed: 1.18 step/s\n",
      "global step 15630, epoch: 4, batch: 1515, loss: 0.1568, ce_loss: 0.1568., accu: 0.8633, speed: 1.19 step/s\n",
      "global step 15640, epoch: 4, batch: 1525, loss: 0.2097, ce_loss: 0.2097., accu: 0.8633, speed: 1.21 step/s\n",
      "global step 15650, epoch: 4, batch: 1535, loss: 0.2976, ce_loss: 0.2976., accu: 0.8633, speed: 1.21 step/s\n",
      "global step 15660, epoch: 4, batch: 1545, loss: 0.2485, ce_loss: 0.2485., accu: 0.8634, speed: 1.20 step/s\n",
      "global step 15670, epoch: 4, batch: 1555, loss: 0.2218, ce_loss: 0.2218., accu: 0.8634, speed: 1.20 step/s\n",
      "global step 15680, epoch: 4, batch: 1565, loss: 0.2961, ce_loss: 0.2961., accu: 0.8634, speed: 1.18 step/s\n",
      "global step 15690, epoch: 4, batch: 1575, loss: 0.1851, ce_loss: 0.1851., accu: 0.8634, speed: 1.18 step/s\n",
      "global step 15700, epoch: 4, batch: 1585, loss: 0.1794, ce_loss: 0.1794., accu: 0.8635, speed: 1.19 step/s\n",
      "2022-09-28 16:49:42,830\t[train.py-do_train]-[line:187]-INFO:【global step 15700, epoch: 4, batch: 1585】，loss: 0.1794, ce_loss: 0.1794., accu: 0.8635,\n",
      "global step 15710, epoch: 4, batch: 1595, loss: 0.2107, ce_loss: 0.2107., accu: 0.8635, speed: 1.18 step/s\n",
      "global step 15720, epoch: 4, batch: 1605, loss: 0.2018, ce_loss: 0.2018., accu: 0.8635, speed: 1.18 step/s\n",
      "global step 15730, epoch: 4, batch: 1615, loss: 0.1680, ce_loss: 0.1680., accu: 0.8636, speed: 1.19 step/s\n",
      "global step 15740, epoch: 4, batch: 1625, loss: 0.2772, ce_loss: 0.2772., accu: 0.8636, speed: 1.18 step/s\n",
      "global step 15750, epoch: 4, batch: 1635, loss: 0.1517, ce_loss: 0.1517., accu: 0.8636, speed: 1.18 step/s\n",
      "global step 15760, epoch: 4, batch: 1645, loss: 0.3060, ce_loss: 0.3060., accu: 0.8636, speed: 1.19 step/s\n",
      "global step 15770, epoch: 4, batch: 1655, loss: 0.2136, ce_loss: 0.2136., accu: 0.8637, speed: 1.18 step/s\n",
      "global step 15780, epoch: 4, batch: 1665, loss: 0.1846, ce_loss: 0.1846., accu: 0.8637, speed: 1.19 step/s\n",
      "global step 15790, epoch: 4, batch: 1675, loss: 0.3167, ce_loss: 0.3167., accu: 0.8637, speed: 1.18 step/s\n",
      "global step 15800, epoch: 4, batch: 1685, loss: 0.1366, ce_loss: 0.1366., accu: 0.8638, speed: 1.18 step/s\n",
      "2022-09-28 16:51:07,374\t[train.py-do_train]-[line:187]-INFO:【global step 15800, epoch: 4, batch: 1685】，loss: 0.1366, ce_loss: 0.1366., accu: 0.8638,\n",
      "global step 15810, epoch: 4, batch: 1695, loss: 0.2210, ce_loss: 0.2210., accu: 0.8638, speed: 1.19 step/s\n",
      "global step 15820, epoch: 4, batch: 1705, loss: 0.2954, ce_loss: 0.2954., accu: 0.8638, speed: 1.20 step/s\n",
      "global step 15830, epoch: 4, batch: 1715, loss: 0.1677, ce_loss: 0.1677., accu: 0.8638, speed: 1.18 step/s\n",
      "global step 15840, epoch: 4, batch: 1725, loss: 0.2033, ce_loss: 0.2033., accu: 0.8639, speed: 1.18 step/s\n",
      "global step 15850, epoch: 4, batch: 1735, loss: 0.1776, ce_loss: 0.1776., accu: 0.8639, speed: 1.19 step/s\n",
      "global step 15860, epoch: 4, batch: 1745, loss: 0.2932, ce_loss: 0.2932., accu: 0.8639, speed: 1.19 step/s\n",
      "global step 15870, epoch: 4, batch: 1755, loss: 0.2078, ce_loss: 0.2078., accu: 0.8640, speed: 1.20 step/s\n",
      "global step 15880, epoch: 4, batch: 1765, loss: 0.1994, ce_loss: 0.1994., accu: 0.8640, speed: 1.22 step/s\n",
      "global step 15890, epoch: 4, batch: 1775, loss: 0.2324, ce_loss: 0.2324., accu: 0.8640, speed: 1.19 step/s\n",
      "global step 15900, epoch: 4, batch: 1785, loss: 0.1878, ce_loss: 0.1878., accu: 0.8641, speed: 1.18 step/s\n",
      "2022-09-28 16:52:31,366\t[train.py-do_train]-[line:187]-INFO:【global step 15900, epoch: 4, batch: 1785】，loss: 0.1878, ce_loss: 0.1878., accu: 0.8641,\n",
      "global step 15910, epoch: 4, batch: 1795, loss: 0.1155, ce_loss: 0.1155., accu: 0.8641, speed: 1.18 step/s\n",
      "global step 15920, epoch: 4, batch: 1805, loss: 0.2202, ce_loss: 0.2202., accu: 0.8641, speed: 1.19 step/s\n",
      "global step 15930, epoch: 4, batch: 1815, loss: 0.2473, ce_loss: 0.2473., accu: 0.8641, speed: 1.18 step/s\n",
      "global step 15940, epoch: 4, batch: 1825, loss: 0.1712, ce_loss: 0.1712., accu: 0.8642, speed: 1.19 step/s\n",
      "global step 15950, epoch: 4, batch: 1835, loss: 0.2156, ce_loss: 0.2156., accu: 0.8642, speed: 1.24 step/s\n",
      "global step 15960, epoch: 4, batch: 1845, loss: 0.1946, ce_loss: 0.1946., accu: 0.8642, speed: 1.18 step/s\n",
      "global step 15970, epoch: 4, batch: 1855, loss: 0.3014, ce_loss: 0.3014., accu: 0.8643, speed: 1.18 step/s\n",
      "global step 15980, epoch: 4, batch: 1865, loss: 0.2908, ce_loss: 0.2908., accu: 0.8643, speed: 1.19 step/s\n",
      "global step 15990, epoch: 4, batch: 1875, loss: 0.2130, ce_loss: 0.2130., accu: 0.8643, speed: 1.18 step/s\n",
      "global step 16000, epoch: 4, batch: 1885, loss: 0.3091, ce_loss: 0.3091., accu: 0.8643, speed: 1.18 step/s\n",
      "2022-09-28 16:53:55,516\t[train.py-do_train]-[line:187]-INFO:【global step 16000, epoch: 4, batch: 1885】，loss: 0.3091, ce_loss: 0.3091., accu: 0.8643,\n",
      "global step 16010, epoch: 4, batch: 1895, loss: 0.1278, ce_loss: 0.1278., accu: 0.8644, speed: 1.18 step/s\n",
      "global step 16020, epoch: 4, batch: 1905, loss: 0.1780, ce_loss: 0.1780., accu: 0.8644, speed: 1.19 step/s\n",
      "global step 16030, epoch: 4, batch: 1915, loss: 0.2355, ce_loss: 0.2355., accu: 0.8644, speed: 1.19 step/s\n",
      "global step 16040, epoch: 4, batch: 1925, loss: 0.2157, ce_loss: 0.2157., accu: 0.8645, speed: 1.20 step/s\n",
      "global step 16050, epoch: 4, batch: 1935, loss: 0.1417, ce_loss: 0.1417., accu: 0.8645, speed: 1.19 step/s\n",
      "global step 16060, epoch: 4, batch: 1945, loss: 0.1667, ce_loss: 0.1667., accu: 0.8645, speed: 1.18 step/s\n",
      "global step 16070, epoch: 4, batch: 1955, loss: 0.1698, ce_loss: 0.1698., accu: 0.8645, speed: 1.18 step/s\n",
      "global step 16080, epoch: 4, batch: 1965, loss: 0.1895, ce_loss: 0.1895., accu: 0.8646, speed: 1.19 step/s\n",
      "global step 16090, epoch: 4, batch: 1975, loss: 0.1721, ce_loss: 0.1721., accu: 0.8646, speed: 1.19 step/s\n",
      "global step 16100, epoch: 4, batch: 1985, loss: 0.1772, ce_loss: 0.1772., accu: 0.8646, speed: 1.18 step/s\n",
      "2022-09-28 16:55:19,816\t[train.py-do_train]-[line:187]-INFO:【global step 16100, epoch: 4, batch: 1985】，loss: 0.1772, ce_loss: 0.1772., accu: 0.8646,\n",
      "global step 16110, epoch: 4, batch: 1995, loss: 0.3185, ce_loss: 0.3185., accu: 0.8647, speed: 1.18 step/s\n",
      "global step 16120, epoch: 4, batch: 2005, loss: 0.1769, ce_loss: 0.1769., accu: 0.8647, speed: 1.18 step/s\n",
      "global step 16130, epoch: 4, batch: 2015, loss: 0.1450, ce_loss: 0.1450., accu: 0.8647, speed: 1.19 step/s\n",
      "global step 16140, epoch: 4, batch: 2025, loss: 0.2699, ce_loss: 0.2699., accu: 0.8647, speed: 1.20 step/s\n",
      "global step 16150, epoch: 4, batch: 2035, loss: 0.2091, ce_loss: 0.2091., accu: 0.8648, speed: 1.18 step/s\n",
      "global step 16160, epoch: 4, batch: 2045, loss: 0.1614, ce_loss: 0.1614., accu: 0.8648, speed: 1.18 step/s\n",
      "global step 16170, epoch: 4, batch: 2055, loss: 0.2466, ce_loss: 0.2466., accu: 0.8648, speed: 1.19 step/s\n",
      "global step 16180, epoch: 4, batch: 2065, loss: 0.2128, ce_loss: 0.2128., accu: 0.8648, speed: 1.19 step/s\n",
      "global step 16190, epoch: 4, batch: 2075, loss: 0.2711, ce_loss: 0.2711., accu: 0.8649, speed: 1.20 step/s\n",
      "global step 16200, epoch: 4, batch: 2085, loss: 0.1407, ce_loss: 0.1407., accu: 0.8649, speed: 1.19 step/s\n",
      "2022-09-28 16:56:44,107\t[train.py-do_train]-[line:187]-INFO:【global step 16200, epoch: 4, batch: 2085】，loss: 0.1407, ce_loss: 0.1407., accu: 0.8649,\n",
      "global step 16210, epoch: 4, batch: 2095, loss: 0.1521, ce_loss: 0.1521., accu: 0.8649, speed: 1.19 step/s\n",
      "global step 16220, epoch: 4, batch: 2105, loss: 0.2564, ce_loss: 0.2564., accu: 0.8649, speed: 1.19 step/s\n",
      "global step 16230, epoch: 4, batch: 2115, loss: 0.2030, ce_loss: 0.2030., accu: 0.8650, speed: 1.19 step/s\n",
      "global step 16240, epoch: 4, batch: 2125, loss: 0.1783, ce_loss: 0.1783., accu: 0.8650, speed: 1.19 step/s\n",
      "global step 16250, epoch: 4, batch: 2135, loss: 0.1920, ce_loss: 0.1920., accu: 0.8650, speed: 1.18 step/s\n",
      "global step 16260, epoch: 4, batch: 2145, loss: 0.1884, ce_loss: 0.1884., accu: 0.8651, speed: 1.19 step/s\n",
      "global step 16270, epoch: 4, batch: 2155, loss: 0.1649, ce_loss: 0.1649., accu: 0.8651, speed: 1.19 step/s\n",
      "global step 16280, epoch: 4, batch: 2165, loss: 0.1856, ce_loss: 0.1856., accu: 0.8651, speed: 1.18 step/s\n",
      "global step 16290, epoch: 4, batch: 2175, loss: 0.2061, ce_loss: 0.2061., accu: 0.8651, speed: 1.20 step/s\n",
      "global step 16300, epoch: 4, batch: 2185, loss: 0.1576, ce_loss: 0.1576., accu: 0.8652, speed: 1.19 step/s\n",
      "2022-09-28 16:58:08,269\t[train.py-do_train]-[line:187]-INFO:【global step 16300, epoch: 4, batch: 2185】，loss: 0.1576, ce_loss: 0.1576., accu: 0.8652,\n",
      "global step 16310, epoch: 4, batch: 2195, loss: 0.1632, ce_loss: 0.1632., accu: 0.8652, speed: 1.18 step/s\n",
      "global step 16320, epoch: 4, batch: 2205, loss: 0.2200, ce_loss: 0.2200., accu: 0.8652, speed: 1.21 step/s\n",
      "global step 16330, epoch: 4, batch: 2215, loss: 0.1940, ce_loss: 0.1940., accu: 0.8653, speed: 1.18 step/s\n",
      "global step 16340, epoch: 4, batch: 2225, loss: 0.2191, ce_loss: 0.2191., accu: 0.8653, speed: 1.19 step/s\n",
      "global step 16350, epoch: 4, batch: 2235, loss: 0.2458, ce_loss: 0.2458., accu: 0.8653, speed: 1.20 step/s\n",
      "global step 16360, epoch: 4, batch: 2245, loss: 0.2123, ce_loss: 0.2123., accu: 0.8653, speed: 1.18 step/s\n",
      "global step 16370, epoch: 4, batch: 2255, loss: 0.2218, ce_loss: 0.2218., accu: 0.8654, speed: 1.18 step/s\n",
      "global step 16380, epoch: 4, batch: 2265, loss: 0.2110, ce_loss: 0.2110., accu: 0.8654, speed: 1.20 step/s\n",
      "global step 16390, epoch: 4, batch: 2275, loss: 0.2123, ce_loss: 0.2123., accu: 0.8654, speed: 1.19 step/s\n",
      "global step 16400, epoch: 4, batch: 2285, loss: 0.2583, ce_loss: 0.2583., accu: 0.8654, speed: 1.19 step/s\n",
      "2022-09-28 16:59:32,398\t[train.py-do_train]-[line:187]-INFO:【global step 16400, epoch: 4, batch: 2285】，loss: 0.2583, ce_loss: 0.2583., accu: 0.8654,\n",
      "global step 16410, epoch: 4, batch: 2295, loss: 0.2206, ce_loss: 0.2206., accu: 0.8655, speed: 1.20 step/s\n",
      "global step 16420, epoch: 4, batch: 2305, loss: 0.1722, ce_loss: 0.1722., accu: 0.8655, speed: 1.19 step/s\n",
      "global step 16430, epoch: 4, batch: 2315, loss: 0.2060, ce_loss: 0.2060., accu: 0.8655, speed: 1.20 step/s\n",
      "global step 16440, epoch: 4, batch: 2325, loss: 0.1447, ce_loss: 0.1447., accu: 0.8656, speed: 1.18 step/s\n",
      "global step 16450, epoch: 4, batch: 2335, loss: 0.2135, ce_loss: 0.2135., accu: 0.8656, speed: 1.18 step/s\n",
      "global step 16460, epoch: 4, batch: 2345, loss: 0.2005, ce_loss: 0.2005., accu: 0.8656, speed: 1.22 step/s\n",
      "global step 16470, epoch: 4, batch: 2355, loss: 0.2002, ce_loss: 0.2002., accu: 0.8656, speed: 1.19 step/s\n",
      "global step 16480, epoch: 4, batch: 2365, loss: 0.2092, ce_loss: 0.2092., accu: 0.8657, speed: 1.18 step/s\n",
      "global step 16490, epoch: 4, batch: 2375, loss: 0.2267, ce_loss: 0.2267., accu: 0.8657, speed: 1.19 step/s\n",
      "global step 16500, epoch: 4, batch: 2385, loss: 0.2199, ce_loss: 0.2199., accu: 0.8657, speed: 1.21 step/s\n",
      "2022-09-28 17:00:56,169\t[train.py-do_train]-[line:187]-INFO:【global step 16500, epoch: 4, batch: 2385】，loss: 0.2199, ce_loss: 0.2199., accu: 0.8657,\n",
      "global step 16510, epoch: 4, batch: 2395, loss: 0.2463, ce_loss: 0.2463., accu: 0.8657, speed: 1.19 step/s\n",
      "global step 16520, epoch: 4, batch: 2405, loss: 0.2040, ce_loss: 0.2040., accu: 0.8658, speed: 1.18 step/s\n",
      "global step 16530, epoch: 4, batch: 2415, loss: 0.1634, ce_loss: 0.1634., accu: 0.8658, speed: 1.18 step/s\n",
      "global step 16540, epoch: 4, batch: 2425, loss: 0.2133, ce_loss: 0.2133., accu: 0.8658, speed: 1.18 step/s\n",
      "global step 16550, epoch: 4, batch: 2435, loss: 0.1720, ce_loss: 0.1720., accu: 0.8659, speed: 1.21 step/s\n",
      "global step 16560, epoch: 4, batch: 2445, loss: 0.2508, ce_loss: 0.2508., accu: 0.8659, speed: 1.19 step/s\n",
      "global step 16570, epoch: 4, batch: 2455, loss: 0.2049, ce_loss: 0.2049., accu: 0.8659, speed: 1.19 step/s\n",
      "global step 16580, epoch: 4, batch: 2465, loss: 0.1768, ce_loss: 0.1768., accu: 0.8659, speed: 1.18 step/s\n",
      "global step 16590, epoch: 4, batch: 2475, loss: 0.2180, ce_loss: 0.2180., accu: 0.8660, speed: 1.19 step/s\n",
      "global step 16600, epoch: 4, batch: 2485, loss: 0.2327, ce_loss: 0.2327., accu: 0.8660, speed: 1.18 step/s\n",
      "2022-09-28 17:02:20,366\t[train.py-do_train]-[line:187]-INFO:【global step 16600, epoch: 4, batch: 2485】，loss: 0.2327, ce_loss: 0.2327., accu: 0.8660,\n",
      "global step 16610, epoch: 4, batch: 2495, loss: 0.2632, ce_loss: 0.2632., accu: 0.8660, speed: 1.19 step/s\n",
      "global step 16620, epoch: 4, batch: 2505, loss: 0.2045, ce_loss: 0.2045., accu: 0.8660, speed: 1.18 step/s\n",
      "global step 16630, epoch: 4, batch: 2515, loss: 0.1916, ce_loss: 0.1916., accu: 0.8661, speed: 1.19 step/s\n",
      "global step 16640, epoch: 4, batch: 2525, loss: 0.1960, ce_loss: 0.1960., accu: 0.8661, speed: 1.19 step/s\n",
      "global step 16650, epoch: 4, batch: 2535, loss: 0.1531, ce_loss: 0.1531., accu: 0.8661, speed: 1.18 step/s\n",
      "global step 16660, epoch: 4, batch: 2545, loss: 0.2464, ce_loss: 0.2464., accu: 0.8661, speed: 1.19 step/s\n",
      "global step 16670, epoch: 4, batch: 2555, loss: 0.2006, ce_loss: 0.2006., accu: 0.8662, speed: 1.19 step/s\n",
      "global step 16680, epoch: 4, batch: 2565, loss: 0.2742, ce_loss: 0.2742., accu: 0.8662, speed: 1.19 step/s\n",
      "global step 16690, epoch: 4, batch: 2575, loss: 0.2262, ce_loss: 0.2262., accu: 0.8662, speed: 1.19 step/s\n",
      "global step 16700, epoch: 4, batch: 2585, loss: 0.2286, ce_loss: 0.2286., accu: 0.8663, speed: 1.21 step/s\n",
      "2022-09-28 17:03:44,388\t[train.py-do_train]-[line:187]-INFO:【global step 16700, epoch: 4, batch: 2585】，loss: 0.2286, ce_loss: 0.2286., accu: 0.8663,\n",
      "global step 16710, epoch: 4, batch: 2595, loss: 0.2781, ce_loss: 0.2781., accu: 0.8663, speed: 1.19 step/s\n",
      "global step 16720, epoch: 4, batch: 2605, loss: 0.2809, ce_loss: 0.2809., accu: 0.8663, speed: 1.18 step/s\n",
      "global step 16730, epoch: 4, batch: 2615, loss: 0.1790, ce_loss: 0.1790., accu: 0.8663, speed: 1.20 step/s\n",
      "global step 16740, epoch: 4, batch: 2625, loss: 0.1364, ce_loss: 0.1364., accu: 0.8664, speed: 1.18 step/s\n",
      "global step 16750, epoch: 4, batch: 2635, loss: 0.2872, ce_loss: 0.2872., accu: 0.8664, speed: 1.19 step/s\n",
      "global step 16760, epoch: 4, batch: 2645, loss: 0.3130, ce_loss: 0.3130., accu: 0.8664, speed: 1.20 step/s\n",
      "global step 16770, epoch: 4, batch: 2655, loss: 0.1738, ce_loss: 0.1738., accu: 0.8665, speed: 1.19 step/s\n",
      "global step 16780, epoch: 4, batch: 2665, loss: 0.1629, ce_loss: 0.1629., accu: 0.8665, speed: 1.20 step/s\n",
      "global step 16790, epoch: 4, batch: 2675, loss: 0.2244, ce_loss: 0.2244., accu: 0.8665, speed: 1.18 step/s\n",
      "global step 16800, epoch: 4, batch: 2685, loss: 0.1789, ce_loss: 0.1789., accu: 0.8665, speed: 1.19 step/s\n",
      "2022-09-28 17:05:08,500\t[train.py-do_train]-[line:187]-INFO:【global step 16800, epoch: 4, batch: 2685】，loss: 0.1789, ce_loss: 0.1789., accu: 0.8665,\n",
      "global step 16810, epoch: 4, batch: 2695, loss: 0.2339, ce_loss: 0.2339., accu: 0.8666, speed: 1.18 step/s\n",
      "global step 16820, epoch: 4, batch: 2705, loss: 0.1941, ce_loss: 0.1941., accu: 0.8666, speed: 1.18 step/s\n",
      "global step 16830, epoch: 4, batch: 2715, loss: 0.2476, ce_loss: 0.2476., accu: 0.8666, speed: 1.18 step/s\n",
      "global step 16840, epoch: 4, batch: 2725, loss: 0.2216, ce_loss: 0.2216., accu: 0.8666, speed: 1.18 step/s\n",
      "global step 16850, epoch: 4, batch: 2735, loss: 0.1654, ce_loss: 0.1654., accu: 0.8667, speed: 1.18 step/s\n",
      "global step 16860, epoch: 4, batch: 2745, loss: 0.1461, ce_loss: 0.1461., accu: 0.8667, speed: 1.18 step/s\n",
      "global step 16870, epoch: 4, batch: 2755, loss: 0.1515, ce_loss: 0.1515., accu: 0.8667, speed: 1.18 step/s\n",
      "global step 16880, epoch: 4, batch: 2765, loss: 0.2499, ce_loss: 0.2499., accu: 0.8667, speed: 1.21 step/s\n",
      "global step 16890, epoch: 4, batch: 2775, loss: 0.2467, ce_loss: 0.2467., accu: 0.8667, speed: 1.18 step/s\n",
      "global step 16900, epoch: 4, batch: 2785, loss: 0.2291, ce_loss: 0.2291., accu: 0.8668, speed: 1.19 step/s\n",
      "2022-09-28 17:06:32,964\t[train.py-do_train]-[line:187]-INFO:【global step 16900, epoch: 4, batch: 2785】，loss: 0.2291, ce_loss: 0.2291., accu: 0.8668,\n",
      "global step 16910, epoch: 4, batch: 2795, loss: 0.2179, ce_loss: 0.2179., accu: 0.8668, speed: 1.18 step/s\n",
      "global step 16920, epoch: 4, batch: 2805, loss: 0.2481, ce_loss: 0.2481., accu: 0.8668, speed: 1.19 step/s\n",
      "global step 16930, epoch: 4, batch: 2815, loss: 0.1603, ce_loss: 0.1603., accu: 0.8668, speed: 1.18 step/s\n",
      "global step 16940, epoch: 4, batch: 2825, loss: 0.2228, ce_loss: 0.2228., accu: 0.8669, speed: 1.18 step/s\n",
      "global step 16950, epoch: 4, batch: 2835, loss: 0.1788, ce_loss: 0.1788., accu: 0.8669, speed: 1.18 step/s\n",
      "global step 16960, epoch: 4, batch: 2845, loss: 0.1730, ce_loss: 0.1730., accu: 0.8669, speed: 1.18 step/s\n",
      "global step 16970, epoch: 4, batch: 2855, loss: 0.1839, ce_loss: 0.1839., accu: 0.8670, speed: 1.18 step/s\n",
      "global step 16980, epoch: 4, batch: 2865, loss: 0.1752, ce_loss: 0.1752., accu: 0.8670, speed: 1.21 step/s\n",
      "global step 16990, epoch: 4, batch: 2875, loss: 0.1638, ce_loss: 0.1638., accu: 0.8670, speed: 1.19 step/s\n",
      "global step 17000, epoch: 4, batch: 2885, loss: 0.1187, ce_loss: 0.1187., accu: 0.8670, speed: 1.18 step/s\n",
      "2022-09-28 17:07:57,454\t[train.py-do_train]-[line:187]-INFO:【global step 17000, epoch: 4, batch: 2885】，loss: 0.1187, ce_loss: 0.1187., accu: 0.8670,\n",
      "global step 17010, epoch: 4, batch: 2895, loss: 0.2133, ce_loss: 0.2133., accu: 0.8670, speed: 1.19 step/s\n",
      "global step 17020, epoch: 4, batch: 2905, loss: 0.2070, ce_loss: 0.2070., accu: 0.8671, speed: 1.19 step/s\n",
      "global step 17030, epoch: 4, batch: 2915, loss: 0.2370, ce_loss: 0.2370., accu: 0.8671, speed: 1.19 step/s\n",
      "global step 17040, epoch: 4, batch: 2925, loss: 0.2238, ce_loss: 0.2238., accu: 0.8671, speed: 1.19 step/s\n",
      "global step 17050, epoch: 4, batch: 2935, loss: 0.2024, ce_loss: 0.2024., accu: 0.8671, speed: 1.18 step/s\n",
      "global step 17060, epoch: 4, batch: 2945, loss: 0.2803, ce_loss: 0.2803., accu: 0.8672, speed: 1.18 step/s\n",
      "global step 17070, epoch: 4, batch: 2955, loss: 0.1931, ce_loss: 0.1931., accu: 0.8672, speed: 1.18 step/s\n",
      "global step 17080, epoch: 4, batch: 2965, loss: 0.2635, ce_loss: 0.2635., accu: 0.8672, speed: 1.18 step/s\n",
      "global step 17090, epoch: 4, batch: 2975, loss: 0.3553, ce_loss: 0.3553., accu: 0.8672, speed: 1.18 step/s\n",
      "global step 17100, epoch: 4, batch: 2985, loss: 0.1894, ce_loss: 0.1894., accu: 0.8672, speed: 1.18 step/s\n",
      "2022-09-28 17:09:21,956\t[train.py-do_train]-[line:187]-INFO:【global step 17100, epoch: 4, batch: 2985】，loss: 0.1894, ce_loss: 0.1894., accu: 0.8672,\n",
      "global step 17110, epoch: 4, batch: 2995, loss: 0.1499, ce_loss: 0.1499., accu: 0.8673, speed: 1.18 step/s\n",
      "global step 17120, epoch: 4, batch: 3005, loss: 0.2179, ce_loss: 0.2179., accu: 0.8673, speed: 1.18 step/s\n",
      "global step 17130, epoch: 4, batch: 3015, loss: 0.1310, ce_loss: 0.1310., accu: 0.8673, speed: 1.18 step/s\n",
      "global step 17140, epoch: 4, batch: 3025, loss: 0.2350, ce_loss: 0.2350., accu: 0.8674, speed: 1.18 step/s\n",
      "global step 17150, epoch: 4, batch: 3035, loss: 0.2543, ce_loss: 0.2543., accu: 0.8674, speed: 1.19 step/s\n",
      "global step 17160, epoch: 4, batch: 3045, loss: 0.1504, ce_loss: 0.1504., accu: 0.8674, speed: 1.19 step/s\n",
      "global step 17170, epoch: 4, batch: 3055, loss: 0.2103, ce_loss: 0.2103., accu: 0.8674, speed: 1.20 step/s\n",
      "global step 17180, epoch: 4, batch: 3065, loss: 0.2094, ce_loss: 0.2094., accu: 0.8674, speed: 1.19 step/s\n",
      "global step 17190, epoch: 4, batch: 3075, loss: 0.2177, ce_loss: 0.2177., accu: 0.8675, speed: 1.21 step/s\n",
      "global step 17200, epoch: 4, batch: 3085, loss: 0.1427, ce_loss: 0.1427., accu: 0.8675, speed: 1.18 step/s\n",
      "2022-09-28 17:10:46,043\t[train.py-do_train]-[line:187]-INFO:【global step 17200, epoch: 4, batch: 3085】，loss: 0.1427, ce_loss: 0.1427., accu: 0.8675,\n",
      "global step 17210, epoch: 4, batch: 3095, loss: 0.1263, ce_loss: 0.1263., accu: 0.8675, speed: 1.19 step/s\n",
      "global step 17220, epoch: 4, batch: 3105, loss: 0.1681, ce_loss: 0.1681., accu: 0.8676, speed: 1.19 step/s\n",
      "global step 17230, epoch: 4, batch: 3115, loss: 0.1349, ce_loss: 0.1349., accu: 0.8676, speed: 1.20 step/s\n",
      "global step 17240, epoch: 4, batch: 3125, loss: 0.1943, ce_loss: 0.1943., accu: 0.8676, speed: 1.18 step/s\n",
      "global step 17250, epoch: 4, batch: 3135, loss: 0.2322, ce_loss: 0.2322., accu: 0.8676, speed: 1.19 step/s\n",
      "global step 17260, epoch: 4, batch: 3145, loss: 0.2430, ce_loss: 0.2430., accu: 0.8677, speed: 1.19 step/s\n",
      "global step 17270, epoch: 4, batch: 3155, loss: 0.2021, ce_loss: 0.2021., accu: 0.8677, speed: 1.19 step/s\n",
      "global step 17280, epoch: 4, batch: 3165, loss: 0.1658, ce_loss: 0.1658., accu: 0.8677, speed: 1.20 step/s\n",
      "global step 17290, epoch: 4, batch: 3175, loss: 0.2211, ce_loss: 0.2211., accu: 0.8677, speed: 1.18 step/s\n",
      "global step 17300, epoch: 4, batch: 3185, loss: 0.1422, ce_loss: 0.1422., accu: 0.8678, speed: 1.20 step/s\n",
      "2022-09-28 17:12:10,100\t[train.py-do_train]-[line:187]-INFO:【global step 17300, epoch: 4, batch: 3185】，loss: 0.1422, ce_loss: 0.1422., accu: 0.8678,\n",
      "global step 17310, epoch: 4, batch: 3195, loss: 0.1274, ce_loss: 0.1274., accu: 0.8678, speed: 1.20 step/s\n",
      "global step 17320, epoch: 4, batch: 3205, loss: 0.2270, ce_loss: 0.2270., accu: 0.8678, speed: 1.21 step/s\n",
      "global step 17330, epoch: 4, batch: 3215, loss: 0.1704, ce_loss: 0.1704., accu: 0.8678, speed: 1.18 step/s\n",
      "global step 17340, epoch: 4, batch: 3225, loss: 0.1896, ce_loss: 0.1896., accu: 0.8679, speed: 1.20 step/s\n",
      "global step 17350, epoch: 4, batch: 3235, loss: 0.1788, ce_loss: 0.1788., accu: 0.8679, speed: 1.18 step/s\n",
      "global step 17360, epoch: 4, batch: 3245, loss: 0.2238, ce_loss: 0.2238., accu: 0.8679, speed: 1.20 step/s\n",
      "global step 17370, epoch: 4, batch: 3255, loss: 0.1596, ce_loss: 0.1596., accu: 0.8679, speed: 1.18 step/s\n",
      "global step 17380, epoch: 4, batch: 3265, loss: 0.2254, ce_loss: 0.2254., accu: 0.8680, speed: 1.18 step/s\n",
      "global step 17390, epoch: 4, batch: 3275, loss: 0.2441, ce_loss: 0.2441., accu: 0.8680, speed: 1.18 step/s\n",
      "global step 17400, epoch: 4, batch: 3285, loss: 0.2132, ce_loss: 0.2132., accu: 0.8680, speed: 1.20 step/s\n",
      "2022-09-28 17:13:34,202\t[train.py-do_train]-[line:187]-INFO:【global step 17400, epoch: 4, batch: 3285】，loss: 0.2132, ce_loss: 0.2132., accu: 0.8680,\n",
      "global step 17410, epoch: 4, batch: 3295, loss: 0.2694, ce_loss: 0.2694., accu: 0.8680, speed: 1.18 step/s\n",
      "global step 17420, epoch: 4, batch: 3305, loss: 0.2318, ce_loss: 0.2318., accu: 0.8680, speed: 1.18 step/s\n",
      "global step 17430, epoch: 4, batch: 3315, loss: 0.2252, ce_loss: 0.2252., accu: 0.8681, speed: 1.18 step/s\n",
      "global step 17440, epoch: 4, batch: 3325, loss: 0.2491, ce_loss: 0.2491., accu: 0.8681, speed: 1.18 step/s\n",
      "global step 17450, epoch: 4, batch: 3335, loss: 0.2131, ce_loss: 0.2131., accu: 0.8681, speed: 1.20 step/s\n",
      "global step 17460, epoch: 4, batch: 3345, loss: 0.2084, ce_loss: 0.2084., accu: 0.8681, speed: 1.18 step/s\n",
      "global step 17470, epoch: 4, batch: 3355, loss: 0.1956, ce_loss: 0.1956., accu: 0.8682, speed: 1.18 step/s\n",
      "global step 17480, epoch: 4, batch: 3365, loss: 0.2551, ce_loss: 0.2551., accu: 0.8682, speed: 1.18 step/s\n",
      "global step 17490, epoch: 4, batch: 3375, loss: 0.2010, ce_loss: 0.2010., accu: 0.8682, speed: 1.18 step/s\n",
      "global step 17500, epoch: 4, batch: 3385, loss: 0.1770, ce_loss: 0.1770., accu: 0.8682, speed: 1.20 step/s\n",
      "2022-09-28 17:14:58,575\t[train.py-do_train]-[line:187]-INFO:【global step 17500, epoch: 4, batch: 3385】，loss: 0.1770, ce_loss: 0.1770., accu: 0.8682,\n",
      "global step 17510, epoch: 4, batch: 3395, loss: 0.1142, ce_loss: 0.1142., accu: 0.8683, speed: 1.18 step/s\n",
      "global step 17520, epoch: 4, batch: 3405, loss: 0.2172, ce_loss: 0.2172., accu: 0.8683, speed: 1.20 step/s\n",
      "global step 17530, epoch: 4, batch: 3415, loss: 0.1769, ce_loss: 0.1769., accu: 0.8683, speed: 1.18 step/s\n",
      "global step 17540, epoch: 4, batch: 3425, loss: 0.2207, ce_loss: 0.2207., accu: 0.8683, speed: 1.19 step/s\n",
      "global step 17550, epoch: 4, batch: 3435, loss: 0.1774, ce_loss: 0.1774., accu: 0.8684, speed: 1.18 step/s\n",
      "global step 17560, epoch: 4, batch: 3445, loss: 0.1761, ce_loss: 0.1761., accu: 0.8684, speed: 1.19 step/s\n",
      "global step 17570, epoch: 4, batch: 3455, loss: 0.2443, ce_loss: 0.2443., accu: 0.8684, speed: 1.18 step/s\n",
      "global step 17580, epoch: 4, batch: 3465, loss: 0.2943, ce_loss: 0.2943., accu: 0.8684, speed: 1.19 step/s\n",
      "global step 17590, epoch: 4, batch: 3475, loss: 0.2320, ce_loss: 0.2320., accu: 0.8685, speed: 1.19 step/s\n",
      "global step 17600, epoch: 4, batch: 3485, loss: 0.1760, ce_loss: 0.1760., accu: 0.8685, speed: 1.19 step/s\n",
      "2022-09-28 17:16:22,789\t[train.py-do_train]-[line:187]-INFO:【global step 17600, epoch: 4, batch: 3485】，loss: 0.1760, ce_loss: 0.1760., accu: 0.8685,\n",
      "global step 17610, epoch: 4, batch: 3495, loss: 0.1794, ce_loss: 0.1794., accu: 0.8685, speed: 1.19 step/s\n",
      "global step 17620, epoch: 4, batch: 3505, loss: 0.1822, ce_loss: 0.1822., accu: 0.8685, speed: 1.18 step/s\n",
      "global step 17630, epoch: 4, batch: 3515, loss: 0.1711, ce_loss: 0.1711., accu: 0.8686, speed: 1.18 step/s\n",
      "global step 17640, epoch: 4, batch: 3525, loss: 0.2658, ce_loss: 0.2658., accu: 0.8686, speed: 1.18 step/s\n",
      "global step 17650, epoch: 4, batch: 3535, loss: 0.1816, ce_loss: 0.1816., accu: 0.8686, speed: 1.20 step/s\n",
      "global step 17660, epoch: 4, batch: 3545, loss: 0.2403, ce_loss: 0.2403., accu: 0.8686, speed: 1.21 step/s\n",
      "global step 17670, epoch: 4, batch: 3555, loss: 0.2660, ce_loss: 0.2660., accu: 0.8686, speed: 1.19 step/s\n",
      "global step 17680, epoch: 4, batch: 3565, loss: 0.2325, ce_loss: 0.2325., accu: 0.8687, speed: 1.19 step/s\n",
      "global step 17690, epoch: 4, batch: 3575, loss: 0.2501, ce_loss: 0.2501., accu: 0.8687, speed: 1.19 step/s\n",
      "global step 17700, epoch: 4, batch: 3585, loss: 0.1536, ce_loss: 0.1536., accu: 0.8687, speed: 1.18 step/s\n",
      "2022-09-28 17:17:46,851\t[train.py-do_train]-[line:187]-INFO:【global step 17700, epoch: 4, batch: 3585】，loss: 0.1536, ce_loss: 0.1536., accu: 0.8687,\n",
      "global step 17710, epoch: 4, batch: 3595, loss: 0.1908, ce_loss: 0.1908., accu: 0.8687, speed: 1.18 step/s\n",
      "global step 17720, epoch: 4, batch: 3605, loss: 0.3283, ce_loss: 0.3283., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 17730, epoch: 4, batch: 3615, loss: 0.2084, ce_loss: 0.2084., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 17740, epoch: 4, batch: 3625, loss: 0.2685, ce_loss: 0.2685., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 17750, epoch: 4, batch: 3635, loss: 0.1873, ce_loss: 0.1873., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 17760, epoch: 4, batch: 3645, loss: 0.1440, ce_loss: 0.1440., accu: 0.8689, speed: 1.19 step/s\n",
      "global step 17770, epoch: 4, batch: 3655, loss: 0.1374, ce_loss: 0.1374., accu: 0.8689, speed: 1.18 step/s\n",
      "global step 17780, epoch: 4, batch: 3665, loss: 0.3634, ce_loss: 0.3634., accu: 0.8689, speed: 1.18 step/s\n",
      "global step 17790, epoch: 4, batch: 3675, loss: 0.1940, ce_loss: 0.1940., accu: 0.8689, speed: 1.18 step/s\n",
      "global step 17800, epoch: 4, batch: 3685, loss: 0.1995, ce_loss: 0.1995., accu: 0.8690, speed: 1.18 step/s\n",
      "2022-09-28 17:19:11,574\t[train.py-do_train]-[line:187]-INFO:【global step 17800, epoch: 4, batch: 3685】，loss: 0.1995, ce_loss: 0.1995., accu: 0.8690,\n",
      "global step 17810, epoch: 4, batch: 3695, loss: 0.2005, ce_loss: 0.2005., accu: 0.8690, speed: 1.18 step/s\n",
      "global step 17820, epoch: 4, batch: 3705, loss: 0.1899, ce_loss: 0.1899., accu: 0.8690, speed: 1.18 step/s\n",
      "global step 17830, epoch: 4, batch: 3715, loss: 0.2203, ce_loss: 0.2203., accu: 0.8690, speed: 1.18 step/s\n",
      "global step 17840, epoch: 4, batch: 3725, loss: 0.2111, ce_loss: 0.2111., accu: 0.8691, speed: 1.19 step/s\n",
      "global step 17850, epoch: 4, batch: 3735, loss: 0.1410, ce_loss: 0.1410., accu: 0.8691, speed: 1.18 step/s\n",
      "global step 17860, epoch: 4, batch: 3745, loss: 0.2132, ce_loss: 0.2132., accu: 0.8691, speed: 1.19 step/s\n",
      "global step 17870, epoch: 4, batch: 3755, loss: 0.1576, ce_loss: 0.1576., accu: 0.8691, speed: 1.18 step/s\n",
      "global step 17880, epoch: 4, batch: 3765, loss: 0.2358, ce_loss: 0.2358., accu: 0.8692, speed: 1.19 step/s\n",
      "global step 17890, epoch: 4, batch: 3775, loss: 0.2306, ce_loss: 0.2306., accu: 0.8692, speed: 1.18 step/s\n",
      "global step 17900, epoch: 4, batch: 3785, loss: 0.2435, ce_loss: 0.2435., accu: 0.8692, speed: 1.18 step/s\n",
      "2022-09-28 17:20:36,194\t[train.py-do_train]-[line:187]-INFO:【global step 17900, epoch: 4, batch: 3785】，loss: 0.2435, ce_loss: 0.2435., accu: 0.8692,\n",
      "global step 17910, epoch: 4, batch: 3795, loss: 0.1903, ce_loss: 0.1903., accu: 0.8692, speed: 1.18 step/s\n",
      "global step 17920, epoch: 4, batch: 3805, loss: 0.1708, ce_loss: 0.1708., accu: 0.8693, speed: 1.18 step/s\n",
      "global step 17930, epoch: 4, batch: 3815, loss: 0.2811, ce_loss: 0.2811., accu: 0.8693, speed: 1.19 step/s\n",
      "global step 17940, epoch: 4, batch: 3825, loss: 0.2230, ce_loss: 0.2230., accu: 0.8693, speed: 1.19 step/s\n",
      "global step 17950, epoch: 4, batch: 3835, loss: 0.1964, ce_loss: 0.1964., accu: 0.8693, speed: 1.18 step/s\n",
      "global step 17960, epoch: 4, batch: 3845, loss: 0.1688, ce_loss: 0.1688., accu: 0.8693, speed: 1.18 step/s\n",
      "global step 17970, epoch: 4, batch: 3855, loss: 0.2235, ce_loss: 0.2235., accu: 0.8694, speed: 1.18 step/s\n",
      "global step 17980, epoch: 4, batch: 3865, loss: 0.1687, ce_loss: 0.1687., accu: 0.8694, speed: 1.20 step/s\n",
      "global step 17990, epoch: 4, batch: 3875, loss: 0.2572, ce_loss: 0.2572., accu: 0.8694, speed: 1.18 step/s\n",
      "global step 18000, epoch: 4, batch: 3885, loss: 0.1458, ce_loss: 0.1458., accu: 0.8694, speed: 1.18 step/s\n",
      "2022-09-28 17:22:00,782\t[train.py-do_train]-[line:187]-INFO:【global step 18000, epoch: 4, batch: 3885】，loss: 0.1458, ce_loss: 0.1458., accu: 0.8694,\n",
      "global step 18010, epoch: 4, batch: 3895, loss: 0.2076, ce_loss: 0.2076., accu: 0.8695, speed: 1.18 step/s\n",
      "global step 18020, epoch: 4, batch: 3905, loss: 0.1243, ce_loss: 0.1243., accu: 0.8695, speed: 1.19 step/s\n",
      "global step 18030, epoch: 4, batch: 3915, loss: 0.2187, ce_loss: 0.2187., accu: 0.8695, speed: 1.18 step/s\n",
      "global step 18040, epoch: 4, batch: 3925, loss: 0.1865, ce_loss: 0.1865., accu: 0.8695, speed: 1.19 step/s\n",
      "global step 18050, epoch: 4, batch: 3935, loss: 0.1761, ce_loss: 0.1761., accu: 0.8696, speed: 1.22 step/s\n",
      "global step 18060, epoch: 4, batch: 3945, loss: 0.1674, ce_loss: 0.1674., accu: 0.8696, speed: 1.18 step/s\n",
      "global step 18070, epoch: 4, batch: 3955, loss: 0.2326, ce_loss: 0.2326., accu: 0.8696, speed: 1.18 step/s\n",
      "global step 18080, epoch: 4, batch: 3965, loss: 0.2193, ce_loss: 0.2193., accu: 0.8696, speed: 1.18 step/s\n",
      "global step 18090, epoch: 4, batch: 3975, loss: 0.2426, ce_loss: 0.2426., accu: 0.8696, speed: 1.19 step/s\n",
      "global step 18100, epoch: 4, batch: 3985, loss: 0.2202, ce_loss: 0.2202., accu: 0.8697, speed: 1.20 step/s\n",
      "2022-09-28 17:23:24,850\t[train.py-do_train]-[line:187]-INFO:【global step 18100, epoch: 4, batch: 3985】，loss: 0.2202, ce_loss: 0.2202., accu: 0.8697,\n",
      "global step 18110, epoch: 4, batch: 3995, loss: 0.1748, ce_loss: 0.1748., accu: 0.8697, speed: 1.18 step/s\n",
      "global step 18120, epoch: 4, batch: 4005, loss: 0.2004, ce_loss: 0.2004., accu: 0.8697, speed: 1.18 step/s\n",
      "global step 18130, epoch: 4, batch: 4015, loss: 0.2314, ce_loss: 0.2314., accu: 0.8697, speed: 1.18 step/s\n",
      "global step 18140, epoch: 4, batch: 4025, loss: 0.1808, ce_loss: 0.1808., accu: 0.8698, speed: 1.18 step/s\n",
      "global step 18150, epoch: 4, batch: 4035, loss: 0.2101, ce_loss: 0.2101., accu: 0.8698, speed: 1.22 step/s\n",
      "global step 18160, epoch: 4, batch: 4045, loss: 0.1501, ce_loss: 0.1501., accu: 0.8698, speed: 1.20 step/s\n",
      "global step 18170, epoch: 4, batch: 4055, loss: 0.2415, ce_loss: 0.2415., accu: 0.8698, speed: 1.18 step/s\n",
      "global step 18180, epoch: 4, batch: 4065, loss: 0.2079, ce_loss: 0.2079., accu: 0.8699, speed: 1.18 step/s\n",
      "global step 18190, epoch: 4, batch: 4075, loss: 0.1547, ce_loss: 0.1547., accu: 0.8699, speed: 1.18 step/s\n",
      "global step 18200, epoch: 4, batch: 4085, loss: 0.1708, ce_loss: 0.1708., accu: 0.8699, speed: 1.19 step/s\n",
      "2022-09-28 17:24:49,094\t[train.py-do_train]-[line:187]-INFO:【global step 18200, epoch: 4, batch: 4085】，loss: 0.1708, ce_loss: 0.1708., accu: 0.8699,\n",
      "global step 18210, epoch: 4, batch: 4095, loss: 0.2179, ce_loss: 0.2179., accu: 0.8699, speed: 1.18 step/s\n",
      "global step 18220, epoch: 4, batch: 4105, loss: 0.1738, ce_loss: 0.1738., accu: 0.8699, speed: 1.19 step/s\n",
      "global step 18230, epoch: 4, batch: 4115, loss: 0.2481, ce_loss: 0.2481., accu: 0.8700, speed: 1.19 step/s\n",
      "global step 18240, epoch: 4, batch: 4125, loss: 0.1655, ce_loss: 0.1655., accu: 0.8700, speed: 1.18 step/s\n",
      "global step 18250, epoch: 4, batch: 4135, loss: 0.2261, ce_loss: 0.2261., accu: 0.8700, speed: 1.19 step/s\n",
      "global step 18260, epoch: 4, batch: 4145, loss: 0.2078, ce_loss: 0.2078., accu: 0.8700, speed: 1.18 step/s\n",
      "global step 18270, epoch: 4, batch: 4155, loss: 0.2426, ce_loss: 0.2426., accu: 0.8701, speed: 1.18 step/s\n",
      "global step 18280, epoch: 4, batch: 4165, loss: 0.2465, ce_loss: 0.2465., accu: 0.8701, speed: 1.18 step/s\n",
      "global step 18290, epoch: 4, batch: 4175, loss: 0.2755, ce_loss: 0.2755., accu: 0.8701, speed: 1.18 step/s\n",
      "global step 18300, epoch: 4, batch: 4185, loss: 0.2305, ce_loss: 0.2305., accu: 0.8701, speed: 1.18 step/s\n",
      "2022-09-28 17:26:13,626\t[train.py-do_train]-[line:187]-INFO:【global step 18300, epoch: 4, batch: 4185】，loss: 0.2305, ce_loss: 0.2305., accu: 0.8701,\n",
      "global step 18310, epoch: 4, batch: 4195, loss: 0.1999, ce_loss: 0.1999., accu: 0.8702, speed: 1.18 step/s\n",
      "global step 18320, epoch: 4, batch: 4205, loss: 0.2262, ce_loss: 0.2262., accu: 0.8702, speed: 1.20 step/s\n",
      "global step 18330, epoch: 4, batch: 4215, loss: 0.2037, ce_loss: 0.2037., accu: 0.8702, speed: 1.18 step/s\n",
      "global step 18340, epoch: 4, batch: 4225, loss: 0.2100, ce_loss: 0.2100., accu: 0.8702, speed: 1.20 step/s\n",
      "global step 18350, epoch: 4, batch: 4235, loss: 0.2310, ce_loss: 0.2310., accu: 0.8702, speed: 1.18 step/s\n",
      "global step 18360, epoch: 4, batch: 4245, loss: 0.1860, ce_loss: 0.1860., accu: 0.8703, speed: 1.19 step/s\n",
      "global step 18370, epoch: 4, batch: 4255, loss: 0.2039, ce_loss: 0.2039., accu: 0.8703, speed: 1.18 step/s\n",
      "global step 18380, epoch: 4, batch: 4265, loss: 0.2010, ce_loss: 0.2010., accu: 0.8703, speed: 1.20 step/s\n",
      "global step 18390, epoch: 4, batch: 4275, loss: 0.2194, ce_loss: 0.2194., accu: 0.8703, speed: 1.18 step/s\n",
      "global step 18400, epoch: 4, batch: 4285, loss: 0.2976, ce_loss: 0.2976., accu: 0.8704, speed: 1.19 step/s\n",
      "2022-09-28 17:27:37,879\t[train.py-do_train]-[line:187]-INFO:【global step 18400, epoch: 4, batch: 4285】，loss: 0.2976, ce_loss: 0.2976., accu: 0.8704,\n",
      "global step 18410, epoch: 4, batch: 4295, loss: 0.2190, ce_loss: 0.2190., accu: 0.8704, speed: 1.19 step/s\n",
      "global step 18420, epoch: 4, batch: 4305, loss: 0.1959, ce_loss: 0.1959., accu: 0.8704, speed: 1.18 step/s\n",
      "global step 18430, epoch: 4, batch: 4315, loss: 0.1665, ce_loss: 0.1665., accu: 0.8704, speed: 1.19 step/s\n",
      "global step 18440, epoch: 4, batch: 4325, loss: 0.1879, ce_loss: 0.1879., accu: 0.8704, speed: 1.19 step/s\n",
      "global step 18450, epoch: 4, batch: 4335, loss: 0.2543, ce_loss: 0.2543., accu: 0.8705, speed: 1.20 step/s\n",
      "global step 18460, epoch: 4, batch: 4345, loss: 0.2230, ce_loss: 0.2230., accu: 0.8705, speed: 1.19 step/s\n",
      "global step 18470, epoch: 4, batch: 4355, loss: 0.1466, ce_loss: 0.1466., accu: 0.8705, speed: 1.18 step/s\n",
      "global step 18480, epoch: 4, batch: 4365, loss: 0.1947, ce_loss: 0.1947., accu: 0.8705, speed: 1.18 step/s\n",
      "global step 18490, epoch: 4, batch: 4375, loss: 0.2579, ce_loss: 0.2579., accu: 0.8706, speed: 1.19 step/s\n",
      "global step 18500, epoch: 4, batch: 4385, loss: 0.1763, ce_loss: 0.1763., accu: 0.8706, speed: 1.18 step/s\n",
      "2022-09-28 17:29:02,130\t[train.py-do_train]-[line:187]-INFO:【global step 18500, epoch: 4, batch: 4385】，loss: 0.1763, ce_loss: 0.1763., accu: 0.8706,\n",
      "global step 18510, epoch: 4, batch: 4395, loss: 0.2056, ce_loss: 0.2056., accu: 0.8706, speed: 1.18 step/s\n",
      "global step 18520, epoch: 4, batch: 4405, loss: 0.2432, ce_loss: 0.2432., accu: 0.8706, speed: 1.18 step/s\n",
      "global step 18530, epoch: 4, batch: 4415, loss: 0.1923, ce_loss: 0.1923., accu: 0.8706, speed: 1.18 step/s\n",
      "global step 18540, epoch: 4, batch: 4425, loss: 0.1643, ce_loss: 0.1643., accu: 0.8707, speed: 1.19 step/s\n",
      "global step 18550, epoch: 4, batch: 4435, loss: 0.2082, ce_loss: 0.2082., accu: 0.8707, speed: 1.18 step/s\n",
      "global step 18560, epoch: 4, batch: 4445, loss: 0.2032, ce_loss: 0.2032., accu: 0.8707, speed: 1.19 step/s\n",
      "global step 18570, epoch: 4, batch: 4455, loss: 0.2746, ce_loss: 0.2746., accu: 0.8707, speed: 1.18 step/s\n",
      "global step 18580, epoch: 4, batch: 4465, loss: 0.2204, ce_loss: 0.2204., accu: 0.8708, speed: 1.18 step/s\n",
      "global step 18590, epoch: 4, batch: 4475, loss: 0.2862, ce_loss: 0.2862., accu: 0.8708, speed: 1.20 step/s\n",
      "global step 18600, epoch: 4, batch: 4485, loss: 0.1844, ce_loss: 0.1844., accu: 0.8708, speed: 1.18 step/s\n",
      "2022-09-28 17:30:26,726\t[train.py-do_train]-[line:187]-INFO:【global step 18600, epoch: 4, batch: 4485】，loss: 0.1844, ce_loss: 0.1844., accu: 0.8708,\n",
      "global step 18610, epoch: 4, batch: 4495, loss: 0.1489, ce_loss: 0.1489., accu: 0.8708, speed: 1.19 step/s\n",
      "global step 18620, epoch: 4, batch: 4505, loss: 0.1478, ce_loss: 0.1478., accu: 0.8708, speed: 1.20 step/s\n",
      "global step 18630, epoch: 4, batch: 4515, loss: 0.1869, ce_loss: 0.1869., accu: 0.8709, speed: 1.19 step/s\n",
      "global step 18640, epoch: 4, batch: 4525, loss: 0.2417, ce_loss: 0.2417., accu: 0.8709, speed: 1.19 step/s\n",
      "global step 18650, epoch: 4, batch: 4535, loss: 0.1758, ce_loss: 0.1758., accu: 0.8709, speed: 1.18 step/s\n",
      "global step 18660, epoch: 4, batch: 4545, loss: 0.2549, ce_loss: 0.2549., accu: 0.8709, speed: 1.19 step/s\n",
      "global step 18670, epoch: 4, batch: 4555, loss: 0.2694, ce_loss: 0.2694., accu: 0.8709, speed: 1.19 step/s\n",
      "global step 18680, epoch: 4, batch: 4565, loss: 0.2110, ce_loss: 0.2110., accu: 0.8710, speed: 1.19 step/s\n",
      "global step 18690, epoch: 4, batch: 4575, loss: 0.1543, ce_loss: 0.1543., accu: 0.8710, speed: 1.18 step/s\n",
      "global step 18700, epoch: 4, batch: 4585, loss: 0.2261, ce_loss: 0.2261., accu: 0.8710, speed: 1.19 step/s\n",
      "2022-09-28 17:31:50,905\t[train.py-do_train]-[line:187]-INFO:【global step 18700, epoch: 4, batch: 4585】，loss: 0.2261, ce_loss: 0.2261., accu: 0.8710,\n",
      "global step 18710, epoch: 4, batch: 4595, loss: 0.1300, ce_loss: 0.1300., accu: 0.8710, speed: 1.19 step/s\n",
      "global step 18720, epoch: 4, batch: 4605, loss: 0.2001, ce_loss: 0.2001., accu: 0.8710, speed: 1.18 step/s\n",
      "global step 18730, epoch: 4, batch: 4615, loss: 0.2203, ce_loss: 0.2203., accu: 0.8711, speed: 1.18 step/s\n",
      "global step 18740, epoch: 4, batch: 4625, loss: 0.1678, ce_loss: 0.1678., accu: 0.8711, speed: 1.18 step/s\n",
      "global step 18750, epoch: 4, batch: 4635, loss: 0.1609, ce_loss: 0.1609., accu: 0.8711, speed: 1.19 step/s\n",
      "global step 18760, epoch: 4, batch: 4645, loss: 0.1144, ce_loss: 0.1144., accu: 0.8711, speed: 1.19 step/s\n",
      "global step 18770, epoch: 4, batch: 4655, loss: 0.2524, ce_loss: 0.2524., accu: 0.8711, speed: 1.19 step/s\n",
      "global step 18780, epoch: 4, batch: 4665, loss: 0.2578, ce_loss: 0.2578., accu: 0.8712, speed: 1.20 step/s\n",
      "global step 18790, epoch: 4, batch: 4675, loss: 0.2206, ce_loss: 0.2206., accu: 0.8712, speed: 1.19 step/s\n",
      "global step 18800, epoch: 4, batch: 4685, loss: 0.1967, ce_loss: 0.1967., accu: 0.8712, speed: 1.20 step/s\n",
      "2022-09-28 17:33:15,063\t[train.py-do_train]-[line:187]-INFO:【global step 18800, epoch: 4, batch: 4685】，loss: 0.1967, ce_loss: 0.1967., accu: 0.8712,\n",
      "global step 18810, epoch: 4, batch: 4695, loss: 0.2408, ce_loss: 0.2408., accu: 0.8712, speed: 1.18 step/s\n",
      "global step 18820, epoch: 4, batch: 4705, loss: 0.2045, ce_loss: 0.2045., accu: 0.8712, speed: 1.30 step/s\n",
      " 80%|███████████████████████████████▏       | 4/5 [4:24:15<1:06:04, 3964.15s/it]global step 18830, epoch: 5, batch: 10, loss: 0.1900, ce_loss: 0.1900., accu: 0.8713, speed: 1.16 step/s\n",
      "global step 18840, epoch: 5, batch: 20, loss: 0.1448, ce_loss: 0.1448., accu: 0.8713, speed: 1.19 step/s\n",
      "global step 18850, epoch: 5, batch: 30, loss: 0.2106, ce_loss: 0.2106., accu: 0.8713, speed: 1.18 step/s\n",
      "global step 18860, epoch: 5, batch: 40, loss: 0.1100, ce_loss: 0.1100., accu: 0.8713, speed: 1.18 step/s\n",
      "global step 18870, epoch: 5, batch: 50, loss: 0.1190, ce_loss: 0.1190., accu: 0.8714, speed: 1.18 step/s\n",
      "global step 18880, epoch: 5, batch: 60, loss: 0.2234, ce_loss: 0.2234., accu: 0.8714, speed: 1.18 step/s\n",
      "global step 18890, epoch: 5, batch: 70, loss: 0.3276, ce_loss: 0.3276., accu: 0.8714, speed: 1.19 step/s\n",
      "global step 18900, epoch: 5, batch: 80, loss: 0.2087, ce_loss: 0.2087., accu: 0.8715, speed: 1.18 step/s\n",
      "2022-09-28 17:34:39,012\t[train.py-do_train]-[line:187]-INFO:【global step 18900, epoch: 5, batch: 80】，loss: 0.2087, ce_loss: 0.2087., accu: 0.8715,\n",
      "global step 18910, epoch: 5, batch: 90, loss: 0.2001, ce_loss: 0.2001., accu: 0.8715, speed: 1.21 step/s\n",
      "global step 18920, epoch: 5, batch: 100, loss: 0.1748, ce_loss: 0.1748., accu: 0.8715, speed: 1.18 step/s\n",
      "global step 18930, epoch: 5, batch: 110, loss: 0.1261, ce_loss: 0.1261., accu: 0.8715, speed: 1.18 step/s\n",
      "global step 18940, epoch: 5, batch: 120, loss: 0.1090, ce_loss: 0.1090., accu: 0.8716, speed: 1.20 step/s\n",
      "global step 18950, epoch: 5, batch: 130, loss: 0.1734, ce_loss: 0.1734., accu: 0.8716, speed: 1.19 step/s\n",
      "global step 18960, epoch: 5, batch: 140, loss: 0.1368, ce_loss: 0.1368., accu: 0.8716, speed: 1.18 step/s\n",
      "global step 18970, epoch: 5, batch: 150, loss: 0.1348, ce_loss: 0.1348., accu: 0.8716, speed: 1.18 step/s\n",
      "global step 18980, epoch: 5, batch: 160, loss: 0.1244, ce_loss: 0.1244., accu: 0.8717, speed: 1.18 step/s\n",
      "global step 18990, epoch: 5, batch: 170, loss: 0.2313, ce_loss: 0.2313., accu: 0.8717, speed: 1.18 step/s\n",
      "global step 19000, epoch: 5, batch: 180, loss: 0.2373, ce_loss: 0.2373., accu: 0.8717, speed: 1.21 step/s\n",
      "2022-09-28 17:36:03,101\t[train.py-do_train]-[line:187]-INFO:【global step 19000, epoch: 5, batch: 180】，loss: 0.2373, ce_loss: 0.2373., accu: 0.8717,\n",
      "global step 19010, epoch: 5, batch: 190, loss: 0.1555, ce_loss: 0.1555., accu: 0.8717, speed: 1.19 step/s\n",
      "global step 19020, epoch: 5, batch: 200, loss: 0.1701, ce_loss: 0.1701., accu: 0.8718, speed: 1.18 step/s\n",
      "global step 19030, epoch: 5, batch: 210, loss: 0.1597, ce_loss: 0.1597., accu: 0.8718, speed: 1.19 step/s\n",
      "global step 19040, epoch: 5, batch: 220, loss: 0.2596, ce_loss: 0.2596., accu: 0.8718, speed: 1.19 step/s\n",
      "global step 19050, epoch: 5, batch: 230, loss: 0.1451, ce_loss: 0.1451., accu: 0.8719, speed: 1.18 step/s\n",
      "global step 19060, epoch: 5, batch: 240, loss: 0.2673, ce_loss: 0.2673., accu: 0.8719, speed: 1.18 step/s\n",
      "global step 19070, epoch: 5, batch: 250, loss: 0.2569, ce_loss: 0.2569., accu: 0.8719, speed: 1.18 step/s\n",
      "global step 19080, epoch: 5, batch: 260, loss: 0.1905, ce_loss: 0.1905., accu: 0.8719, speed: 1.20 step/s\n",
      "global step 19090, epoch: 5, batch: 270, loss: 0.1642, ce_loss: 0.1642., accu: 0.8719, speed: 1.18 step/s\n",
      "global step 19100, epoch: 5, batch: 280, loss: 0.1870, ce_loss: 0.1870., accu: 0.8720, speed: 1.18 step/s\n",
      "2022-09-28 17:37:27,456\t[train.py-do_train]-[line:187]-INFO:【global step 19100, epoch: 5, batch: 280】，loss: 0.1870, ce_loss: 0.1870., accu: 0.8720,\n",
      "global step 19110, epoch: 5, batch: 290, loss: 0.2799, ce_loss: 0.2799., accu: 0.8720, speed: 1.20 step/s\n",
      "global step 19120, epoch: 5, batch: 300, loss: 0.1776, ce_loss: 0.1776., accu: 0.8720, speed: 1.19 step/s\n",
      "global step 19130, epoch: 5, batch: 310, loss: 0.1025, ce_loss: 0.1025., accu: 0.8720, speed: 1.18 step/s\n",
      "global step 19140, epoch: 5, batch: 320, loss: 0.1571, ce_loss: 0.1571., accu: 0.8721, speed: 1.19 step/s\n",
      "global step 19150, epoch: 5, batch: 330, loss: 0.1884, ce_loss: 0.1884., accu: 0.8721, speed: 1.19 step/s\n",
      "global step 19160, epoch: 5, batch: 340, loss: 0.2038, ce_loss: 0.2038., accu: 0.8721, speed: 1.19 step/s\n",
      "global step 19170, epoch: 5, batch: 350, loss: 0.2263, ce_loss: 0.2263., accu: 0.8721, speed: 1.19 step/s\n",
      "global step 19180, epoch: 5, batch: 360, loss: 0.1396, ce_loss: 0.1396., accu: 0.8722, speed: 1.19 step/s\n",
      "global step 19190, epoch: 5, batch: 370, loss: 0.2586, ce_loss: 0.2586., accu: 0.8722, speed: 1.20 step/s\n",
      "global step 19200, epoch: 5, batch: 380, loss: 0.1527, ce_loss: 0.1527., accu: 0.8722, speed: 1.19 step/s\n",
      "2022-09-28 17:38:51,511\t[train.py-do_train]-[line:187]-INFO:【global step 19200, epoch: 5, batch: 380】，loss: 0.1527, ce_loss: 0.1527., accu: 0.8722,\n",
      "global step 19210, epoch: 5, batch: 390, loss: 0.2290, ce_loss: 0.2290., accu: 0.8722, speed: 1.18 step/s\n",
      "global step 19220, epoch: 5, batch: 400, loss: 0.1578, ce_loss: 0.1578., accu: 0.8723, speed: 1.19 step/s\n",
      "global step 19230, epoch: 5, batch: 410, loss: 0.1520, ce_loss: 0.1520., accu: 0.8723, speed: 1.18 step/s\n",
      "global step 19240, epoch: 5, batch: 420, loss: 0.1430, ce_loss: 0.1430., accu: 0.8723, speed: 1.21 step/s\n",
      "global step 19250, epoch: 5, batch: 430, loss: 0.1964, ce_loss: 0.1964., accu: 0.8723, speed: 1.19 step/s\n",
      "global step 19260, epoch: 5, batch: 440, loss: 0.2259, ce_loss: 0.2259., accu: 0.8724, speed: 1.20 step/s\n",
      "global step 19270, epoch: 5, batch: 450, loss: 0.1659, ce_loss: 0.1659., accu: 0.8724, speed: 1.19 step/s\n",
      "global step 19280, epoch: 5, batch: 460, loss: 0.1248, ce_loss: 0.1248., accu: 0.8724, speed: 1.18 step/s\n",
      "global step 19290, epoch: 5, batch: 470, loss: 0.1534, ce_loss: 0.1534., accu: 0.8725, speed: 1.19 step/s\n",
      "global step 19300, epoch: 5, batch: 480, loss: 0.1970, ce_loss: 0.1970., accu: 0.8725, speed: 1.20 step/s\n",
      "2022-09-28 17:40:15,515\t[train.py-do_train]-[line:187]-INFO:【global step 19300, epoch: 5, batch: 480】，loss: 0.1970, ce_loss: 0.1970., accu: 0.8725,\n",
      "global step 19310, epoch: 5, batch: 490, loss: 0.2083, ce_loss: 0.2083., accu: 0.8725, speed: 1.18 step/s\n",
      "global step 19320, epoch: 5, batch: 500, loss: 0.1959, ce_loss: 0.1959., accu: 0.8725, speed: 1.18 step/s\n",
      "global step 19330, epoch: 5, batch: 510, loss: 0.1488, ce_loss: 0.1488., accu: 0.8725, speed: 1.19 step/s\n",
      "global step 19340, epoch: 5, batch: 520, loss: 0.1647, ce_loss: 0.1647., accu: 0.8726, speed: 1.19 step/s\n",
      "global step 19350, epoch: 5, batch: 530, loss: 0.2440, ce_loss: 0.2440., accu: 0.8726, speed: 1.18 step/s\n",
      "global step 19360, epoch: 5, batch: 540, loss: 0.1719, ce_loss: 0.1719., accu: 0.8726, speed: 1.20 step/s\n",
      "global step 19370, epoch: 5, batch: 550, loss: 0.2076, ce_loss: 0.2076., accu: 0.8726, speed: 1.20 step/s\n",
      "global step 19380, epoch: 5, batch: 560, loss: 0.1445, ce_loss: 0.1445., accu: 0.8727, speed: 1.20 step/s\n",
      "global step 19390, epoch: 5, batch: 570, loss: 0.2065, ce_loss: 0.2065., accu: 0.8727, speed: 1.22 step/s\n",
      "global step 19400, epoch: 5, batch: 580, loss: 0.1380, ce_loss: 0.1380., accu: 0.8727, speed: 1.20 step/s\n",
      "2022-09-28 17:41:39,304\t[train.py-do_train]-[line:187]-INFO:【global step 19400, epoch: 5, batch: 580】，loss: 0.1380, ce_loss: 0.1380., accu: 0.8727,\n",
      "global step 19410, epoch: 5, batch: 590, loss: 0.2204, ce_loss: 0.2204., accu: 0.8728, speed: 1.18 step/s\n",
      "global step 19420, epoch: 5, batch: 600, loss: 0.1973, ce_loss: 0.1973., accu: 0.8728, speed: 1.19 step/s\n",
      "global step 19430, epoch: 5, batch: 610, loss: 0.2140, ce_loss: 0.2140., accu: 0.8728, speed: 1.18 step/s\n",
      "global step 19440, epoch: 5, batch: 620, loss: 0.1494, ce_loss: 0.1494., accu: 0.8728, speed: 1.19 step/s\n",
      "global step 19450, epoch: 5, batch: 630, loss: 0.2104, ce_loss: 0.2104., accu: 0.8729, speed: 1.20 step/s\n",
      "global step 19460, epoch: 5, batch: 640, loss: 0.1862, ce_loss: 0.1862., accu: 0.8729, speed: 1.18 step/s\n",
      "global step 19470, epoch: 5, batch: 650, loss: 0.1724, ce_loss: 0.1724., accu: 0.8729, speed: 1.20 step/s\n",
      "global step 19480, epoch: 5, batch: 660, loss: 0.2468, ce_loss: 0.2468., accu: 0.8729, speed: 1.18 step/s\n",
      "global step 19490, epoch: 5, batch: 670, loss: 0.2536, ce_loss: 0.2536., accu: 0.8730, speed: 1.18 step/s\n",
      "global step 19500, epoch: 5, batch: 680, loss: 0.1342, ce_loss: 0.1342., accu: 0.8730, speed: 1.21 step/s\n",
      "2022-09-28 17:43:03,403\t[train.py-do_train]-[line:187]-INFO:【global step 19500, epoch: 5, batch: 680】，loss: 0.1342, ce_loss: 0.1342., accu: 0.8730,\n",
      "global step 19510, epoch: 5, batch: 690, loss: 0.1091, ce_loss: 0.1091., accu: 0.8730, speed: 1.18 step/s\n",
      "global step 19520, epoch: 5, batch: 700, loss: 0.2062, ce_loss: 0.2062., accu: 0.8730, speed: 1.21 step/s\n",
      "global step 19530, epoch: 5, batch: 710, loss: 0.2298, ce_loss: 0.2298., accu: 0.8731, speed: 1.19 step/s\n",
      "global step 19540, epoch: 5, batch: 720, loss: 0.1901, ce_loss: 0.1901., accu: 0.8731, speed: 1.20 step/s\n",
      "global step 19550, epoch: 5, batch: 730, loss: 0.2030, ce_loss: 0.2030., accu: 0.8731, speed: 1.18 step/s\n",
      "global step 19560, epoch: 5, batch: 740, loss: 0.2122, ce_loss: 0.2122., accu: 0.8731, speed: 1.18 step/s\n",
      "global step 19570, epoch: 5, batch: 750, loss: 0.1288, ce_loss: 0.1288., accu: 0.8732, speed: 1.20 step/s\n",
      "global step 19580, epoch: 5, batch: 760, loss: 0.1226, ce_loss: 0.1226., accu: 0.8732, speed: 1.18 step/s\n",
      "global step 19590, epoch: 5, batch: 770, loss: 0.1767, ce_loss: 0.1767., accu: 0.8732, speed: 1.19 step/s\n",
      "global step 19600, epoch: 5, batch: 780, loss: 0.1592, ce_loss: 0.1592., accu: 0.8733, speed: 1.19 step/s\n",
      "2022-09-28 17:44:27,547\t[train.py-do_train]-[line:187]-INFO:【global step 19600, epoch: 5, batch: 780】，loss: 0.1592, ce_loss: 0.1592., accu: 0.8733,\n",
      "global step 19610, epoch: 5, batch: 790, loss: 0.1192, ce_loss: 0.1192., accu: 0.8733, speed: 1.19 step/s\n",
      "global step 19620, epoch: 5, batch: 800, loss: 0.1813, ce_loss: 0.1813., accu: 0.8733, speed: 1.19 step/s\n",
      "global step 19630, epoch: 5, batch: 810, loss: 0.1595, ce_loss: 0.1595., accu: 0.8733, speed: 1.19 step/s\n",
      "global step 19640, epoch: 5, batch: 820, loss: 0.1014, ce_loss: 0.1014., accu: 0.8733, speed: 1.19 step/s\n",
      "global step 19650, epoch: 5, batch: 830, loss: 0.2157, ce_loss: 0.2157., accu: 0.8734, speed: 1.18 step/s\n",
      "global step 19660, epoch: 5, batch: 840, loss: 0.1857, ce_loss: 0.1857., accu: 0.8734, speed: 1.19 step/s\n",
      "global step 19670, epoch: 5, batch: 850, loss: 0.2436, ce_loss: 0.2436., accu: 0.8734, speed: 1.22 step/s\n",
      "global step 19680, epoch: 5, batch: 860, loss: 0.0980, ce_loss: 0.0980., accu: 0.8735, speed: 1.18 step/s\n",
      "global step 19690, epoch: 5, batch: 870, loss: 0.2045, ce_loss: 0.2045., accu: 0.8735, speed: 1.19 step/s\n",
      "global step 19700, epoch: 5, batch: 880, loss: 0.2276, ce_loss: 0.2276., accu: 0.8735, speed: 1.18 step/s\n",
      "2022-09-28 17:45:51,652\t[train.py-do_train]-[line:187]-INFO:【global step 19700, epoch: 5, batch: 880】，loss: 0.2276, ce_loss: 0.2276., accu: 0.8735,\n",
      "global step 19710, epoch: 5, batch: 890, loss: 0.2051, ce_loss: 0.2051., accu: 0.8735, speed: 1.19 step/s\n",
      "global step 19720, epoch: 5, batch: 900, loss: 0.2564, ce_loss: 0.2564., accu: 0.8735, speed: 1.18 step/s\n",
      "global step 19730, epoch: 5, batch: 910, loss: 0.3109, ce_loss: 0.3109., accu: 0.8736, speed: 1.18 step/s\n",
      "global step 19740, epoch: 5, batch: 920, loss: 0.1396, ce_loss: 0.1396., accu: 0.8736, speed: 1.18 step/s\n",
      "global step 19750, epoch: 5, batch: 930, loss: 0.1602, ce_loss: 0.1602., accu: 0.8736, speed: 1.18 step/s\n",
      "global step 19760, epoch: 5, batch: 940, loss: 0.1988, ce_loss: 0.1988., accu: 0.8736, speed: 1.18 step/s\n",
      "global step 19770, epoch: 5, batch: 950, loss: 0.1907, ce_loss: 0.1907., accu: 0.8737, speed: 1.21 step/s\n",
      "global step 19780, epoch: 5, batch: 960, loss: 0.1835, ce_loss: 0.1835., accu: 0.8737, speed: 1.19 step/s\n",
      "global step 19790, epoch: 5, batch: 970, loss: 0.1571, ce_loss: 0.1571., accu: 0.8737, speed: 1.18 step/s\n",
      "global step 19800, epoch: 5, batch: 980, loss: 0.1781, ce_loss: 0.1781., accu: 0.8737, speed: 1.19 step/s\n",
      "2022-09-28 17:47:15,941\t[train.py-do_train]-[line:187]-INFO:【global step 19800, epoch: 5, batch: 980】，loss: 0.1781, ce_loss: 0.1781., accu: 0.8737,\n",
      "global step 19810, epoch: 5, batch: 990, loss: 0.1407, ce_loss: 0.1407., accu: 0.8738, speed: 1.18 step/s\n",
      "global step 19820, epoch: 5, batch: 1000, loss: 0.1904, ce_loss: 0.1904., accu: 0.8738, speed: 1.18 step/s\n",
      "global step 19830, epoch: 5, batch: 1010, loss: 0.1622, ce_loss: 0.1622., accu: 0.8738, speed: 1.18 step/s\n",
      "global step 19840, epoch: 5, batch: 1020, loss: 0.1381, ce_loss: 0.1381., accu: 0.8738, speed: 1.19 step/s\n",
      "global step 19850, epoch: 5, batch: 1030, loss: 0.1984, ce_loss: 0.1984., accu: 0.8739, speed: 1.18 step/s\n",
      "global step 19860, epoch: 5, batch: 1040, loss: 0.2106, ce_loss: 0.2106., accu: 0.8739, speed: 1.18 step/s\n",
      "global step 19870, epoch: 5, batch: 1050, loss: 0.1734, ce_loss: 0.1734., accu: 0.8739, speed: 1.19 step/s\n",
      "global step 19880, epoch: 5, batch: 1060, loss: 0.1248, ce_loss: 0.1248., accu: 0.8739, speed: 1.18 step/s\n",
      "global step 19890, epoch: 5, batch: 1070, loss: 0.2106, ce_loss: 0.2106., accu: 0.8739, speed: 1.20 step/s\n",
      "global step 19900, epoch: 5, batch: 1080, loss: 0.1145, ce_loss: 0.1145., accu: 0.8740, speed: 1.19 step/s\n",
      "2022-09-28 17:48:40,430\t[train.py-do_train]-[line:187]-INFO:【global step 19900, epoch: 5, batch: 1080】，loss: 0.1145, ce_loss: 0.1145., accu: 0.8740,\n",
      "global step 19910, epoch: 5, batch: 1090, loss: 0.2449, ce_loss: 0.2449., accu: 0.8740, speed: 1.20 step/s\n",
      "global step 19920, epoch: 5, batch: 1100, loss: 0.1805, ce_loss: 0.1805., accu: 0.8740, speed: 1.19 step/s\n",
      "global step 19930, epoch: 5, batch: 1110, loss: 0.1703, ce_loss: 0.1703., accu: 0.8740, speed: 1.19 step/s\n",
      "global step 19940, epoch: 5, batch: 1120, loss: 0.2021, ce_loss: 0.2021., accu: 0.8741, speed: 1.18 step/s\n",
      "global step 19950, epoch: 5, batch: 1130, loss: 0.2289, ce_loss: 0.2289., accu: 0.8741, speed: 1.20 step/s\n",
      "global step 19960, epoch: 5, batch: 1140, loss: 0.1721, ce_loss: 0.1721., accu: 0.8741, speed: 1.18 step/s\n",
      "global step 19970, epoch: 5, batch: 1150, loss: 0.1531, ce_loss: 0.1531., accu: 0.8742, speed: 1.18 step/s\n",
      "global step 19980, epoch: 5, batch: 1160, loss: 0.1236, ce_loss: 0.1236., accu: 0.8742, speed: 1.18 step/s\n",
      "global step 19990, epoch: 5, batch: 1170, loss: 0.1602, ce_loss: 0.1602., accu: 0.8742, speed: 1.19 step/s\n",
      "global step 20000, epoch: 5, batch: 1180, loss: 0.1578, ce_loss: 0.1578., accu: 0.8742, speed: 1.22 step/s\n",
      "2022-09-28 17:50:04,401\t[train.py-do_train]-[line:187]-INFO:【global step 20000, epoch: 5, batch: 1180】，loss: 0.1578, ce_loss: 0.1578., accu: 0.8742,\n",
      "global step 20010, epoch: 5, batch: 1190, loss: 0.1176, ce_loss: 0.1176., accu: 0.8743, speed: 1.20 step/s\n",
      "global step 20020, epoch: 5, batch: 1200, loss: 0.1446, ce_loss: 0.1446., accu: 0.8743, speed: 1.19 step/s\n",
      "global step 20030, epoch: 5, batch: 1210, loss: 0.1773, ce_loss: 0.1773., accu: 0.8743, speed: 1.18 step/s\n",
      "global step 20040, epoch: 5, batch: 1220, loss: 0.1667, ce_loss: 0.1667., accu: 0.8743, speed: 1.18 step/s\n",
      "global step 20050, epoch: 5, batch: 1230, loss: 0.1745, ce_loss: 0.1745., accu: 0.8743, speed: 1.19 step/s\n",
      "global step 20060, epoch: 5, batch: 1240, loss: 0.1188, ce_loss: 0.1188., accu: 0.8744, speed: 1.19 step/s\n",
      "global step 20070, epoch: 5, batch: 1250, loss: 0.1612, ce_loss: 0.1612., accu: 0.8744, speed: 1.19 step/s\n",
      "global step 20080, epoch: 5, batch: 1260, loss: 0.2483, ce_loss: 0.2483., accu: 0.8744, speed: 1.18 step/s\n",
      "global step 20090, epoch: 5, batch: 1270, loss: 0.1860, ce_loss: 0.1860., accu: 0.8744, speed: 1.18 step/s\n",
      "global step 20100, epoch: 5, batch: 1280, loss: 0.2505, ce_loss: 0.2505., accu: 0.8745, speed: 1.18 step/s\n",
      "2022-09-28 17:51:28,629\t[train.py-do_train]-[line:187]-INFO:【global step 20100, epoch: 5, batch: 1280】，loss: 0.2505, ce_loss: 0.2505., accu: 0.8745,\n",
      "global step 20110, epoch: 5, batch: 1290, loss: 0.2119, ce_loss: 0.2119., accu: 0.8745, speed: 1.19 step/s\n",
      "global step 20120, epoch: 5, batch: 1300, loss: 0.1609, ce_loss: 0.1609., accu: 0.8745, speed: 1.18 step/s\n",
      "global step 20130, epoch: 5, batch: 1310, loss: 0.1261, ce_loss: 0.1261., accu: 0.8745, speed: 1.19 step/s\n",
      "global step 20140, epoch: 5, batch: 1320, loss: 0.1665, ce_loss: 0.1665., accu: 0.8746, speed: 1.19 step/s\n",
      "global step 20150, epoch: 5, batch: 1330, loss: 0.2545, ce_loss: 0.2545., accu: 0.8746, speed: 1.20 step/s\n",
      "global step 20160, epoch: 5, batch: 1340, loss: 0.1224, ce_loss: 0.1224., accu: 0.8746, speed: 1.19 step/s\n",
      "global step 20170, epoch: 5, batch: 1350, loss: 0.1291, ce_loss: 0.1291., accu: 0.8746, speed: 1.19 step/s\n",
      "global step 20180, epoch: 5, batch: 1360, loss: 0.1987, ce_loss: 0.1987., accu: 0.8746, speed: 1.18 step/s\n",
      "global step 20190, epoch: 5, batch: 1370, loss: 0.1915, ce_loss: 0.1915., accu: 0.8747, speed: 1.20 step/s\n",
      "global step 20200, epoch: 5, batch: 1380, loss: 0.2134, ce_loss: 0.2134., accu: 0.8747, speed: 1.18 step/s\n",
      "2022-09-28 17:52:52,778\t[train.py-do_train]-[line:187]-INFO:【global step 20200, epoch: 5, batch: 1380】，loss: 0.2134, ce_loss: 0.2134., accu: 0.8747,\n",
      "global step 20210, epoch: 5, batch: 1390, loss: 0.1464, ce_loss: 0.1464., accu: 0.8747, speed: 1.20 step/s\n",
      "global step 20220, epoch: 5, batch: 1400, loss: 0.1705, ce_loss: 0.1705., accu: 0.8747, speed: 1.18 step/s\n",
      "global step 20230, epoch: 5, batch: 1410, loss: 0.1628, ce_loss: 0.1628., accu: 0.8747, speed: 1.18 step/s\n",
      "global step 20240, epoch: 5, batch: 1420, loss: 0.1876, ce_loss: 0.1876., accu: 0.8748, speed: 1.18 step/s\n",
      "global step 20250, epoch: 5, batch: 1430, loss: 0.1979, ce_loss: 0.1979., accu: 0.8748, speed: 1.18 step/s\n",
      "global step 20260, epoch: 5, batch: 1440, loss: 0.1813, ce_loss: 0.1813., accu: 0.8748, speed: 1.20 step/s\n",
      "global step 20270, epoch: 5, batch: 1450, loss: 0.2207, ce_loss: 0.2207., accu: 0.8748, speed: 1.18 step/s\n",
      "global step 20280, epoch: 5, batch: 1460, loss: 0.2405, ce_loss: 0.2405., accu: 0.8749, speed: 1.20 step/s\n",
      "global step 20290, epoch: 5, batch: 1470, loss: 0.1422, ce_loss: 0.1422., accu: 0.8749, speed: 1.19 step/s\n",
      "global step 20300, epoch: 5, batch: 1480, loss: 0.1183, ce_loss: 0.1183., accu: 0.8749, speed: 1.18 step/s\n",
      "2022-09-28 17:54:16,893\t[train.py-do_train]-[line:187]-INFO:【global step 20300, epoch: 5, batch: 1480】，loss: 0.1183, ce_loss: 0.1183., accu: 0.8749,\n",
      "global step 20310, epoch: 5, batch: 1490, loss: 0.2537, ce_loss: 0.2537., accu: 0.8749, speed: 1.18 step/s\n",
      "global step 20320, epoch: 5, batch: 1500, loss: 0.1859, ce_loss: 0.1859., accu: 0.8750, speed: 1.19 step/s\n",
      "global step 20330, epoch: 5, batch: 1510, loss: 0.2418, ce_loss: 0.2418., accu: 0.8750, speed: 1.18 step/s\n",
      "global step 20340, epoch: 5, batch: 1520, loss: 0.1993, ce_loss: 0.1993., accu: 0.8750, speed: 1.19 step/s\n",
      "global step 20350, epoch: 5, batch: 1530, loss: 0.1681, ce_loss: 0.1681., accu: 0.8750, speed: 1.20 step/s\n",
      "global step 20360, epoch: 5, batch: 1540, loss: 0.2182, ce_loss: 0.2182., accu: 0.8751, speed: 1.18 step/s\n",
      "global step 20370, epoch: 5, batch: 1550, loss: 0.1307, ce_loss: 0.1307., accu: 0.8751, speed: 1.20 step/s\n",
      "global step 20380, epoch: 5, batch: 1560, loss: 0.1865, ce_loss: 0.1865., accu: 0.8751, speed: 1.19 step/s\n",
      "global step 20390, epoch: 5, batch: 1570, loss: 0.1827, ce_loss: 0.1827., accu: 0.8751, speed: 1.18 step/s\n",
      "global step 20400, epoch: 5, batch: 1580, loss: 0.1385, ce_loss: 0.1385., accu: 0.8751, speed: 1.18 step/s\n",
      "2022-09-28 17:55:41,134\t[train.py-do_train]-[line:187]-INFO:【global step 20400, epoch: 5, batch: 1580】，loss: 0.1385, ce_loss: 0.1385., accu: 0.8751,\n",
      "global step 20410, epoch: 5, batch: 1590, loss: 0.0991, ce_loss: 0.0991., accu: 0.8752, speed: 1.19 step/s\n",
      "global step 20420, epoch: 5, batch: 1600, loss: 0.1730, ce_loss: 0.1730., accu: 0.8752, speed: 1.18 step/s\n",
      "global step 20430, epoch: 5, batch: 1610, loss: 0.2583, ce_loss: 0.2583., accu: 0.8752, speed: 1.21 step/s\n",
      "global step 20440, epoch: 5, batch: 1620, loss: 0.1892, ce_loss: 0.1892., accu: 0.8753, speed: 1.18 step/s\n",
      "global step 20450, epoch: 5, batch: 1630, loss: 0.1467, ce_loss: 0.1467., accu: 0.8753, speed: 1.20 step/s\n",
      "global step 20460, epoch: 5, batch: 1640, loss: 0.2176, ce_loss: 0.2176., accu: 0.8753, speed: 1.18 step/s\n",
      "global step 20470, epoch: 5, batch: 1650, loss: 0.1924, ce_loss: 0.1924., accu: 0.8753, speed: 1.19 step/s\n",
      "global step 20480, epoch: 5, batch: 1660, loss: 0.1416, ce_loss: 0.1416., accu: 0.8753, speed: 1.19 step/s\n",
      "global step 20490, epoch: 5, batch: 1670, loss: 0.1731, ce_loss: 0.1731., accu: 0.8754, speed: 1.19 step/s\n",
      "global step 20500, epoch: 5, batch: 1680, loss: 0.3224, ce_loss: 0.3224., accu: 0.8754, speed: 1.19 step/s\n",
      "2022-09-28 17:57:05,191\t[train.py-do_train]-[line:187]-INFO:【global step 20500, epoch: 5, batch: 1680】，loss: 0.3224, ce_loss: 0.3224., accu: 0.8754,\n",
      "global step 20510, epoch: 5, batch: 1690, loss: 0.1430, ce_loss: 0.1430., accu: 0.8754, speed: 1.19 step/s\n",
      "global step 20520, epoch: 5, batch: 1700, loss: 0.1592, ce_loss: 0.1592., accu: 0.8754, speed: 1.20 step/s\n",
      "global step 20530, epoch: 5, batch: 1710, loss: 0.1702, ce_loss: 0.1702., accu: 0.8755, speed: 1.20 step/s\n",
      "global step 20540, epoch: 5, batch: 1720, loss: 0.1163, ce_loss: 0.1163., accu: 0.8755, speed: 1.19 step/s\n",
      "global step 20550, epoch: 5, batch: 1730, loss: 0.2096, ce_loss: 0.2096., accu: 0.8755, speed: 1.18 step/s\n",
      "global step 20560, epoch: 5, batch: 1740, loss: 0.1493, ce_loss: 0.1493., accu: 0.8755, speed: 1.18 step/s\n",
      "global step 20570, epoch: 5, batch: 1750, loss: 0.2672, ce_loss: 0.2672., accu: 0.8756, speed: 1.18 step/s\n",
      "global step 20580, epoch: 5, batch: 1760, loss: 0.1439, ce_loss: 0.1439., accu: 0.8756, speed: 1.19 step/s\n",
      "global step 20590, epoch: 5, batch: 1770, loss: 0.1679, ce_loss: 0.1679., accu: 0.8756, speed: 1.19 step/s\n",
      "global step 20600, epoch: 5, batch: 1780, loss: 0.1429, ce_loss: 0.1429., accu: 0.8756, speed: 1.22 step/s\n",
      "2022-09-28 17:58:29,045\t[train.py-do_train]-[line:187]-INFO:【global step 20600, epoch: 5, batch: 1780】，loss: 0.1429, ce_loss: 0.1429., accu: 0.8756,\n",
      "global step 20610, epoch: 5, batch: 1790, loss: 0.1771, ce_loss: 0.1771., accu: 0.8757, speed: 1.21 step/s\n",
      "global step 20620, epoch: 5, batch: 1800, loss: 0.1763, ce_loss: 0.1763., accu: 0.8757, speed: 1.18 step/s\n",
      "global step 20630, epoch: 5, batch: 1810, loss: 0.1954, ce_loss: 0.1954., accu: 0.8757, speed: 1.18 step/s\n",
      "global step 20640, epoch: 5, batch: 1820, loss: 0.1488, ce_loss: 0.1488., accu: 0.8757, speed: 1.18 step/s\n",
      "global step 20650, epoch: 5, batch: 1830, loss: 0.1496, ce_loss: 0.1496., accu: 0.8757, speed: 1.18 step/s\n",
      "global step 20660, epoch: 5, batch: 1840, loss: 0.0827, ce_loss: 0.0827., accu: 0.8758, speed: 1.18 step/s\n",
      "global step 20670, epoch: 5, batch: 1850, loss: 0.2166, ce_loss: 0.2166., accu: 0.8758, speed: 1.18 step/s\n",
      "global step 20680, epoch: 5, batch: 1860, loss: 0.2628, ce_loss: 0.2628., accu: 0.8758, speed: 1.18 step/s\n",
      "global step 20690, epoch: 5, batch: 1870, loss: 0.1578, ce_loss: 0.1578., accu: 0.8758, speed: 1.19 step/s\n",
      "global step 20700, epoch: 5, batch: 1880, loss: 0.1693, ce_loss: 0.1693., accu: 0.8759, speed: 1.20 step/s\n",
      "2022-09-28 17:59:53,402\t[train.py-do_train]-[line:187]-INFO:【global step 20700, epoch: 5, batch: 1880】，loss: 0.1693, ce_loss: 0.1693., accu: 0.8759,\n",
      "global step 20710, epoch: 5, batch: 1890, loss: 0.2111, ce_loss: 0.2111., accu: 0.8759, speed: 1.18 step/s\n",
      "global step 20720, epoch: 5, batch: 1900, loss: 0.1542, ce_loss: 0.1542., accu: 0.8759, speed: 1.18 step/s\n",
      "global step 20730, epoch: 5, batch: 1910, loss: 0.1051, ce_loss: 0.1051., accu: 0.8759, speed: 1.18 step/s\n",
      "global step 20740, epoch: 5, batch: 1920, loss: 0.2615, ce_loss: 0.2615., accu: 0.8759, speed: 1.20 step/s\n",
      "global step 20750, epoch: 5, batch: 1930, loss: 0.2421, ce_loss: 0.2421., accu: 0.8760, speed: 1.18 step/s\n",
      "global step 20760, epoch: 5, batch: 1940, loss: 0.2046, ce_loss: 0.2046., accu: 0.8760, speed: 1.21 step/s\n",
      "global step 20770, epoch: 5, batch: 1950, loss: 0.3242, ce_loss: 0.3242., accu: 0.8760, speed: 1.20 step/s\n",
      "global step 20780, epoch: 5, batch: 1960, loss: 0.1380, ce_loss: 0.1380., accu: 0.8760, speed: 1.18 step/s\n",
      "global step 20790, epoch: 5, batch: 1970, loss: 0.1789, ce_loss: 0.1789., accu: 0.8760, speed: 1.18 step/s\n",
      "global step 20800, epoch: 5, batch: 1980, loss: 0.2719, ce_loss: 0.2719., accu: 0.8761, speed: 1.18 step/s\n",
      "2022-09-28 18:01:17,641\t[train.py-do_train]-[line:187]-INFO:【global step 20800, epoch: 5, batch: 1980】，loss: 0.2719, ce_loss: 0.2719., accu: 0.8761,\n",
      "global step 20810, epoch: 5, batch: 1990, loss: 0.2453, ce_loss: 0.2453., accu: 0.8761, speed: 1.18 step/s\n",
      "global step 20820, epoch: 5, batch: 2000, loss: 0.1519, ce_loss: 0.1519., accu: 0.8761, speed: 1.20 step/s\n",
      "global step 20830, epoch: 5, batch: 2010, loss: 0.1697, ce_loss: 0.1697., accu: 0.8761, speed: 1.18 step/s\n",
      "global step 20840, epoch: 5, batch: 2020, loss: 0.1844, ce_loss: 0.1844., accu: 0.8761, speed: 1.19 step/s\n",
      "global step 20850, epoch: 5, batch: 2030, loss: 0.1398, ce_loss: 0.1398., accu: 0.8762, speed: 1.19 step/s\n",
      "global step 20860, epoch: 5, batch: 2040, loss: 0.1493, ce_loss: 0.1493., accu: 0.8762, speed: 1.18 step/s\n",
      "global step 20870, epoch: 5, batch: 2050, loss: 0.1498, ce_loss: 0.1498., accu: 0.8762, speed: 1.18 step/s\n",
      "global step 20880, epoch: 5, batch: 2060, loss: 0.2494, ce_loss: 0.2494., accu: 0.8762, speed: 1.18 step/s\n",
      "global step 20890, epoch: 5, batch: 2070, loss: 0.3107, ce_loss: 0.3107., accu: 0.8762, speed: 1.18 step/s\n",
      "global step 20900, epoch: 5, batch: 2080, loss: 0.1899, ce_loss: 0.1899., accu: 0.8763, speed: 1.20 step/s\n",
      "2022-09-28 18:02:42,079\t[train.py-do_train]-[line:187]-INFO:【global step 20900, epoch: 5, batch: 2080】，loss: 0.1899, ce_loss: 0.1899., accu: 0.8763,\n",
      "global step 20910, epoch: 5, batch: 2090, loss: 0.1849, ce_loss: 0.1849., accu: 0.8763, speed: 1.19 step/s\n",
      "global step 20920, epoch: 5, batch: 2100, loss: 0.1630, ce_loss: 0.1630., accu: 0.8763, speed: 1.17 step/s\n",
      "global step 20930, epoch: 5, batch: 2110, loss: 0.1497, ce_loss: 0.1497., accu: 0.8763, speed: 1.18 step/s\n",
      "global step 20940, epoch: 5, batch: 2120, loss: 0.2211, ce_loss: 0.2211., accu: 0.8764, speed: 1.18 step/s\n",
      "global step 20950, epoch: 5, batch: 2130, loss: 0.1893, ce_loss: 0.1893., accu: 0.8764, speed: 1.19 step/s\n",
      "global step 20960, epoch: 5, batch: 2140, loss: 0.2325, ce_loss: 0.2325., accu: 0.8764, speed: 1.18 step/s\n",
      "global step 20970, epoch: 5, batch: 2150, loss: 0.1404, ce_loss: 0.1404., accu: 0.8764, speed: 1.18 step/s\n",
      "global step 20980, epoch: 5, batch: 2160, loss: 0.1418, ce_loss: 0.1418., accu: 0.8764, speed: 1.18 step/s\n",
      "global step 20990, epoch: 5, batch: 2170, loss: 0.1349, ce_loss: 0.1349., accu: 0.8765, speed: 1.19 step/s\n",
      "global step 21000, epoch: 5, batch: 2180, loss: 0.1578, ce_loss: 0.1578., accu: 0.8765, speed: 1.19 step/s\n",
      "2022-09-28 18:04:06,635\t[train.py-do_train]-[line:187]-INFO:【global step 21000, epoch: 5, batch: 2180】，loss: 0.1578, ce_loss: 0.1578., accu: 0.8765,\n",
      "global step 21010, epoch: 5, batch: 2190, loss: 0.2435, ce_loss: 0.2435., accu: 0.8765, speed: 1.18 step/s\n",
      "global step 21020, epoch: 5, batch: 2200, loss: 0.1667, ce_loss: 0.1667., accu: 0.8765, speed: 1.18 step/s\n",
      "global step 21030, epoch: 5, batch: 2210, loss: 0.1906, ce_loss: 0.1906., accu: 0.8765, speed: 1.20 step/s\n",
      "global step 21040, epoch: 5, batch: 2220, loss: 0.1977, ce_loss: 0.1977., accu: 0.8766, speed: 1.18 step/s\n",
      "global step 21050, epoch: 5, batch: 2230, loss: 0.2216, ce_loss: 0.2216., accu: 0.8766, speed: 1.18 step/s\n",
      "global step 21060, epoch: 5, batch: 2240, loss: 0.2369, ce_loss: 0.2369., accu: 0.8766, speed: 1.18 step/s\n",
      "global step 21070, epoch: 5, batch: 2250, loss: 0.1666, ce_loss: 0.1666., accu: 0.8766, speed: 1.18 step/s\n",
      "global step 21080, epoch: 5, batch: 2260, loss: 0.1572, ce_loss: 0.1572., accu: 0.8766, speed: 1.20 step/s\n",
      "global step 21090, epoch: 5, batch: 2270, loss: 0.1830, ce_loss: 0.1830., accu: 0.8767, speed: 1.19 step/s\n",
      "global step 21100, epoch: 5, batch: 2280, loss: 0.1263, ce_loss: 0.1263., accu: 0.8767, speed: 1.18 step/s\n",
      "2022-09-28 18:05:30,972\t[train.py-do_train]-[line:187]-INFO:【global step 21100, epoch: 5, batch: 2280】，loss: 0.1263, ce_loss: 0.1263., accu: 0.8767,\n",
      "global step 21110, epoch: 5, batch: 2290, loss: 0.1422, ce_loss: 0.1422., accu: 0.8767, speed: 1.21 step/s\n",
      "global step 21120, epoch: 5, batch: 2300, loss: 0.1804, ce_loss: 0.1804., accu: 0.8767, speed: 1.19 step/s\n",
      "global step 21130, epoch: 5, batch: 2310, loss: 0.2872, ce_loss: 0.2872., accu: 0.8768, speed: 1.19 step/s\n",
      "global step 21140, epoch: 5, batch: 2320, loss: 0.1554, ce_loss: 0.1554., accu: 0.8768, speed: 1.19 step/s\n",
      "global step 21150, epoch: 5, batch: 2330, loss: 0.1312, ce_loss: 0.1312., accu: 0.8768, speed: 1.18 step/s\n",
      "global step 21160, epoch: 5, batch: 2340, loss: 0.1325, ce_loss: 0.1325., accu: 0.8768, speed: 1.19 step/s\n",
      "global step 21170, epoch: 5, batch: 2350, loss: 0.1464, ce_loss: 0.1464., accu: 0.8769, speed: 1.19 step/s\n",
      "global step 21180, epoch: 5, batch: 2360, loss: 0.2377, ce_loss: 0.2377., accu: 0.8769, speed: 1.19 step/s\n",
      "global step 21190, epoch: 5, batch: 2370, loss: 0.1933, ce_loss: 0.1933., accu: 0.8769, speed: 1.17 step/s\n",
      "global step 21200, epoch: 5, batch: 2380, loss: 0.1562, ce_loss: 0.1562., accu: 0.8769, speed: 1.17 step/s\n",
      "2022-09-28 18:06:55,183\t[train.py-do_train]-[line:187]-INFO:【global step 21200, epoch: 5, batch: 2380】，loss: 0.1562, ce_loss: 0.1562., accu: 0.8769,\n",
      "global step 21210, epoch: 5, batch: 2390, loss: 0.1382, ce_loss: 0.1382., accu: 0.8769, speed: 1.17 step/s\n",
      "global step 21220, epoch: 5, batch: 2400, loss: 0.2483, ce_loss: 0.2483., accu: 0.8770, speed: 1.18 step/s\n",
      "global step 21230, epoch: 5, batch: 2410, loss: 0.1729, ce_loss: 0.1729., accu: 0.8770, speed: 1.19 step/s\n",
      "global step 21240, epoch: 5, batch: 2420, loss: 0.2229, ce_loss: 0.2229., accu: 0.8770, speed: 1.18 step/s\n",
      "global step 21250, epoch: 5, batch: 2430, loss: 0.2350, ce_loss: 0.2350., accu: 0.8770, speed: 1.21 step/s\n",
      "global step 21260, epoch: 5, batch: 2440, loss: 0.2285, ce_loss: 0.2285., accu: 0.8770, speed: 1.20 step/s\n",
      "global step 21270, epoch: 5, batch: 2450, loss: 0.1889, ce_loss: 0.1889., accu: 0.8771, speed: 1.19 step/s\n",
      "global step 21280, epoch: 5, batch: 2460, loss: 0.2262, ce_loss: 0.2262., accu: 0.8771, speed: 1.19 step/s\n",
      "global step 21290, epoch: 5, batch: 2470, loss: 0.1648, ce_loss: 0.1648., accu: 0.8771, speed: 1.18 step/s\n",
      "global step 21300, epoch: 5, batch: 2480, loss: 0.1972, ce_loss: 0.1972., accu: 0.8771, speed: 1.18 step/s\n",
      "2022-09-28 18:08:19,532\t[train.py-do_train]-[line:187]-INFO:【global step 21300, epoch: 5, batch: 2480】，loss: 0.1972, ce_loss: 0.1972., accu: 0.8771,\n",
      "global step 21310, epoch: 5, batch: 2490, loss: 0.1831, ce_loss: 0.1831., accu: 0.8771, speed: 1.18 step/s\n",
      "global step 21320, epoch: 5, batch: 2500, loss: 0.1542, ce_loss: 0.1542., accu: 0.8772, speed: 1.18 step/s\n",
      "global step 21330, epoch: 5, batch: 2510, loss: 0.0679, ce_loss: 0.0679., accu: 0.8772, speed: 1.18 step/s\n",
      "global step 21340, epoch: 5, batch: 2520, loss: 0.2144, ce_loss: 0.2144., accu: 0.8772, speed: 1.18 step/s\n",
      "global step 21350, epoch: 5, batch: 2530, loss: 0.1999, ce_loss: 0.1999., accu: 0.8772, speed: 1.19 step/s\n",
      "global step 21360, epoch: 5, batch: 2540, loss: 0.1503, ce_loss: 0.1503., accu: 0.8772, speed: 1.18 step/s\n",
      "global step 21370, epoch: 5, batch: 2550, loss: 0.1718, ce_loss: 0.1718., accu: 0.8773, speed: 1.18 step/s\n",
      "global step 21380, epoch: 5, batch: 2560, loss: 0.1955, ce_loss: 0.1955., accu: 0.8773, speed: 1.18 step/s\n",
      "global step 21390, epoch: 5, batch: 2570, loss: 0.2295, ce_loss: 0.2295., accu: 0.8773, speed: 1.21 step/s\n",
      "global step 21400, epoch: 5, batch: 2580, loss: 0.1866, ce_loss: 0.1866., accu: 0.8773, speed: 1.18 step/s\n",
      "2022-09-28 18:09:44,052\t[train.py-do_train]-[line:187]-INFO:【global step 21400, epoch: 5, batch: 2580】，loss: 0.1866, ce_loss: 0.1866., accu: 0.8773,\n",
      "global step 21410, epoch: 5, batch: 2590, loss: 0.2443, ce_loss: 0.2443., accu: 0.8774, speed: 1.19 step/s\n",
      "global step 21420, epoch: 5, batch: 2600, loss: 0.1723, ce_loss: 0.1723., accu: 0.8774, speed: 1.18 step/s\n",
      "global step 21430, epoch: 5, batch: 2610, loss: 0.1336, ce_loss: 0.1336., accu: 0.8774, speed: 1.18 step/s\n",
      "global step 21440, epoch: 5, batch: 2620, loss: 0.1713, ce_loss: 0.1713., accu: 0.8774, speed: 1.20 step/s\n",
      "global step 21450, epoch: 5, batch: 2630, loss: 0.1546, ce_loss: 0.1546., accu: 0.8774, speed: 1.19 step/s\n",
      "global step 21460, epoch: 5, batch: 2640, loss: 0.2523, ce_loss: 0.2523., accu: 0.8775, speed: 1.19 step/s\n",
      "global step 21470, epoch: 5, batch: 2650, loss: 0.1388, ce_loss: 0.1388., accu: 0.8775, speed: 1.18 step/s\n",
      "global step 21480, epoch: 5, batch: 2660, loss: 0.2095, ce_loss: 0.2095., accu: 0.8775, speed: 1.19 step/s\n",
      "global step 21490, epoch: 5, batch: 2670, loss: 0.1951, ce_loss: 0.1951., accu: 0.8775, speed: 1.18 step/s\n",
      "global step 21500, epoch: 5, batch: 2680, loss: 0.2653, ce_loss: 0.2653., accu: 0.8775, speed: 1.18 step/s\n",
      "2022-09-28 18:11:08,383\t[train.py-do_train]-[line:187]-INFO:【global step 21500, epoch: 5, batch: 2680】，loss: 0.2653, ce_loss: 0.2653., accu: 0.8775,\n",
      "global step 21510, epoch: 5, batch: 2690, loss: 0.1807, ce_loss: 0.1807., accu: 0.8776, speed: 1.19 step/s\n",
      "global step 21520, epoch: 5, batch: 2700, loss: 0.2109, ce_loss: 0.2109., accu: 0.8776, speed: 1.18 step/s\n",
      "global step 21530, epoch: 5, batch: 2710, loss: 0.1820, ce_loss: 0.1820., accu: 0.8776, speed: 1.18 step/s\n",
      "global step 21540, epoch: 5, batch: 2720, loss: 0.1300, ce_loss: 0.1300., accu: 0.8776, speed: 1.21 step/s\n",
      "global step 21550, epoch: 5, batch: 2730, loss: 0.1770, ce_loss: 0.1770., accu: 0.8776, speed: 1.18 step/s\n",
      "global step 21560, epoch: 5, batch: 2740, loss: 0.2336, ce_loss: 0.2336., accu: 0.8777, speed: 1.19 step/s\n",
      "global step 21570, epoch: 5, batch: 2750, loss: 0.1527, ce_loss: 0.1527., accu: 0.8777, speed: 1.18 step/s\n",
      "global step 21580, epoch: 5, batch: 2760, loss: 0.1220, ce_loss: 0.1220., accu: 0.8777, speed: 1.18 step/s\n",
      "global step 21590, epoch: 5, batch: 2770, loss: 0.1188, ce_loss: 0.1188., accu: 0.8777, speed: 1.19 step/s\n",
      "global step 21600, epoch: 5, batch: 2780, loss: 0.1282, ce_loss: 0.1282., accu: 0.8778, speed: 1.20 step/s\n",
      "2022-09-28 18:12:32,503\t[train.py-do_train]-[line:187]-INFO:【global step 21600, epoch: 5, batch: 2780】，loss: 0.1282, ce_loss: 0.1282., accu: 0.8778,\n",
      "global step 21610, epoch: 5, batch: 2790, loss: 0.1730, ce_loss: 0.1730., accu: 0.8778, speed: 1.20 step/s\n",
      "global step 21620, epoch: 5, batch: 2800, loss: 0.2151, ce_loss: 0.2151., accu: 0.8778, speed: 1.19 step/s\n",
      "global step 21630, epoch: 5, batch: 2810, loss: 0.1677, ce_loss: 0.1677., accu: 0.8778, speed: 1.18 step/s\n",
      "global step 21640, epoch: 5, batch: 2820, loss: 0.1814, ce_loss: 0.1814., accu: 0.8778, speed: 1.18 step/s\n",
      "global step 21650, epoch: 5, batch: 2830, loss: 0.1816, ce_loss: 0.1816., accu: 0.8778, speed: 1.18 step/s\n",
      "global step 21660, epoch: 5, batch: 2840, loss: 0.2350, ce_loss: 0.2350., accu: 0.8779, speed: 1.18 step/s\n",
      "global step 21670, epoch: 5, batch: 2850, loss: 0.2238, ce_loss: 0.2238., accu: 0.8779, speed: 1.20 step/s\n",
      "global step 21680, epoch: 5, batch: 2860, loss: 0.1893, ce_loss: 0.1893., accu: 0.8779, speed: 1.19 step/s\n",
      "global step 21690, epoch: 5, batch: 2870, loss: 0.2357, ce_loss: 0.2357., accu: 0.8779, speed: 1.18 step/s\n",
      "global step 21700, epoch: 5, batch: 2880, loss: 0.2141, ce_loss: 0.2141., accu: 0.8779, speed: 1.18 step/s\n",
      "2022-09-28 18:13:56,737\t[train.py-do_train]-[line:187]-INFO:【global step 21700, epoch: 5, batch: 2880】，loss: 0.2141, ce_loss: 0.2141., accu: 0.8779,\n",
      "global step 21710, epoch: 5, batch: 2890, loss: 0.1567, ce_loss: 0.1567., accu: 0.8780, speed: 1.19 step/s\n",
      "global step 21720, epoch: 5, batch: 2900, loss: 0.2256, ce_loss: 0.2256., accu: 0.8780, speed: 1.19 step/s\n",
      "global step 21730, epoch: 5, batch: 2910, loss: 0.1880, ce_loss: 0.1880., accu: 0.8780, speed: 1.19 step/s\n",
      "global step 21740, epoch: 5, batch: 2920, loss: 0.2020, ce_loss: 0.2020., accu: 0.8780, speed: 1.18 step/s\n",
      "global step 21750, epoch: 5, batch: 2930, loss: 0.1997, ce_loss: 0.1997., accu: 0.8781, speed: 1.19 step/s\n",
      "global step 21760, epoch: 5, batch: 2940, loss: 0.1994, ce_loss: 0.1994., accu: 0.8781, speed: 1.18 step/s\n",
      "global step 21770, epoch: 5, batch: 2950, loss: 0.2060, ce_loss: 0.2060., accu: 0.8781, speed: 1.18 step/s\n",
      "global step 21780, epoch: 5, batch: 2960, loss: 0.1347, ce_loss: 0.1347., accu: 0.8781, speed: 1.18 step/s\n",
      "global step 21790, epoch: 5, batch: 2970, loss: 0.1989, ce_loss: 0.1989., accu: 0.8781, speed: 1.18 step/s\n",
      "global step 21800, epoch: 5, batch: 2980, loss: 0.1697, ce_loss: 0.1697., accu: 0.8782, speed: 1.19 step/s\n",
      "2022-09-28 18:15:21,172\t[train.py-do_train]-[line:187]-INFO:【global step 21800, epoch: 5, batch: 2980】，loss: 0.1697, ce_loss: 0.1697., accu: 0.8782,\n",
      "global step 21810, epoch: 5, batch: 2990, loss: 0.2092, ce_loss: 0.2092., accu: 0.8782, speed: 1.18 step/s\n",
      "global step 21820, epoch: 5, batch: 3000, loss: 0.2562, ce_loss: 0.2562., accu: 0.8782, speed: 1.20 step/s\n",
      "global step 21830, epoch: 5, batch: 3010, loss: 0.1749, ce_loss: 0.1749., accu: 0.8782, speed: 1.18 step/s\n",
      "global step 21840, epoch: 5, batch: 3020, loss: 0.1399, ce_loss: 0.1399., accu: 0.8782, speed: 1.18 step/s\n",
      "global step 21850, epoch: 5, batch: 3030, loss: 0.2946, ce_loss: 0.2946., accu: 0.8783, speed: 1.19 step/s\n",
      "global step 21860, epoch: 5, batch: 3040, loss: 0.2233, ce_loss: 0.2233., accu: 0.8783, speed: 1.19 step/s\n",
      "global step 21870, epoch: 5, batch: 3050, loss: 0.3271, ce_loss: 0.3271., accu: 0.8783, speed: 1.19 step/s\n",
      "global step 21880, epoch: 5, batch: 3060, loss: 0.1922, ce_loss: 0.1922., accu: 0.8783, speed: 1.18 step/s\n",
      "global step 21890, epoch: 5, batch: 3070, loss: 0.2059, ce_loss: 0.2059., accu: 0.8783, speed: 1.18 step/s\n",
      "global step 21900, epoch: 5, batch: 3080, loss: 0.1430, ce_loss: 0.1430., accu: 0.8783, speed: 1.18 step/s\n",
      "2022-09-28 18:16:45,557\t[train.py-do_train]-[line:187]-INFO:【global step 21900, epoch: 5, batch: 3080】，loss: 0.1430, ce_loss: 0.1430., accu: 0.8783,\n",
      "global step 21910, epoch: 5, batch: 3090, loss: 0.2212, ce_loss: 0.2212., accu: 0.8784, speed: 1.20 step/s\n",
      "global step 21920, epoch: 5, batch: 3100, loss: 0.1678, ce_loss: 0.1678., accu: 0.8784, speed: 1.19 step/s\n",
      "global step 21930, epoch: 5, batch: 3110, loss: 0.1754, ce_loss: 0.1754., accu: 0.8784, speed: 1.19 step/s\n",
      "global step 21940, epoch: 5, batch: 3120, loss: 0.2362, ce_loss: 0.2362., accu: 0.8784, speed: 1.18 step/s\n",
      "global step 21950, epoch: 5, batch: 3130, loss: 0.1586, ce_loss: 0.1586., accu: 0.8785, speed: 1.19 step/s\n",
      "global step 21960, epoch: 5, batch: 3140, loss: 0.1066, ce_loss: 0.1066., accu: 0.8785, speed: 1.18 step/s\n",
      "global step 21970, epoch: 5, batch: 3150, loss: 0.1195, ce_loss: 0.1195., accu: 0.8785, speed: 1.19 step/s\n",
      "global step 21980, epoch: 5, batch: 3160, loss: 0.1113, ce_loss: 0.1113., accu: 0.8785, speed: 1.19 step/s\n",
      "global step 21990, epoch: 5, batch: 3170, loss: 0.1555, ce_loss: 0.1555., accu: 0.8785, speed: 1.19 step/s\n",
      "global step 22000, epoch: 5, batch: 3180, loss: 0.1989, ce_loss: 0.1989., accu: 0.8786, speed: 1.19 step/s\n",
      "2022-09-28 18:18:09,675\t[train.py-do_train]-[line:187]-INFO:【global step 22000, epoch: 5, batch: 3180】，loss: 0.1989, ce_loss: 0.1989., accu: 0.8786,\n",
      "global step 22010, epoch: 5, batch: 3190, loss: 0.1813, ce_loss: 0.1813., accu: 0.8786, speed: 1.20 step/s\n",
      "global step 22020, epoch: 5, batch: 3200, loss: 0.1509, ce_loss: 0.1509., accu: 0.8786, speed: 1.19 step/s\n",
      "global step 22030, epoch: 5, batch: 3210, loss: 0.1506, ce_loss: 0.1506., accu: 0.8786, speed: 1.18 step/s\n",
      "global step 22040, epoch: 5, batch: 3220, loss: 0.1840, ce_loss: 0.1840., accu: 0.8786, speed: 1.19 step/s\n",
      "global step 22050, epoch: 5, batch: 3230, loss: 0.2144, ce_loss: 0.2144., accu: 0.8787, speed: 1.18 step/s\n",
      "global step 22060, epoch: 5, batch: 3240, loss: 0.2528, ce_loss: 0.2528., accu: 0.8787, speed: 1.18 step/s\n",
      "global step 22070, epoch: 5, batch: 3250, loss: 0.0800, ce_loss: 0.0800., accu: 0.8787, speed: 1.20 step/s\n",
      "global step 22080, epoch: 5, batch: 3260, loss: 0.2429, ce_loss: 0.2429., accu: 0.8787, speed: 1.18 step/s\n",
      "global step 22090, epoch: 5, batch: 3270, loss: 0.2125, ce_loss: 0.2125., accu: 0.8787, speed: 1.19 step/s\n",
      "global step 22100, epoch: 5, batch: 3280, loss: 0.1679, ce_loss: 0.1679., accu: 0.8788, speed: 1.19 step/s\n",
      "2022-09-28 18:19:33,831\t[train.py-do_train]-[line:187]-INFO:【global step 22100, epoch: 5, batch: 3280】，loss: 0.1679, ce_loss: 0.1679., accu: 0.8788,\n",
      "global step 22110, epoch: 5, batch: 3290, loss: 0.1834, ce_loss: 0.1834., accu: 0.8788, speed: 1.18 step/s\n",
      "global step 22120, epoch: 5, batch: 3300, loss: 0.2380, ce_loss: 0.2380., accu: 0.8788, speed: 1.18 step/s\n",
      "global step 22130, epoch: 5, batch: 3310, loss: 0.1503, ce_loss: 0.1503., accu: 0.8788, speed: 1.18 step/s\n",
      "global step 22140, epoch: 5, batch: 3320, loss: 0.2044, ce_loss: 0.2044., accu: 0.8788, speed: 1.18 step/s\n",
      "global step 22150, epoch: 5, batch: 3330, loss: 0.1781, ce_loss: 0.1781., accu: 0.8788, speed: 1.18 step/s\n",
      "global step 22160, epoch: 5, batch: 3340, loss: 0.1373, ce_loss: 0.1373., accu: 0.8789, speed: 1.18 step/s\n",
      "global step 22170, epoch: 5, batch: 3350, loss: 0.1818, ce_loss: 0.1818., accu: 0.8789, speed: 1.19 step/s\n",
      "global step 22180, epoch: 5, batch: 3360, loss: 0.2820, ce_loss: 0.2820., accu: 0.8789, speed: 1.18 step/s\n",
      "global step 22190, epoch: 5, batch: 3370, loss: 0.1633, ce_loss: 0.1633., accu: 0.8789, speed: 1.18 step/s\n",
      "global step 22200, epoch: 5, batch: 3380, loss: 0.1405, ce_loss: 0.1405., accu: 0.8790, speed: 1.18 step/s\n",
      "2022-09-28 18:20:58,531\t[train.py-do_train]-[line:187]-INFO:【global step 22200, epoch: 5, batch: 3380】，loss: 0.1405, ce_loss: 0.1405., accu: 0.8790,\n",
      "global step 22210, epoch: 5, batch: 3390, loss: 0.2368, ce_loss: 0.2368., accu: 0.8790, speed: 1.20 step/s\n",
      "global step 22220, epoch: 5, batch: 3400, loss: 0.1686, ce_loss: 0.1686., accu: 0.8790, speed: 1.19 step/s\n",
      "global step 22230, epoch: 5, batch: 3410, loss: 0.2431, ce_loss: 0.2431., accu: 0.8790, speed: 1.18 step/s\n",
      "global step 22240, epoch: 5, batch: 3420, loss: 0.2348, ce_loss: 0.2348., accu: 0.8790, speed: 1.18 step/s\n",
      "global step 22250, epoch: 5, batch: 3430, loss: 0.1859, ce_loss: 0.1859., accu: 0.8791, speed: 1.19 step/s\n",
      "global step 22260, epoch: 5, batch: 3440, loss: 0.2196, ce_loss: 0.2196., accu: 0.8791, speed: 1.20 step/s\n",
      "global step 22270, epoch: 5, batch: 3450, loss: 0.2450, ce_loss: 0.2450., accu: 0.8791, speed: 1.18 step/s\n",
      "global step 22280, epoch: 5, batch: 3460, loss: 0.1578, ce_loss: 0.1578., accu: 0.8791, speed: 1.19 step/s\n",
      "global step 22290, epoch: 5, batch: 3470, loss: 0.1711, ce_loss: 0.1711., accu: 0.8791, speed: 1.19 step/s\n",
      "global step 22300, epoch: 5, batch: 3480, loss: 0.2106, ce_loss: 0.2106., accu: 0.8792, speed: 1.18 step/s\n",
      "2022-09-28 18:22:22,855\t[train.py-do_train]-[line:187]-INFO:【global step 22300, epoch: 5, batch: 3480】，loss: 0.2106, ce_loss: 0.2106., accu: 0.8792,\n",
      "global step 22310, epoch: 5, batch: 3490, loss: 0.2148, ce_loss: 0.2148., accu: 0.8792, speed: 1.18 step/s\n",
      "global step 22320, epoch: 5, batch: 3500, loss: 0.1814, ce_loss: 0.1814., accu: 0.8792, speed: 1.19 step/s\n",
      "global step 22330, epoch: 5, batch: 3510, loss: 0.1414, ce_loss: 0.1414., accu: 0.8792, speed: 1.21 step/s\n",
      "global step 22340, epoch: 5, batch: 3520, loss: 0.2467, ce_loss: 0.2467., accu: 0.8792, speed: 1.18 step/s\n",
      "global step 22350, epoch: 5, batch: 3530, loss: 0.2439, ce_loss: 0.2439., accu: 0.8792, speed: 1.19 step/s\n",
      "global step 22360, epoch: 5, batch: 3540, loss: 0.1808, ce_loss: 0.1808., accu: 0.8793, speed: 1.18 step/s\n",
      "global step 22370, epoch: 5, batch: 3550, loss: 0.1609, ce_loss: 0.1609., accu: 0.8793, speed: 1.19 step/s\n",
      "global step 22380, epoch: 5, batch: 3560, loss: 0.1915, ce_loss: 0.1915., accu: 0.8793, speed: 1.18 step/s\n",
      "global step 22390, epoch: 5, batch: 3570, loss: 0.1866, ce_loss: 0.1866., accu: 0.8793, speed: 1.18 step/s\n",
      "global step 22400, epoch: 5, batch: 3580, loss: 0.1939, ce_loss: 0.1939., accu: 0.8793, speed: 1.21 step/s\n",
      "2022-09-28 18:23:46,915\t[train.py-do_train]-[line:187]-INFO:【global step 22400, epoch: 5, batch: 3580】，loss: 0.1939, ce_loss: 0.1939., accu: 0.8793,\n",
      "global step 22410, epoch: 5, batch: 3590, loss: 0.2219, ce_loss: 0.2219., accu: 0.8794, speed: 1.20 step/s\n",
      "global step 22420, epoch: 5, batch: 3600, loss: 0.1436, ce_loss: 0.1436., accu: 0.8794, speed: 1.18 step/s\n",
      "global step 22430, epoch: 5, batch: 3610, loss: 0.1625, ce_loss: 0.1625., accu: 0.8794, speed: 1.20 step/s\n",
      "global step 22440, epoch: 5, batch: 3620, loss: 0.2369, ce_loss: 0.2369., accu: 0.8794, speed: 1.18 step/s\n",
      "global step 22450, epoch: 5, batch: 3630, loss: 0.1221, ce_loss: 0.1221., accu: 0.8795, speed: 1.20 step/s\n",
      "global step 22460, epoch: 5, batch: 3640, loss: 0.1628, ce_loss: 0.1628., accu: 0.8795, speed: 1.18 step/s\n",
      "global step 22470, epoch: 5, batch: 3650, loss: 0.2757, ce_loss: 0.2757., accu: 0.8795, speed: 1.19 step/s\n",
      "global step 22480, epoch: 5, batch: 3660, loss: 0.1487, ce_loss: 0.1487., accu: 0.8795, speed: 1.19 step/s\n",
      "global step 22490, epoch: 5, batch: 3670, loss: 0.1564, ce_loss: 0.1564., accu: 0.8795, speed: 1.22 step/s\n",
      "global step 22500, epoch: 5, batch: 3680, loss: 0.1966, ce_loss: 0.1966., accu: 0.8795, speed: 1.18 step/s\n",
      "2022-09-28 18:25:10,849\t[train.py-do_train]-[line:187]-INFO:【global step 22500, epoch: 5, batch: 3680】，loss: 0.1966, ce_loss: 0.1966., accu: 0.8795,\n",
      "global step 22510, epoch: 5, batch: 3690, loss: 0.1139, ce_loss: 0.1139., accu: 0.8796, speed: 1.18 step/s\n",
      "global step 22520, epoch: 5, batch: 3700, loss: 0.1440, ce_loss: 0.1440., accu: 0.8796, speed: 1.19 step/s\n",
      "global step 22530, epoch: 5, batch: 3710, loss: 0.1464, ce_loss: 0.1464., accu: 0.8796, speed: 1.18 step/s\n",
      "global step 22540, epoch: 5, batch: 3720, loss: 0.1342, ce_loss: 0.1342., accu: 0.8796, speed: 1.21 step/s\n",
      "global step 22550, epoch: 5, batch: 3730, loss: 0.2143, ce_loss: 0.2143., accu: 0.8796, speed: 1.19 step/s\n",
      "global step 22560, epoch: 5, batch: 3740, loss: 0.1476, ce_loss: 0.1476., accu: 0.8796, speed: 1.20 step/s\n",
      "global step 22570, epoch: 5, batch: 3750, loss: 0.1290, ce_loss: 0.1290., accu: 0.8797, speed: 1.18 step/s\n",
      "global step 22580, epoch: 5, batch: 3760, loss: 0.2016, ce_loss: 0.2016., accu: 0.8797, speed: 1.19 step/s\n",
      "global step 22590, epoch: 5, batch: 3770, loss: 0.1974, ce_loss: 0.1974., accu: 0.8797, speed: 1.19 step/s\n",
      "global step 22600, epoch: 5, batch: 3780, loss: 0.1202, ce_loss: 0.1202., accu: 0.8797, speed: 1.19 step/s\n",
      "2022-09-28 18:26:34,991\t[train.py-do_train]-[line:187]-INFO:【global step 22600, epoch: 5, batch: 3780】，loss: 0.1202, ce_loss: 0.1202., accu: 0.8797,\n",
      "global step 22610, epoch: 5, batch: 3790, loss: 0.2223, ce_loss: 0.2223., accu: 0.8797, speed: 1.19 step/s\n",
      "global step 22620, epoch: 5, batch: 3800, loss: 0.1479, ce_loss: 0.1479., accu: 0.8798, speed: 1.18 step/s\n",
      "global step 22630, epoch: 5, batch: 3810, loss: 0.1719, ce_loss: 0.1719., accu: 0.8798, speed: 1.18 step/s\n",
      "global step 22640, epoch: 5, batch: 3820, loss: 0.1807, ce_loss: 0.1807., accu: 0.8798, speed: 1.20 step/s\n",
      "global step 22650, epoch: 5, batch: 3830, loss: 0.1739, ce_loss: 0.1739., accu: 0.8798, speed: 1.18 step/s\n",
      "global step 22660, epoch: 5, batch: 3840, loss: 0.1812, ce_loss: 0.1812., accu: 0.8798, speed: 1.19 step/s\n",
      "global step 22670, epoch: 5, batch: 3850, loss: 0.1933, ce_loss: 0.1933., accu: 0.8798, speed: 1.18 step/s\n",
      "global step 22680, epoch: 5, batch: 3860, loss: 0.1963, ce_loss: 0.1963., accu: 0.8799, speed: 1.18 step/s\n",
      "global step 22690, epoch: 5, batch: 3870, loss: 0.2023, ce_loss: 0.2023., accu: 0.8799, speed: 1.20 step/s\n",
      "global step 22700, epoch: 5, batch: 3880, loss: 0.2558, ce_loss: 0.2558., accu: 0.8799, speed: 1.19 step/s\n",
      "2022-09-28 18:27:59,251\t[train.py-do_train]-[line:187]-INFO:【global step 22700, epoch: 5, batch: 3880】，loss: 0.2558, ce_loss: 0.2558., accu: 0.8799,\n",
      "global step 22710, epoch: 5, batch: 3890, loss: 0.1481, ce_loss: 0.1481., accu: 0.8799, speed: 1.19 step/s\n",
      "global step 22720, epoch: 5, batch: 3900, loss: 0.1353, ce_loss: 0.1353., accu: 0.8799, speed: 1.18 step/s\n",
      "global step 22730, epoch: 5, batch: 3910, loss: 0.1491, ce_loss: 0.1491., accu: 0.8800, speed: 1.20 step/s\n",
      "global step 22740, epoch: 5, batch: 3920, loss: 0.1558, ce_loss: 0.1558., accu: 0.8800, speed: 1.20 step/s\n",
      "global step 22750, epoch: 5, batch: 3930, loss: 0.1547, ce_loss: 0.1547., accu: 0.8800, speed: 1.19 step/s\n",
      "global step 22760, epoch: 5, batch: 3940, loss: 0.2543, ce_loss: 0.2543., accu: 0.8800, speed: 1.21 step/s\n",
      "global step 22770, epoch: 5, batch: 3950, loss: 0.1838, ce_loss: 0.1838., accu: 0.8800, speed: 1.18 step/s\n",
      "global step 22780, epoch: 5, batch: 3960, loss: 0.1654, ce_loss: 0.1654., accu: 0.8800, speed: 1.18 step/s\n",
      "global step 22790, epoch: 5, batch: 3970, loss: 0.1949, ce_loss: 0.1949., accu: 0.8800, speed: 1.18 step/s\n",
      "global step 22800, epoch: 5, batch: 3980, loss: 0.1719, ce_loss: 0.1719., accu: 0.8801, speed: 1.18 step/s\n",
      "2022-09-28 18:29:23,410\t[train.py-do_train]-[line:187]-INFO:【global step 22800, epoch: 5, batch: 3980】，loss: 0.1719, ce_loss: 0.1719., accu: 0.8801,\n",
      "global step 22810, epoch: 5, batch: 3990, loss: 0.1574, ce_loss: 0.1574., accu: 0.8801, speed: 1.18 step/s\n",
      "global step 22820, epoch: 5, batch: 4000, loss: 0.0988, ce_loss: 0.0988., accu: 0.8801, speed: 1.19 step/s\n",
      "global step 22830, epoch: 5, batch: 4010, loss: 0.2202, ce_loss: 0.2202., accu: 0.8801, speed: 1.19 step/s\n",
      "global step 22840, epoch: 5, batch: 4020, loss: 0.2247, ce_loss: 0.2247., accu: 0.8801, speed: 1.20 step/s\n",
      "global step 22850, epoch: 5, batch: 4030, loss: 0.1380, ce_loss: 0.1380., accu: 0.8801, speed: 1.20 step/s\n",
      "global step 22860, epoch: 5, batch: 4040, loss: 0.2228, ce_loss: 0.2228., accu: 0.8802, speed: 1.18 step/s\n",
      "global step 22870, epoch: 5, batch: 4050, loss: 0.1703, ce_loss: 0.1703., accu: 0.8802, speed: 1.20 step/s\n",
      "global step 22880, epoch: 5, batch: 4060, loss: 0.1538, ce_loss: 0.1538., accu: 0.8802, speed: 1.19 step/s\n",
      "global step 22890, epoch: 5, batch: 4070, loss: 0.1136, ce_loss: 0.1136., accu: 0.8802, speed: 1.19 step/s\n",
      "global step 22900, epoch: 5, batch: 4080, loss: 0.1531, ce_loss: 0.1531., accu: 0.8802, speed: 1.18 step/s\n",
      "2022-09-28 18:30:47,513\t[train.py-do_train]-[line:187]-INFO:【global step 22900, epoch: 5, batch: 4080】，loss: 0.1531, ce_loss: 0.1531., accu: 0.8802,\n",
      "global step 22910, epoch: 5, batch: 4090, loss: 0.1811, ce_loss: 0.1811., accu: 0.8803, speed: 1.18 step/s\n",
      "global step 22920, epoch: 5, batch: 4100, loss: 0.1571, ce_loss: 0.1571., accu: 0.8803, speed: 1.18 step/s\n",
      "global step 22930, epoch: 5, batch: 4110, loss: 0.1418, ce_loss: 0.1418., accu: 0.8803, speed: 1.19 step/s\n",
      "global step 22940, epoch: 5, batch: 4120, loss: 0.1437, ce_loss: 0.1437., accu: 0.8803, speed: 1.18 step/s\n",
      "global step 22950, epoch: 5, batch: 4130, loss: 0.1517, ce_loss: 0.1517., accu: 0.8803, speed: 1.19 step/s\n",
      "global step 22960, epoch: 5, batch: 4140, loss: 0.2281, ce_loss: 0.2281., accu: 0.8803, speed: 1.18 step/s\n",
      "global step 22970, epoch: 5, batch: 4150, loss: 0.1661, ce_loss: 0.1661., accu: 0.8804, speed: 1.19 step/s\n",
      "global step 22980, epoch: 5, batch: 4160, loss: 0.1778, ce_loss: 0.1778., accu: 0.8804, speed: 1.20 step/s\n",
      "global step 22990, epoch: 5, batch: 4170, loss: 0.1413, ce_loss: 0.1413., accu: 0.8804, speed: 1.22 step/s\n",
      "global step 23000, epoch: 5, batch: 4180, loss: 0.2200, ce_loss: 0.2200., accu: 0.8804, speed: 1.18 step/s\n",
      "2022-09-28 18:32:11,649\t[train.py-do_train]-[line:187]-INFO:【global step 23000, epoch: 5, batch: 4180】，loss: 0.2200, ce_loss: 0.2200., accu: 0.8804,\n",
      "global step 23010, epoch: 5, batch: 4190, loss: 0.1593, ce_loss: 0.1593., accu: 0.8804, speed: 1.19 step/s\n",
      "global step 23020, epoch: 5, batch: 4200, loss: 0.1828, ce_loss: 0.1828., accu: 0.8804, speed: 1.18 step/s\n",
      "global step 23030, epoch: 5, batch: 4210, loss: 0.1599, ce_loss: 0.1599., accu: 0.8805, speed: 1.20 step/s\n",
      "global step 23040, epoch: 5, batch: 4220, loss: 0.1549, ce_loss: 0.1549., accu: 0.8805, speed: 1.19 step/s\n",
      "global step 23050, epoch: 5, batch: 4230, loss: 0.1897, ce_loss: 0.1897., accu: 0.8805, speed: 1.22 step/s\n",
      "global step 23060, epoch: 5, batch: 4240, loss: 0.1211, ce_loss: 0.1211., accu: 0.8805, speed: 1.18 step/s\n",
      "global step 23070, epoch: 5, batch: 4250, loss: 0.1698, ce_loss: 0.1698., accu: 0.8805, speed: 1.18 step/s\n",
      "global step 23080, epoch: 5, batch: 4260, loss: 0.1881, ce_loss: 0.1881., accu: 0.8806, speed: 1.19 step/s\n",
      "global step 23090, epoch: 5, batch: 4270, loss: 0.2193, ce_loss: 0.2193., accu: 0.8806, speed: 1.20 step/s\n",
      "global step 23100, epoch: 5, batch: 4280, loss: 0.1412, ce_loss: 0.1412., accu: 0.8806, speed: 1.19 step/s\n",
      "2022-09-28 18:33:35,497\t[train.py-do_train]-[line:187]-INFO:【global step 23100, epoch: 5, batch: 4280】，loss: 0.1412, ce_loss: 0.1412., accu: 0.8806,\n",
      "global step 23110, epoch: 5, batch: 4290, loss: 0.1438, ce_loss: 0.1438., accu: 0.8806, speed: 1.18 step/s\n",
      "global step 23120, epoch: 5, batch: 4300, loss: 0.1554, ce_loss: 0.1554., accu: 0.8806, speed: 1.18 step/s\n",
      "global step 23130, epoch: 5, batch: 4310, loss: 0.2050, ce_loss: 0.2050., accu: 0.8807, speed: 1.21 step/s\n",
      "global step 23140, epoch: 5, batch: 4320, loss: 0.2307, ce_loss: 0.2307., accu: 0.8807, speed: 1.18 step/s\n",
      "global step 23150, epoch: 5, batch: 4330, loss: 0.2176, ce_loss: 0.2176., accu: 0.8807, speed: 1.18 step/s\n",
      "global step 23160, epoch: 5, batch: 4340, loss: 0.1607, ce_loss: 0.1607., accu: 0.8807, speed: 1.20 step/s\n",
      "global step 23170, epoch: 5, batch: 4350, loss: 0.1974, ce_loss: 0.1974., accu: 0.8807, speed: 1.18 step/s\n",
      "global step 23180, epoch: 5, batch: 4360, loss: 0.2200, ce_loss: 0.2200., accu: 0.8807, speed: 1.19 step/s\n",
      "global step 23190, epoch: 5, batch: 4370, loss: 0.1095, ce_loss: 0.1095., accu: 0.8808, speed: 1.19 step/s\n",
      "global step 23200, epoch: 5, batch: 4380, loss: 0.2082, ce_loss: 0.2082., accu: 0.8808, speed: 1.19 step/s\n",
      "2022-09-28 18:34:59,756\t[train.py-do_train]-[line:187]-INFO:【global step 23200, epoch: 5, batch: 4380】，loss: 0.2082, ce_loss: 0.2082., accu: 0.8808,\n",
      "global step 23210, epoch: 5, batch: 4390, loss: 0.2781, ce_loss: 0.2781., accu: 0.8808, speed: 1.18 step/s\n",
      "global step 23220, epoch: 5, batch: 4400, loss: 0.1385, ce_loss: 0.1385., accu: 0.8808, speed: 1.18 step/s\n",
      "global step 23230, epoch: 5, batch: 4410, loss: 0.1725, ce_loss: 0.1725., accu: 0.8808, speed: 1.21 step/s\n",
      "global step 23240, epoch: 5, batch: 4420, loss: 0.0755, ce_loss: 0.0755., accu: 0.8809, speed: 1.19 step/s\n",
      "global step 23250, epoch: 5, batch: 4430, loss: 0.1815, ce_loss: 0.1815., accu: 0.8809, speed: 1.19 step/s\n",
      "global step 23260, epoch: 5, batch: 4440, loss: 0.1310, ce_loss: 0.1310., accu: 0.8809, speed: 1.19 step/s\n",
      "global step 23270, epoch: 5, batch: 4450, loss: 0.1979, ce_loss: 0.1979., accu: 0.8809, speed: 1.20 step/s\n",
      "global step 23280, epoch: 5, batch: 4460, loss: 0.2867, ce_loss: 0.2867., accu: 0.8809, speed: 1.18 step/s\n",
      "global step 23290, epoch: 5, batch: 4470, loss: 0.1875, ce_loss: 0.1875., accu: 0.8809, speed: 1.20 step/s\n",
      "global step 23300, epoch: 5, batch: 4480, loss: 0.1732, ce_loss: 0.1732., accu: 0.8810, speed: 1.18 step/s\n",
      "2022-09-28 18:36:23,776\t[train.py-do_train]-[line:187]-INFO:【global step 23300, epoch: 5, batch: 4480】，loss: 0.1732, ce_loss: 0.1732., accu: 0.8810,\n",
      "global step 23310, epoch: 5, batch: 4490, loss: 0.1433, ce_loss: 0.1433., accu: 0.8810, speed: 1.18 step/s\n",
      "global step 23320, epoch: 5, batch: 4500, loss: 0.1835, ce_loss: 0.1835., accu: 0.8810, speed: 1.18 step/s\n",
      "global step 23330, epoch: 5, batch: 4510, loss: 0.1363, ce_loss: 0.1363., accu: 0.8810, speed: 1.18 step/s\n",
      "global step 23340, epoch: 5, batch: 4520, loss: 0.1723, ce_loss: 0.1723., accu: 0.8810, speed: 1.20 step/s\n",
      "global step 23350, epoch: 5, batch: 4530, loss: 0.1841, ce_loss: 0.1841., accu: 0.8810, speed: 1.19 step/s\n",
      "global step 23360, epoch: 5, batch: 4540, loss: 0.1785, ce_loss: 0.1785., accu: 0.8811, speed: 1.19 step/s\n",
      "global step 23370, epoch: 5, batch: 4550, loss: 0.1320, ce_loss: 0.1320., accu: 0.8811, speed: 1.18 step/s\n",
      "global step 23380, epoch: 5, batch: 4560, loss: 0.2041, ce_loss: 0.2041., accu: 0.8811, speed: 1.19 step/s\n",
      "global step 23390, epoch: 5, batch: 4570, loss: 0.1735, ce_loss: 0.1735., accu: 0.8811, speed: 1.22 step/s\n",
      "global step 23400, epoch: 5, batch: 4580, loss: 0.2003, ce_loss: 0.2003., accu: 0.8812, speed: 1.19 step/s\n",
      "2022-09-28 18:37:47,773\t[train.py-do_train]-[line:187]-INFO:【global step 23400, epoch: 5, batch: 4580】，loss: 0.2003, ce_loss: 0.2003., accu: 0.8812,\n",
      "global step 23410, epoch: 5, batch: 4590, loss: 0.0924, ce_loss: 0.0924., accu: 0.8812, speed: 1.19 step/s\n",
      "global step 23420, epoch: 5, batch: 4600, loss: 0.1640, ce_loss: 0.1640., accu: 0.8812, speed: 1.22 step/s\n",
      "global step 23430, epoch: 5, batch: 4610, loss: 0.2476, ce_loss: 0.2476., accu: 0.8812, speed: 1.19 step/s\n",
      "global step 23440, epoch: 5, batch: 4620, loss: 0.2351, ce_loss: 0.2351., accu: 0.8812, speed: 1.18 step/s\n",
      "global step 23450, epoch: 5, batch: 4630, loss: 0.1639, ce_loss: 0.1639., accu: 0.8812, speed: 1.20 step/s\n",
      "global step 23460, epoch: 5, batch: 4640, loss: 0.1420, ce_loss: 0.1420., accu: 0.8813, speed: 1.18 step/s\n",
      "global step 23470, epoch: 5, batch: 4650, loss: 0.2030, ce_loss: 0.2030., accu: 0.8813, speed: 1.19 step/s\n",
      "global step 23480, epoch: 5, batch: 4660, loss: 0.2015, ce_loss: 0.2015., accu: 0.8813, speed: 1.19 step/s\n",
      "global step 23490, epoch: 5, batch: 4670, loss: 0.1311, ce_loss: 0.1311., accu: 0.8813, speed: 1.19 step/s\n",
      "global step 23500, epoch: 5, batch: 4680, loss: 0.1340, ce_loss: 0.1340., accu: 0.8813, speed: 1.18 step/s\n",
      "2022-09-28 18:39:11,895\t[train.py-do_train]-[line:187]-INFO:【global step 23500, epoch: 5, batch: 4680】，loss: 0.1340, ce_loss: 0.1340., accu: 0.8813,\n",
      "global step 23510, epoch: 5, batch: 4690, loss: 0.1142, ce_loss: 0.1142., accu: 0.8814, speed: 1.20 step/s\n",
      "global step 23520, epoch: 5, batch: 4700, loss: 0.2404, ce_loss: 0.2404., accu: 0.8814, speed: 1.21 step/s\n",
      "100%|█████████████████████████████████████████| 5/5 [5:30:16<00:00, 3963.21s/it]\n",
      "2022-09-28 18:39:32,795\t[train.py-do_train]-[line:219]-INFO:BEST SCORE ACC: 0.0 \n"
     ]
    }
   ],
   "source": [
    "!python run_att.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0928 23:42:23.103516   872 analysis_predictor.cc:1736] Deprecated. Please use CreatePredictor instead.\n",
      "2022-09-28 23:42:23,306\t[run_multitask.py-context]-[line:48]-INFO:set device gpu:3\n",
      "2022-09-28 23:42:23,306\t[run_multitask.py-context]-[line:53]-INFO:{\n",
      " \"model_config\": {\n",
      "  \"model_name\": \"debug\",\n",
      "  \"init_ckpt\": \"ernie-gram-zh\",\n",
      "  \"init_from_ckpt\": null,\n",
      "  \"num_labels\": 2,\n",
      "  \"rdrop_coef\": 0.0,\n",
      "  \"dropout\": 0.2\n",
      " },\n",
      " \"data_config\": {\n",
      "  \"max_seq_length\": 68,\n",
      "  \"ratio\": 70\n",
      " },\n",
      " \"train_config\": {\n",
      "  \"attack\": \"fgm\",\n",
      "  \"train_batch_size\": 128,\n",
      "  \"eval_batch_size\": 256,\n",
      "  \"max_steps\": -1,\n",
      "  \"learning_rate\": 2e-05,\n",
      "  \"weight_decay\": 0.001,\n",
      "  \"epochs\": 5,\n",
      "  \"eval_step\": 300,\n",
      "  \"save_step\": 10000,\n",
      "  \"warmup_proportion\": 0.2,\n",
      "  \"gpus\": \"0,1,2,3\",\n",
      "  \"gpu\": \"0,1,2,3\",\n",
      "  \"init_from_ckpt\": \"\",\n",
      "  \"seed\": 2022,\n",
      "  \"device\": \"gpu\",\n",
      "  \"silent\": false,\n",
      "  \"save_chkpoint\": [\n",
      "   18300,\n",
      "   20700,\n",
      "   22500,\n",
      "   24000\n",
      "  ],\n",
      "  \"max_grad_norm\": null\n",
      " },\n",
      " \"debug\": false,\n",
      " \"logger_name\": \"debug\"\n",
      "}\n",
      "\u001b[32m[2022-09-28 23:42:28,039] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-09-28 23:42:28,050] [    INFO]\u001b[0m - tokenizer config file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-09-28 23:42:28,050] [    INFO]\u001b[0m - Special tokens file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2022-09-28 23:42:28,051] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\u001b[0m\n",
      "init data set ,lac feat!\n",
      "init data set ,lac feat!\n",
      "2022-09-28 23:43:33,409\t[train.py-do_train_multitask]-[line:233]-INFO:总步数 24650\n",
      "  0%|                                                     | 0/5 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.603 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "global step 10, epoch: 1, batch: 10, loss: 0.9469,domain_loss: 1.3729 ,ce_loss: 0.8404., accu: 0.5344, speed: 0.96 step/s\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.8713,domain_loss: 1.3497 ,ce_loss: 0.7516., accu: 0.5289, speed: 1.22 step/s\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.8579,domain_loss: 1.3788 ,ce_loss: 0.7276., accu: 0.5341, speed: 1.22 step/s\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.9579,domain_loss: 1.4601 ,ce_loss: 0.8323., accu: 0.5381, speed: 1.22 step/s\n",
      "global step 50, epoch: 1, batch: 50, loss: 0.8620,domain_loss: 1.4531 ,ce_loss: 0.7143., accu: 0.5434, speed: 1.21 step/s\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.8641,domain_loss: 1.5131 ,ce_loss: 0.7018., accu: 0.5422, speed: 1.21 step/s\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.8051,domain_loss: 1.3342 ,ce_loss: 0.6728., accu: 0.5446, speed: 1.21 step/s\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.8285,domain_loss: 1.4611 ,ce_loss: 0.6703., accu: 0.5479, speed: 1.20 step/s\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.8074,domain_loss: 1.3676 ,ce_loss: 0.6673., accu: 0.5560, speed: 1.20 step/s\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.7635,domain_loss: 1.3951 ,ce_loss: 0.6056., accu: 0.5573, speed: 1.21 step/s\n",
      "global step 110, epoch: 1, batch: 110, loss: 0.7764,domain_loss: 1.2075 ,ce_loss: 0.6687., accu: 0.5632, speed: 1.18 step/s\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.7752,domain_loss: 1.2603 ,ce_loss: 0.6539., accu: 0.5671, speed: 1.18 step/s\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.7823,domain_loss: 1.2355 ,ce_loss: 0.6690., accu: 0.5700, speed: 1.18 step/s\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.7955,domain_loss: 1.1498 ,ce_loss: 0.7069., accu: 0.5729, speed: 1.19 step/s\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.7869,domain_loss: 1.3421 ,ce_loss: 0.6481., accu: 0.5765, speed: 1.20 step/s\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.7384,domain_loss: 1.1056 ,ce_loss: 0.6466., accu: 0.5786, speed: 1.18 step/s\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.8082,domain_loss: 1.2908 ,ce_loss: 0.6875., accu: 0.5811, speed: 1.20 step/s\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.7348,domain_loss: 1.0461 ,ce_loss: 0.6569., accu: 0.5841, speed: 1.20 step/s\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.7128,domain_loss: 1.0170 ,ce_loss: 0.6368., accu: 0.5871, speed: 1.19 step/s\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.7744,domain_loss: 1.0127 ,ce_loss: 0.7149., accu: 0.5887, speed: 1.17 step/s\n",
      "global step 210, epoch: 1, batch: 210, loss: 0.7196,domain_loss: 1.0406 ,ce_loss: 0.6393., accu: 0.5906, speed: 1.17 step/s\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.6716,domain_loss: 1.0323 ,ce_loss: 0.5814., accu: 0.5933, speed: 1.19 step/s\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.7089,domain_loss: 0.9576 ,ce_loss: 0.6467., accu: 0.5964, speed: 1.17 step/s\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.7142,domain_loss: 0.9268 ,ce_loss: 0.6610., accu: 0.5994, speed: 1.18 step/s\n",
      "global step 250, epoch: 1, batch: 250, loss: 0.6191,domain_loss: 0.8991 ,ce_loss: 0.5491., accu: 0.6015, speed: 1.18 step/s\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.6682,domain_loss: 1.0423 ,ce_loss: 0.5747., accu: 0.6039, speed: 1.17 step/s\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.6649,domain_loss: 0.8529 ,ce_loss: 0.6179., accu: 0.6063, speed: 1.17 step/s\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.6351,domain_loss: 0.8323 ,ce_loss: 0.5858., accu: 0.6088, speed: 1.19 step/s\n",
      "global step 290, epoch: 1, batch: 290, loss: 0.6749,domain_loss: 0.9508 ,ce_loss: 0.6059., accu: 0.6113, speed: 1.18 step/s\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.6416,domain_loss: 0.9163 ,ce_loss: 0.5729., accu: 0.6131, speed: 1.21 step/s\n",
      "2022-09-28 23:47:47,127\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 300, epoch: 1, batch: 300】，loss: 0.6416,domain_loss: 0.9163 ,ce_loss: 0.5729., accu: 0.6131,\n",
      "2022-09-28 23:47:47,433\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.57481, accuracy: 0.7[0.72],threshold:0.458, domain_acc:0.13,total_num:100\n",
      "global step 310, epoch: 1, batch: 310, loss: 0.6452,domain_loss: 0.8552 ,ce_loss: 0.5926., accu: 0.6797, speed: 0.98 step/s\n",
      "global step 320, epoch: 1, batch: 320, loss: 0.5781,domain_loss: 0.8206 ,ce_loss: 0.5175., accu: 0.6898, speed: 1.18 step/s\n",
      "global step 330, epoch: 1, batch: 330, loss: 0.6751,domain_loss: 0.9003 ,ce_loss: 0.6188., accu: 0.6940, speed: 1.20 step/s\n",
      "global step 340, epoch: 1, batch: 340, loss: 0.5161,domain_loss: 0.6849 ,ce_loss: 0.4739., accu: 0.6973, speed: 1.18 step/s\n",
      "global step 350, epoch: 1, batch: 350, loss: 0.5864,domain_loss: 0.7740 ,ce_loss: 0.5395., accu: 0.7016, speed: 1.18 step/s\n",
      "global step 360, epoch: 1, batch: 360, loss: 0.6577,domain_loss: 0.8139 ,ce_loss: 0.6186., accu: 0.7018, speed: 1.18 step/s\n",
      "global step 370, epoch: 1, batch: 370, loss: 0.6298,domain_loss: 0.7588 ,ce_loss: 0.5976., accu: 0.7039, speed: 1.19 step/s\n",
      "global step 380, epoch: 1, batch: 380, loss: 0.5576,domain_loss: 0.7420 ,ce_loss: 0.5115., accu: 0.7060, speed: 1.18 step/s\n",
      "global step 390, epoch: 1, batch: 390, loss: 0.6034,domain_loss: 0.6275 ,ce_loss: 0.5974., accu: 0.7046, speed: 1.18 step/s\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.6082,domain_loss: 0.7025 ,ce_loss: 0.5846., accu: 0.7066, speed: 1.17 step/s\n",
      "global step 410, epoch: 1, batch: 410, loss: 0.5930,domain_loss: 0.6741 ,ce_loss: 0.5728., accu: 0.7077, speed: 1.18 step/s\n",
      "global step 420, epoch: 1, batch: 420, loss: 0.5800,domain_loss: 0.6822 ,ce_loss: 0.5544., accu: 0.7105, speed: 1.18 step/s\n",
      "global step 430, epoch: 1, batch: 430, loss: 0.4975,domain_loss: 0.5545 ,ce_loss: 0.4832., accu: 0.7141, speed: 1.17 step/s\n",
      "global step 440, epoch: 1, batch: 440, loss: 0.5421,domain_loss: 0.5528 ,ce_loss: 0.5395., accu: 0.7160, speed: 1.18 step/s\n",
      "global step 450, epoch: 1, batch: 450, loss: 0.5086,domain_loss: 0.6330 ,ce_loss: 0.4775., accu: 0.7184, speed: 1.18 step/s\n",
      "global step 460, epoch: 1, batch: 460, loss: 0.4996,domain_loss: 0.5318 ,ce_loss: 0.4915., accu: 0.7200, speed: 1.18 step/s\n",
      "global step 470, epoch: 1, batch: 470, loss: 0.4688,domain_loss: 0.6119 ,ce_loss: 0.4330., accu: 0.7210, speed: 1.18 step/s\n",
      "global step 480, epoch: 1, batch: 480, loss: 0.5366,domain_loss: 0.5422 ,ce_loss: 0.5352., accu: 0.7219, speed: 1.21 step/s\n",
      "global step 490, epoch: 1, batch: 490, loss: 0.4612,domain_loss: 0.5875 ,ce_loss: 0.4296., accu: 0.7238, speed: 1.19 step/s\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.4680,domain_loss: 0.5647 ,ce_loss: 0.4439., accu: 0.7246, speed: 1.17 step/s\n",
      "global step 510, epoch: 1, batch: 510, loss: 0.4975,domain_loss: 0.5447 ,ce_loss: 0.4856., accu: 0.7248, speed: 1.20 step/s\n",
      "global step 520, epoch: 1, batch: 520, loss: 0.5977,domain_loss: 0.5733 ,ce_loss: 0.6037., accu: 0.7263, speed: 1.18 step/s\n",
      "global step 530, epoch: 1, batch: 530, loss: 0.5169,domain_loss: 0.5098 ,ce_loss: 0.5187., accu: 0.7280, speed: 1.19 step/s\n",
      "global step 540, epoch: 1, batch: 540, loss: 0.4468,domain_loss: 0.5826 ,ce_loss: 0.4128., accu: 0.7296, speed: 1.18 step/s\n",
      "global step 550, epoch: 1, batch: 550, loss: 0.5723,domain_loss: 0.4367 ,ce_loss: 0.6062., accu: 0.7305, speed: 1.17 step/s\n",
      "global step 560, epoch: 1, batch: 560, loss: 0.5241,domain_loss: 0.5190 ,ce_loss: 0.5254., accu: 0.7313, speed: 1.20 step/s\n",
      "global step 570, epoch: 1, batch: 570, loss: 0.4525,domain_loss: 0.4906 ,ce_loss: 0.4430., accu: 0.7316, speed: 1.18 step/s\n",
      "global step 580, epoch: 1, batch: 580, loss: 0.5612,domain_loss: 0.3921 ,ce_loss: 0.6035., accu: 0.7326, speed: 1.19 step/s\n",
      "global step 590, epoch: 1, batch: 590, loss: 0.5135,domain_loss: 0.4336 ,ce_loss: 0.5335., accu: 0.7331, speed: 1.18 step/s\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.4661,domain_loss: 0.4867 ,ce_loss: 0.4610., accu: 0.7342, speed: 1.18 step/s\n",
      "2022-09-28 23:52:02,465\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 600, epoch: 1, batch: 600】，loss: 0.4661,domain_loss: 0.4867 ,ce_loss: 0.4610., accu: 0.7342,\n",
      "2022-09-28 23:52:02,788\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.62224, accuracy: 0.69[0.78],threshold:0.501, domain_acc:0.8,total_num:100\n",
      "global step 610, epoch: 1, batch: 610, loss: 0.4920,domain_loss: 0.5161 ,ce_loss: 0.4859., accu: 0.7664, speed: 1.14 step/s\n",
      "global step 620, epoch: 1, batch: 620, loss: 0.3524,domain_loss: 0.3376 ,ce_loss: 0.3561., accu: 0.7672, speed: 1.18 step/s\n",
      "global step 630, epoch: 1, batch: 630, loss: 0.5021,domain_loss: 0.4893 ,ce_loss: 0.5053., accu: 0.7633, speed: 1.18 step/s\n",
      "global step 640, epoch: 1, batch: 640, loss: 0.4469,domain_loss: 0.3345 ,ce_loss: 0.4750., accu: 0.7629, speed: 1.18 step/s\n",
      "global step 650, epoch: 1, batch: 650, loss: 0.5047,domain_loss: 0.3696 ,ce_loss: 0.5385., accu: 0.7600, speed: 1.19 step/s\n",
      "global step 660, epoch: 1, batch: 660, loss: 0.4754,domain_loss: 0.2479 ,ce_loss: 0.5323., accu: 0.7611, speed: 1.18 step/s\n",
      "global step 670, epoch: 1, batch: 670, loss: 0.4877,domain_loss: 0.3333 ,ce_loss: 0.5263., accu: 0.7622, speed: 1.18 step/s\n",
      "global step 680, epoch: 1, batch: 680, loss: 0.4066,domain_loss: 0.3323 ,ce_loss: 0.4252., accu: 0.7647, speed: 1.19 step/s\n",
      "global step 690, epoch: 1, batch: 690, loss: 0.4599,domain_loss: 0.4416 ,ce_loss: 0.4645., accu: 0.7653, speed: 1.18 step/s\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.3806,domain_loss: 0.3330 ,ce_loss: 0.3926., accu: 0.7644, speed: 1.18 step/s\n",
      "global step 710, epoch: 1, batch: 710, loss: 0.4599,domain_loss: 0.2566 ,ce_loss: 0.5107., accu: 0.7639, speed: 1.19 step/s\n",
      "global step 720, epoch: 1, batch: 720, loss: 0.5515,domain_loss: 0.3098 ,ce_loss: 0.6120., accu: 0.7646, speed: 1.18 step/s\n",
      "global step 730, epoch: 1, batch: 730, loss: 0.3878,domain_loss: 0.2465 ,ce_loss: 0.4231., accu: 0.7659, speed: 1.19 step/s\n",
      "global step 740, epoch: 1, batch: 740, loss: 0.4363,domain_loss: 0.4054 ,ce_loss: 0.4440., accu: 0.7661, speed: 1.20 step/s\n",
      "global step 750, epoch: 1, batch: 750, loss: 0.4669,domain_loss: 0.3559 ,ce_loss: 0.4947., accu: 0.7667, speed: 1.18 step/s\n",
      "global step 760, epoch: 1, batch: 760, loss: 0.4068,domain_loss: 0.3110 ,ce_loss: 0.4307., accu: 0.7672, speed: 1.18 step/s\n",
      "global step 770, epoch: 1, batch: 770, loss: 0.4317,domain_loss: 0.2830 ,ce_loss: 0.4689., accu: 0.7681, speed: 1.18 step/s\n",
      "global step 780, epoch: 1, batch: 780, loss: 0.5074,domain_loss: 0.2769 ,ce_loss: 0.5650., accu: 0.7674, speed: 1.19 step/s\n",
      "global step 790, epoch: 1, batch: 790, loss: 0.4955,domain_loss: 0.3576 ,ce_loss: 0.5300., accu: 0.7680, speed: 1.19 step/s\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.4460,domain_loss: 0.2955 ,ce_loss: 0.4836., accu: 0.7679, speed: 1.18 step/s\n",
      "global step 810, epoch: 1, batch: 810, loss: 0.3495,domain_loss: 0.2384 ,ce_loss: 0.3773., accu: 0.7689, speed: 1.20 step/s\n",
      "global step 820, epoch: 1, batch: 820, loss: 0.4234,domain_loss: 0.3794 ,ce_loss: 0.4344., accu: 0.7697, speed: 1.18 step/s\n",
      "global step 830, epoch: 1, batch: 830, loss: 0.3852,domain_loss: 0.2003 ,ce_loss: 0.4314., accu: 0.7698, speed: 1.18 step/s\n",
      "global step 840, epoch: 1, batch: 840, loss: 0.4281,domain_loss: 0.3531 ,ce_loss: 0.4468., accu: 0.7711, speed: 1.18 step/s\n",
      "global step 850, epoch: 1, batch: 850, loss: 0.3946,domain_loss: 0.1561 ,ce_loss: 0.4543., accu: 0.7717, speed: 1.18 step/s\n",
      "global step 860, epoch: 1, batch: 860, loss: 0.3995,domain_loss: 0.2414 ,ce_loss: 0.4390., accu: 0.7722, speed: 1.19 step/s\n",
      "global step 870, epoch: 1, batch: 870, loss: 0.3478,domain_loss: 0.2000 ,ce_loss: 0.3848., accu: 0.7725, speed: 1.18 step/s\n",
      "global step 880, epoch: 1, batch: 880, loss: 0.3980,domain_loss: 0.2604 ,ce_loss: 0.4324., accu: 0.7727, speed: 1.19 step/s\n",
      "global step 890, epoch: 1, batch: 890, loss: 0.4179,domain_loss: 0.2116 ,ce_loss: 0.4695., accu: 0.7740, speed: 1.19 step/s\n",
      "global step 900, epoch: 1, batch: 900, loss: 0.4357,domain_loss: 0.2814 ,ce_loss: 0.4743., accu: 0.7749, speed: 1.19 step/s\n",
      "2022-09-28 23:56:16,015\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 900, epoch: 1, batch: 900】，loss: 0.4357,domain_loss: 0.2814 ,ce_loss: 0.4743., accu: 0.7749,\n",
      "2022-09-28 23:56:16,322\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.52191, accuracy: 0.72[0.79],threshold:0.477, domain_acc:0.94,total_num:100\n",
      "global step 910, epoch: 1, batch: 910, loss: 0.3898,domain_loss: 0.2264 ,ce_loss: 0.4306., accu: 0.7828, speed: 1.02 step/s\n",
      "global step 920, epoch: 1, batch: 920, loss: 0.3643,domain_loss: 0.1637 ,ce_loss: 0.4144., accu: 0.7902, speed: 1.18 step/s\n",
      "global step 930, epoch: 1, batch: 930, loss: 0.3810,domain_loss: 0.3236 ,ce_loss: 0.3953., accu: 0.7924, speed: 1.18 step/s\n",
      "global step 940, epoch: 1, batch: 940, loss: 0.3892,domain_loss: 0.1391 ,ce_loss: 0.4518., accu: 0.7930, speed: 1.20 step/s\n",
      "global step 950, epoch: 1, batch: 950, loss: 0.3997,domain_loss: 0.1404 ,ce_loss: 0.4645., accu: 0.7936, speed: 1.20 step/s\n",
      "global step 960, epoch: 1, batch: 960, loss: 0.3728,domain_loss: 0.1408 ,ce_loss: 0.4308., accu: 0.7922, speed: 1.21 step/s\n",
      "global step 970, epoch: 1, batch: 970, loss: 0.4478,domain_loss: 0.2260 ,ce_loss: 0.5032., accu: 0.7926, speed: 1.18 step/s\n",
      "global step 980, epoch: 1, batch: 980, loss: 0.4510,domain_loss: 0.2062 ,ce_loss: 0.5122., accu: 0.7923, speed: 1.18 step/s\n",
      "global step 990, epoch: 1, batch: 990, loss: 0.3556,domain_loss: 0.2659 ,ce_loss: 0.3781., accu: 0.7924, speed: 1.18 step/s\n",
      "global step 1000, epoch: 1, batch: 1000, loss: 0.3427,domain_loss: 0.1754 ,ce_loss: 0.3845., accu: 0.7907, speed: 1.18 step/s\n",
      "global step 1010, epoch: 1, batch: 1010, loss: 0.3909,domain_loss: 0.2230 ,ce_loss: 0.4328., accu: 0.7888, speed: 1.19 step/s\n",
      "global step 1020, epoch: 1, batch: 1020, loss: 0.4524,domain_loss: 0.2714 ,ce_loss: 0.4976., accu: 0.7895, speed: 1.18 step/s\n",
      "global step 1030, epoch: 1, batch: 1030, loss: 0.3568,domain_loss: 0.1924 ,ce_loss: 0.3979., accu: 0.7910, speed: 1.18 step/s\n",
      "global step 1040, epoch: 1, batch: 1040, loss: 0.3304,domain_loss: 0.2148 ,ce_loss: 0.3593., accu: 0.7924, speed: 1.19 step/s\n",
      "global step 1050, epoch: 1, batch: 1050, loss: 0.3904,domain_loss: 0.2388 ,ce_loss: 0.4283., accu: 0.7915, speed: 1.19 step/s\n",
      "global step 1060, epoch: 1, batch: 1060, loss: 0.4071,domain_loss: 0.2838 ,ce_loss: 0.4380., accu: 0.7910, speed: 1.17 step/s\n",
      "global step 1070, epoch: 1, batch: 1070, loss: 0.3277,domain_loss: 0.2293 ,ce_loss: 0.3523., accu: 0.7912, speed: 1.18 step/s\n",
      "global step 1080, epoch: 1, batch: 1080, loss: 0.3572,domain_loss: 0.1357 ,ce_loss: 0.4126., accu: 0.7925, speed: 1.19 step/s\n",
      "global step 1090, epoch: 1, batch: 1090, loss: 0.3166,domain_loss: 0.2044 ,ce_loss: 0.3446., accu: 0.7929, speed: 1.19 step/s\n",
      "global step 1100, epoch: 1, batch: 1100, loss: 0.4674,domain_loss: 0.2595 ,ce_loss: 0.5194., accu: 0.7936, speed: 1.18 step/s\n",
      "global step 1110, epoch: 1, batch: 1110, loss: 0.3647,domain_loss: 0.2104 ,ce_loss: 0.4033., accu: 0.7925, speed: 1.17 step/s\n",
      "global step 1120, epoch: 1, batch: 1120, loss: 0.4114,domain_loss: 0.2573 ,ce_loss: 0.4499., accu: 0.7939, speed: 1.18 step/s\n",
      "global step 1130, epoch: 1, batch: 1130, loss: 0.3503,domain_loss: 0.3012 ,ce_loss: 0.3626., accu: 0.7935, speed: 1.20 step/s\n",
      "global step 1140, epoch: 1, batch: 1140, loss: 0.3499,domain_loss: 0.2090 ,ce_loss: 0.3852., accu: 0.7935, speed: 1.18 step/s\n",
      "global step 1150, epoch: 1, batch: 1150, loss: 0.3895,domain_loss: 0.1460 ,ce_loss: 0.4504., accu: 0.7945, speed: 1.17 step/s\n",
      "global step 1160, epoch: 1, batch: 1160, loss: 0.3920,domain_loss: 0.2598 ,ce_loss: 0.4250., accu: 0.7941, speed: 1.20 step/s\n",
      "global step 1170, epoch: 1, batch: 1170, loss: 0.3610,domain_loss: 0.1680 ,ce_loss: 0.4093., accu: 0.7956, speed: 1.19 step/s\n",
      "global step 1180, epoch: 1, batch: 1180, loss: 0.3581,domain_loss: 0.1522 ,ce_loss: 0.4096., accu: 0.7956, speed: 1.18 step/s\n",
      "global step 1190, epoch: 1, batch: 1190, loss: 0.4859,domain_loss: 0.2304 ,ce_loss: 0.5497., accu: 0.7954, speed: 1.19 step/s\n",
      "global step 1200, epoch: 1, batch: 1200, loss: 0.3570,domain_loss: 0.0623 ,ce_loss: 0.4307., accu: 0.7954, speed: 1.21 step/s\n",
      "2022-09-29 00:00:30,349\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 1200, epoch: 1, batch: 1200】，loss: 0.3570,domain_loss: 0.0623 ,ce_loss: 0.4307., accu: 0.7954,\n",
      "2022-09-29 00:00:30,664\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.54199, accuracy: 0.72[0.83],threshold:0.543, domain_acc:0.96,total_num:100\n",
      "global step 1210, epoch: 1, batch: 1210, loss: 0.3560,domain_loss: 0.1546 ,ce_loss: 0.4063., accu: 0.8070, speed: 1.14 step/s\n",
      "global step 1220, epoch: 1, batch: 1220, loss: 0.4154,domain_loss: 0.1679 ,ce_loss: 0.4773., accu: 0.8004, speed: 1.19 step/s\n",
      "global step 1230, epoch: 1, batch: 1230, loss: 0.3311,domain_loss: 0.2094 ,ce_loss: 0.3616., accu: 0.8068, speed: 1.18 step/s\n",
      "global step 1240, epoch: 1, batch: 1240, loss: 0.3321,domain_loss: 0.2146 ,ce_loss: 0.3615., accu: 0.8045, speed: 1.18 step/s\n",
      "global step 1250, epoch: 1, batch: 1250, loss: 0.3745,domain_loss: 0.1291 ,ce_loss: 0.4358., accu: 0.8017, speed: 1.23 step/s\n",
      "global step 1260, epoch: 1, batch: 1260, loss: 0.3419,domain_loss: 0.1250 ,ce_loss: 0.3961., accu: 0.8031, speed: 1.20 step/s\n",
      "global step 1270, epoch: 1, batch: 1270, loss: 0.4142,domain_loss: 0.2115 ,ce_loss: 0.4649., accu: 0.8048, speed: 1.18 step/s\n",
      "global step 1280, epoch: 1, batch: 1280, loss: 0.2951,domain_loss: 0.0986 ,ce_loss: 0.3443., accu: 0.8073, speed: 1.20 step/s\n",
      "global step 1290, epoch: 1, batch: 1290, loss: 0.3848,domain_loss: 0.3341 ,ce_loss: 0.3975., accu: 0.8076, speed: 1.19 step/s\n",
      "global step 1300, epoch: 1, batch: 1300, loss: 0.3087,domain_loss: 0.1562 ,ce_loss: 0.3468., accu: 0.8072, speed: 1.17 step/s\n",
      "global step 1310, epoch: 1, batch: 1310, loss: 0.4124,domain_loss: 0.1714 ,ce_loss: 0.4727., accu: 0.8069, speed: 1.19 step/s\n",
      "global step 1320, epoch: 1, batch: 1320, loss: 0.2690,domain_loss: 0.1659 ,ce_loss: 0.2947., accu: 0.8077, speed: 1.19 step/s\n",
      "global step 1330, epoch: 1, batch: 1330, loss: 0.3793,domain_loss: 0.1795 ,ce_loss: 0.4293., accu: 0.8079, speed: 1.18 step/s\n",
      "global step 1340, epoch: 1, batch: 1340, loss: 0.3155,domain_loss: 0.1324 ,ce_loss: 0.3612., accu: 0.8083, speed: 1.19 step/s\n",
      "global step 1350, epoch: 1, batch: 1350, loss: 0.3493,domain_loss: 0.1628 ,ce_loss: 0.3960., accu: 0.8091, speed: 1.20 step/s\n",
      "global step 1360, epoch: 1, batch: 1360, loss: 0.4556,domain_loss: 0.1688 ,ce_loss: 0.5273., accu: 0.8089, speed: 1.20 step/s\n",
      "global step 1370, epoch: 1, batch: 1370, loss: 0.3215,domain_loss: 0.1138 ,ce_loss: 0.3735., accu: 0.8092, speed: 1.18 step/s\n",
      "global step 1380, epoch: 1, batch: 1380, loss: 0.3493,domain_loss: 0.1401 ,ce_loss: 0.4016., accu: 0.8090, speed: 1.20 step/s\n",
      "global step 1390, epoch: 1, batch: 1390, loss: 0.2999,domain_loss: 0.1383 ,ce_loss: 0.3403., accu: 0.8095, speed: 1.18 step/s\n",
      "global step 1400, epoch: 1, batch: 1400, loss: 0.2833,domain_loss: 0.2154 ,ce_loss: 0.3003., accu: 0.8099, speed: 1.18 step/s\n",
      "global step 1410, epoch: 1, batch: 1410, loss: 0.3923,domain_loss: 0.2485 ,ce_loss: 0.4283., accu: 0.8091, speed: 1.18 step/s\n",
      "global step 1420, epoch: 1, batch: 1420, loss: 0.3766,domain_loss: 0.1480 ,ce_loss: 0.4338., accu: 0.8083, speed: 1.18 step/s\n",
      "global step 1430, epoch: 1, batch: 1430, loss: 0.3967,domain_loss: 0.1918 ,ce_loss: 0.4479., accu: 0.8085, speed: 1.20 step/s\n",
      "global step 1440, epoch: 1, batch: 1440, loss: 0.3814,domain_loss: 0.1804 ,ce_loss: 0.4317., accu: 0.8089, speed: 1.18 step/s\n",
      "global step 1450, epoch: 1, batch: 1450, loss: 0.3542,domain_loss: 0.1198 ,ce_loss: 0.4128., accu: 0.8092, speed: 1.19 step/s\n",
      "global step 1460, epoch: 1, batch: 1460, loss: 0.3187,domain_loss: 0.0996 ,ce_loss: 0.3734., accu: 0.8091, speed: 1.18 step/s\n",
      "global step 1470, epoch: 1, batch: 1470, loss: 0.3087,domain_loss: 0.1474 ,ce_loss: 0.3490., accu: 0.8095, speed: 1.18 step/s\n",
      "global step 1480, epoch: 1, batch: 1480, loss: 0.3573,domain_loss: 0.2415 ,ce_loss: 0.3862., accu: 0.8103, speed: 1.19 step/s\n",
      "global step 1490, epoch: 1, batch: 1490, loss: 0.3863,domain_loss: 0.1885 ,ce_loss: 0.4357., accu: 0.8106, speed: 1.18 step/s\n",
      "global step 1500, epoch: 1, batch: 1500, loss: 0.3517,domain_loss: 0.1748 ,ce_loss: 0.3959., accu: 0.8102, speed: 1.18 step/s\n",
      "2022-09-29 00:04:43,512\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 1500, epoch: 1, batch: 1500】，loss: 0.3517,domain_loss: 0.1748 ,ce_loss: 0.3959., accu: 0.8102,\n",
      "2022-09-29 00:04:43,828\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.40468, accuracy: 0.82[0.84],threshold:0.579, domain_acc:0.96,total_num:100\n",
      "global step 1510, epoch: 1, batch: 1510, loss: 0.3175,domain_loss: 0.1315 ,ce_loss: 0.3639., accu: 0.8070, speed: 1.02 step/s\n",
      "global step 1520, epoch: 1, batch: 1520, loss: 0.3789,domain_loss: 0.2350 ,ce_loss: 0.4149., accu: 0.8102, speed: 1.21 step/s\n",
      "global step 1530, epoch: 1, batch: 1530, loss: 0.3095,domain_loss: 0.0869 ,ce_loss: 0.3652., accu: 0.8159, speed: 1.19 step/s\n",
      "global step 1540, epoch: 1, batch: 1540, loss: 0.3828,domain_loss: 0.0867 ,ce_loss: 0.4568., accu: 0.8127, speed: 1.20 step/s\n",
      "global step 1550, epoch: 1, batch: 1550, loss: 0.3375,domain_loss: 0.1930 ,ce_loss: 0.3736., accu: 0.8145, speed: 1.18 step/s\n",
      "global step 1560, epoch: 1, batch: 1560, loss: 0.3814,domain_loss: 0.1465 ,ce_loss: 0.4401., accu: 0.8141, speed: 1.18 step/s\n",
      "global step 1570, epoch: 1, batch: 1570, loss: 0.3380,domain_loss: 0.1768 ,ce_loss: 0.3783., accu: 0.8142, speed: 1.18 step/s\n",
      "global step 1580, epoch: 1, batch: 1580, loss: 0.3103,domain_loss: 0.2251 ,ce_loss: 0.3316., accu: 0.8137, speed: 1.18 step/s\n",
      "global step 1590, epoch: 1, batch: 1590, loss: 0.2745,domain_loss: 0.0884 ,ce_loss: 0.3211., accu: 0.8140, speed: 1.19 step/s\n",
      "global step 1600, epoch: 1, batch: 1600, loss: 0.3289,domain_loss: 0.2703 ,ce_loss: 0.3436., accu: 0.8143, speed: 1.18 step/s\n",
      "global step 1610, epoch: 1, batch: 1610, loss: 0.3597,domain_loss: 0.1354 ,ce_loss: 0.4158., accu: 0.8151, speed: 1.18 step/s\n",
      "global step 1620, epoch: 1, batch: 1620, loss: 0.3252,domain_loss: 0.0941 ,ce_loss: 0.3830., accu: 0.8156, speed: 1.17 step/s\n",
      "global step 1630, epoch: 1, batch: 1630, loss: 0.3373,domain_loss: 0.1399 ,ce_loss: 0.3867., accu: 0.8157, speed: 1.19 step/s\n",
      "global step 1640, epoch: 1, batch: 1640, loss: 0.3561,domain_loss: 0.1187 ,ce_loss: 0.4155., accu: 0.8156, speed: 1.19 step/s\n",
      "global step 1650, epoch: 1, batch: 1650, loss: 0.2630,domain_loss: 0.1274 ,ce_loss: 0.2969., accu: 0.8155, speed: 1.18 step/s\n",
      "global step 1660, epoch: 1, batch: 1660, loss: 0.2889,domain_loss: 0.1217 ,ce_loss: 0.3307., accu: 0.8163, speed: 1.17 step/s\n",
      "global step 1670, epoch: 1, batch: 1670, loss: 0.3676,domain_loss: 0.1330 ,ce_loss: 0.4262., accu: 0.8153, speed: 1.18 step/s\n",
      "global step 1680, epoch: 1, batch: 1680, loss: 0.3852,domain_loss: 0.1518 ,ce_loss: 0.4435., accu: 0.8151, speed: 1.17 step/s\n",
      "global step 1690, epoch: 1, batch: 1690, loss: 0.4113,domain_loss: 0.1073 ,ce_loss: 0.4873., accu: 0.8148, speed: 1.19 step/s\n",
      "global step 1700, epoch: 1, batch: 1700, loss: 0.3540,domain_loss: 0.1642 ,ce_loss: 0.4015., accu: 0.8150, speed: 1.18 step/s\n",
      "global step 1710, epoch: 1, batch: 1710, loss: 0.3232,domain_loss: 0.1827 ,ce_loss: 0.3583., accu: 0.8151, speed: 1.18 step/s\n",
      "global step 1720, epoch: 1, batch: 1720, loss: 0.3219,domain_loss: 0.2183 ,ce_loss: 0.3479., accu: 0.8152, speed: 1.18 step/s\n",
      "global step 1730, epoch: 1, batch: 1730, loss: 0.3449,domain_loss: 0.0854 ,ce_loss: 0.4098., accu: 0.8155, speed: 1.22 step/s\n",
      "global step 1740, epoch: 1, batch: 1740, loss: 0.2738,domain_loss: 0.1134 ,ce_loss: 0.3139., accu: 0.8161, speed: 1.20 step/s\n",
      "global step 1750, epoch: 1, batch: 1750, loss: 0.4088,domain_loss: 0.1040 ,ce_loss: 0.4850., accu: 0.8161, speed: 1.18 step/s\n",
      "global step 1760, epoch: 1, batch: 1760, loss: 0.3264,domain_loss: 0.1991 ,ce_loss: 0.3582., accu: 0.8162, speed: 1.18 step/s\n",
      "global step 1770, epoch: 1, batch: 1770, loss: 0.3330,domain_loss: 0.1146 ,ce_loss: 0.3875., accu: 0.8169, speed: 1.18 step/s\n",
      "global step 1780, epoch: 1, batch: 1780, loss: 0.3385,domain_loss: 0.0941 ,ce_loss: 0.3996., accu: 0.8164, speed: 1.18 step/s\n",
      "global step 1790, epoch: 1, batch: 1790, loss: 0.3656,domain_loss: 0.2300 ,ce_loss: 0.3995., accu: 0.8167, speed: 1.18 step/s\n",
      "global step 1800, epoch: 1, batch: 1800, loss: 0.3467,domain_loss: 0.1352 ,ce_loss: 0.3995., accu: 0.8163, speed: 1.19 step/s\n",
      "2022-09-29 00:08:58,041\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 1800, epoch: 1, batch: 1800】，loss: 0.3467,domain_loss: 0.1352 ,ce_loss: 0.3995., accu: 0.8163,\n",
      "2022-09-29 00:08:58,344\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.43096, accuracy: 0.79[0.86],threshold:0.437, domain_acc:0.99,total_num:100\n",
      "global step 1810, epoch: 1, batch: 1810, loss: 0.2627,domain_loss: 0.1252 ,ce_loss: 0.2970., accu: 0.8313, speed: 1.17 step/s\n",
      "global step 1820, epoch: 1, batch: 1820, loss: 0.3526,domain_loss: 0.2044 ,ce_loss: 0.3896., accu: 0.8234, speed: 1.17 step/s\n",
      "global step 1830, epoch: 1, batch: 1830, loss: 0.3223,domain_loss: 0.1225 ,ce_loss: 0.3722., accu: 0.8268, speed: 1.19 step/s\n",
      "global step 1840, epoch: 1, batch: 1840, loss: 0.3381,domain_loss: 0.1191 ,ce_loss: 0.3929., accu: 0.8246, speed: 1.18 step/s\n",
      "global step 1850, epoch: 1, batch: 1850, loss: 0.2828,domain_loss: 0.1441 ,ce_loss: 0.3175., accu: 0.8225, speed: 1.19 step/s\n",
      "global step 1860, epoch: 1, batch: 1860, loss: 0.3511,domain_loss: 0.0893 ,ce_loss: 0.4166., accu: 0.8255, speed: 1.18 step/s\n",
      "global step 1870, epoch: 1, batch: 1870, loss: 0.2790,domain_loss: 0.1338 ,ce_loss: 0.3152., accu: 0.8276, speed: 1.18 step/s\n",
      "global step 1880, epoch: 1, batch: 1880, loss: 0.3816,domain_loss: 0.1542 ,ce_loss: 0.4384., accu: 0.8254, speed: 1.17 step/s\n",
      "global step 1890, epoch: 1, batch: 1890, loss: 0.2859,domain_loss: 0.1520 ,ce_loss: 0.3193., accu: 0.8269, speed: 1.18 step/s\n",
      "global step 1900, epoch: 1, batch: 1900, loss: 0.3971,domain_loss: 0.1334 ,ce_loss: 0.4631., accu: 0.8268, speed: 1.19 step/s\n",
      "global step 1910, epoch: 1, batch: 1910, loss: 0.3656,domain_loss: 0.1318 ,ce_loss: 0.4240., accu: 0.8280, speed: 1.18 step/s\n",
      "global step 1920, epoch: 1, batch: 1920, loss: 0.2637,domain_loss: 0.1732 ,ce_loss: 0.2863., accu: 0.8274, speed: 1.18 step/s\n",
      "global step 1930, epoch: 1, batch: 1930, loss: 0.3180,domain_loss: 0.1284 ,ce_loss: 0.3654., accu: 0.8261, speed: 1.18 step/s\n",
      "global step 1940, epoch: 1, batch: 1940, loss: 0.2984,domain_loss: 0.1176 ,ce_loss: 0.3436., accu: 0.8272, speed: 1.20 step/s\n",
      "global step 1950, epoch: 1, batch: 1950, loss: 0.2906,domain_loss: 0.1208 ,ce_loss: 0.3331., accu: 0.8278, speed: 1.19 step/s\n",
      "global step 1960, epoch: 1, batch: 1960, loss: 0.3540,domain_loss: 0.1215 ,ce_loss: 0.4121., accu: 0.8284, speed: 1.18 step/s\n",
      "global step 1970, epoch: 1, batch: 1970, loss: 0.3583,domain_loss: 0.0607 ,ce_loss: 0.4327., accu: 0.8276, speed: 1.18 step/s\n",
      "global step 1980, epoch: 1, batch: 1980, loss: 0.2606,domain_loss: 0.0810 ,ce_loss: 0.3055., accu: 0.8282, speed: 1.18 step/s\n",
      "global step 1990, epoch: 1, batch: 1990, loss: 0.2927,domain_loss: 0.0789 ,ce_loss: 0.3461., accu: 0.8285, speed: 1.19 step/s\n",
      "global step 2000, epoch: 1, batch: 2000, loss: 0.3092,domain_loss: 0.1056 ,ce_loss: 0.3601., accu: 0.8289, speed: 1.19 step/s\n",
      "global step 2010, epoch: 1, batch: 2010, loss: 0.2845,domain_loss: 0.2161 ,ce_loss: 0.3016., accu: 0.8288, speed: 1.21 step/s\n",
      "global step 2020, epoch: 1, batch: 2020, loss: 0.3224,domain_loss: 0.1853 ,ce_loss: 0.3566., accu: 0.8289, speed: 1.18 step/s\n",
      "global step 2030, epoch: 1, batch: 2030, loss: 0.3605,domain_loss: 0.0664 ,ce_loss: 0.4340., accu: 0.8286, speed: 1.18 step/s\n",
      "global step 2040, epoch: 1, batch: 2040, loss: 0.3761,domain_loss: 0.2098 ,ce_loss: 0.4176., accu: 0.8290, speed: 1.18 step/s\n",
      "global step 2050, epoch: 1, batch: 2050, loss: 0.2832,domain_loss: 0.1101 ,ce_loss: 0.3265., accu: 0.8291, speed: 1.19 step/s\n",
      "global step 2060, epoch: 1, batch: 2060, loss: 0.3550,domain_loss: 0.2183 ,ce_loss: 0.3891., accu: 0.8283, speed: 1.17 step/s\n",
      "global step 2070, epoch: 1, batch: 2070, loss: 0.2634,domain_loss: 0.1118 ,ce_loss: 0.3014., accu: 0.8281, speed: 1.18 step/s\n",
      "global step 2080, epoch: 1, batch: 2080, loss: 0.3376,domain_loss: 0.1378 ,ce_loss: 0.3876., accu: 0.8282, speed: 1.17 step/s\n",
      "global step 2090, epoch: 1, batch: 2090, loss: 0.3418,domain_loss: 0.0760 ,ce_loss: 0.4083., accu: 0.8285, speed: 1.19 step/s\n",
      "global step 2100, epoch: 1, batch: 2100, loss: 0.2829,domain_loss: 0.1374 ,ce_loss: 0.3192., accu: 0.8282, speed: 1.20 step/s\n",
      "2022-09-29 00:13:11,607\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 2100, epoch: 1, batch: 2100】，loss: 0.2829,domain_loss: 0.1374 ,ce_loss: 0.3192., accu: 0.8282,\n",
      "2022-09-29 00:13:11,917\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.41265, accuracy: 0.81[0.86],threshold:0.473, domain_acc:0.98,total_num:100\n",
      "global step 2110, epoch: 1, batch: 2110, loss: 0.3132,domain_loss: 0.1671 ,ce_loss: 0.3497., accu: 0.8320, speed: 1.14 step/s\n",
      "global step 2120, epoch: 1, batch: 2120, loss: 0.2968,domain_loss: 0.1445 ,ce_loss: 0.3349., accu: 0.8227, speed: 1.19 step/s\n",
      "global step 2130, epoch: 1, batch: 2130, loss: 0.3180,domain_loss: 0.1346 ,ce_loss: 0.3638., accu: 0.8250, speed: 1.18 step/s\n",
      "global step 2140, epoch: 1, batch: 2140, loss: 0.2806,domain_loss: 0.0965 ,ce_loss: 0.3266., accu: 0.8289, speed: 1.18 step/s\n",
      "global step 2150, epoch: 1, batch: 2150, loss: 0.2688,domain_loss: 0.0784 ,ce_loss: 0.3164., accu: 0.8266, speed: 1.19 step/s\n",
      "global step 2160, epoch: 1, batch: 2160, loss: 0.3697,domain_loss: 0.1824 ,ce_loss: 0.4165., accu: 0.8264, speed: 1.18 step/s\n",
      "global step 2170, epoch: 1, batch: 2170, loss: 0.3502,domain_loss: 0.0932 ,ce_loss: 0.4145., accu: 0.8258, speed: 1.17 step/s\n",
      "global step 2180, epoch: 1, batch: 2180, loss: 0.2575,domain_loss: 0.1353 ,ce_loss: 0.2880., accu: 0.8271, speed: 1.17 step/s\n",
      "global step 2190, epoch: 1, batch: 2190, loss: 0.2675,domain_loss: 0.0696 ,ce_loss: 0.3170., accu: 0.8260, speed: 1.18 step/s\n",
      "global step 2200, epoch: 1, batch: 2200, loss: 0.3269,domain_loss: 0.0975 ,ce_loss: 0.3843., accu: 0.8278, speed: 1.17 step/s\n",
      "global step 2210, epoch: 1, batch: 2210, loss: 0.3936,domain_loss: 0.1107 ,ce_loss: 0.4643., accu: 0.8285, speed: 1.19 step/s\n",
      "global step 2220, epoch: 1, batch: 2220, loss: 0.3585,domain_loss: 0.2218 ,ce_loss: 0.3927., accu: 0.8291, speed: 1.19 step/s\n",
      "global step 2230, epoch: 1, batch: 2230, loss: 0.2248,domain_loss: 0.0542 ,ce_loss: 0.2674., accu: 0.8299, speed: 1.22 step/s\n",
      "global step 2240, epoch: 1, batch: 2240, loss: 0.3064,domain_loss: 0.0931 ,ce_loss: 0.3598., accu: 0.8305, speed: 1.19 step/s\n",
      "global step 2250, epoch: 1, batch: 2250, loss: 0.3164,domain_loss: 0.1614 ,ce_loss: 0.3551., accu: 0.8310, speed: 1.18 step/s\n",
      "global step 2260, epoch: 1, batch: 2260, loss: 0.3396,domain_loss: 0.0330 ,ce_loss: 0.4162., accu: 0.8313, speed: 1.18 step/s\n",
      "global step 2270, epoch: 1, batch: 2270, loss: 0.2945,domain_loss: 0.1304 ,ce_loss: 0.3355., accu: 0.8312, speed: 1.18 step/s\n",
      "global step 2280, epoch: 1, batch: 2280, loss: 0.3093,domain_loss: 0.1069 ,ce_loss: 0.3599., accu: 0.8309, speed: 1.20 step/s\n",
      "global step 2290, epoch: 1, batch: 2290, loss: 0.2716,domain_loss: 0.0632 ,ce_loss: 0.3237., accu: 0.8318, speed: 1.19 step/s\n",
      "global step 2300, epoch: 1, batch: 2300, loss: 0.3202,domain_loss: 0.0523 ,ce_loss: 0.3872., accu: 0.8320, speed: 1.20 step/s\n",
      "global step 2310, epoch: 1, batch: 2310, loss: 0.3337,domain_loss: 0.1697 ,ce_loss: 0.3747., accu: 0.8318, speed: 1.19 step/s\n",
      "global step 2320, epoch: 1, batch: 2320, loss: 0.2533,domain_loss: 0.0911 ,ce_loss: 0.2938., accu: 0.8316, speed: 1.18 step/s\n",
      "global step 2330, epoch: 1, batch: 2330, loss: 0.3401,domain_loss: 0.0900 ,ce_loss: 0.4027., accu: 0.8311, speed: 1.17 step/s\n",
      "global step 2340, epoch: 1, batch: 2340, loss: 0.2978,domain_loss: 0.2182 ,ce_loss: 0.3177., accu: 0.8316, speed: 1.18 step/s\n",
      "global step 2350, epoch: 1, batch: 2350, loss: 0.3670,domain_loss: 0.1070 ,ce_loss: 0.4320., accu: 0.8317, speed: 1.17 step/s\n",
      "global step 2360, epoch: 1, batch: 2360, loss: 0.3313,domain_loss: 0.1194 ,ce_loss: 0.3843., accu: 0.8321, speed: 1.19 step/s\n",
      "global step 2370, epoch: 1, batch: 2370, loss: 0.3903,domain_loss: 0.0973 ,ce_loss: 0.4635., accu: 0.8317, speed: 1.18 step/s\n",
      "global step 2380, epoch: 1, batch: 2380, loss: 0.2885,domain_loss: 0.0722 ,ce_loss: 0.3426., accu: 0.8311, speed: 1.17 step/s\n",
      "global step 2390, epoch: 1, batch: 2390, loss: 0.2834,domain_loss: 0.1806 ,ce_loss: 0.3091., accu: 0.8312, speed: 1.18 step/s\n",
      "global step 2400, epoch: 1, batch: 2400, loss: 0.3181,domain_loss: 0.1893 ,ce_loss: 0.3502., accu: 0.8316, speed: 1.19 step/s\n",
      "2022-09-29 00:17:25,279\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 2400, epoch: 1, batch: 2400】，loss: 0.3181,domain_loss: 0.1893 ,ce_loss: 0.3502., accu: 0.8316,\n",
      "2022-09-29 00:17:25,579\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.41478, accuracy: 0.82[0.85],threshold:0.456, domain_acc:1.0,total_num:100\n",
      "global step 2410, epoch: 1, batch: 2410, loss: 0.2643,domain_loss: 0.1500 ,ce_loss: 0.2929., accu: 0.8102, speed: 1.14 step/s\n",
      "global step 2420, epoch: 1, batch: 2420, loss: 0.3276,domain_loss: 0.1413 ,ce_loss: 0.3741., accu: 0.8293, speed: 1.19 step/s\n",
      "global step 2430, epoch: 1, batch: 2430, loss: 0.3208,domain_loss: 0.1347 ,ce_loss: 0.3673., accu: 0.8367, speed: 1.19 step/s\n",
      "global step 2440, epoch: 1, batch: 2440, loss: 0.2747,domain_loss: 0.0361 ,ce_loss: 0.3343., accu: 0.8359, speed: 1.17 step/s\n",
      "global step 2450, epoch: 1, batch: 2450, loss: 0.2966,domain_loss: 0.0961 ,ce_loss: 0.3467., accu: 0.8369, speed: 1.19 step/s\n",
      "global step 2460, epoch: 1, batch: 2460, loss: 0.3266,domain_loss: 0.1238 ,ce_loss: 0.3773., accu: 0.8348, speed: 1.18 step/s\n",
      "global step 2470, epoch: 1, batch: 2470, loss: 0.3203,domain_loss: 0.1020 ,ce_loss: 0.3749., accu: 0.8360, speed: 1.18 step/s\n",
      "global step 2480, epoch: 1, batch: 2480, loss: 0.2938,domain_loss: 0.0833 ,ce_loss: 0.3465., accu: 0.8352, speed: 1.18 step/s\n",
      "global step 2490, epoch: 1, batch: 2490, loss: 0.2782,domain_loss: 0.1154 ,ce_loss: 0.3190., accu: 0.8352, speed: 1.18 step/s\n",
      "global step 2500, epoch: 1, batch: 2500, loss: 0.2725,domain_loss: 0.1080 ,ce_loss: 0.3136., accu: 0.8334, speed: 1.17 step/s\n",
      "global step 2510, epoch: 1, batch: 2510, loss: 0.3094,domain_loss: 0.1638 ,ce_loss: 0.3457., accu: 0.8339, speed: 1.18 step/s\n",
      "global step 2520, epoch: 1, batch: 2520, loss: 0.2931,domain_loss: 0.1263 ,ce_loss: 0.3347., accu: 0.8323, speed: 1.17 step/s\n",
      "global step 2530, epoch: 1, batch: 2530, loss: 0.3460,domain_loss: 0.1366 ,ce_loss: 0.3984., accu: 0.8341, speed: 1.17 step/s\n",
      "global step 2540, epoch: 1, batch: 2540, loss: 0.3181,domain_loss: 0.1647 ,ce_loss: 0.3565., accu: 0.8323, speed: 1.17 step/s\n",
      "global step 2550, epoch: 1, batch: 2550, loss: 0.2711,domain_loss: 0.1190 ,ce_loss: 0.3091., accu: 0.8335, speed: 1.19 step/s\n",
      "global step 2560, epoch: 1, batch: 2560, loss: 0.2838,domain_loss: 0.1111 ,ce_loss: 0.3270., accu: 0.8330, speed: 1.17 step/s\n",
      "global step 2570, epoch: 1, batch: 2570, loss: 0.2468,domain_loss: 0.0889 ,ce_loss: 0.2863., accu: 0.8333, speed: 1.18 step/s\n",
      "global step 2580, epoch: 1, batch: 2580, loss: 0.3258,domain_loss: 0.2250 ,ce_loss: 0.3510., accu: 0.8336, speed: 1.17 step/s\n",
      "global step 2590, epoch: 1, batch: 2590, loss: 0.2625,domain_loss: 0.0957 ,ce_loss: 0.3042., accu: 0.8340, speed: 1.19 step/s\n",
      "global step 2600, epoch: 1, batch: 2600, loss: 0.2969,domain_loss: 0.1965 ,ce_loss: 0.3220., accu: 0.8344, speed: 1.19 step/s\n",
      "global step 2610, epoch: 1, batch: 2610, loss: 0.3065,domain_loss: 0.1004 ,ce_loss: 0.3580., accu: 0.8350, speed: 1.17 step/s\n",
      "global step 2620, epoch: 1, batch: 2620, loss: 0.3126,domain_loss: 0.0639 ,ce_loss: 0.3748., accu: 0.8346, speed: 1.18 step/s\n",
      "global step 2630, epoch: 1, batch: 2630, loss: 0.2854,domain_loss: 0.0966 ,ce_loss: 0.3326., accu: 0.8348, speed: 1.17 step/s\n",
      "global step 2640, epoch: 1, batch: 2640, loss: 0.3117,domain_loss: 0.1553 ,ce_loss: 0.3508., accu: 0.8352, speed: 1.17 step/s\n",
      "global step 2650, epoch: 1, batch: 2650, loss: 0.2871,domain_loss: 0.0315 ,ce_loss: 0.3510., accu: 0.8347, speed: 1.20 step/s\n",
      "global step 2660, epoch: 1, batch: 2660, loss: 0.3468,domain_loss: 0.0534 ,ce_loss: 0.4201., accu: 0.8345, speed: 1.19 step/s\n",
      "global step 2670, epoch: 1, batch: 2670, loss: 0.2487,domain_loss: 0.1007 ,ce_loss: 0.2857., accu: 0.8350, speed: 1.17 step/s\n",
      "global step 2680, epoch: 1, batch: 2680, loss: 0.2576,domain_loss: 0.1052 ,ce_loss: 0.2957., accu: 0.8354, speed: 1.18 step/s\n",
      "global step 2690, epoch: 1, batch: 2690, loss: 0.2434,domain_loss: 0.1414 ,ce_loss: 0.2689., accu: 0.8359, speed: 1.18 step/s\n",
      "global step 2700, epoch: 1, batch: 2700, loss: 0.3688,domain_loss: 0.0416 ,ce_loss: 0.4505., accu: 0.8352, speed: 1.20 step/s\n",
      "2022-09-29 00:21:40,004\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 2700, epoch: 1, batch: 2700】，loss: 0.3688,domain_loss: 0.0416 ,ce_loss: 0.4505., accu: 0.8352,\n",
      "2022-09-29 00:21:40,311\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.31131, accuracy: 0.86[0.9],threshold:0.398, domain_acc:1.0,total_num:100\n",
      "global step 2710, epoch: 1, batch: 2710, loss: 0.3096,domain_loss: 0.0544 ,ce_loss: 0.3734., accu: 0.8453, speed: 1.06 step/s\n",
      "global step 2720, epoch: 1, batch: 2720, loss: 0.3422,domain_loss: 0.0663 ,ce_loss: 0.4112., accu: 0.8348, speed: 1.17 step/s\n",
      "global step 2730, epoch: 1, batch: 2730, loss: 0.2743,domain_loss: 0.0615 ,ce_loss: 0.3275., accu: 0.8398, speed: 1.18 step/s\n",
      "global step 2740, epoch: 1, batch: 2740, loss: 0.2776,domain_loss: 0.1123 ,ce_loss: 0.3190., accu: 0.8387, speed: 1.18 step/s\n",
      "global step 2750, epoch: 1, batch: 2750, loss: 0.3300,domain_loss: 0.2998 ,ce_loss: 0.3375., accu: 0.8369, speed: 1.17 step/s\n",
      "global step 2760, epoch: 1, batch: 2760, loss: 0.2945,domain_loss: 0.1162 ,ce_loss: 0.3391., accu: 0.8378, speed: 1.20 step/s\n",
      "global step 2770, epoch: 1, batch: 2770, loss: 0.2962,domain_loss: 0.0644 ,ce_loss: 0.3541., accu: 0.8377, speed: 1.18 step/s\n",
      "global step 2780, epoch: 1, batch: 2780, loss: 0.3422,domain_loss: 0.0715 ,ce_loss: 0.4099., accu: 0.8388, speed: 1.18 step/s\n",
      "global step 2790, epoch: 1, batch: 2790, loss: 0.2889,domain_loss: 0.0274 ,ce_loss: 0.3542., accu: 0.8402, speed: 1.17 step/s\n",
      "global step 2800, epoch: 1, batch: 2800, loss: 0.2955,domain_loss: 0.0795 ,ce_loss: 0.3495., accu: 0.8386, speed: 1.17 step/s\n",
      "global step 2810, epoch: 1, batch: 2810, loss: 0.2948,domain_loss: 0.1116 ,ce_loss: 0.3406., accu: 0.8394, speed: 1.17 step/s\n",
      "global step 2820, epoch: 1, batch: 2820, loss: 0.3378,domain_loss: 0.1590 ,ce_loss: 0.3825., accu: 0.8411, speed: 1.18 step/s\n",
      "global step 2830, epoch: 1, batch: 2830, loss: 0.2401,domain_loss: 0.0929 ,ce_loss: 0.2769., accu: 0.8414, speed: 1.18 step/s\n",
      "global step 2840, epoch: 1, batch: 2840, loss: 0.3270,domain_loss: 0.1305 ,ce_loss: 0.3761., accu: 0.8412, speed: 1.17 step/s\n",
      "global step 2850, epoch: 1, batch: 2850, loss: 0.3854,domain_loss: 0.0404 ,ce_loss: 0.4717., accu: 0.8402, speed: 1.19 step/s\n",
      "global step 2860, epoch: 1, batch: 2860, loss: 0.3047,domain_loss: 0.1125 ,ce_loss: 0.3527., accu: 0.8396, speed: 1.19 step/s\n",
      "global step 2870, epoch: 1, batch: 2870, loss: 0.2833,domain_loss: 0.0365 ,ce_loss: 0.3450., accu: 0.8403, speed: 1.17 step/s\n",
      "global step 2880, epoch: 1, batch: 2880, loss: 0.3468,domain_loss: 0.1778 ,ce_loss: 0.3890., accu: 0.8399, speed: 1.18 step/s\n",
      "global step 2890, epoch: 1, batch: 2890, loss: 0.3806,domain_loss: 0.1596 ,ce_loss: 0.4359., accu: 0.8401, speed: 1.19 step/s\n",
      "global step 2900, epoch: 1, batch: 2900, loss: 0.2856,domain_loss: 0.0745 ,ce_loss: 0.3383., accu: 0.8387, speed: 1.18 step/s\n",
      "global step 2910, epoch: 1, batch: 2910, loss: 0.3001,domain_loss: 0.1024 ,ce_loss: 0.3495., accu: 0.8384, speed: 1.20 step/s\n",
      "global step 2920, epoch: 1, batch: 2920, loss: 0.3297,domain_loss: 0.0539 ,ce_loss: 0.3987., accu: 0.8390, speed: 1.20 step/s\n",
      "global step 2930, epoch: 1, batch: 2930, loss: 0.2606,domain_loss: 0.0752 ,ce_loss: 0.3070., accu: 0.8386, speed: 1.18 step/s\n",
      "global step 2940, epoch: 1, batch: 2940, loss: 0.3225,domain_loss: 0.0609 ,ce_loss: 0.3879., accu: 0.8384, speed: 1.19 step/s\n",
      "global step 2950, epoch: 1, batch: 2950, loss: 0.3339,domain_loss: 0.1020 ,ce_loss: 0.3919., accu: 0.8385, speed: 1.18 step/s\n",
      "global step 2960, epoch: 1, batch: 2960, loss: 0.2748,domain_loss: 0.0502 ,ce_loss: 0.3310., accu: 0.8391, speed: 1.18 step/s\n",
      "global step 2970, epoch: 1, batch: 2970, loss: 0.1740,domain_loss: 0.1168 ,ce_loss: 0.1883., accu: 0.8396, speed: 1.18 step/s\n",
      "global step 2980, epoch: 1, batch: 2980, loss: 0.2620,domain_loss: 0.0609 ,ce_loss: 0.3122., accu: 0.8392, speed: 1.18 step/s\n",
      "global step 2990, epoch: 1, batch: 2990, loss: 0.2775,domain_loss: 0.1062 ,ce_loss: 0.3204., accu: 0.8392, speed: 1.20 step/s\n",
      "global step 3000, epoch: 1, batch: 3000, loss: 0.2796,domain_loss: 0.1072 ,ce_loss: 0.3227., accu: 0.8384, speed: 1.18 step/s\n",
      "2022-09-29 00:25:54,971\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 3000, epoch: 1, batch: 3000】，loss: 0.2796,domain_loss: 0.1072 ,ce_loss: 0.3227., accu: 0.8384,\n",
      "2022-09-29 00:25:55,275\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.3507, accuracy: 0.87[0.86],threshold:0.422, domain_acc:1.0,total_num:100\n",
      "global step 3010, epoch: 1, batch: 3010, loss: 0.2638,domain_loss: 0.1129 ,ce_loss: 0.3015., accu: 0.8391, speed: 1.01 step/s\n",
      "global step 3020, epoch: 1, batch: 3020, loss: 0.3309,domain_loss: 0.0888 ,ce_loss: 0.3915., accu: 0.8309, speed: 1.19 step/s\n",
      "global step 3030, epoch: 1, batch: 3030, loss: 0.2753,domain_loss: 0.0704 ,ce_loss: 0.3265., accu: 0.8375, speed: 1.18 step/s\n",
      "global step 3040, epoch: 1, batch: 3040, loss: 0.2789,domain_loss: 0.1286 ,ce_loss: 0.3165., accu: 0.8389, speed: 1.17 step/s\n",
      "global step 3050, epoch: 1, batch: 3050, loss: 0.2666,domain_loss: 0.1707 ,ce_loss: 0.2905., accu: 0.8395, speed: 1.19 step/s\n",
      "global step 3060, epoch: 1, batch: 3060, loss: 0.3211,domain_loss: 0.0842 ,ce_loss: 0.3804., accu: 0.8380, speed: 1.17 step/s\n",
      "global step 3070, epoch: 1, batch: 3070, loss: 0.3422,domain_loss: 0.1918 ,ce_loss: 0.3798., accu: 0.8376, speed: 1.18 step/s\n",
      "global step 3080, epoch: 1, batch: 3080, loss: 0.3019,domain_loss: 0.0861 ,ce_loss: 0.3558., accu: 0.8370, speed: 1.19 step/s\n",
      "global step 3090, epoch: 1, batch: 3090, loss: 0.3171,domain_loss: 0.0742 ,ce_loss: 0.3778., accu: 0.8373, speed: 1.19 step/s\n",
      "global step 3100, epoch: 1, batch: 3100, loss: 0.2730,domain_loss: 0.1008 ,ce_loss: 0.3161., accu: 0.8381, speed: 1.18 step/s\n",
      "global step 3110, epoch: 1, batch: 3110, loss: 0.2929,domain_loss: 0.0697 ,ce_loss: 0.3487., accu: 0.8377, speed: 1.18 step/s\n",
      "global step 3120, epoch: 1, batch: 3120, loss: 0.3268,domain_loss: 0.0711 ,ce_loss: 0.3907., accu: 0.8370, speed: 1.21 step/s\n",
      "global step 3130, epoch: 1, batch: 3130, loss: 0.2248,domain_loss: 0.0564 ,ce_loss: 0.2669., accu: 0.8383, speed: 1.18 step/s\n",
      "global step 3140, epoch: 1, batch: 3140, loss: 0.2246,domain_loss: 0.1072 ,ce_loss: 0.2539., accu: 0.8391, speed: 1.18 step/s\n",
      "global step 3150, epoch: 1, batch: 3150, loss: 0.2879,domain_loss: 0.0668 ,ce_loss: 0.3432., accu: 0.8398, speed: 1.18 step/s\n",
      "global step 3160, epoch: 1, batch: 3160, loss: 0.3102,domain_loss: 0.0983 ,ce_loss: 0.3631., accu: 0.8404, speed: 1.17 step/s\n",
      "global step 3170, epoch: 1, batch: 3170, loss: 0.3012,domain_loss: 0.0864 ,ce_loss: 0.3549., accu: 0.8404, speed: 1.20 step/s\n",
      "global step 3180, epoch: 1, batch: 3180, loss: 0.2407,domain_loss: 0.0684 ,ce_loss: 0.2837., accu: 0.8404, speed: 1.18 step/s\n",
      "global step 3190, epoch: 1, batch: 3190, loss: 0.3338,domain_loss: 0.1089 ,ce_loss: 0.3901., accu: 0.8397, speed: 1.19 step/s\n",
      "global step 3200, epoch: 1, batch: 3200, loss: 0.3123,domain_loss: 0.0614 ,ce_loss: 0.3751., accu: 0.8395, speed: 1.17 step/s\n",
      "global step 3210, epoch: 1, batch: 3210, loss: 0.2620,domain_loss: 0.0526 ,ce_loss: 0.3144., accu: 0.8403, speed: 1.19 step/s\n",
      "global step 3220, epoch: 1, batch: 3220, loss: 0.3140,domain_loss: 0.0705 ,ce_loss: 0.3748., accu: 0.8400, speed: 1.17 step/s\n",
      "global step 3230, epoch: 1, batch: 3230, loss: 0.2986,domain_loss: 0.0744 ,ce_loss: 0.3547., accu: 0.8404, speed: 1.17 step/s\n",
      "global step 3240, epoch: 1, batch: 3240, loss: 0.2835,domain_loss: 0.0638 ,ce_loss: 0.3385., accu: 0.8408, speed: 1.17 step/s\n",
      "global step 3250, epoch: 1, batch: 3250, loss: 0.2834,domain_loss: 0.1142 ,ce_loss: 0.3257., accu: 0.8407, speed: 1.18 step/s\n",
      "global step 3260, epoch: 1, batch: 3260, loss: 0.2801,domain_loss: 0.1035 ,ce_loss: 0.3243., accu: 0.8409, speed: 1.20 step/s\n",
      "global step 3270, epoch: 1, batch: 3270, loss: 0.2905,domain_loss: 0.0629 ,ce_loss: 0.3474., accu: 0.8412, speed: 1.17 step/s\n",
      "global step 3280, epoch: 1, batch: 3280, loss: 0.2737,domain_loss: 0.0613 ,ce_loss: 0.3268., accu: 0.8414, speed: 1.17 step/s\n",
      "global step 3290, epoch: 1, batch: 3290, loss: 0.3030,domain_loss: 0.0793 ,ce_loss: 0.3589., accu: 0.8412, speed: 1.18 step/s\n",
      "global step 3300, epoch: 1, batch: 3300, loss: 0.3376,domain_loss: 0.0489 ,ce_loss: 0.4098., accu: 0.8406, speed: 1.19 step/s\n",
      "2022-09-29 00:30:10,215\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 3300, epoch: 1, batch: 3300】，loss: 0.3376,domain_loss: 0.0489 ,ce_loss: 0.4098., accu: 0.8406,\n",
      "2022-09-29 00:30:10,522\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.2584, accuracy: 0.85[0.89],threshold:0.378, domain_acc:1.0,total_num:100\n",
      "global step 3310, epoch: 1, batch: 3310, loss: 0.3264,domain_loss: 0.0517 ,ce_loss: 0.3951., accu: 0.8281, speed: 1.14 step/s\n",
      "global step 3320, epoch: 1, batch: 3320, loss: 0.3725,domain_loss: 0.1521 ,ce_loss: 0.4276., accu: 0.8301, speed: 1.18 step/s\n",
      "global step 3330, epoch: 1, batch: 3330, loss: 0.2389,domain_loss: 0.0674 ,ce_loss: 0.2818., accu: 0.8346, speed: 1.19 step/s\n",
      "global step 3340, epoch: 1, batch: 3340, loss: 0.2681,domain_loss: 0.0660 ,ce_loss: 0.3186., accu: 0.8363, speed: 1.17 step/s\n",
      "global step 3350, epoch: 1, batch: 3350, loss: 0.2610,domain_loss: 0.1086 ,ce_loss: 0.2991., accu: 0.8400, speed: 1.18 step/s\n",
      "global step 3360, epoch: 1, batch: 3360, loss: 0.3099,domain_loss: 0.0925 ,ce_loss: 0.3643., accu: 0.8413, speed: 1.17 step/s\n",
      "global step 3370, epoch: 1, batch: 3370, loss: 0.2695,domain_loss: 0.2101 ,ce_loss: 0.2843., accu: 0.8440, speed: 1.18 step/s\n",
      "global step 3380, epoch: 1, batch: 3380, loss: 0.2824,domain_loss: 0.0814 ,ce_loss: 0.3326., accu: 0.8449, speed: 1.18 step/s\n",
      "global step 3390, epoch: 1, batch: 3390, loss: 0.2879,domain_loss: 0.0453 ,ce_loss: 0.3486., accu: 0.8444, speed: 1.18 step/s\n",
      "global step 3400, epoch: 1, batch: 3400, loss: 0.2937,domain_loss: 0.0237 ,ce_loss: 0.3612., accu: 0.8437, speed: 1.18 step/s\n",
      "global step 3410, epoch: 1, batch: 3410, loss: 0.2431,domain_loss: 0.0960 ,ce_loss: 0.2799., accu: 0.8445, speed: 1.17 step/s\n",
      "global step 3420, epoch: 1, batch: 3420, loss: 0.3091,domain_loss: 0.1000 ,ce_loss: 0.3614., accu: 0.8437, speed: 1.20 step/s\n",
      "global step 3430, epoch: 1, batch: 3430, loss: 0.2958,domain_loss: 0.0734 ,ce_loss: 0.3514., accu: 0.8446, speed: 1.17 step/s\n",
      "global step 3440, epoch: 1, batch: 3440, loss: 0.2925,domain_loss: 0.1434 ,ce_loss: 0.3298., accu: 0.8453, speed: 1.19 step/s\n",
      "global step 3450, epoch: 1, batch: 3450, loss: 0.2919,domain_loss: 0.0446 ,ce_loss: 0.3537., accu: 0.8448, speed: 1.17 step/s\n",
      "global step 3460, epoch: 1, batch: 3460, loss: 0.3461,domain_loss: 0.1384 ,ce_loss: 0.3980., accu: 0.8446, speed: 1.17 step/s\n",
      "global step 3470, epoch: 1, batch: 3470, loss: 0.3348,domain_loss: 0.0918 ,ce_loss: 0.3956., accu: 0.8436, speed: 1.17 step/s\n",
      "global step 3480, epoch: 1, batch: 3480, loss: 0.2934,domain_loss: 0.0415 ,ce_loss: 0.3564., accu: 0.8434, speed: 1.17 step/s\n",
      "global step 3490, epoch: 1, batch: 3490, loss: 0.3130,domain_loss: 0.0387 ,ce_loss: 0.3815., accu: 0.8428, speed: 1.18 step/s\n",
      "global step 3500, epoch: 1, batch: 3500, loss: 0.2752,domain_loss: 0.0595 ,ce_loss: 0.3292., accu: 0.8423, speed: 1.17 step/s\n",
      "global step 3510, epoch: 1, batch: 3510, loss: 0.3838,domain_loss: 0.1160 ,ce_loss: 0.4508., accu: 0.8416, speed: 1.22 step/s\n",
      "global step 3520, epoch: 1, batch: 3520, loss: 0.3094,domain_loss: 0.0615 ,ce_loss: 0.3714., accu: 0.8413, speed: 1.17 step/s\n",
      "global step 3530, epoch: 1, batch: 3530, loss: 0.2752,domain_loss: 0.0375 ,ce_loss: 0.3347., accu: 0.8417, speed: 1.19 step/s\n",
      "global step 3540, epoch: 1, batch: 3540, loss: 0.2826,domain_loss: 0.1546 ,ce_loss: 0.3146., accu: 0.8419, speed: 1.17 step/s\n",
      "global step 3550, epoch: 1, batch: 3550, loss: 0.3063,domain_loss: 0.0638 ,ce_loss: 0.3669., accu: 0.8420, speed: 1.18 step/s\n",
      "global step 3560, epoch: 1, batch: 3560, loss: 0.3375,domain_loss: 0.0355 ,ce_loss: 0.4130., accu: 0.8414, speed: 1.18 step/s\n",
      "global step 3570, epoch: 1, batch: 3570, loss: 0.3165,domain_loss: 0.0237 ,ce_loss: 0.3897., accu: 0.8418, speed: 1.20 step/s\n",
      "global step 3580, epoch: 1, batch: 3580, loss: 0.3297,domain_loss: 0.0948 ,ce_loss: 0.3884., accu: 0.8416, speed: 1.19 step/s\n",
      "global step 3590, epoch: 1, batch: 3590, loss: 0.3115,domain_loss: 0.0705 ,ce_loss: 0.3717., accu: 0.8416, speed: 1.19 step/s\n",
      "global step 3600, epoch: 1, batch: 3600, loss: 0.2766,domain_loss: 0.1188 ,ce_loss: 0.3160., accu: 0.8414, speed: 1.20 step/s\n",
      "2022-09-29 00:34:24,370\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 3600, epoch: 1, batch: 3600】，loss: 0.2766,domain_loss: 0.1188 ,ce_loss: 0.3160., accu: 0.8414,\n",
      "2022-09-29 00:34:24,674\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.27872, accuracy: 0.87[0.92],threshold:0.469, domain_acc:1.0,total_num:100\n",
      "global step 3610, epoch: 1, batch: 3610, loss: 0.2830,domain_loss: 0.0378 ,ce_loss: 0.3443., accu: 0.8180, speed: 1.14 step/s\n",
      "global step 3620, epoch: 1, batch: 3620, loss: 0.2554,domain_loss: 0.1467 ,ce_loss: 0.2825., accu: 0.8324, speed: 1.17 step/s\n",
      "global step 3630, epoch: 1, batch: 3630, loss: 0.2934,domain_loss: 0.0361 ,ce_loss: 0.3577., accu: 0.8380, speed: 1.20 step/s\n",
      "global step 3640, epoch: 1, batch: 3640, loss: 0.2518,domain_loss: 0.1338 ,ce_loss: 0.2813., accu: 0.8373, speed: 1.19 step/s\n",
      "global step 3650, epoch: 1, batch: 3650, loss: 0.3123,domain_loss: 0.1556 ,ce_loss: 0.3515., accu: 0.8369, speed: 1.19 step/s\n",
      "global step 3660, epoch: 1, batch: 3660, loss: 0.2978,domain_loss: 0.0961 ,ce_loss: 0.3482., accu: 0.8346, speed: 1.19 step/s\n",
      "global step 3670, epoch: 1, batch: 3670, loss: 0.2894,domain_loss: 0.0283 ,ce_loss: 0.3546., accu: 0.8357, speed: 1.18 step/s\n",
      "global step 3680, epoch: 1, batch: 3680, loss: 0.3831,domain_loss: 0.1946 ,ce_loss: 0.4302., accu: 0.8368, speed: 1.18 step/s\n",
      "global step 3690, epoch: 1, batch: 3690, loss: 0.2637,domain_loss: 0.0996 ,ce_loss: 0.3048., accu: 0.8388, speed: 1.20 step/s\n",
      "global step 3700, epoch: 1, batch: 3700, loss: 0.2755,domain_loss: 0.0967 ,ce_loss: 0.3203., accu: 0.8394, speed: 1.17 step/s\n",
      "global step 3710, epoch: 1, batch: 3710, loss: 0.2262,domain_loss: 0.0750 ,ce_loss: 0.2640., accu: 0.8401, speed: 1.18 step/s\n",
      "global step 3720, epoch: 1, batch: 3720, loss: 0.2582,domain_loss: 0.0787 ,ce_loss: 0.3031., accu: 0.8413, speed: 1.17 step/s\n",
      "global step 3730, epoch: 1, batch: 3730, loss: 0.2242,domain_loss: 0.0526 ,ce_loss: 0.2671., accu: 0.8422, speed: 1.18 step/s\n",
      "global step 3740, epoch: 1, batch: 3740, loss: 0.2805,domain_loss: 0.1068 ,ce_loss: 0.3239., accu: 0.8424, speed: 1.19 step/s\n",
      "global step 3750, epoch: 1, batch: 3750, loss: 0.3212,domain_loss: 0.0383 ,ce_loss: 0.3920., accu: 0.8429, speed: 1.17 step/s\n",
      "global step 3760, epoch: 1, batch: 3760, loss: 0.3044,domain_loss: 0.0872 ,ce_loss: 0.3587., accu: 0.8448, speed: 1.18 step/s\n",
      "global step 3770, epoch: 1, batch: 3770, loss: 0.3083,domain_loss: 0.1100 ,ce_loss: 0.3579., accu: 0.8452, speed: 1.19 step/s\n",
      "global step 3780, epoch: 1, batch: 3780, loss: 0.2432,domain_loss: 0.0550 ,ce_loss: 0.2903., accu: 0.8455, speed: 1.19 step/s\n",
      "global step 3790, epoch: 1, batch: 3790, loss: 0.2758,domain_loss: 0.0551 ,ce_loss: 0.3310., accu: 0.8452, speed: 1.20 step/s\n",
      "global step 3800, epoch: 1, batch: 3800, loss: 0.2332,domain_loss: 0.0590 ,ce_loss: 0.2767., accu: 0.8450, speed: 1.17 step/s\n",
      "global step 3810, epoch: 1, batch: 3810, loss: 0.3246,domain_loss: 0.0632 ,ce_loss: 0.3899., accu: 0.8449, speed: 1.17 step/s\n",
      "global step 3820, epoch: 1, batch: 3820, loss: 0.3004,domain_loss: 0.0434 ,ce_loss: 0.3647., accu: 0.8451, speed: 1.17 step/s\n",
      "global step 3830, epoch: 1, batch: 3830, loss: 0.2369,domain_loss: 0.0548 ,ce_loss: 0.2825., accu: 0.8459, speed: 1.18 step/s\n",
      "global step 3840, epoch: 1, batch: 3840, loss: 0.2946,domain_loss: 0.0722 ,ce_loss: 0.3502., accu: 0.8466, speed: 1.20 step/s\n",
      "global step 3850, epoch: 1, batch: 3850, loss: 0.3183,domain_loss: 0.0937 ,ce_loss: 0.3744., accu: 0.8461, speed: 1.19 step/s\n",
      "global step 3860, epoch: 1, batch: 3860, loss: 0.1974,domain_loss: 0.1211 ,ce_loss: 0.2165., accu: 0.8468, speed: 1.18 step/s\n",
      "global step 3870, epoch: 1, batch: 3870, loss: 0.2509,domain_loss: 0.0334 ,ce_loss: 0.3052., accu: 0.8467, speed: 1.17 step/s\n",
      "global step 3880, epoch: 1, batch: 3880, loss: 0.3126,domain_loss: 0.0616 ,ce_loss: 0.3754., accu: 0.8464, speed: 1.19 step/s\n",
      "global step 3890, epoch: 1, batch: 3890, loss: 0.2839,domain_loss: 0.0645 ,ce_loss: 0.3388., accu: 0.8459, speed: 1.17 step/s\n",
      "global step 3900, epoch: 1, batch: 3900, loss: 0.2537,domain_loss: 0.0771 ,ce_loss: 0.2978., accu: 0.8458, speed: 1.18 step/s\n",
      "2022-09-29 00:38:38,123\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 3900, epoch: 1, batch: 3900】，loss: 0.2537,domain_loss: 0.0771 ,ce_loss: 0.2978., accu: 0.8458,\n",
      "2022-09-29 00:38:38,431\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.2906, accuracy: 0.88[0.9],threshold:0.42, domain_acc:1.0,total_num:100\n",
      "global step 3910, epoch: 1, batch: 3910, loss: 0.2664,domain_loss: 0.0385 ,ce_loss: 0.3234., accu: 0.8648, speed: 1.03 step/s\n",
      "global step 3920, epoch: 1, batch: 3920, loss: 0.2480,domain_loss: 0.0351 ,ce_loss: 0.3012., accu: 0.8562, speed: 1.18 step/s\n",
      "global step 3930, epoch: 1, batch: 3930, loss: 0.2588,domain_loss: 0.0775 ,ce_loss: 0.3041., accu: 0.8521, speed: 1.18 step/s\n",
      "global step 3940, epoch: 1, batch: 3940, loss: 0.3934,domain_loss: 0.0387 ,ce_loss: 0.4821., accu: 0.8496, speed: 1.19 step/s\n",
      "global step 3950, epoch: 1, batch: 3950, loss: 0.2150,domain_loss: 0.0824 ,ce_loss: 0.2482., accu: 0.8512, speed: 1.19 step/s\n",
      "global step 3960, epoch: 1, batch: 3960, loss: 0.2981,domain_loss: 0.0646 ,ce_loss: 0.3564., accu: 0.8493, speed: 1.18 step/s\n",
      "global step 3970, epoch: 1, batch: 3970, loss: 0.2535,domain_loss: 0.0454 ,ce_loss: 0.3055., accu: 0.8507, speed: 1.22 step/s\n",
      "global step 3980, epoch: 1, batch: 3980, loss: 0.2298,domain_loss: 0.0939 ,ce_loss: 0.2638., accu: 0.8518, speed: 1.17 step/s\n",
      "global step 3990, epoch: 1, batch: 3990, loss: 0.2383,domain_loss: 0.0206 ,ce_loss: 0.2927., accu: 0.8504, speed: 1.17 step/s\n",
      "global step 4000, epoch: 1, batch: 4000, loss: 0.3243,domain_loss: 0.0544 ,ce_loss: 0.3918., accu: 0.8516, speed: 1.18 step/s\n",
      "global step 4010, epoch: 1, batch: 4010, loss: 0.2747,domain_loss: 0.0758 ,ce_loss: 0.3244., accu: 0.8506, speed: 1.19 step/s\n",
      "global step 4020, epoch: 1, batch: 4020, loss: 0.2489,domain_loss: 0.0539 ,ce_loss: 0.2976., accu: 0.8488, speed: 1.19 step/s\n",
      "global step 4030, epoch: 1, batch: 4030, loss: 0.2393,domain_loss: 0.0517 ,ce_loss: 0.2862., accu: 0.8502, speed: 1.23 step/s\n",
      "global step 4040, epoch: 1, batch: 4040, loss: 0.2427,domain_loss: 0.0693 ,ce_loss: 0.2861., accu: 0.8506, speed: 1.18 step/s\n",
      "global step 4050, epoch: 1, batch: 4050, loss: 0.2600,domain_loss: 0.0652 ,ce_loss: 0.3087., accu: 0.8518, speed: 1.18 step/s\n",
      "global step 4060, epoch: 1, batch: 4060, loss: 0.2914,domain_loss: 0.0707 ,ce_loss: 0.3466., accu: 0.8504, speed: 1.17 step/s\n",
      "global step 4070, epoch: 1, batch: 4070, loss: 0.2718,domain_loss: 0.0840 ,ce_loss: 0.3188., accu: 0.8507, speed: 1.18 step/s\n",
      "global step 4080, epoch: 1, batch: 4080, loss: 0.2812,domain_loss: 0.0886 ,ce_loss: 0.3294., accu: 0.8506, speed: 1.17 step/s\n",
      "global step 4090, epoch: 1, batch: 4090, loss: 0.3354,domain_loss: 0.0793 ,ce_loss: 0.3994., accu: 0.8502, speed: 1.18 step/s\n",
      "global step 4100, epoch: 1, batch: 4100, loss: 0.2915,domain_loss: 0.0429 ,ce_loss: 0.3536., accu: 0.8496, speed: 1.19 step/s\n",
      "global step 4110, epoch: 1, batch: 4110, loss: 0.3167,domain_loss: 0.0921 ,ce_loss: 0.3728., accu: 0.8494, speed: 1.18 step/s\n",
      "global step 4120, epoch: 1, batch: 4120, loss: 0.2580,domain_loss: 0.0619 ,ce_loss: 0.3070., accu: 0.8501, speed: 1.18 step/s\n",
      "global step 4130, epoch: 1, batch: 4130, loss: 0.2576,domain_loss: 0.1817 ,ce_loss: 0.2766., accu: 0.8499, speed: 1.18 step/s\n",
      "global step 4140, epoch: 1, batch: 4140, loss: 0.3084,domain_loss: 0.0796 ,ce_loss: 0.3656., accu: 0.8497, speed: 1.19 step/s\n",
      "global step 4150, epoch: 1, batch: 4150, loss: 0.2808,domain_loss: 0.1475 ,ce_loss: 0.3141., accu: 0.8503, speed: 1.19 step/s\n",
      "global step 4160, epoch: 1, batch: 4160, loss: 0.2585,domain_loss: 0.0190 ,ce_loss: 0.3184., accu: 0.8503, speed: 1.18 step/s\n",
      "global step 4170, epoch: 1, batch: 4170, loss: 0.2750,domain_loss: 0.0512 ,ce_loss: 0.3309., accu: 0.8500, speed: 1.18 step/s\n",
      "global step 4180, epoch: 1, batch: 4180, loss: 0.2569,domain_loss: 0.1088 ,ce_loss: 0.2939., accu: 0.8496, speed: 1.17 step/s\n",
      "global step 4190, epoch: 1, batch: 4190, loss: 0.2590,domain_loss: 0.0891 ,ce_loss: 0.3015., accu: 0.8487, speed: 1.20 step/s\n",
      "global step 4200, epoch: 1, batch: 4200, loss: 0.3998,domain_loss: 0.1637 ,ce_loss: 0.4588., accu: 0.8490, speed: 1.17 step/s\n",
      "2022-09-29 00:42:52,880\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 4200, epoch: 1, batch: 4200】，loss: 0.3998,domain_loss: 0.1637 ,ce_loss: 0.4588., accu: 0.8490,\n",
      "2022-09-29 00:42:53,184\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.24022, accuracy: 0.89[0.93],threshold:0.553, domain_acc:1.0,total_num:100\n",
      "global step 4210, epoch: 1, batch: 4210, loss: 0.1846,domain_loss: 0.0796 ,ce_loss: 0.2109., accu: 0.8516, speed: 0.97 step/s\n",
      "global step 4220, epoch: 1, batch: 4220, loss: 0.3325,domain_loss: 0.1259 ,ce_loss: 0.3841., accu: 0.8441, speed: 1.17 step/s\n",
      "global step 4230, epoch: 1, batch: 4230, loss: 0.3078,domain_loss: 0.0376 ,ce_loss: 0.3754., accu: 0.8417, speed: 1.20 step/s\n",
      "global step 4240, epoch: 1, batch: 4240, loss: 0.2142,domain_loss: 0.0361 ,ce_loss: 0.2587., accu: 0.8408, speed: 1.17 step/s\n",
      "global step 4250, epoch: 1, batch: 4250, loss: 0.2771,domain_loss: 0.0722 ,ce_loss: 0.3283., accu: 0.8409, speed: 1.18 step/s\n",
      "global step 4260, epoch: 1, batch: 4260, loss: 0.2323,domain_loss: 0.0883 ,ce_loss: 0.2683., accu: 0.8426, speed: 1.20 step/s\n",
      "global step 4270, epoch: 1, batch: 4270, loss: 0.2766,domain_loss: 0.0297 ,ce_loss: 0.3383., accu: 0.8420, speed: 1.19 step/s\n",
      "global step 4280, epoch: 1, batch: 4280, loss: 0.1947,domain_loss: 0.0654 ,ce_loss: 0.2270., accu: 0.8422, speed: 1.17 step/s\n",
      "global step 4290, epoch: 1, batch: 4290, loss: 0.3546,domain_loss: 0.1227 ,ce_loss: 0.4126., accu: 0.8393, speed: 1.17 step/s\n",
      "global step 4300, epoch: 1, batch: 4300, loss: 0.3220,domain_loss: 0.1160 ,ce_loss: 0.3735., accu: 0.8409, speed: 1.19 step/s\n",
      "global step 4310, epoch: 1, batch: 4310, loss: 0.2584,domain_loss: 0.0646 ,ce_loss: 0.3069., accu: 0.8405, speed: 1.18 step/s\n",
      "global step 4320, epoch: 1, batch: 4320, loss: 0.2992,domain_loss: 0.1255 ,ce_loss: 0.3426., accu: 0.8427, speed: 1.19 step/s\n",
      "global step 4330, epoch: 1, batch: 4330, loss: 0.2942,domain_loss: 0.0948 ,ce_loss: 0.3440., accu: 0.8424, speed: 1.17 step/s\n",
      "global step 4340, epoch: 1, batch: 4340, loss: 0.2806,domain_loss: 0.0378 ,ce_loss: 0.3413., accu: 0.8430, speed: 1.19 step/s\n",
      "global step 4350, epoch: 1, batch: 4350, loss: 0.2948,domain_loss: 0.1056 ,ce_loss: 0.3421., accu: 0.8432, speed: 1.17 step/s\n",
      "global step 4360, epoch: 1, batch: 4360, loss: 0.2788,domain_loss: 0.0936 ,ce_loss: 0.3251., accu: 0.8442, speed: 1.17 step/s\n",
      "global step 4370, epoch: 1, batch: 4370, loss: 0.3032,domain_loss: 0.0406 ,ce_loss: 0.3689., accu: 0.8445, speed: 1.18 step/s\n",
      "global step 4380, epoch: 1, batch: 4380, loss: 0.2772,domain_loss: 0.0612 ,ce_loss: 0.3312., accu: 0.8444, speed: 1.18 step/s\n",
      "global step 4390, epoch: 1, batch: 4390, loss: 0.2849,domain_loss: 0.0382 ,ce_loss: 0.3465., accu: 0.8444, speed: 1.18 step/s\n",
      "global step 4400, epoch: 1, batch: 4400, loss: 0.3085,domain_loss: 0.0291 ,ce_loss: 0.3783., accu: 0.8450, speed: 1.20 step/s\n",
      "global step 4410, epoch: 1, batch: 4410, loss: 0.2618,domain_loss: 0.0558 ,ce_loss: 0.3134., accu: 0.8451, speed: 1.19 step/s\n",
      "global step 4420, epoch: 1, batch: 4420, loss: 0.2533,domain_loss: 0.0773 ,ce_loss: 0.2972., accu: 0.8455, speed: 1.19 step/s\n",
      "global step 4430, epoch: 1, batch: 4430, loss: 0.3582,domain_loss: 0.0837 ,ce_loss: 0.4268., accu: 0.8453, speed: 1.19 step/s\n",
      "global step 4440, epoch: 1, batch: 4440, loss: 0.2242,domain_loss: 0.0430 ,ce_loss: 0.2696., accu: 0.8461, speed: 1.19 step/s\n",
      "global step 4450, epoch: 1, batch: 4450, loss: 0.3482,domain_loss: 0.0962 ,ce_loss: 0.4111., accu: 0.8466, speed: 1.18 step/s\n",
      "global step 4460, epoch: 1, batch: 4460, loss: 0.2922,domain_loss: 0.1018 ,ce_loss: 0.3397., accu: 0.8470, speed: 1.18 step/s\n",
      "global step 4470, epoch: 1, batch: 4470, loss: 0.2814,domain_loss: 0.0844 ,ce_loss: 0.3307., accu: 0.8470, speed: 1.20 step/s\n",
      "global step 4480, epoch: 1, batch: 4480, loss: 0.2572,domain_loss: 0.0630 ,ce_loss: 0.3058., accu: 0.8472, speed: 1.19 step/s\n",
      "global step 4490, epoch: 1, batch: 4490, loss: 0.2495,domain_loss: 0.0854 ,ce_loss: 0.2906., accu: 0.8477, speed: 1.20 step/s\n",
      "global step 4500, epoch: 1, batch: 4500, loss: 0.2345,domain_loss: 0.0738 ,ce_loss: 0.2746., accu: 0.8472, speed: 1.18 step/s\n",
      "2022-09-29 00:47:07,990\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 4500, epoch: 1, batch: 4500】，loss: 0.2345,domain_loss: 0.0738 ,ce_loss: 0.2746., accu: 0.8472,\n",
      "2022-09-29 00:47:08,312\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.21277, accuracy: 0.93[0.94],threshold:0.331, domain_acc:1.0,total_num:100\n",
      "global step 4510, epoch: 1, batch: 4510, loss: 0.3418,domain_loss: 0.0952 ,ce_loss: 0.4034., accu: 0.8281, speed: 0.95 step/s\n",
      "global step 4520, epoch: 1, batch: 4520, loss: 0.2302,domain_loss: 0.0315 ,ce_loss: 0.2799., accu: 0.8465, speed: 1.18 step/s\n",
      "global step 4530, epoch: 1, batch: 4530, loss: 0.2244,domain_loss: 0.0151 ,ce_loss: 0.2767., accu: 0.8503, speed: 1.19 step/s\n",
      "global step 4540, epoch: 1, batch: 4540, loss: 0.2010,domain_loss: 0.0514 ,ce_loss: 0.2384., accu: 0.8496, speed: 1.19 step/s\n",
      "global step 4550, epoch: 1, batch: 4550, loss: 0.2722,domain_loss: 0.0513 ,ce_loss: 0.3274., accu: 0.8473, speed: 1.18 step/s\n",
      "global step 4560, epoch: 1, batch: 4560, loss: 0.2274,domain_loss: 0.0890 ,ce_loss: 0.2620., accu: 0.8461, speed: 1.18 step/s\n",
      "global step 4570, epoch: 1, batch: 4570, loss: 0.2668,domain_loss: 0.1194 ,ce_loss: 0.3037., accu: 0.8472, speed: 1.17 step/s\n",
      "global step 4580, epoch: 1, batch: 4580, loss: 0.2473,domain_loss: 0.0316 ,ce_loss: 0.3012., accu: 0.8477, speed: 1.17 step/s\n",
      "global step 4590, epoch: 1, batch: 4590, loss: 0.2597,domain_loss: 0.0532 ,ce_loss: 0.3113., accu: 0.8478, speed: 1.18 step/s\n",
      "global step 4600, epoch: 1, batch: 4600, loss: 0.2857,domain_loss: 0.0216 ,ce_loss: 0.3518., accu: 0.8464, speed: 1.19 step/s\n",
      "global step 4610, epoch: 1, batch: 4610, loss: 0.2610,domain_loss: 0.0810 ,ce_loss: 0.3060., accu: 0.8479, speed: 1.20 step/s\n",
      "global step 4620, epoch: 1, batch: 4620, loss: 0.2330,domain_loss: 0.0467 ,ce_loss: 0.2796., accu: 0.8490, speed: 1.18 step/s\n",
      "global step 4630, epoch: 1, batch: 4630, loss: 0.2909,domain_loss: 0.1223 ,ce_loss: 0.3331., accu: 0.8491, speed: 1.18 step/s\n",
      "global step 4640, epoch: 1, batch: 4640, loss: 0.2366,domain_loss: 0.0708 ,ce_loss: 0.2780., accu: 0.8489, speed: 1.18 step/s\n",
      "global step 4650, epoch: 1, batch: 4650, loss: 0.2512,domain_loss: 0.1254 ,ce_loss: 0.2827., accu: 0.8497, speed: 1.21 step/s\n",
      "global step 4660, epoch: 1, batch: 4660, loss: 0.2572,domain_loss: 0.0327 ,ce_loss: 0.3133., accu: 0.8510, speed: 1.18 step/s\n",
      "global step 4670, epoch: 1, batch: 4670, loss: 0.2555,domain_loss: 0.0584 ,ce_loss: 0.3048., accu: 0.8511, speed: 1.18 step/s\n",
      "global step 4680, epoch: 1, batch: 4680, loss: 0.1952,domain_loss: 0.0153 ,ce_loss: 0.2402., accu: 0.8523, speed: 1.18 step/s\n",
      "global step 4690, epoch: 1, batch: 4690, loss: 0.2898,domain_loss: 0.1470 ,ce_loss: 0.3255., accu: 0.8514, speed: 1.18 step/s\n",
      "global step 4700, epoch: 1, batch: 4700, loss: 0.2486,domain_loss: 0.0821 ,ce_loss: 0.2902., accu: 0.8516, speed: 1.19 step/s\n",
      "global step 4710, epoch: 1, batch: 4710, loss: 0.2573,domain_loss: 0.0669 ,ce_loss: 0.3049., accu: 0.8522, speed: 1.18 step/s\n",
      "global step 4720, epoch: 1, batch: 4720, loss: 0.2272,domain_loss: 0.0713 ,ce_loss: 0.2662., accu: 0.8523, speed: 1.18 step/s\n",
      "global step 4730, epoch: 1, batch: 4730, loss: 0.1979,domain_loss: 0.1701 ,ce_loss: 0.2049., accu: 0.8528, speed: 1.18 step/s\n",
      "global step 4740, epoch: 1, batch: 4740, loss: 0.2639,domain_loss: 0.0372 ,ce_loss: 0.3206., accu: 0.8530, speed: 1.18 step/s\n",
      "global step 4750, epoch: 1, batch: 4750, loss: 0.2460,domain_loss: 0.0447 ,ce_loss: 0.2963., accu: 0.8533, speed: 1.18 step/s\n",
      "global step 4760, epoch: 1, batch: 4760, loss: 0.2572,domain_loss: 0.0553 ,ce_loss: 0.3076., accu: 0.8530, speed: 1.19 step/s\n",
      "global step 4770, epoch: 1, batch: 4770, loss: 0.2873,domain_loss: 0.0862 ,ce_loss: 0.3375., accu: 0.8532, speed: 1.20 step/s\n",
      "global step 4780, epoch: 1, batch: 4780, loss: 0.2333,domain_loss: 0.0739 ,ce_loss: 0.2731., accu: 0.8527, speed: 1.17 step/s\n",
      "global step 4790, epoch: 1, batch: 4790, loss: 0.2002,domain_loss: 0.0566 ,ce_loss: 0.2361., accu: 0.8529, speed: 1.20 step/s\n",
      "global step 4800, epoch: 1, batch: 4800, loss: 0.2294,domain_loss: 0.0210 ,ce_loss: 0.2815., accu: 0.8527, speed: 1.18 step/s\n",
      "2022-09-29 00:51:23,402\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 4800, epoch: 1, batch: 4800】，loss: 0.2294,domain_loss: 0.0210 ,ce_loss: 0.2815., accu: 0.8527,\n",
      "2022-09-29 00:51:23,712\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.24744, accuracy: 0.89[0.95],threshold:0.47, domain_acc:0.99,total_num:100\n",
      "2022-09-29 00:51:24,635\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 4810, epoch: 1, batch: 4810, loss: 0.2702,domain_loss: 0.0499 ,ce_loss: 0.3252., accu: 0.8680, speed: 1.04 step/s\n",
      "global step 4820, epoch: 1, batch: 4820, loss: 0.2593,domain_loss: 0.0759 ,ce_loss: 0.3051., accu: 0.8609, speed: 1.17 step/s\n",
      "global step 4830, epoch: 1, batch: 4830, loss: 0.2958,domain_loss: 0.0883 ,ce_loss: 0.3477., accu: 0.8557, speed: 1.19 step/s\n",
      "global step 4840, epoch: 1, batch: 4840, loss: 0.3014,domain_loss: 0.1335 ,ce_loss: 0.3434., accu: 0.8557, speed: 1.19 step/s\n",
      "global step 4850, epoch: 1, batch: 4850, loss: 0.2895,domain_loss: 0.0135 ,ce_loss: 0.3585., accu: 0.8503, speed: 1.18 step/s\n",
      "global step 4860, epoch: 1, batch: 4860, loss: 0.2572,domain_loss: 0.0834 ,ce_loss: 0.3007., accu: 0.8504, speed: 1.17 step/s\n",
      "global step 4870, epoch: 1, batch: 4870, loss: 0.2251,domain_loss: 0.0513 ,ce_loss: 0.2686., accu: 0.8522, speed: 1.17 step/s\n",
      "global step 4880, epoch: 1, batch: 4880, loss: 0.2645,domain_loss: 0.0318 ,ce_loss: 0.3226., accu: 0.8534, speed: 1.19 step/s\n",
      "global step 4890, epoch: 1, batch: 4890, loss: 0.2178,domain_loss: 0.0758 ,ce_loss: 0.2533., accu: 0.8530, speed: 1.17 step/s\n",
      "global step 4900, epoch: 1, batch: 4900, loss: 0.2381,domain_loss: 0.1201 ,ce_loss: 0.2676., accu: 0.8521, speed: 1.17 step/s\n",
      "global step 4910, epoch: 1, batch: 4910, loss: 0.3011,domain_loss: 0.0256 ,ce_loss: 0.3699., accu: 0.8516, speed: 1.17 step/s\n",
      "global step 4920, epoch: 1, batch: 4920, loss: 0.2867,domain_loss: 0.0768 ,ce_loss: 0.3392., accu: 0.8523, speed: 1.20 step/s\n",
      "global step 4930, epoch: 1, batch: 4930, loss: 0.1623,domain_loss: 0.0054 ,ce_loss: 0.2016., accu: 0.8530, speed: 1.27 step/s\n",
      " 20%|███████▊                               | 1/5 [1:09:40<4:38:42, 4180.69s/it]global step 4940, epoch: 2, batch: 10, loss: 0.2487,domain_loss: 0.0472 ,ce_loss: 0.2991., accu: 0.8538, speed: 1.14 step/s\n",
      "global step 4950, epoch: 2, batch: 20, loss: 0.2186,domain_loss: 0.0354 ,ce_loss: 0.2644., accu: 0.8549, speed: 1.19 step/s\n",
      "global step 4960, epoch: 2, batch: 30, loss: 0.2707,domain_loss: 0.0890 ,ce_loss: 0.3162., accu: 0.8549, speed: 1.18 step/s\n",
      "global step 4970, epoch: 2, batch: 40, loss: 0.2680,domain_loss: 0.0669 ,ce_loss: 0.3183., accu: 0.8554, speed: 1.17 step/s\n",
      "global step 4980, epoch: 2, batch: 50, loss: 0.2540,domain_loss: 0.0489 ,ce_loss: 0.3053., accu: 0.8560, speed: 1.18 step/s\n",
      "global step 4990, epoch: 2, batch: 60, loss: 0.2480,domain_loss: 0.0367 ,ce_loss: 0.3008., accu: 0.8567, speed: 1.19 step/s\n",
      "global step 5000, epoch: 2, batch: 70, loss: 0.2889,domain_loss: 0.0770 ,ce_loss: 0.3419., accu: 0.8569, speed: 1.17 step/s\n",
      "global step 5010, epoch: 2, batch: 80, loss: 0.2933,domain_loss: 0.0344 ,ce_loss: 0.3581., accu: 0.8569, speed: 1.18 step/s\n",
      "global step 5020, epoch: 2, batch: 90, loss: 0.2254,domain_loss: 0.0509 ,ce_loss: 0.2690., accu: 0.8571, speed: 1.17 step/s\n",
      "global step 5030, epoch: 2, batch: 100, loss: 0.3016,domain_loss: 0.0329 ,ce_loss: 0.3688., accu: 0.8577, speed: 1.18 step/s\n",
      "global step 5040, epoch: 2, batch: 110, loss: 0.2564,domain_loss: 0.0799 ,ce_loss: 0.3006., accu: 0.8570, speed: 1.19 step/s\n",
      "global step 5050, epoch: 2, batch: 120, loss: 0.2395,domain_loss: 0.0373 ,ce_loss: 0.2900., accu: 0.8573, speed: 1.20 step/s\n",
      "global step 5060, epoch: 2, batch: 130, loss: 0.2553,domain_loss: 0.0571 ,ce_loss: 0.3048., accu: 0.8581, speed: 1.18 step/s\n",
      "global step 5070, epoch: 2, batch: 140, loss: 0.2775,domain_loss: 0.0396 ,ce_loss: 0.3370., accu: 0.8578, speed: 1.20 step/s\n",
      "global step 5080, epoch: 2, batch: 150, loss: 0.1789,domain_loss: 0.0407 ,ce_loss: 0.2135., accu: 0.8575, speed: 1.18 step/s\n",
      "global step 5090, epoch: 2, batch: 160, loss: 0.2511,domain_loss: 0.0627 ,ce_loss: 0.2983., accu: 0.8579, speed: 1.19 step/s\n",
      "global step 5100, epoch: 2, batch: 170, loss: 0.2646,domain_loss: 0.0880 ,ce_loss: 0.3088., accu: 0.8587, speed: 1.17 step/s\n",
      "2022-09-29 00:55:38,026\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 5100, epoch: 2, batch: 170】，loss: 0.2646,domain_loss: 0.0880 ,ce_loss: 0.3088., accu: 0.8587,\n",
      "2022-09-29 00:55:38,330\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.23032, accuracy: 0.92[0.95],threshold:0.491, domain_acc:1.0,total_num:100\n",
      "global step 5110, epoch: 2, batch: 180, loss: 0.2482,domain_loss: 0.1081 ,ce_loss: 0.2832., accu: 0.8688, speed: 1.05 step/s\n",
      "global step 5120, epoch: 2, batch: 190, loss: 0.3138,domain_loss: 0.0379 ,ce_loss: 0.3828., accu: 0.8641, speed: 1.20 step/s\n",
      "global step 5130, epoch: 2, batch: 200, loss: 0.2325,domain_loss: 0.0854 ,ce_loss: 0.2693., accu: 0.8669, speed: 1.21 step/s\n",
      "global step 5140, epoch: 2, batch: 210, loss: 0.3270,domain_loss: 0.0769 ,ce_loss: 0.3895., accu: 0.8650, speed: 1.19 step/s\n",
      "global step 5150, epoch: 2, batch: 220, loss: 0.2575,domain_loss: 0.0816 ,ce_loss: 0.3014., accu: 0.8650, speed: 1.19 step/s\n",
      "global step 5160, epoch: 2, batch: 230, loss: 0.2653,domain_loss: 0.0846 ,ce_loss: 0.3104., accu: 0.8656, speed: 1.17 step/s\n",
      "global step 5170, epoch: 2, batch: 240, loss: 0.2924,domain_loss: 0.0130 ,ce_loss: 0.3622., accu: 0.8624, speed: 1.18 step/s\n",
      "global step 5180, epoch: 2, batch: 250, loss: 0.2426,domain_loss: 0.0440 ,ce_loss: 0.2922., accu: 0.8636, speed: 1.19 step/s\n",
      "global step 5190, epoch: 2, batch: 260, loss: 0.1883,domain_loss: 0.0384 ,ce_loss: 0.2258., accu: 0.8646, speed: 1.18 step/s\n",
      "global step 5200, epoch: 2, batch: 270, loss: 0.2411,domain_loss: 0.0408 ,ce_loss: 0.2912., accu: 0.8658, speed: 1.18 step/s\n",
      "global step 5210, epoch: 2, batch: 280, loss: 0.2613,domain_loss: 0.1583 ,ce_loss: 0.2871., accu: 0.8652, speed: 1.17 step/s\n",
      "global step 5220, epoch: 2, batch: 290, loss: 0.2702,domain_loss: 0.0788 ,ce_loss: 0.3181., accu: 0.8666, speed: 1.17 step/s\n",
      "global step 5230, epoch: 2, batch: 300, loss: 0.2050,domain_loss: 0.0478 ,ce_loss: 0.2443., accu: 0.8666, speed: 1.18 step/s\n",
      "global step 5240, epoch: 2, batch: 310, loss: 0.3253,domain_loss: 0.0160 ,ce_loss: 0.4027., accu: 0.8680, speed: 1.18 step/s\n",
      "global step 5250, epoch: 2, batch: 320, loss: 0.2910,domain_loss: 0.1355 ,ce_loss: 0.3299., accu: 0.8673, speed: 1.18 step/s\n",
      "global step 5260, epoch: 2, batch: 330, loss: 0.2153,domain_loss: 0.0647 ,ce_loss: 0.2529., accu: 0.8669, speed: 1.18 step/s\n",
      "global step 5270, epoch: 2, batch: 340, loss: 0.2826,domain_loss: 0.0134 ,ce_loss: 0.3499., accu: 0.8682, speed: 1.19 step/s\n",
      "global step 5280, epoch: 2, batch: 350, loss: 0.2682,domain_loss: 0.0506 ,ce_loss: 0.3226., accu: 0.8674, speed: 1.17 step/s\n",
      "global step 5290, epoch: 2, batch: 360, loss: 0.2192,domain_loss: 0.0544 ,ce_loss: 0.2604., accu: 0.8669, speed: 1.17 step/s\n",
      "global step 5300, epoch: 2, batch: 370, loss: 0.2715,domain_loss: 0.0626 ,ce_loss: 0.3237., accu: 0.8670, speed: 1.17 step/s\n",
      "global step 5310, epoch: 2, batch: 380, loss: 0.2676,domain_loss: 0.0856 ,ce_loss: 0.3131., accu: 0.8670, speed: 1.17 step/s\n",
      "global step 5320, epoch: 2, batch: 390, loss: 0.3644,domain_loss: 0.1031 ,ce_loss: 0.4297., accu: 0.8670, speed: 1.17 step/s\n",
      "global step 5330, epoch: 2, batch: 400, loss: 0.2995,domain_loss: 0.0862 ,ce_loss: 0.3529., accu: 0.8664, speed: 1.17 step/s\n",
      "global step 5340, epoch: 2, batch: 410, loss: 0.2391,domain_loss: 0.0797 ,ce_loss: 0.2790., accu: 0.8662, speed: 1.18 step/s\n",
      "global step 5350, epoch: 2, batch: 420, loss: 0.2758,domain_loss: 0.0894 ,ce_loss: 0.3223., accu: 0.8660, speed: 1.19 step/s\n",
      "global step 5360, epoch: 2, batch: 430, loss: 0.2970,domain_loss: 0.0259 ,ce_loss: 0.3648., accu: 0.8660, speed: 1.19 step/s\n",
      "global step 5370, epoch: 2, batch: 440, loss: 0.2843,domain_loss: 0.0200 ,ce_loss: 0.3504., accu: 0.8652, speed: 1.18 step/s\n",
      "global step 5380, epoch: 2, batch: 450, loss: 0.2813,domain_loss: 0.0368 ,ce_loss: 0.3424., accu: 0.8648, speed: 1.18 step/s\n",
      "global step 5390, epoch: 2, batch: 460, loss: 0.2751,domain_loss: 0.0697 ,ce_loss: 0.3265., accu: 0.8648, speed: 1.17 step/s\n",
      "global step 5400, epoch: 2, batch: 470, loss: 0.2282,domain_loss: 0.0737 ,ce_loss: 0.2668., accu: 0.8645, speed: 1.18 step/s\n",
      "2022-09-29 00:59:53,020\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 5400, epoch: 2, batch: 470】，loss: 0.2282,domain_loss: 0.0737 ,ce_loss: 0.2668., accu: 0.8645,\n",
      "2022-09-29 00:59:53,330\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.26701, accuracy: 0.89[0.91],threshold:0.466, domain_acc:1.0,total_num:100\n",
      "2022-09-29 00:59:54,196\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 5410, epoch: 2, batch: 480, loss: 0.2440,domain_loss: 0.0740 ,ce_loss: 0.2865., accu: 0.8641, speed: 1.04 step/s\n",
      "global step 5420, epoch: 2, batch: 490, loss: 0.2184,domain_loss: 0.0361 ,ce_loss: 0.2639., accu: 0.8578, speed: 1.20 step/s\n",
      "global step 5430, epoch: 2, batch: 500, loss: 0.2829,domain_loss: 0.0192 ,ce_loss: 0.3488., accu: 0.8568, speed: 1.17 step/s\n",
      "global step 5440, epoch: 2, batch: 510, loss: 0.3014,domain_loss: 0.1110 ,ce_loss: 0.3490., accu: 0.8605, speed: 1.23 step/s\n",
      "global step 5450, epoch: 2, batch: 520, loss: 0.3043,domain_loss: 0.0543 ,ce_loss: 0.3668., accu: 0.8612, speed: 1.18 step/s\n",
      "global step 5460, epoch: 2, batch: 530, loss: 0.2522,domain_loss: 0.0359 ,ce_loss: 0.3063., accu: 0.8624, speed: 1.19 step/s\n",
      "global step 5470, epoch: 2, batch: 540, loss: 0.2574,domain_loss: 0.0464 ,ce_loss: 0.3102., accu: 0.8606, speed: 1.18 step/s\n",
      "global step 5480, epoch: 2, batch: 550, loss: 0.2259,domain_loss: 0.0683 ,ce_loss: 0.2653., accu: 0.8620, speed: 1.17 step/s\n",
      "global step 5490, epoch: 2, batch: 560, loss: 0.2515,domain_loss: 0.0569 ,ce_loss: 0.3002., accu: 0.8610, speed: 1.18 step/s\n",
      "global step 5500, epoch: 2, batch: 570, loss: 0.3676,domain_loss: 0.1177 ,ce_loss: 0.4301., accu: 0.8599, speed: 1.19 step/s\n",
      "global step 5510, epoch: 2, batch: 580, loss: 0.2566,domain_loss: 0.0319 ,ce_loss: 0.3128., accu: 0.8589, speed: 1.17 step/s\n",
      "global step 5520, epoch: 2, batch: 590, loss: 0.2550,domain_loss: 0.0408 ,ce_loss: 0.3085., accu: 0.8599, speed: 1.18 step/s\n",
      "global step 5530, epoch: 2, batch: 600, loss: 0.2826,domain_loss: 0.0711 ,ce_loss: 0.3355., accu: 0.8597, speed: 1.17 step/s\n",
      "global step 5540, epoch: 2, batch: 610, loss: 0.1990,domain_loss: 0.0451 ,ce_loss: 0.2375., accu: 0.8602, speed: 1.17 step/s\n",
      "global step 5550, epoch: 2, batch: 620, loss: 0.2591,domain_loss: 0.0621 ,ce_loss: 0.3084., accu: 0.8599, speed: 1.19 step/s\n",
      "global step 5560, epoch: 2, batch: 630, loss: 0.2114,domain_loss: 0.0368 ,ce_loss: 0.2550., accu: 0.8602, speed: 1.17 step/s\n",
      "global step 5570, epoch: 2, batch: 640, loss: 0.2471,domain_loss: 0.0583 ,ce_loss: 0.2943., accu: 0.8597, speed: 1.21 step/s\n",
      "global step 5580, epoch: 2, batch: 650, loss: 0.3108,domain_loss: 0.1557 ,ce_loss: 0.3495., accu: 0.8588, speed: 1.18 step/s\n",
      "global step 5590, epoch: 2, batch: 660, loss: 0.2186,domain_loss: 0.0171 ,ce_loss: 0.2690., accu: 0.8604, speed: 1.18 step/s\n",
      "global step 5600, epoch: 2, batch: 670, loss: 0.2370,domain_loss: 0.0518 ,ce_loss: 0.2832., accu: 0.8611, speed: 1.18 step/s\n",
      "global step 5610, epoch: 2, batch: 680, loss: 0.2123,domain_loss: 0.0877 ,ce_loss: 0.2435., accu: 0.8607, speed: 1.19 step/s\n",
      "global step 5620, epoch: 2, batch: 690, loss: 0.2748,domain_loss: 0.0155 ,ce_loss: 0.3397., accu: 0.8611, speed: 1.20 step/s\n",
      "global step 5630, epoch: 2, batch: 700, loss: 0.2633,domain_loss: 0.0435 ,ce_loss: 0.3183., accu: 0.8615, speed: 1.20 step/s\n",
      "global step 5640, epoch: 2, batch: 710, loss: 0.2872,domain_loss: 0.0322 ,ce_loss: 0.3510., accu: 0.8623, speed: 1.21 step/s\n",
      "global step 5650, epoch: 2, batch: 720, loss: 0.2526,domain_loss: 0.0583 ,ce_loss: 0.3011., accu: 0.8622, speed: 1.19 step/s\n",
      "global step 5660, epoch: 2, batch: 730, loss: 0.2328,domain_loss: 0.0843 ,ce_loss: 0.2699., accu: 0.8626, speed: 1.17 step/s\n",
      "global step 5670, epoch: 2, batch: 740, loss: 0.1934,domain_loss: 0.0363 ,ce_loss: 0.2327., accu: 0.8632, speed: 1.20 step/s\n",
      "global step 5680, epoch: 2, batch: 750, loss: 0.2418,domain_loss: 0.0317 ,ce_loss: 0.2944., accu: 0.8638, speed: 1.20 step/s\n",
      "global step 5690, epoch: 2, batch: 760, loss: 0.2626,domain_loss: 0.0204 ,ce_loss: 0.3231., accu: 0.8638, speed: 1.18 step/s\n",
      "global step 5700, epoch: 2, batch: 770, loss: 0.3169,domain_loss: 0.0625 ,ce_loss: 0.3805., accu: 0.8646, speed: 1.18 step/s\n",
      "2022-09-29 01:04:06,973\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 5700, epoch: 2, batch: 770】，loss: 0.3169,domain_loss: 0.0625 ,ce_loss: 0.3805., accu: 0.8646,\n",
      "2022-09-29 01:04:07,281\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.23236, accuracy: 0.92[0.93],threshold:0.335, domain_acc:1.0,total_num:100\n",
      "global step 5710, epoch: 2, batch: 780, loss: 0.1461,domain_loss: 0.0585 ,ce_loss: 0.1680., accu: 0.8773, speed: 1.06 step/s\n",
      "global step 5720, epoch: 2, batch: 790, loss: 0.2257,domain_loss: 0.0968 ,ce_loss: 0.2580., accu: 0.8707, speed: 1.19 step/s\n",
      "global step 5730, epoch: 2, batch: 800, loss: 0.2824,domain_loss: 0.0902 ,ce_loss: 0.3304., accu: 0.8674, speed: 1.18 step/s\n",
      "global step 5740, epoch: 2, batch: 810, loss: 0.2413,domain_loss: 0.0263 ,ce_loss: 0.2950., accu: 0.8705, speed: 1.18 step/s\n",
      "global step 5750, epoch: 2, batch: 820, loss: 0.2738,domain_loss: 0.0750 ,ce_loss: 0.3235., accu: 0.8689, speed: 1.18 step/s\n",
      "global step 5760, epoch: 2, batch: 830, loss: 0.2559,domain_loss: 0.0641 ,ce_loss: 0.3038., accu: 0.8677, speed: 1.18 step/s\n",
      "global step 5770, epoch: 2, batch: 840, loss: 0.1761,domain_loss: 0.0543 ,ce_loss: 0.2066., accu: 0.8683, speed: 1.19 step/s\n",
      "global step 5780, epoch: 2, batch: 850, loss: 0.2225,domain_loss: 0.0272 ,ce_loss: 0.2713., accu: 0.8665, speed: 1.19 step/s\n",
      "global step 5790, epoch: 2, batch: 860, loss: 0.2594,domain_loss: 0.1699 ,ce_loss: 0.2818., accu: 0.8681, speed: 1.21 step/s\n",
      "global step 5800, epoch: 2, batch: 870, loss: 0.2130,domain_loss: 0.0523 ,ce_loss: 0.2531., accu: 0.8681, speed: 1.20 step/s\n",
      "global step 5810, epoch: 2, batch: 880, loss: 0.2449,domain_loss: 0.0338 ,ce_loss: 0.2977., accu: 0.8670, speed: 1.17 step/s\n",
      "global step 5820, epoch: 2, batch: 890, loss: 0.3097,domain_loss: 0.0648 ,ce_loss: 0.3710., accu: 0.8667, speed: 1.17 step/s\n",
      "global step 5830, epoch: 2, batch: 900, loss: 0.2072,domain_loss: 0.0050 ,ce_loss: 0.2577., accu: 0.8668, speed: 1.17 step/s\n",
      "global step 5840, epoch: 2, batch: 910, loss: 0.2983,domain_loss: 0.1355 ,ce_loss: 0.3390., accu: 0.8671, speed: 1.18 step/s\n",
      "global step 5850, epoch: 2, batch: 920, loss: 0.3338,domain_loss: 0.1538 ,ce_loss: 0.3787., accu: 0.8672, speed: 1.19 step/s\n",
      "global step 5860, epoch: 2, batch: 930, loss: 0.2128,domain_loss: 0.0684 ,ce_loss: 0.2489., accu: 0.8678, speed: 1.17 step/s\n",
      "global step 5870, epoch: 2, batch: 940, loss: 0.2677,domain_loss: 0.0207 ,ce_loss: 0.3295., accu: 0.8675, speed: 1.17 step/s\n",
      "global step 5880, epoch: 2, batch: 950, loss: 0.1698,domain_loss: 0.0482 ,ce_loss: 0.2002., accu: 0.8684, speed: 1.17 step/s\n",
      "global step 5890, epoch: 2, batch: 960, loss: 0.2309,domain_loss: 0.0075 ,ce_loss: 0.2867., accu: 0.8679, speed: 1.19 step/s\n",
      "global step 5900, epoch: 2, batch: 970, loss: 0.2291,domain_loss: 0.0378 ,ce_loss: 0.2770., accu: 0.8676, speed: 1.18 step/s\n",
      "global step 5910, epoch: 2, batch: 980, loss: 0.2931,domain_loss: 0.0497 ,ce_loss: 0.3540., accu: 0.8665, speed: 1.18 step/s\n",
      "global step 5920, epoch: 2, batch: 990, loss: 0.1892,domain_loss: 0.0544 ,ce_loss: 0.2229., accu: 0.8665, speed: 1.17 step/s\n",
      "global step 5930, epoch: 2, batch: 1000, loss: 0.2039,domain_loss: 0.0510 ,ce_loss: 0.2422., accu: 0.8676, speed: 1.18 step/s\n",
      "global step 5940, epoch: 2, batch: 1010, loss: 0.2285,domain_loss: 0.0884 ,ce_loss: 0.2635., accu: 0.8676, speed: 1.18 step/s\n",
      "global step 5950, epoch: 2, batch: 1020, loss: 0.2696,domain_loss: 0.0968 ,ce_loss: 0.3128., accu: 0.8677, speed: 1.18 step/s\n",
      "global step 5960, epoch: 2, batch: 1030, loss: 0.2736,domain_loss: 0.1134 ,ce_loss: 0.3137., accu: 0.8676, speed: 1.17 step/s\n",
      "global step 5970, epoch: 2, batch: 1040, loss: 0.2083,domain_loss: 0.0262 ,ce_loss: 0.2539., accu: 0.8668, speed: 1.18 step/s\n",
      "global step 5980, epoch: 2, batch: 1050, loss: 0.2323,domain_loss: 0.0311 ,ce_loss: 0.2826., accu: 0.8674, speed: 1.17 step/s\n",
      "global step 5990, epoch: 2, batch: 1060, loss: 0.2430,domain_loss: 0.0550 ,ce_loss: 0.2900., accu: 0.8674, speed: 1.17 step/s\n",
      "global step 6000, epoch: 2, batch: 1070, loss: 0.2938,domain_loss: 0.0850 ,ce_loss: 0.3460., accu: 0.8673, speed: 1.19 step/s\n",
      "2022-09-29 01:08:21,925\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 6000, epoch: 2, batch: 1070】，loss: 0.2938,domain_loss: 0.0850 ,ce_loss: 0.3460., accu: 0.8673,\n",
      "2022-09-29 01:08:22,232\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.20591, accuracy: 0.94[0.95],threshold:0.422, domain_acc:1.0,total_num:100\n",
      "global step 6010, epoch: 2, batch: 1080, loss: 0.1795,domain_loss: 0.0476 ,ce_loss: 0.2125., accu: 0.8781, speed: 0.95 step/s\n",
      "global step 6020, epoch: 2, batch: 1090, loss: 0.1984,domain_loss: 0.0526 ,ce_loss: 0.2348., accu: 0.8750, speed: 1.18 step/s\n",
      "global step 6030, epoch: 2, batch: 1100, loss: 0.1546,domain_loss: 0.0298 ,ce_loss: 0.1857., accu: 0.8779, speed: 1.17 step/s\n",
      "global step 6040, epoch: 2, batch: 1110, loss: 0.1763,domain_loss: 0.0504 ,ce_loss: 0.2077., accu: 0.8758, speed: 1.18 step/s\n",
      "global step 6050, epoch: 2, batch: 1120, loss: 0.2617,domain_loss: 0.0770 ,ce_loss: 0.3078., accu: 0.8752, speed: 1.18 step/s\n",
      "global step 6060, epoch: 2, batch: 1130, loss: 0.2569,domain_loss: 0.0504 ,ce_loss: 0.3085., accu: 0.8750, speed: 1.19 step/s\n",
      "global step 6070, epoch: 2, batch: 1140, loss: 0.2364,domain_loss: 0.0835 ,ce_loss: 0.2746., accu: 0.8763, speed: 1.18 step/s\n",
      "global step 6080, epoch: 2, batch: 1150, loss: 0.3362,domain_loss: 0.0299 ,ce_loss: 0.4127., accu: 0.8742, speed: 1.20 step/s\n",
      "global step 6090, epoch: 2, batch: 1160, loss: 0.2280,domain_loss: 0.0421 ,ce_loss: 0.2745., accu: 0.8728, speed: 1.17 step/s\n",
      "global step 6100, epoch: 2, batch: 1170, loss: 0.3258,domain_loss: 0.0710 ,ce_loss: 0.3895., accu: 0.8731, speed: 1.19 step/s\n",
      "global step 6110, epoch: 2, batch: 1180, loss: 0.2656,domain_loss: 0.0732 ,ce_loss: 0.3137., accu: 0.8722, speed: 1.17 step/s\n",
      "global step 6120, epoch: 2, batch: 1190, loss: 0.2599,domain_loss: 0.1040 ,ce_loss: 0.2989., accu: 0.8703, speed: 1.21 step/s\n",
      "global step 6130, epoch: 2, batch: 1200, loss: 0.2712,domain_loss: 0.0248 ,ce_loss: 0.3328., accu: 0.8699, speed: 1.18 step/s\n",
      "global step 6140, epoch: 2, batch: 1210, loss: 0.2523,domain_loss: 0.0659 ,ce_loss: 0.2989., accu: 0.8696, speed: 1.18 step/s\n",
      "global step 6150, epoch: 2, batch: 1220, loss: 0.3346,domain_loss: 0.0606 ,ce_loss: 0.4031., accu: 0.8690, speed: 1.19 step/s\n",
      "global step 6160, epoch: 2, batch: 1230, loss: 0.1938,domain_loss: 0.0829 ,ce_loss: 0.2215., accu: 0.8685, speed: 1.17 step/s\n",
      "global step 6170, epoch: 2, batch: 1240, loss: 0.2373,domain_loss: 0.0710 ,ce_loss: 0.2789., accu: 0.8692, speed: 1.19 step/s\n",
      "global step 6180, epoch: 2, batch: 1250, loss: 0.2580,domain_loss: 0.0213 ,ce_loss: 0.3172., accu: 0.8689, speed: 1.19 step/s\n",
      "global step 6190, epoch: 2, batch: 1260, loss: 0.2420,domain_loss: 0.0621 ,ce_loss: 0.2870., accu: 0.8690, speed: 1.17 step/s\n",
      "global step 6200, epoch: 2, batch: 1270, loss: 0.2840,domain_loss: 0.0348 ,ce_loss: 0.3463., accu: 0.8681, speed: 1.18 step/s\n",
      "global step 6210, epoch: 2, batch: 1280, loss: 0.2406,domain_loss: 0.0455 ,ce_loss: 0.2893., accu: 0.8688, speed: 1.19 step/s\n",
      "global step 6220, epoch: 2, batch: 1290, loss: 0.2872,domain_loss: 0.0282 ,ce_loss: 0.3519., accu: 0.8685, speed: 1.20 step/s\n",
      "global step 6230, epoch: 2, batch: 1300, loss: 0.2186,domain_loss: 0.0310 ,ce_loss: 0.2655., accu: 0.8690, speed: 1.19 step/s\n",
      "global step 6240, epoch: 2, batch: 1310, loss: 0.1943,domain_loss: 0.0133 ,ce_loss: 0.2396., accu: 0.8696, speed: 1.18 step/s\n",
      "global step 6250, epoch: 2, batch: 1320, loss: 0.2188,domain_loss: 0.0134 ,ce_loss: 0.2701., accu: 0.8695, speed: 1.18 step/s\n",
      "global step 6260, epoch: 2, batch: 1330, loss: 0.2160,domain_loss: 0.0481 ,ce_loss: 0.2580., accu: 0.8696, speed: 1.19 step/s\n",
      "global step 6270, epoch: 2, batch: 1340, loss: 0.2575,domain_loss: 0.0497 ,ce_loss: 0.3095., accu: 0.8699, speed: 1.18 step/s\n",
      "global step 6280, epoch: 2, batch: 1350, loss: 0.2298,domain_loss: 0.0108 ,ce_loss: 0.2845., accu: 0.8702, speed: 1.17 step/s\n",
      "global step 6290, epoch: 2, batch: 1360, loss: 0.2628,domain_loss: 0.1100 ,ce_loss: 0.3009., accu: 0.8699, speed: 1.19 step/s\n",
      "global step 6300, epoch: 2, batch: 1370, loss: 0.2345,domain_loss: 0.1196 ,ce_loss: 0.2632., accu: 0.8701, speed: 1.18 step/s\n",
      "2022-09-29 01:12:37,571\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 6300, epoch: 2, batch: 1370】，loss: 0.2345,domain_loss: 0.1196 ,ce_loss: 0.2632., accu: 0.8701,\n",
      "2022-09-29 01:12:37,878\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.19828, accuracy: 0.91[0.93],threshold:0.536, domain_acc:1.0,total_num:100\n",
      "2022-09-29 01:12:38,761\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 6310, epoch: 2, batch: 1380, loss: 0.2031,domain_loss: 0.0286 ,ce_loss: 0.2467., accu: 0.8719, speed: 1.03 step/s\n",
      "global step 6320, epoch: 2, batch: 1390, loss: 0.2755,domain_loss: 0.0959 ,ce_loss: 0.3204., accu: 0.8688, speed: 1.20 step/s\n",
      "global step 6330, epoch: 2, batch: 1400, loss: 0.3242,domain_loss: 0.0611 ,ce_loss: 0.3900., accu: 0.8664, speed: 1.18 step/s\n",
      "global step 6340, epoch: 2, batch: 1410, loss: 0.2080,domain_loss: 0.0183 ,ce_loss: 0.2555., accu: 0.8684, speed: 1.20 step/s\n",
      "global step 6350, epoch: 2, batch: 1420, loss: 0.1947,domain_loss: 0.0156 ,ce_loss: 0.2394., accu: 0.8672, speed: 1.18 step/s\n",
      "global step 6360, epoch: 2, batch: 1430, loss: 0.2529,domain_loss: 0.0682 ,ce_loss: 0.2991., accu: 0.8669, speed: 1.17 step/s\n",
      "global step 6370, epoch: 2, batch: 1440, loss: 0.2168,domain_loss: 0.0382 ,ce_loss: 0.2614., accu: 0.8667, speed: 1.22 step/s\n",
      "global step 6380, epoch: 2, batch: 1450, loss: 0.2871,domain_loss: 0.1360 ,ce_loss: 0.3249., accu: 0.8688, speed: 1.19 step/s\n",
      "global step 6390, epoch: 2, batch: 1460, loss: 0.2482,domain_loss: 0.0547 ,ce_loss: 0.2965., accu: 0.8681, speed: 1.18 step/s\n",
      "global step 6400, epoch: 2, batch: 1470, loss: 0.2580,domain_loss: 0.0447 ,ce_loss: 0.3114., accu: 0.8670, speed: 1.18 step/s\n",
      "global step 6410, epoch: 2, batch: 1480, loss: 0.2092,domain_loss: 0.0452 ,ce_loss: 0.2502., accu: 0.8667, speed: 1.18 step/s\n",
      "global step 6420, epoch: 2, batch: 1490, loss: 0.2411,domain_loss: 0.0461 ,ce_loss: 0.2899., accu: 0.8663, speed: 1.19 step/s\n",
      "global step 6430, epoch: 2, batch: 1500, loss: 0.2829,domain_loss: 0.0182 ,ce_loss: 0.3491., accu: 0.8664, speed: 1.18 step/s\n",
      "global step 6440, epoch: 2, batch: 1510, loss: 0.2509,domain_loss: 0.0694 ,ce_loss: 0.2963., accu: 0.8666, speed: 1.18 step/s\n",
      "global step 6450, epoch: 2, batch: 1520, loss: 0.2285,domain_loss: 0.0117 ,ce_loss: 0.2827., accu: 0.8679, speed: 1.17 step/s\n",
      "global step 6460, epoch: 2, batch: 1530, loss: 0.2567,domain_loss: 0.0634 ,ce_loss: 0.3051., accu: 0.8686, speed: 1.18 step/s\n",
      "global step 6470, epoch: 2, batch: 1540, loss: 0.2009,domain_loss: 0.0474 ,ce_loss: 0.2393., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 6480, epoch: 2, batch: 1550, loss: 0.2254,domain_loss: 0.0779 ,ce_loss: 0.2623., accu: 0.8685, speed: 1.18 step/s\n",
      "global step 6490, epoch: 2, batch: 1560, loss: 0.2208,domain_loss: 0.0147 ,ce_loss: 0.2723., accu: 0.8683, speed: 1.19 step/s\n",
      "global step 6500, epoch: 2, batch: 1570, loss: 0.2929,domain_loss: 0.0950 ,ce_loss: 0.3423., accu: 0.8677, speed: 1.19 step/s\n",
      "global step 6510, epoch: 2, batch: 1580, loss: 0.3111,domain_loss: 0.0711 ,ce_loss: 0.3711., accu: 0.8674, speed: 1.19 step/s\n",
      "global step 6520, epoch: 2, batch: 1590, loss: 0.2534,domain_loss: 0.0357 ,ce_loss: 0.3079., accu: 0.8666, speed: 1.19 step/s\n",
      "global step 6530, epoch: 2, batch: 1600, loss: 0.2515,domain_loss: 0.0490 ,ce_loss: 0.3021., accu: 0.8671, speed: 1.18 step/s\n",
      "global step 6540, epoch: 2, batch: 1610, loss: 0.2503,domain_loss: 0.1197 ,ce_loss: 0.2829., accu: 0.8674, speed: 1.17 step/s\n",
      "global step 6550, epoch: 2, batch: 1620, loss: 0.3474,domain_loss: 0.0452 ,ce_loss: 0.4230., accu: 0.8670, speed: 1.18 step/s\n",
      "global step 6560, epoch: 2, batch: 1630, loss: 0.2635,domain_loss: 0.0530 ,ce_loss: 0.3162., accu: 0.8671, speed: 1.20 step/s\n",
      "global step 6570, epoch: 2, batch: 1640, loss: 0.2856,domain_loss: 0.0736 ,ce_loss: 0.3386., accu: 0.8671, speed: 1.17 step/s\n",
      "global step 6580, epoch: 2, batch: 1650, loss: 0.2638,domain_loss: 0.0633 ,ce_loss: 0.3139., accu: 0.8669, speed: 1.18 step/s\n",
      "global step 6590, epoch: 2, batch: 1660, loss: 0.2212,domain_loss: 0.0835 ,ce_loss: 0.2556., accu: 0.8670, speed: 1.21 step/s\n",
      "global step 6600, epoch: 2, batch: 1670, loss: 0.2204,domain_loss: 0.0633 ,ce_loss: 0.2596., accu: 0.8665, speed: 1.17 step/s\n",
      "2022-09-29 01:16:52,051\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 6600, epoch: 2, batch: 1670】，loss: 0.2204,domain_loss: 0.0633 ,ce_loss: 0.2596., accu: 0.8665,\n",
      "2022-09-29 01:16:52,360\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.20158, accuracy: 0.94[0.94],threshold:0.424, domain_acc:1.0,total_num:100\n",
      "global step 6610, epoch: 2, batch: 1680, loss: 0.2358,domain_loss: 0.0249 ,ce_loss: 0.2885., accu: 0.8641, speed: 1.05 step/s\n",
      "global step 6620, epoch: 2, batch: 1690, loss: 0.2397,domain_loss: 0.0354 ,ce_loss: 0.2908., accu: 0.8645, speed: 1.19 step/s\n",
      "global step 6630, epoch: 2, batch: 1700, loss: 0.2138,domain_loss: 0.0315 ,ce_loss: 0.2594., accu: 0.8680, speed: 1.18 step/s\n",
      "global step 6640, epoch: 2, batch: 1710, loss: 0.2418,domain_loss: 0.0493 ,ce_loss: 0.2899., accu: 0.8689, speed: 1.18 step/s\n",
      "global step 6650, epoch: 2, batch: 1720, loss: 0.2468,domain_loss: 0.0240 ,ce_loss: 0.3025., accu: 0.8711, speed: 1.18 step/s\n",
      "global step 6660, epoch: 2, batch: 1730, loss: 0.2659,domain_loss: 0.0066 ,ce_loss: 0.3308., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 6670, epoch: 2, batch: 1740, loss: 0.2763,domain_loss: 0.0660 ,ce_loss: 0.3289., accu: 0.8681, speed: 1.17 step/s\n",
      "global step 6680, epoch: 2, batch: 1750, loss: 0.2257,domain_loss: 0.0243 ,ce_loss: 0.2761., accu: 0.8678, speed: 1.18 step/s\n",
      "global step 6690, epoch: 2, batch: 1760, loss: 0.2606,domain_loss: 0.0416 ,ce_loss: 0.3154., accu: 0.8662, speed: 1.18 step/s\n",
      "global step 6700, epoch: 2, batch: 1770, loss: 0.2155,domain_loss: 0.0777 ,ce_loss: 0.2500., accu: 0.8666, speed: 1.21 step/s\n",
      "global step 6710, epoch: 2, batch: 1780, loss: 0.2953,domain_loss: 0.0826 ,ce_loss: 0.3484., accu: 0.8661, speed: 1.18 step/s\n",
      "global step 6720, epoch: 2, batch: 1790, loss: 0.1997,domain_loss: 0.1222 ,ce_loss: 0.2190., accu: 0.8671, speed: 1.17 step/s\n",
      "global step 6730, epoch: 2, batch: 1800, loss: 0.2650,domain_loss: 0.0136 ,ce_loss: 0.3278., accu: 0.8677, speed: 1.20 step/s\n",
      "global step 6740, epoch: 2, batch: 1810, loss: 0.2231,domain_loss: 0.0244 ,ce_loss: 0.2727., accu: 0.8667, speed: 1.17 step/s\n",
      "global step 6750, epoch: 2, batch: 1820, loss: 0.1971,domain_loss: 0.0605 ,ce_loss: 0.2312., accu: 0.8670, speed: 1.17 step/s\n",
      "global step 6760, epoch: 2, batch: 1830, loss: 0.2235,domain_loss: 0.0494 ,ce_loss: 0.2670., accu: 0.8670, speed: 1.20 step/s\n",
      "global step 6770, epoch: 2, batch: 1840, loss: 0.2246,domain_loss: 0.0438 ,ce_loss: 0.2698., accu: 0.8665, speed: 1.19 step/s\n",
      "global step 6780, epoch: 2, batch: 1850, loss: 0.1601,domain_loss: 0.0088 ,ce_loss: 0.1979., accu: 0.8672, speed: 1.17 step/s\n",
      "global step 6790, epoch: 2, batch: 1860, loss: 0.2149,domain_loss: 0.0799 ,ce_loss: 0.2487., accu: 0.8670, speed: 1.19 step/s\n",
      "global step 6800, epoch: 2, batch: 1870, loss: 0.2360,domain_loss: 0.0457 ,ce_loss: 0.2835., accu: 0.8674, speed: 1.17 step/s\n",
      "global step 6810, epoch: 2, batch: 1880, loss: 0.2386,domain_loss: 0.0695 ,ce_loss: 0.2809., accu: 0.8680, speed: 1.18 step/s\n",
      "global step 6820, epoch: 2, batch: 1890, loss: 0.2459,domain_loss: 0.1437 ,ce_loss: 0.2714., accu: 0.8686, speed: 1.17 step/s\n",
      "global step 6830, epoch: 2, batch: 1900, loss: 0.2200,domain_loss: 0.0443 ,ce_loss: 0.2640., accu: 0.8685, speed: 1.19 step/s\n",
      "global step 6840, epoch: 2, batch: 1910, loss: 0.2661,domain_loss: 0.0531 ,ce_loss: 0.3193., accu: 0.8689, speed: 1.18 step/s\n",
      "global step 6850, epoch: 2, batch: 1920, loss: 0.2446,domain_loss: 0.1038 ,ce_loss: 0.2798., accu: 0.8678, speed: 1.19 step/s\n",
      "global step 6860, epoch: 2, batch: 1930, loss: 0.3009,domain_loss: 0.0408 ,ce_loss: 0.3660., accu: 0.8675, speed: 1.18 step/s\n",
      "global step 6870, epoch: 2, batch: 1940, loss: 0.1716,domain_loss: 0.0385 ,ce_loss: 0.2048., accu: 0.8678, speed: 1.18 step/s\n",
      "global step 6880, epoch: 2, batch: 1950, loss: 0.2888,domain_loss: 0.0556 ,ce_loss: 0.3471., accu: 0.8672, speed: 1.19 step/s\n",
      "global step 6890, epoch: 2, batch: 1960, loss: 0.2251,domain_loss: 0.0767 ,ce_loss: 0.2622., accu: 0.8668, speed: 1.21 step/s\n",
      "global step 6900, epoch: 2, batch: 1970, loss: 0.2611,domain_loss: 0.0352 ,ce_loss: 0.3176., accu: 0.8667, speed: 1.18 step/s\n",
      "2022-09-29 01:21:06,586\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 6900, epoch: 2, batch: 1970】，loss: 0.2611,domain_loss: 0.0352 ,ce_loss: 0.3176., accu: 0.8667,\n",
      "2022-09-29 01:21:06,894\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.22113, accuracy: 0.93[0.94],threshold:0.411, domain_acc:0.99,total_num:100\n",
      "2022-09-29 01:21:07,787\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 6910, epoch: 2, batch: 1980, loss: 0.2135,domain_loss: 0.0336 ,ce_loss: 0.2585., accu: 0.8688, speed: 1.03 step/s\n",
      "global step 6920, epoch: 2, batch: 1990, loss: 0.2120,domain_loss: 0.0516 ,ce_loss: 0.2521., accu: 0.8637, speed: 1.19 step/s\n",
      "global step 6930, epoch: 2, batch: 2000, loss: 0.2820,domain_loss: 0.0993 ,ce_loss: 0.3277., accu: 0.8685, speed: 1.19 step/s\n",
      "global step 6940, epoch: 2, batch: 2010, loss: 0.2410,domain_loss: 0.0949 ,ce_loss: 0.2775., accu: 0.8711, speed: 1.17 step/s\n",
      "global step 6950, epoch: 2, batch: 2020, loss: 0.2518,domain_loss: 0.0345 ,ce_loss: 0.3062., accu: 0.8689, speed: 1.19 step/s\n",
      "global step 6960, epoch: 2, batch: 2030, loss: 0.3267,domain_loss: 0.1106 ,ce_loss: 0.3807., accu: 0.8680, speed: 1.17 step/s\n",
      "global step 6970, epoch: 2, batch: 2040, loss: 0.2942,domain_loss: 0.1190 ,ce_loss: 0.3380., accu: 0.8689, speed: 1.18 step/s\n",
      "global step 6980, epoch: 2, batch: 2050, loss: 0.1934,domain_loss: 0.0235 ,ce_loss: 0.2359., accu: 0.8699, speed: 1.17 step/s\n",
      "global step 6990, epoch: 2, batch: 2060, loss: 0.2860,domain_loss: 0.0611 ,ce_loss: 0.3422., accu: 0.8687, speed: 1.19 step/s\n",
      "global step 7000, epoch: 2, batch: 2070, loss: 0.2682,domain_loss: 0.0631 ,ce_loss: 0.3195., accu: 0.8682, speed: 1.20 step/s\n",
      "global step 7010, epoch: 2, batch: 2080, loss: 0.1792,domain_loss: 0.0128 ,ce_loss: 0.2208., accu: 0.8685, speed: 1.18 step/s\n",
      "global step 7020, epoch: 2, batch: 2090, loss: 0.2577,domain_loss: 0.0263 ,ce_loss: 0.3156., accu: 0.8684, speed: 1.17 step/s\n",
      "global step 7030, epoch: 2, batch: 2100, loss: 0.2467,domain_loss: 0.0170 ,ce_loss: 0.3042., accu: 0.8676, speed: 1.17 step/s\n",
      "global step 7040, epoch: 2, batch: 2110, loss: 0.1987,domain_loss: 0.0517 ,ce_loss: 0.2355., accu: 0.8677, speed: 1.19 step/s\n",
      "global step 7050, epoch: 2, batch: 2120, loss: 0.2098,domain_loss: 0.0118 ,ce_loss: 0.2593., accu: 0.8686, speed: 1.18 step/s\n",
      "global step 7060, epoch: 2, batch: 2130, loss: 0.1822,domain_loss: 0.0872 ,ce_loss: 0.2060., accu: 0.8690, speed: 1.17 step/s\n",
      "global step 7070, epoch: 2, batch: 2140, loss: 0.2882,domain_loss: 0.0873 ,ce_loss: 0.3384., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 7080, epoch: 2, batch: 2150, loss: 0.1893,domain_loss: 0.0556 ,ce_loss: 0.2228., accu: 0.8694, speed: 1.19 step/s\n",
      "global step 7090, epoch: 2, batch: 2160, loss: 0.2304,domain_loss: 0.0358 ,ce_loss: 0.2790., accu: 0.8703, speed: 1.18 step/s\n",
      "global step 7100, epoch: 2, batch: 2170, loss: 0.2027,domain_loss: 0.0463 ,ce_loss: 0.2418., accu: 0.8704, speed: 1.19 step/s\n",
      "global step 7110, epoch: 2, batch: 2180, loss: 0.2695,domain_loss: 0.0130 ,ce_loss: 0.3336., accu: 0.8700, speed: 1.18 step/s\n",
      "global step 7120, epoch: 2, batch: 2190, loss: 0.2363,domain_loss: 0.0408 ,ce_loss: 0.2852., accu: 0.8692, speed: 1.18 step/s\n",
      "global step 7130, epoch: 2, batch: 2200, loss: 0.2675,domain_loss: 0.0501 ,ce_loss: 0.3219., accu: 0.8698, speed: 1.17 step/s\n",
      "global step 7140, epoch: 2, batch: 2210, loss: 0.2562,domain_loss: 0.0432 ,ce_loss: 0.3095., accu: 0.8692, speed: 1.17 step/s\n",
      "global step 7150, epoch: 2, batch: 2220, loss: 0.2667,domain_loss: 0.0661 ,ce_loss: 0.3168., accu: 0.8694, speed: 1.19 step/s\n",
      "global step 7160, epoch: 2, batch: 2230, loss: 0.2676,domain_loss: 0.0705 ,ce_loss: 0.3169., accu: 0.8694, speed: 1.18 step/s\n",
      "global step 7170, epoch: 2, batch: 2240, loss: 0.2294,domain_loss: 0.0449 ,ce_loss: 0.2756., accu: 0.8696, speed: 1.19 step/s\n",
      "global step 7180, epoch: 2, batch: 2250, loss: 0.2042,domain_loss: 0.0288 ,ce_loss: 0.2481., accu: 0.8700, speed: 1.17 step/s\n",
      "global step 7190, epoch: 2, batch: 2260, loss: 0.2274,domain_loss: 0.0137 ,ce_loss: 0.2808., accu: 0.8695, speed: 1.18 step/s\n",
      "global step 7200, epoch: 2, batch: 2270, loss: 0.2727,domain_loss: 0.0890 ,ce_loss: 0.3186., accu: 0.8692, speed: 1.19 step/s\n",
      "2022-09-29 01:25:21,805\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 7200, epoch: 2, batch: 2270】，loss: 0.2727,domain_loss: 0.0890 ,ce_loss: 0.3186., accu: 0.8692,\n",
      "2022-09-29 01:25:22,113\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.18851, accuracy: 0.93[0.95],threshold:0.484, domain_acc:1.0,total_num:100\n",
      "global step 7210, epoch: 2, batch: 2280, loss: 0.1908,domain_loss: 0.0568 ,ce_loss: 0.2244., accu: 0.8797, speed: 1.06 step/s\n",
      "global step 7220, epoch: 2, batch: 2290, loss: 0.2091,domain_loss: 0.0144 ,ce_loss: 0.2578., accu: 0.8785, speed: 1.17 step/s\n",
      "global step 7230, epoch: 2, batch: 2300, loss: 0.2347,domain_loss: 0.0515 ,ce_loss: 0.2804., accu: 0.8693, speed: 1.18 step/s\n",
      "global step 7240, epoch: 2, batch: 2310, loss: 0.2786,domain_loss: 0.0235 ,ce_loss: 0.3423., accu: 0.8713, speed: 1.19 step/s\n",
      "global step 7250, epoch: 2, batch: 2320, loss: 0.2321,domain_loss: 0.0221 ,ce_loss: 0.2845., accu: 0.8703, speed: 1.19 step/s\n",
      "global step 7260, epoch: 2, batch: 2330, loss: 0.2567,domain_loss: 0.0130 ,ce_loss: 0.3176., accu: 0.8701, speed: 1.21 step/s\n",
      "global step 7270, epoch: 2, batch: 2340, loss: 0.2529,domain_loss: 0.0360 ,ce_loss: 0.3071., accu: 0.8704, speed: 1.20 step/s\n",
      "global step 7280, epoch: 2, batch: 2350, loss: 0.2959,domain_loss: 0.0229 ,ce_loss: 0.3641., accu: 0.8707, speed: 1.18 step/s\n",
      "global step 7290, epoch: 2, batch: 2360, loss: 0.2652,domain_loss: 0.0513 ,ce_loss: 0.3187., accu: 0.8701, speed: 1.18 step/s\n",
      "global step 7300, epoch: 2, batch: 2370, loss: 0.2252,domain_loss: 0.1173 ,ce_loss: 0.2522., accu: 0.8705, speed: 1.17 step/s\n",
      "global step 7310, epoch: 2, batch: 2380, loss: 0.1856,domain_loss: 0.0198 ,ce_loss: 0.2271., accu: 0.8710, speed: 1.20 step/s\n",
      "global step 7320, epoch: 2, batch: 2390, loss: 0.1894,domain_loss: 0.0647 ,ce_loss: 0.2206., accu: 0.8714, speed: 1.18 step/s\n",
      "global step 7330, epoch: 2, batch: 2400, loss: 0.2011,domain_loss: 0.0462 ,ce_loss: 0.2398., accu: 0.8715, speed: 1.18 step/s\n",
      "global step 7340, epoch: 2, batch: 2410, loss: 0.1648,domain_loss: 0.0460 ,ce_loss: 0.1946., accu: 0.8718, speed: 1.19 step/s\n",
      "global step 7350, epoch: 2, batch: 2420, loss: 0.2258,domain_loss: 0.0093 ,ce_loss: 0.2800., accu: 0.8728, speed: 1.18 step/s\n",
      "global step 7360, epoch: 2, batch: 2430, loss: 0.2314,domain_loss: 0.0388 ,ce_loss: 0.2796., accu: 0.8723, speed: 1.19 step/s\n",
      "global step 7370, epoch: 2, batch: 2440, loss: 0.2724,domain_loss: 0.0255 ,ce_loss: 0.3341., accu: 0.8716, speed: 1.18 step/s\n",
      "global step 7380, epoch: 2, batch: 2450, loss: 0.3137,domain_loss: 0.1284 ,ce_loss: 0.3601., accu: 0.8717, speed: 1.18 step/s\n",
      "global step 7390, epoch: 2, batch: 2460, loss: 0.2585,domain_loss: 0.0634 ,ce_loss: 0.3073., accu: 0.8724, speed: 1.18 step/s\n",
      "global step 7400, epoch: 2, batch: 2470, loss: 0.1910,domain_loss: 0.0407 ,ce_loss: 0.2285., accu: 0.8725, speed: 1.17 step/s\n",
      "global step 7410, epoch: 2, batch: 2480, loss: 0.2047,domain_loss: 0.0976 ,ce_loss: 0.2315., accu: 0.8723, speed: 1.19 step/s\n",
      "global step 7420, epoch: 2, batch: 2490, loss: 0.2060,domain_loss: 0.0681 ,ce_loss: 0.2405., accu: 0.8719, speed: 1.17 step/s\n",
      "global step 7430, epoch: 2, batch: 2500, loss: 0.2367,domain_loss: 0.0368 ,ce_loss: 0.2866., accu: 0.8720, speed: 1.18 step/s\n",
      "global step 7440, epoch: 2, batch: 2510, loss: 0.2526,domain_loss: 0.0383 ,ce_loss: 0.3062., accu: 0.8721, speed: 1.19 step/s\n",
      "global step 7450, epoch: 2, batch: 2520, loss: 0.2159,domain_loss: 0.0788 ,ce_loss: 0.2502., accu: 0.8722, speed: 1.18 step/s\n",
      "global step 7460, epoch: 2, batch: 2530, loss: 0.1975,domain_loss: 0.0225 ,ce_loss: 0.2412., accu: 0.8730, speed: 1.18 step/s\n",
      "global step 7470, epoch: 2, batch: 2540, loss: 0.2161,domain_loss: 0.0337 ,ce_loss: 0.2617., accu: 0.8728, speed: 1.18 step/s\n",
      "global step 7480, epoch: 2, batch: 2550, loss: 0.2988,domain_loss: 0.1132 ,ce_loss: 0.3452., accu: 0.8723, speed: 1.18 step/s\n",
      "global step 7490, epoch: 2, batch: 2560, loss: 0.2487,domain_loss: 0.0252 ,ce_loss: 0.3046., accu: 0.8722, speed: 1.18 step/s\n",
      "global step 7500, epoch: 2, batch: 2570, loss: 0.2823,domain_loss: 0.0493 ,ce_loss: 0.3405., accu: 0.8722, speed: 1.18 step/s\n",
      "2022-09-29 01:29:36,315\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 7500, epoch: 2, batch: 2570】，loss: 0.2823,domain_loss: 0.0493 ,ce_loss: 0.3405., accu: 0.8722,\n",
      "2022-09-29 01:29:36,624\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.23064, accuracy: 0.92[0.94],threshold:0.47, domain_acc:1.0,total_num:100\n",
      "2022-09-29 01:29:37,521\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 7510, epoch: 2, batch: 2580, loss: 0.2899,domain_loss: 0.0365 ,ce_loss: 0.3533., accu: 0.8586, speed: 1.04 step/s\n",
      "global step 7520, epoch: 2, batch: 2590, loss: 0.2577,domain_loss: 0.0809 ,ce_loss: 0.3019., accu: 0.8633, speed: 1.18 step/s\n",
      "global step 7530, epoch: 2, batch: 2600, loss: 0.1771,domain_loss: 0.0288 ,ce_loss: 0.2142., accu: 0.8695, speed: 1.19 step/s\n",
      "global step 7540, epoch: 2, batch: 2610, loss: 0.2286,domain_loss: 0.0350 ,ce_loss: 0.2770., accu: 0.8721, speed: 1.18 step/s\n",
      "global step 7550, epoch: 2, batch: 2620, loss: 0.1643,domain_loss: 0.0232 ,ce_loss: 0.1995., accu: 0.8744, speed: 1.19 step/s\n",
      "global step 7560, epoch: 2, batch: 2630, loss: 0.2229,domain_loss: 0.0520 ,ce_loss: 0.2657., accu: 0.8742, speed: 1.19 step/s\n",
      "global step 7570, epoch: 2, batch: 2640, loss: 0.2149,domain_loss: 0.0189 ,ce_loss: 0.2639., accu: 0.8748, speed: 1.18 step/s\n",
      "global step 7580, epoch: 2, batch: 2650, loss: 0.2044,domain_loss: 0.0366 ,ce_loss: 0.2464., accu: 0.8775, speed: 1.18 step/s\n",
      "global step 7590, epoch: 2, batch: 2660, loss: 0.2369,domain_loss: 0.0226 ,ce_loss: 0.2905., accu: 0.8773, speed: 1.17 step/s\n",
      "global step 7600, epoch: 2, batch: 2670, loss: 0.2806,domain_loss: 0.0168 ,ce_loss: 0.3465., accu: 0.8777, speed: 1.21 step/s\n",
      "global step 7610, epoch: 2, batch: 2680, loss: 0.2273,domain_loss: 0.0603 ,ce_loss: 0.2690., accu: 0.8769, speed: 1.17 step/s\n",
      "global step 7620, epoch: 2, batch: 2690, loss: 0.2628,domain_loss: 0.0204 ,ce_loss: 0.3234., accu: 0.8760, speed: 1.17 step/s\n",
      "global step 7630, epoch: 2, batch: 2700, loss: 0.2076,domain_loss: 0.0115 ,ce_loss: 0.2566., accu: 0.8749, speed: 1.20 step/s\n",
      "global step 7640, epoch: 2, batch: 2710, loss: 0.2547,domain_loss: 0.0779 ,ce_loss: 0.2989., accu: 0.8742, speed: 1.18 step/s\n",
      "global step 7650, epoch: 2, batch: 2720, loss: 0.2546,domain_loss: 0.0205 ,ce_loss: 0.3131., accu: 0.8740, speed: 1.18 step/s\n",
      "global step 7660, epoch: 2, batch: 2730, loss: 0.2608,domain_loss: 0.0221 ,ce_loss: 0.3205., accu: 0.8739, speed: 1.18 step/s\n",
      "global step 7670, epoch: 2, batch: 2740, loss: 0.2251,domain_loss: 0.0573 ,ce_loss: 0.2670., accu: 0.8744, speed: 1.18 step/s\n",
      "global step 7680, epoch: 2, batch: 2750, loss: 0.2626,domain_loss: 0.0676 ,ce_loss: 0.3114., accu: 0.8742, speed: 1.18 step/s\n",
      "global step 7690, epoch: 2, batch: 2760, loss: 0.1790,domain_loss: 0.0390 ,ce_loss: 0.2140., accu: 0.8743, speed: 1.18 step/s\n",
      "global step 7700, epoch: 2, batch: 2770, loss: 0.2260,domain_loss: 0.0646 ,ce_loss: 0.2663., accu: 0.8747, speed: 1.20 step/s\n",
      "global step 7710, epoch: 2, batch: 2780, loss: 0.2468,domain_loss: 0.0216 ,ce_loss: 0.3031., accu: 0.8744, speed: 1.17 step/s\n",
      "global step 7720, epoch: 2, batch: 2790, loss: 0.3058,domain_loss: 0.0804 ,ce_loss: 0.3622., accu: 0.8749, speed: 1.22 step/s\n",
      "global step 7730, epoch: 2, batch: 2800, loss: 0.2685,domain_loss: 0.1003 ,ce_loss: 0.3105., accu: 0.8754, speed: 1.18 step/s\n",
      "global step 7740, epoch: 2, batch: 2810, loss: 0.1972,domain_loss: 0.0212 ,ce_loss: 0.2412., accu: 0.8754, speed: 1.18 step/s\n",
      "global step 7750, epoch: 2, batch: 2820, loss: 0.1970,domain_loss: 0.0462 ,ce_loss: 0.2347., accu: 0.8754, speed: 1.18 step/s\n",
      "global step 7760, epoch: 2, batch: 2830, loss: 0.2760,domain_loss: 0.0125 ,ce_loss: 0.3418., accu: 0.8751, speed: 1.19 step/s\n",
      "global step 7770, epoch: 2, batch: 2840, loss: 0.1887,domain_loss: 0.0434 ,ce_loss: 0.2250., accu: 0.8748, speed: 1.18 step/s\n",
      "global step 7780, epoch: 2, batch: 2850, loss: 0.2740,domain_loss: 0.1146 ,ce_loss: 0.3139., accu: 0.8749, speed: 1.19 step/s\n",
      "global step 7790, epoch: 2, batch: 2860, loss: 0.2674,domain_loss: 0.0585 ,ce_loss: 0.3196., accu: 0.8744, speed: 1.19 step/s\n",
      "global step 7800, epoch: 2, batch: 2870, loss: 0.2690,domain_loss: 0.0371 ,ce_loss: 0.3270., accu: 0.8735, speed: 1.18 step/s\n",
      "2022-09-29 01:33:50,580\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 7800, epoch: 2, batch: 2870】，loss: 0.2690,domain_loss: 0.0371 ,ce_loss: 0.3270., accu: 0.8735,\n",
      "2022-09-29 01:33:50,892\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.17652, accuracy: 0.95[0.96],threshold:0.377, domain_acc:0.99,total_num:100\n",
      "global step 7810, epoch: 2, batch: 2880, loss: 0.2431,domain_loss: 0.0425 ,ce_loss: 0.2932., accu: 0.8664, speed: 0.98 step/s\n",
      "global step 7820, epoch: 2, batch: 2890, loss: 0.1502,domain_loss: 0.0083 ,ce_loss: 0.1857., accu: 0.8711, speed: 1.19 step/s\n",
      "global step 7830, epoch: 2, batch: 2900, loss: 0.3084,domain_loss: 0.0659 ,ce_loss: 0.3690., accu: 0.8724, speed: 1.18 step/s\n",
      "global step 7840, epoch: 2, batch: 2910, loss: 0.1930,domain_loss: 0.0335 ,ce_loss: 0.2329., accu: 0.8693, speed: 1.18 step/s\n",
      "global step 7850, epoch: 2, batch: 2920, loss: 0.2208,domain_loss: 0.0155 ,ce_loss: 0.2721., accu: 0.8656, speed: 1.19 step/s\n",
      "global step 7860, epoch: 2, batch: 2930, loss: 0.2620,domain_loss: 0.0663 ,ce_loss: 0.3109., accu: 0.8682, speed: 1.17 step/s\n",
      "global step 7870, epoch: 2, batch: 2940, loss: 0.2550,domain_loss: 0.0104 ,ce_loss: 0.3162., accu: 0.8691, speed: 1.19 step/s\n",
      "global step 7880, epoch: 2, batch: 2950, loss: 0.2501,domain_loss: 0.0102 ,ce_loss: 0.3101., accu: 0.8697, speed: 1.18 step/s\n",
      "global step 7890, epoch: 2, batch: 2960, loss: 0.2960,domain_loss: 0.1048 ,ce_loss: 0.3438., accu: 0.8692, speed: 1.21 step/s\n",
      "global step 7900, epoch: 2, batch: 2970, loss: 0.2248,domain_loss: 0.0161 ,ce_loss: 0.2770., accu: 0.8695, speed: 1.17 step/s\n",
      "global step 7910, epoch: 2, batch: 2980, loss: 0.2542,domain_loss: 0.0436 ,ce_loss: 0.3068., accu: 0.8685, speed: 1.19 step/s\n",
      "global step 7920, epoch: 2, batch: 2990, loss: 0.1923,domain_loss: 0.0418 ,ce_loss: 0.2300., accu: 0.8687, speed: 1.19 step/s\n",
      "global step 7930, epoch: 2, batch: 3000, loss: 0.2679,domain_loss: 0.0589 ,ce_loss: 0.3201., accu: 0.8691, speed: 1.22 step/s\n",
      "global step 7940, epoch: 2, batch: 3010, loss: 0.1705,domain_loss: 0.0604 ,ce_loss: 0.1980., accu: 0.8698, speed: 1.17 step/s\n",
      "global step 7950, epoch: 2, batch: 3020, loss: 0.2278,domain_loss: 0.0132 ,ce_loss: 0.2814., accu: 0.8708, speed: 1.17 step/s\n",
      "global step 7960, epoch: 2, batch: 3030, loss: 0.1750,domain_loss: 0.0171 ,ce_loss: 0.2144., accu: 0.8713, speed: 1.20 step/s\n",
      "global step 7970, epoch: 2, batch: 3040, loss: 0.3085,domain_loss: 0.0639 ,ce_loss: 0.3697., accu: 0.8709, speed: 1.20 step/s\n",
      "global step 7980, epoch: 2, batch: 3050, loss: 0.2279,domain_loss: 0.0207 ,ce_loss: 0.2797., accu: 0.8705, speed: 1.19 step/s\n",
      "global step 7990, epoch: 2, batch: 3060, loss: 0.1930,domain_loss: 0.0157 ,ce_loss: 0.2374., accu: 0.8708, speed: 1.17 step/s\n",
      "global step 8000, epoch: 2, batch: 3070, loss: 0.2698,domain_loss: 0.0403 ,ce_loss: 0.3272., accu: 0.8710, speed: 1.18 step/s\n",
      "global step 8010, epoch: 2, batch: 3080, loss: 0.2417,domain_loss: 0.0892 ,ce_loss: 0.2798., accu: 0.8711, speed: 1.20 step/s\n",
      "global step 8020, epoch: 2, batch: 3090, loss: 0.2638,domain_loss: 0.0684 ,ce_loss: 0.3127., accu: 0.8713, speed: 1.17 step/s\n",
      "global step 8030, epoch: 2, batch: 3100, loss: 0.2058,domain_loss: 0.0114 ,ce_loss: 0.2544., accu: 0.8720, speed: 1.19 step/s\n",
      "global step 8040, epoch: 2, batch: 3110, loss: 0.2025,domain_loss: 0.1555 ,ce_loss: 0.2142., accu: 0.8723, speed: 1.17 step/s\n",
      "global step 8050, epoch: 2, batch: 3120, loss: 0.1880,domain_loss: 0.0471 ,ce_loss: 0.2232., accu: 0.8725, speed: 1.22 step/s\n",
      "global step 8060, epoch: 2, batch: 3130, loss: 0.2807,domain_loss: 0.0493 ,ce_loss: 0.3385., accu: 0.8725, speed: 1.18 step/s\n",
      "global step 8070, epoch: 2, batch: 3140, loss: 0.1857,domain_loss: 0.0575 ,ce_loss: 0.2177., accu: 0.8725, speed: 1.18 step/s\n",
      "global step 8080, epoch: 2, batch: 3150, loss: 0.2550,domain_loss: 0.0556 ,ce_loss: 0.3049., accu: 0.8725, speed: 1.17 step/s\n",
      "global step 8090, epoch: 2, batch: 3160, loss: 0.2424,domain_loss: 0.1144 ,ce_loss: 0.2744., accu: 0.8728, speed: 1.19 step/s\n",
      "global step 8100, epoch: 2, batch: 3170, loss: 0.1594,domain_loss: 0.0188 ,ce_loss: 0.1946., accu: 0.8729, speed: 1.20 step/s\n",
      "2022-09-29 01:38:05,173\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 8100, epoch: 2, batch: 3170】，loss: 0.1594,domain_loss: 0.0188 ,ce_loss: 0.1946., accu: 0.8729,\n",
      "2022-09-29 01:38:05,500\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.19024, accuracy: 0.94[0.96],threshold:0.487, domain_acc:1.0,total_num:100\n",
      "2022-09-29 01:38:06,413\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 8110, epoch: 2, batch: 3180, loss: 0.2624,domain_loss: 0.0357 ,ce_loss: 0.3191., accu: 0.8812, speed: 1.03 step/s\n",
      "global step 8120, epoch: 2, batch: 3190, loss: 0.2582,domain_loss: 0.0892 ,ce_loss: 0.3005., accu: 0.8746, speed: 1.17 step/s\n",
      "global step 8130, epoch: 2, batch: 3200, loss: 0.2339,domain_loss: 0.0447 ,ce_loss: 0.2813., accu: 0.8753, speed: 1.18 step/s\n",
      "global step 8140, epoch: 2, batch: 3210, loss: 0.2591,domain_loss: 0.0867 ,ce_loss: 0.3022., accu: 0.8748, speed: 1.19 step/s\n",
      "global step 8150, epoch: 2, batch: 3220, loss: 0.1454,domain_loss: 0.0594 ,ce_loss: 0.1669., accu: 0.8725, speed: 1.19 step/s\n",
      "global step 8160, epoch: 2, batch: 3230, loss: 0.2839,domain_loss: 0.0309 ,ce_loss: 0.3471., accu: 0.8745, speed: 1.17 step/s\n",
      "global step 8170, epoch: 2, batch: 3240, loss: 0.2068,domain_loss: 0.0444 ,ce_loss: 0.2474., accu: 0.8743, speed: 1.20 step/s\n",
      "global step 8180, epoch: 2, batch: 3250, loss: 0.3023,domain_loss: 0.0446 ,ce_loss: 0.3667., accu: 0.8729, speed: 1.18 step/s\n",
      "global step 8190, epoch: 2, batch: 3260, loss: 0.2036,domain_loss: 0.0247 ,ce_loss: 0.2484., accu: 0.8714, speed: 1.18 step/s\n",
      "global step 8200, epoch: 2, batch: 3270, loss: 0.2277,domain_loss: 0.0124 ,ce_loss: 0.2815., accu: 0.8718, speed: 1.18 step/s\n",
      "global step 8210, epoch: 2, batch: 3280, loss: 0.1867,domain_loss: 0.0509 ,ce_loss: 0.2206., accu: 0.8713, speed: 1.18 step/s\n",
      "global step 8220, epoch: 2, batch: 3290, loss: 0.2061,domain_loss: 0.0378 ,ce_loss: 0.2482., accu: 0.8732, speed: 1.18 step/s\n",
      "global step 8230, epoch: 2, batch: 3300, loss: 0.2524,domain_loss: 0.0570 ,ce_loss: 0.3012., accu: 0.8734, speed: 1.18 step/s\n",
      "global step 8240, epoch: 2, batch: 3310, loss: 0.1819,domain_loss: 0.0772 ,ce_loss: 0.2081., accu: 0.8738, speed: 1.18 step/s\n",
      "global step 8250, epoch: 2, batch: 3320, loss: 0.2289,domain_loss: 0.0612 ,ce_loss: 0.2708., accu: 0.8734, speed: 1.19 step/s\n",
      "global step 8260, epoch: 2, batch: 3330, loss: 0.2893,domain_loss: 0.0492 ,ce_loss: 0.3494., accu: 0.8729, speed: 1.21 step/s\n",
      "global step 8270, epoch: 2, batch: 3340, loss: 0.2200,domain_loss: 0.0175 ,ce_loss: 0.2707., accu: 0.8726, speed: 1.18 step/s\n",
      "global step 8280, epoch: 2, batch: 3350, loss: 0.2161,domain_loss: 0.0651 ,ce_loss: 0.2538., accu: 0.8717, speed: 1.18 step/s\n",
      "global step 8290, epoch: 2, batch: 3360, loss: 0.1912,domain_loss: 0.1305 ,ce_loss: 0.2064., accu: 0.8706, speed: 1.19 step/s\n",
      "global step 8300, epoch: 2, batch: 3370, loss: 0.2352,domain_loss: 0.0773 ,ce_loss: 0.2747., accu: 0.8701, speed: 1.18 step/s\n",
      "global step 8310, epoch: 2, batch: 3380, loss: 0.2362,domain_loss: 0.0396 ,ce_loss: 0.2853., accu: 0.8699, speed: 1.18 step/s\n",
      "global step 8320, epoch: 2, batch: 3390, loss: 0.1664,domain_loss: 0.0400 ,ce_loss: 0.1980., accu: 0.8708, speed: 1.18 step/s\n",
      "global step 8330, epoch: 2, batch: 3400, loss: 0.2432,domain_loss: 0.0845 ,ce_loss: 0.2829., accu: 0.8713, speed: 1.17 step/s\n",
      "global step 8340, epoch: 2, batch: 3410, loss: 0.2533,domain_loss: 0.0294 ,ce_loss: 0.3093., accu: 0.8716, speed: 1.21 step/s\n",
      "global step 8350, epoch: 2, batch: 3420, loss: 0.1883,domain_loss: 0.0206 ,ce_loss: 0.2302., accu: 0.8724, speed: 1.18 step/s\n",
      "global step 8360, epoch: 2, batch: 3430, loss: 0.2649,domain_loss: 0.0351 ,ce_loss: 0.3224., accu: 0.8723, speed: 1.18 step/s\n",
      "global step 8370, epoch: 2, batch: 3440, loss: 0.2627,domain_loss: 0.0857 ,ce_loss: 0.3070., accu: 0.8725, speed: 1.20 step/s\n",
      "global step 8380, epoch: 2, batch: 3450, loss: 0.2692,domain_loss: 0.0429 ,ce_loss: 0.3258., accu: 0.8732, speed: 1.17 step/s\n",
      "global step 8390, epoch: 2, batch: 3460, loss: 0.2283,domain_loss: 0.0602 ,ce_loss: 0.2704., accu: 0.8730, speed: 1.17 step/s\n",
      "global step 8400, epoch: 2, batch: 3470, loss: 0.2900,domain_loss: 0.0187 ,ce_loss: 0.3578., accu: 0.8730, speed: 1.18 step/s\n",
      "2022-09-29 01:42:19,923\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 8400, epoch: 2, batch: 3470】，loss: 0.2900,domain_loss: 0.0187 ,ce_loss: 0.3578., accu: 0.8730,\n",
      "2022-09-29 01:42:20,232\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.13663, accuracy: 0.95[0.96],threshold:0.275, domain_acc:0.99,total_num:100\n",
      "global step 8410, epoch: 2, batch: 3480, loss: 0.2732,domain_loss: 0.0787 ,ce_loss: 0.3219., accu: 0.8766, speed: 1.06 step/s\n",
      "global step 8420, epoch: 2, batch: 3490, loss: 0.2766,domain_loss: 0.0291 ,ce_loss: 0.3385., accu: 0.8672, speed: 1.18 step/s\n",
      "global step 8430, epoch: 2, batch: 3500, loss: 0.2270,domain_loss: 0.0635 ,ce_loss: 0.2678., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 8440, epoch: 2, batch: 3510, loss: 0.2195,domain_loss: 0.0414 ,ce_loss: 0.2640., accu: 0.8693, speed: 1.19 step/s\n",
      "global step 8450, epoch: 2, batch: 3520, loss: 0.2449,domain_loss: 0.1140 ,ce_loss: 0.2776., accu: 0.8688, speed: 1.18 step/s\n",
      "global step 8460, epoch: 2, batch: 3530, loss: 0.1381,domain_loss: 0.0174 ,ce_loss: 0.1683., accu: 0.8691, speed: 1.17 step/s\n",
      "global step 8470, epoch: 2, batch: 3540, loss: 0.1879,domain_loss: 0.0204 ,ce_loss: 0.2298., accu: 0.8718, speed: 1.19 step/s\n",
      "global step 8480, epoch: 2, batch: 3550, loss: 0.2085,domain_loss: 0.0618 ,ce_loss: 0.2452., accu: 0.8715, speed: 1.18 step/s\n",
      "global step 8490, epoch: 2, batch: 3560, loss: 0.2561,domain_loss: 0.0584 ,ce_loss: 0.3055., accu: 0.8718, speed: 1.18 step/s\n",
      "global step 8500, epoch: 2, batch: 3570, loss: 0.2269,domain_loss: 0.0378 ,ce_loss: 0.2742., accu: 0.8719, speed: 1.17 step/s\n",
      "global step 8510, epoch: 2, batch: 3580, loss: 0.2175,domain_loss: 0.0173 ,ce_loss: 0.2675., accu: 0.8722, speed: 1.19 step/s\n",
      "global step 8520, epoch: 2, batch: 3590, loss: 0.2749,domain_loss: 0.0088 ,ce_loss: 0.3414., accu: 0.8721, speed: 1.19 step/s\n",
      "global step 8530, epoch: 2, batch: 3600, loss: 0.2261,domain_loss: 0.0274 ,ce_loss: 0.2758., accu: 0.8714, speed: 1.22 step/s\n",
      "global step 8540, epoch: 2, batch: 3610, loss: 0.2382,domain_loss: 0.0259 ,ce_loss: 0.2913., accu: 0.8717, speed: 1.18 step/s\n",
      "global step 8550, epoch: 2, batch: 3620, loss: 0.2332,domain_loss: 0.0441 ,ce_loss: 0.2805., accu: 0.8704, speed: 1.19 step/s\n",
      "global step 8560, epoch: 2, batch: 3630, loss: 0.2222,domain_loss: 0.0325 ,ce_loss: 0.2696., accu: 0.8705, speed: 1.17 step/s\n",
      "global step 8570, epoch: 2, batch: 3640, loss: 0.1909,domain_loss: 0.0251 ,ce_loss: 0.2324., accu: 0.8707, speed: 1.18 step/s\n",
      "global step 8580, epoch: 2, batch: 3650, loss: 0.2574,domain_loss: 0.0457 ,ce_loss: 0.3104., accu: 0.8697, speed: 1.18 step/s\n",
      "global step 8590, epoch: 2, batch: 3660, loss: 0.2693,domain_loss: 0.0215 ,ce_loss: 0.3313., accu: 0.8692, speed: 1.19 step/s\n",
      "global step 8600, epoch: 2, batch: 3670, loss: 0.2796,domain_loss: 0.0129 ,ce_loss: 0.3463., accu: 0.8691, speed: 1.18 step/s\n",
      "global step 8610, epoch: 2, batch: 3680, loss: 0.2237,domain_loss: 0.0355 ,ce_loss: 0.2707., accu: 0.8697, speed: 1.18 step/s\n",
      "global step 8620, epoch: 2, batch: 3690, loss: 0.2274,domain_loss: 0.0138 ,ce_loss: 0.2808., accu: 0.8701, speed: 1.18 step/s\n",
      "global step 8630, epoch: 2, batch: 3700, loss: 0.2225,domain_loss: 0.0375 ,ce_loss: 0.2687., accu: 0.8695, speed: 1.18 step/s\n",
      "global step 8640, epoch: 2, batch: 3710, loss: 0.2604,domain_loss: 0.1454 ,ce_loss: 0.2891., accu: 0.8702, speed: 1.17 step/s\n",
      "global step 8650, epoch: 2, batch: 3720, loss: 0.2605,domain_loss: 0.0569 ,ce_loss: 0.3113., accu: 0.8703, speed: 1.17 step/s\n",
      "global step 8660, epoch: 2, batch: 3730, loss: 0.2025,domain_loss: 0.0623 ,ce_loss: 0.2376., accu: 0.8706, speed: 1.21 step/s\n",
      "global step 8670, epoch: 2, batch: 3740, loss: 0.2423,domain_loss: 0.0797 ,ce_loss: 0.2829., accu: 0.8705, speed: 1.18 step/s\n",
      "global step 8680, epoch: 2, batch: 3750, loss: 0.1689,domain_loss: 0.0234 ,ce_loss: 0.2053., accu: 0.8705, speed: 1.18 step/s\n",
      "global step 8690, epoch: 2, batch: 3760, loss: 0.2646,domain_loss: 0.0367 ,ce_loss: 0.3216., accu: 0.8707, speed: 1.17 step/s\n",
      "global step 8700, epoch: 2, batch: 3770, loss: 0.2648,domain_loss: 0.0623 ,ce_loss: 0.3154., accu: 0.8713, speed: 1.18 step/s\n",
      "2022-09-29 01:46:34,728\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 8700, epoch: 2, batch: 3770】，loss: 0.2648,domain_loss: 0.0623 ,ce_loss: 0.3154., accu: 0.8713,\n",
      "2022-09-29 01:46:35,031\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.14836, accuracy: 0.95[0.96],threshold:0.472, domain_acc:0.99,total_num:100\n",
      "global step 8710, epoch: 2, batch: 3780, loss: 0.2333,domain_loss: 0.0759 ,ce_loss: 0.2727., accu: 0.8742, speed: 1.04 step/s\n",
      "global step 8720, epoch: 2, batch: 3790, loss: 0.2418,domain_loss: 0.0178 ,ce_loss: 0.2978., accu: 0.8738, speed: 1.21 step/s\n",
      "global step 8730, epoch: 2, batch: 3800, loss: 0.2111,domain_loss: 0.0381 ,ce_loss: 0.2544., accu: 0.8747, speed: 1.18 step/s\n",
      "global step 8740, epoch: 2, batch: 3810, loss: 0.3300,domain_loss: 0.0828 ,ce_loss: 0.3919., accu: 0.8748, speed: 1.18 step/s\n",
      "global step 8750, epoch: 2, batch: 3820, loss: 0.1699,domain_loss: 0.0179 ,ce_loss: 0.2079., accu: 0.8759, speed: 1.18 step/s\n",
      "global step 8760, epoch: 2, batch: 3830, loss: 0.2415,domain_loss: 0.0287 ,ce_loss: 0.2947., accu: 0.8783, speed: 1.17 step/s\n",
      "global step 8770, epoch: 2, batch: 3840, loss: 0.2095,domain_loss: 0.0384 ,ce_loss: 0.2523., accu: 0.8769, speed: 1.18 step/s\n",
      "global step 8780, epoch: 2, batch: 3850, loss: 0.2324,domain_loss: 0.0457 ,ce_loss: 0.2791., accu: 0.8751, speed: 1.19 step/s\n",
      "global step 8790, epoch: 2, batch: 3860, loss: 0.2052,domain_loss: 0.0858 ,ce_loss: 0.2351., accu: 0.8734, speed: 1.18 step/s\n",
      "global step 8800, epoch: 2, batch: 3870, loss: 0.2590,domain_loss: 0.0689 ,ce_loss: 0.3065., accu: 0.8735, speed: 1.20 step/s\n",
      "global step 8810, epoch: 2, batch: 3880, loss: 0.1941,domain_loss: 0.0226 ,ce_loss: 0.2370., accu: 0.8745, speed: 1.18 step/s\n",
      "global step 8820, epoch: 2, batch: 3890, loss: 0.1960,domain_loss: 0.0377 ,ce_loss: 0.2355., accu: 0.8741, speed: 1.18 step/s\n",
      "global step 8830, epoch: 2, batch: 3900, loss: 0.2215,domain_loss: 0.0184 ,ce_loss: 0.2723., accu: 0.8748, speed: 1.18 step/s\n",
      "global step 8840, epoch: 2, batch: 3910, loss: 0.2202,domain_loss: 0.0385 ,ce_loss: 0.2656., accu: 0.8743, speed: 1.19 step/s\n",
      "global step 8850, epoch: 2, batch: 3920, loss: 0.2424,domain_loss: 0.0228 ,ce_loss: 0.2972., accu: 0.8749, speed: 1.19 step/s\n",
      "global step 8860, epoch: 2, batch: 3930, loss: 0.2470,domain_loss: 0.0309 ,ce_loss: 0.3010., accu: 0.8741, speed: 1.19 step/s\n",
      "global step 8870, epoch: 2, batch: 3940, loss: 0.2837,domain_loss: 0.0202 ,ce_loss: 0.3496., accu: 0.8743, speed: 1.18 step/s\n",
      "global step 8880, epoch: 2, batch: 3950, loss: 0.2432,domain_loss: 0.1150 ,ce_loss: 0.2752., accu: 0.8735, speed: 1.18 step/s\n",
      "global step 8890, epoch: 2, batch: 3960, loss: 0.2482,domain_loss: 0.0210 ,ce_loss: 0.3050., accu: 0.8737, speed: 1.18 step/s\n",
      "global step 8900, epoch: 2, batch: 3970, loss: 0.1975,domain_loss: 0.0441 ,ce_loss: 0.2359., accu: 0.8741, speed: 1.17 step/s\n",
      "global step 8910, epoch: 2, batch: 3980, loss: 0.3369,domain_loss: 0.0393 ,ce_loss: 0.4113., accu: 0.8744, speed: 1.18 step/s\n",
      "global step 8920, epoch: 2, batch: 3990, loss: 0.1966,domain_loss: 0.1450 ,ce_loss: 0.2095., accu: 0.8738, speed: 1.19 step/s\n",
      "global step 8930, epoch: 2, batch: 4000, loss: 0.1897,domain_loss: 0.0842 ,ce_loss: 0.2161., accu: 0.8736, speed: 1.21 step/s\n",
      "global step 8940, epoch: 2, batch: 4010, loss: 0.2483,domain_loss: 0.0518 ,ce_loss: 0.2974., accu: 0.8736, speed: 1.18 step/s\n",
      "global step 8950, epoch: 2, batch: 4020, loss: 0.1974,domain_loss: 0.0777 ,ce_loss: 0.2273., accu: 0.8738, speed: 1.19 step/s\n",
      "global step 8960, epoch: 2, batch: 4030, loss: 0.2231,domain_loss: 0.0984 ,ce_loss: 0.2543., accu: 0.8737, speed: 1.18 step/s\n",
      "global step 8970, epoch: 2, batch: 4040, loss: 0.2379,domain_loss: 0.0104 ,ce_loss: 0.2948., accu: 0.8739, speed: 1.18 step/s\n",
      "global step 8980, epoch: 2, batch: 4050, loss: 0.2490,domain_loss: 0.0153 ,ce_loss: 0.3075., accu: 0.8735, speed: 1.17 step/s\n",
      "global step 8990, epoch: 2, batch: 4060, loss: 0.2227,domain_loss: 0.0228 ,ce_loss: 0.2726., accu: 0.8730, speed: 1.18 step/s\n",
      "global step 9000, epoch: 2, batch: 4070, loss: 0.3057,domain_loss: 0.0607 ,ce_loss: 0.3670., accu: 0.8734, speed: 1.18 step/s\n",
      "2022-09-29 01:50:49,392\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 9000, epoch: 2, batch: 4070】，loss: 0.3057,domain_loss: 0.0607 ,ce_loss: 0.3670., accu: 0.8734,\n",
      "2022-09-29 01:50:49,705\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.14532, accuracy: 0.93[0.96],threshold:0.544, domain_acc:1.0,total_num:100\n",
      "2022-09-29 01:50:50,598\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 9010, epoch: 2, batch: 4080, loss: 0.2330,domain_loss: 0.0295 ,ce_loss: 0.2839., accu: 0.8820, speed: 1.03 step/s\n",
      "global step 9020, epoch: 2, batch: 4090, loss: 0.2503,domain_loss: 0.0375 ,ce_loss: 0.3034., accu: 0.8816, speed: 1.18 step/s\n",
      "global step 9030, epoch: 2, batch: 4100, loss: 0.1435,domain_loss: 0.0178 ,ce_loss: 0.1749., accu: 0.8776, speed: 1.18 step/s\n",
      "global step 9040, epoch: 2, batch: 4110, loss: 0.2081,domain_loss: 0.0280 ,ce_loss: 0.2532., accu: 0.8812, speed: 1.21 step/s\n",
      "global step 9050, epoch: 2, batch: 4120, loss: 0.1863,domain_loss: 0.0811 ,ce_loss: 0.2126., accu: 0.8797, speed: 1.19 step/s\n",
      "global step 9060, epoch: 2, batch: 4130, loss: 0.2206,domain_loss: 0.0457 ,ce_loss: 0.2643., accu: 0.8797, speed: 1.17 step/s\n",
      "global step 9070, epoch: 2, batch: 4140, loss: 0.2512,domain_loss: 0.0120 ,ce_loss: 0.3110., accu: 0.8816, speed: 1.18 step/s\n",
      "global step 9080, epoch: 2, batch: 4150, loss: 0.2257,domain_loss: 0.0667 ,ce_loss: 0.2654., accu: 0.8810, speed: 1.19 step/s\n",
      "global step 9090, epoch: 2, batch: 4160, loss: 0.2186,domain_loss: 0.0408 ,ce_loss: 0.2631., accu: 0.8799, speed: 1.20 step/s\n",
      "global step 9100, epoch: 2, batch: 4170, loss: 0.2670,domain_loss: 0.0660 ,ce_loss: 0.3173., accu: 0.8785, speed: 1.18 step/s\n",
      "global step 9110, epoch: 2, batch: 4180, loss: 0.2346,domain_loss: 0.0645 ,ce_loss: 0.2771., accu: 0.8791, speed: 1.18 step/s\n",
      "global step 9120, epoch: 2, batch: 4190, loss: 0.2297,domain_loss: 0.0188 ,ce_loss: 0.2824., accu: 0.8777, speed: 1.19 step/s\n",
      "global step 9130, epoch: 2, batch: 4200, loss: 0.2045,domain_loss: 0.0168 ,ce_loss: 0.2515., accu: 0.8770, speed: 1.18 step/s\n",
      "global step 9140, epoch: 2, batch: 4210, loss: 0.1657,domain_loss: 0.0170 ,ce_loss: 0.2028., accu: 0.8769, speed: 1.19 step/s\n",
      "global step 9150, epoch: 2, batch: 4220, loss: 0.2226,domain_loss: 0.0094 ,ce_loss: 0.2759., accu: 0.8772, speed: 1.19 step/s\n",
      "global step 9160, epoch: 2, batch: 4230, loss: 0.3052,domain_loss: 0.0300 ,ce_loss: 0.3741., accu: 0.8763, speed: 1.18 step/s\n",
      "global step 9170, epoch: 2, batch: 4240, loss: 0.2268,domain_loss: 0.0427 ,ce_loss: 0.2729., accu: 0.8763, speed: 1.18 step/s\n",
      "global step 9180, epoch: 2, batch: 4250, loss: 0.2163,domain_loss: 0.0528 ,ce_loss: 0.2572., accu: 0.8767, speed: 1.17 step/s\n",
      "global step 9190, epoch: 2, batch: 4260, loss: 0.2368,domain_loss: 0.0150 ,ce_loss: 0.2923., accu: 0.8766, speed: 1.18 step/s\n",
      "global step 9200, epoch: 2, batch: 4270, loss: 0.2359,domain_loss: 0.0453 ,ce_loss: 0.2835., accu: 0.8768, speed: 1.18 step/s\n",
      "global step 9210, epoch: 2, batch: 4280, loss: 0.1937,domain_loss: 0.0725 ,ce_loss: 0.2240., accu: 0.8765, speed: 1.19 step/s\n",
      "global step 9220, epoch: 2, batch: 4290, loss: 0.2082,domain_loss: 0.0840 ,ce_loss: 0.2393., accu: 0.8763, speed: 1.18 step/s\n",
      "global step 9230, epoch: 2, batch: 4300, loss: 0.2049,domain_loss: 0.0164 ,ce_loss: 0.2520., accu: 0.8765, speed: 1.20 step/s\n",
      "global step 9240, epoch: 2, batch: 4310, loss: 0.2262,domain_loss: 0.0821 ,ce_loss: 0.2622., accu: 0.8768, speed: 1.18 step/s\n",
      "global step 9250, epoch: 2, batch: 4320, loss: 0.2474,domain_loss: 0.0291 ,ce_loss: 0.3020., accu: 0.8764, speed: 1.19 step/s\n",
      "global step 9260, epoch: 2, batch: 4330, loss: 0.2599,domain_loss: 0.0789 ,ce_loss: 0.3052., accu: 0.8756, speed: 1.18 step/s\n",
      "global step 9270, epoch: 2, batch: 4340, loss: 0.2516,domain_loss: 0.1386 ,ce_loss: 0.2798., accu: 0.8756, speed: 1.17 step/s\n",
      "global step 9280, epoch: 2, batch: 4350, loss: 0.2724,domain_loss: 0.1097 ,ce_loss: 0.3130., accu: 0.8755, speed: 1.17 step/s\n",
      "global step 9290, epoch: 2, batch: 4360, loss: 0.2461,domain_loss: 0.0494 ,ce_loss: 0.2953., accu: 0.8755, speed: 1.18 step/s\n",
      "global step 9300, epoch: 2, batch: 4370, loss: 0.1678,domain_loss: 0.0114 ,ce_loss: 0.2069., accu: 0.8756, speed: 1.18 step/s\n",
      "2022-09-29 01:55:03,942\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 9300, epoch: 2, batch: 4370】，loss: 0.1678,domain_loss: 0.0114 ,ce_loss: 0.2069., accu: 0.8756,\n",
      "2022-09-29 01:55:04,247\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.17506, accuracy: 0.94[0.96],threshold:0.455, domain_acc:1.0,total_num:100\n",
      "global step 9310, epoch: 2, batch: 4380, loss: 0.2029,domain_loss: 0.0686 ,ce_loss: 0.2365., accu: 0.8867, speed: 1.07 step/s\n",
      "global step 9320, epoch: 2, batch: 4390, loss: 0.2564,domain_loss: 0.0401 ,ce_loss: 0.3105., accu: 0.8820, speed: 1.18 step/s\n",
      "global step 9330, epoch: 2, batch: 4400, loss: 0.2378,domain_loss: 0.0476 ,ce_loss: 0.2854., accu: 0.8820, speed: 1.18 step/s\n",
      "global step 9340, epoch: 2, batch: 4410, loss: 0.2207,domain_loss: 0.0617 ,ce_loss: 0.2604., accu: 0.8775, speed: 1.18 step/s\n",
      "global step 9350, epoch: 2, batch: 4420, loss: 0.2862,domain_loss: 0.0218 ,ce_loss: 0.3523., accu: 0.8766, speed: 1.19 step/s\n",
      "global step 9360, epoch: 2, batch: 4430, loss: 0.2436,domain_loss: 0.1110 ,ce_loss: 0.2768., accu: 0.8747, speed: 1.18 step/s\n",
      "global step 9370, epoch: 2, batch: 4440, loss: 0.2028,domain_loss: 0.0413 ,ce_loss: 0.2432., accu: 0.8758, speed: 1.18 step/s\n",
      "global step 9380, epoch: 2, batch: 4450, loss: 0.2389,domain_loss: 0.0482 ,ce_loss: 0.2866., accu: 0.8774, speed: 1.19 step/s\n",
      "global step 9390, epoch: 2, batch: 4460, loss: 0.2146,domain_loss: 0.0635 ,ce_loss: 0.2524., accu: 0.8768, speed: 1.18 step/s\n",
      "global step 9400, epoch: 2, batch: 4470, loss: 0.1781,domain_loss: 0.0241 ,ce_loss: 0.2166., accu: 0.8788, speed: 1.19 step/s\n",
      "global step 9410, epoch: 2, batch: 4480, loss: 0.2197,domain_loss: 0.0205 ,ce_loss: 0.2695., accu: 0.8791, speed: 1.20 step/s\n",
      "global step 9420, epoch: 2, batch: 4490, loss: 0.2628,domain_loss: 0.0762 ,ce_loss: 0.3094., accu: 0.8787, speed: 1.17 step/s\n",
      "global step 9430, epoch: 2, batch: 4500, loss: 0.2231,domain_loss: 0.0486 ,ce_loss: 0.2667., accu: 0.8782, speed: 1.18 step/s\n",
      "global step 9440, epoch: 2, batch: 4510, loss: 0.2066,domain_loss: 0.0512 ,ce_loss: 0.2454., accu: 0.8785, speed: 1.18 step/s\n",
      "global step 9450, epoch: 2, batch: 4520, loss: 0.2317,domain_loss: 0.0499 ,ce_loss: 0.2771., accu: 0.8786, speed: 1.17 step/s\n",
      "global step 9460, epoch: 2, batch: 4530, loss: 0.1959,domain_loss: 0.0270 ,ce_loss: 0.2381., accu: 0.8796, speed: 1.18 step/s\n",
      "global step 9470, epoch: 2, batch: 4540, loss: 0.2332,domain_loss: 0.1033 ,ce_loss: 0.2656., accu: 0.8793, speed: 1.18 step/s\n",
      "global step 9480, epoch: 2, batch: 4550, loss: 0.2668,domain_loss: 0.0451 ,ce_loss: 0.3222., accu: 0.8787, speed: 1.17 step/s\n",
      "global step 9490, epoch: 2, batch: 4560, loss: 0.2853,domain_loss: 0.0850 ,ce_loss: 0.3353., accu: 0.8792, speed: 1.17 step/s\n",
      "global step 9500, epoch: 2, batch: 4570, loss: 0.2884,domain_loss: 0.0740 ,ce_loss: 0.3420., accu: 0.8792, speed: 1.19 step/s\n",
      "global step 9510, epoch: 2, batch: 4580, loss: 0.2411,domain_loss: 0.0069 ,ce_loss: 0.2997., accu: 0.8796, speed: 1.17 step/s\n",
      "global step 9520, epoch: 2, batch: 4590, loss: 0.2890,domain_loss: 0.0802 ,ce_loss: 0.3412., accu: 0.8796, speed: 1.18 step/s\n",
      "global step 9530, epoch: 2, batch: 4600, loss: 0.3302,domain_loss: 0.0533 ,ce_loss: 0.3994., accu: 0.8797, speed: 1.17 step/s\n",
      "global step 9540, epoch: 2, batch: 4610, loss: 0.2313,domain_loss: 0.1126 ,ce_loss: 0.2610., accu: 0.8794, speed: 1.17 step/s\n",
      "global step 9550, epoch: 2, batch: 4620, loss: 0.2143,domain_loss: 0.0188 ,ce_loss: 0.2632., accu: 0.8790, speed: 1.17 step/s\n",
      "global step 9560, epoch: 2, batch: 4630, loss: 0.1972,domain_loss: 0.0145 ,ce_loss: 0.2428., accu: 0.8789, speed: 1.21 step/s\n",
      "global step 9570, epoch: 2, batch: 4640, loss: 0.1988,domain_loss: 0.0344 ,ce_loss: 0.2399., accu: 0.8794, speed: 1.19 step/s\n",
      "global step 9580, epoch: 2, batch: 4650, loss: 0.3037,domain_loss: 0.0275 ,ce_loss: 0.3728., accu: 0.8797, speed: 1.17 step/s\n",
      "global step 9590, epoch: 2, batch: 4660, loss: 0.2315,domain_loss: 0.0447 ,ce_loss: 0.2782., accu: 0.8789, speed: 1.19 step/s\n",
      "global step 9600, epoch: 2, batch: 4670, loss: 0.2164,domain_loss: 0.0321 ,ce_loss: 0.2625., accu: 0.8788, speed: 1.20 step/s\n",
      "2022-09-29 01:59:18,414\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 9600, epoch: 2, batch: 4670】，loss: 0.2164,domain_loss: 0.0321 ,ce_loss: 0.2625., accu: 0.8788,\n",
      "2022-09-29 01:59:18,722\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.17839, accuracy: 0.94[0.96],threshold:0.465, domain_acc:1.0,total_num:100\n",
      "global step 9610, epoch: 2, batch: 4680, loss: 0.2247,domain_loss: 0.0911 ,ce_loss: 0.2581., accu: 0.8781, speed: 1.03 step/s\n",
      "global step 9620, epoch: 2, batch: 4690, loss: 0.2281,domain_loss: 0.0621 ,ce_loss: 0.2697., accu: 0.8715, speed: 1.17 step/s\n",
      "global step 9630, epoch: 2, batch: 4700, loss: 0.2368,domain_loss: 0.1170 ,ce_loss: 0.2667., accu: 0.8771, speed: 1.18 step/s\n",
      "global step 9640, epoch: 2, batch: 4710, loss: 0.2377,domain_loss: 0.0704 ,ce_loss: 0.2795., accu: 0.8730, speed: 1.18 step/s\n",
      "global step 9650, epoch: 2, batch: 4720, loss: 0.2266,domain_loss: 0.0559 ,ce_loss: 0.2693., accu: 0.8709, speed: 1.20 step/s\n",
      "global step 9660, epoch: 2, batch: 4730, loss: 0.2676,domain_loss: 0.0818 ,ce_loss: 0.3141., accu: 0.8704, speed: 1.18 step/s\n",
      "global step 9670, epoch: 2, batch: 4740, loss: 0.1656,domain_loss: 0.0286 ,ce_loss: 0.1999., accu: 0.8724, speed: 1.18 step/s\n",
      "global step 9680, epoch: 2, batch: 4750, loss: 0.1921,domain_loss: 0.0152 ,ce_loss: 0.2363., accu: 0.8757, speed: 1.18 step/s\n",
      "global step 9690, epoch: 2, batch: 4760, loss: 0.2803,domain_loss: 0.0489 ,ce_loss: 0.3381., accu: 0.8747, speed: 1.17 step/s\n",
      "global step 9700, epoch: 2, batch: 4770, loss: 0.1889,domain_loss: 0.0662 ,ce_loss: 0.2196., accu: 0.8762, speed: 1.18 step/s\n",
      "global step 9710, epoch: 2, batch: 4780, loss: 0.2457,domain_loss: 0.0836 ,ce_loss: 0.2863., accu: 0.8761, speed: 1.18 step/s\n",
      "global step 9720, epoch: 2, batch: 4790, loss: 0.1911,domain_loss: 0.0211 ,ce_loss: 0.2336., accu: 0.8762, speed: 1.20 step/s\n",
      "global step 9730, epoch: 2, batch: 4800, loss: 0.1986,domain_loss: 0.0421 ,ce_loss: 0.2377., accu: 0.8762, speed: 1.20 step/s\n",
      "global step 9740, epoch: 2, batch: 4810, loss: 0.2144,domain_loss: 0.0602 ,ce_loss: 0.2529., accu: 0.8752, speed: 1.20 step/s\n",
      "global step 9750, epoch: 2, batch: 4820, loss: 0.2475,domain_loss: 0.0321 ,ce_loss: 0.3013., accu: 0.8760, speed: 1.18 step/s\n",
      "global step 9760, epoch: 2, batch: 4830, loss: 0.2163,domain_loss: 0.0681 ,ce_loss: 0.2533., accu: 0.8765, speed: 1.19 step/s\n",
      "global step 9770, epoch: 2, batch: 4840, loss: 0.2368,domain_loss: 0.0349 ,ce_loss: 0.2872., accu: 0.8761, speed: 1.18 step/s\n",
      "global step 9780, epoch: 2, batch: 4850, loss: 0.2071,domain_loss: 0.0159 ,ce_loss: 0.2549., accu: 0.8766, speed: 1.19 step/s\n",
      "global step 9790, epoch: 2, batch: 4860, loss: 0.2449,domain_loss: 0.0809 ,ce_loss: 0.2859., accu: 0.8768, speed: 1.17 step/s\n",
      "global step 9800, epoch: 2, batch: 4870, loss: 0.2472,domain_loss: 0.0435 ,ce_loss: 0.2982., accu: 0.8767, speed: 1.18 step/s\n",
      "global step 9810, epoch: 2, batch: 4880, loss: 0.1657,domain_loss: 0.0193 ,ce_loss: 0.2023., accu: 0.8765, speed: 1.18 step/s\n",
      "global step 9820, epoch: 2, batch: 4890, loss: 0.2103,domain_loss: 0.0600 ,ce_loss: 0.2479., accu: 0.8761, speed: 1.19 step/s\n",
      "global step 9830, epoch: 2, batch: 4900, loss: 0.2169,domain_loss: 0.0703 ,ce_loss: 0.2535., accu: 0.8758, speed: 1.19 step/s\n",
      "global step 9840, epoch: 2, batch: 4910, loss: 0.2779,domain_loss: 0.0867 ,ce_loss: 0.3257., accu: 0.8763, speed: 1.18 step/s\n",
      "global step 9850, epoch: 2, batch: 4920, loss: 0.1983,domain_loss: 0.0334 ,ce_loss: 0.2395., accu: 0.8762, speed: 1.20 step/s\n",
      "global step 9860, epoch: 2, batch: 4930, loss: 0.4034,domain_loss: 0.1426 ,ce_loss: 0.4686., accu: 0.8759, speed: 1.27 step/s\n",
      " 40%|███████████████▌                       | 2/5 [2:19:25<3:29:08, 4182.84s/it]global step 9870, epoch: 3, batch: 10, loss: 0.3384,domain_loss: 0.0598 ,ce_loss: 0.4080., accu: 0.8759, speed: 1.17 step/s\n",
      "global step 9880, epoch: 3, batch: 20, loss: 0.1891,domain_loss: 0.0265 ,ce_loss: 0.2297., accu: 0.8763, speed: 1.18 step/s\n",
      "global step 9890, epoch: 3, batch: 30, loss: 0.1751,domain_loss: 0.0962 ,ce_loss: 0.1948., accu: 0.8767, speed: 1.19 step/s\n",
      "global step 9900, epoch: 3, batch: 40, loss: 0.2587,domain_loss: 0.0090 ,ce_loss: 0.3211., accu: 0.8771, speed: 1.19 step/s\n",
      "2022-09-29 02:03:32,330\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 9900, epoch: 3, batch: 40】，loss: 0.2587,domain_loss: 0.0090 ,ce_loss: 0.3211., accu: 0.8771,\n",
      "2022-09-29 02:03:32,633\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.14749, accuracy: 0.94[0.96],threshold:0.456, domain_acc:1.0,total_num:100\n",
      "global step 9910, epoch: 3, batch: 50, loss: 0.1943,domain_loss: 0.0496 ,ce_loss: 0.2305., accu: 0.9086, speed: 1.04 step/s\n",
      "global step 9920, epoch: 3, batch: 60, loss: 0.1897,domain_loss: 0.0968 ,ce_loss: 0.2129., accu: 0.9008, speed: 1.19 step/s\n",
      "global step 9930, epoch: 3, batch: 70, loss: 0.2281,domain_loss: 0.0474 ,ce_loss: 0.2733., accu: 0.8971, speed: 1.18 step/s\n",
      "global step 9940, epoch: 3, batch: 80, loss: 0.2231,domain_loss: 0.0470 ,ce_loss: 0.2671., accu: 0.8947, speed: 1.19 step/s\n",
      "global step 9950, epoch: 3, batch: 90, loss: 0.2248,domain_loss: 0.0878 ,ce_loss: 0.2590., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 9960, epoch: 3, batch: 100, loss: 0.1897,domain_loss: 0.0850 ,ce_loss: 0.2159., accu: 0.8915, speed: 1.18 step/s\n",
      "global step 9970, epoch: 3, batch: 110, loss: 0.1897,domain_loss: 0.0368 ,ce_loss: 0.2279., accu: 0.8920, speed: 1.18 step/s\n",
      "global step 9980, epoch: 3, batch: 120, loss: 0.1656,domain_loss: 0.0315 ,ce_loss: 0.1992., accu: 0.8938, speed: 1.18 step/s\n",
      "global step 9990, epoch: 3, batch: 130, loss: 0.1886,domain_loss: 0.0143 ,ce_loss: 0.2322., accu: 0.8940, speed: 1.17 step/s\n",
      "global step 10000, epoch: 3, batch: 140, loss: 0.2322,domain_loss: 0.0848 ,ce_loss: 0.2690., accu: 0.8947, speed: 1.17 step/s\n",
      "global step 10010, epoch: 3, batch: 150, loss: 0.2336,domain_loss: 0.0157 ,ce_loss: 0.2880., accu: 0.8939, speed: 1.18 step/s\n",
      "global step 10020, epoch: 3, batch: 160, loss: 0.2389,domain_loss: 0.0525 ,ce_loss: 0.2855., accu: 0.8919, speed: 1.18 step/s\n",
      "global step 10030, epoch: 3, batch: 170, loss: 0.2317,domain_loss: 0.0445 ,ce_loss: 0.2785., accu: 0.8927, speed: 1.18 step/s\n",
      "global step 10040, epoch: 3, batch: 180, loss: 0.2151,domain_loss: 0.0139 ,ce_loss: 0.2654., accu: 0.8930, speed: 1.19 step/s\n",
      "global step 10050, epoch: 3, batch: 190, loss: 0.2456,domain_loss: 0.0659 ,ce_loss: 0.2905., accu: 0.8927, speed: 1.18 step/s\n",
      "global step 10060, epoch: 3, batch: 200, loss: 0.1667,domain_loss: 0.0351 ,ce_loss: 0.1996., accu: 0.8930, speed: 1.18 step/s\n",
      "global step 10070, epoch: 3, batch: 210, loss: 0.1907,domain_loss: 0.0363 ,ce_loss: 0.2293., accu: 0.8929, speed: 1.20 step/s\n",
      "global step 10080, epoch: 3, batch: 220, loss: 0.2567,domain_loss: 0.0192 ,ce_loss: 0.3160., accu: 0.8931, speed: 1.18 step/s\n",
      "global step 10090, epoch: 3, batch: 230, loss: 0.1809,domain_loss: 0.0204 ,ce_loss: 0.2210., accu: 0.8930, speed: 1.19 step/s\n",
      "global step 10100, epoch: 3, batch: 240, loss: 0.2179,domain_loss: 0.0771 ,ce_loss: 0.2531., accu: 0.8936, speed: 1.18 step/s\n",
      "global step 10110, epoch: 3, batch: 250, loss: 0.2266,domain_loss: 0.0288 ,ce_loss: 0.2760., accu: 0.8933, speed: 1.18 step/s\n",
      "global step 10120, epoch: 3, batch: 260, loss: 0.1741,domain_loss: 0.0297 ,ce_loss: 0.2102., accu: 0.8934, speed: 1.19 step/s\n",
      "global step 10130, epoch: 3, batch: 270, loss: 0.1805,domain_loss: 0.0399 ,ce_loss: 0.2157., accu: 0.8939, speed: 1.18 step/s\n",
      "global step 10140, epoch: 3, batch: 280, loss: 0.1806,domain_loss: 0.1207 ,ce_loss: 0.1956., accu: 0.8938, speed: 1.18 step/s\n",
      "global step 10150, epoch: 3, batch: 290, loss: 0.1909,domain_loss: 0.0329 ,ce_loss: 0.2304., accu: 0.8940, speed: 1.18 step/s\n",
      "global step 10160, epoch: 3, batch: 300, loss: 0.2161,domain_loss: 0.0264 ,ce_loss: 0.2635., accu: 0.8939, speed: 1.18 step/s\n",
      "global step 10170, epoch: 3, batch: 310, loss: 0.2333,domain_loss: 0.0192 ,ce_loss: 0.2869., accu: 0.8934, speed: 1.19 step/s\n",
      "global step 10180, epoch: 3, batch: 320, loss: 0.1795,domain_loss: 0.0865 ,ce_loss: 0.2028., accu: 0.8932, speed: 1.19 step/s\n",
      "global step 10190, epoch: 3, batch: 330, loss: 0.2170,domain_loss: 0.0219 ,ce_loss: 0.2657., accu: 0.8930, speed: 1.21 step/s\n",
      "global step 10200, epoch: 3, batch: 340, loss: 0.2104,domain_loss: 0.0668 ,ce_loss: 0.2463., accu: 0.8925, speed: 1.19 step/s\n",
      "2022-09-29 02:07:47,010\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 10200, epoch: 3, batch: 340】，loss: 0.2104,domain_loss: 0.0668 ,ce_loss: 0.2463., accu: 0.8925,\n",
      "2022-09-29 02:07:47,317\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.1338, accuracy: 0.94[0.96],threshold:0.468, domain_acc:1.0,total_num:100\n",
      "global step 10210, epoch: 3, batch: 350, loss: 0.1693,domain_loss: 0.0096 ,ce_loss: 0.2092., accu: 0.8953, speed: 1.04 step/s\n",
      "global step 10220, epoch: 3, batch: 360, loss: 0.2307,domain_loss: 0.0543 ,ce_loss: 0.2748., accu: 0.8836, speed: 1.18 step/s\n",
      "global step 10230, epoch: 3, batch: 370, loss: 0.2427,domain_loss: 0.0649 ,ce_loss: 0.2872., accu: 0.8849, speed: 1.18 step/s\n",
      "global step 10240, epoch: 3, batch: 380, loss: 0.2330,domain_loss: 0.0166 ,ce_loss: 0.2870., accu: 0.8891, speed: 1.21 step/s\n",
      "global step 10250, epoch: 3, batch: 390, loss: 0.1808,domain_loss: 0.0175 ,ce_loss: 0.2216., accu: 0.8905, speed: 1.19 step/s\n",
      "global step 10260, epoch: 3, batch: 400, loss: 0.2271,domain_loss: 0.0100 ,ce_loss: 0.2814., accu: 0.8885, speed: 1.17 step/s\n",
      "global step 10270, epoch: 3, batch: 410, loss: 0.1771,domain_loss: 0.0939 ,ce_loss: 0.1979., accu: 0.8888, speed: 1.18 step/s\n",
      "global step 10280, epoch: 3, batch: 420, loss: 0.1544,domain_loss: 0.0335 ,ce_loss: 0.1846., accu: 0.8857, speed: 1.18 step/s\n",
      "global step 10290, epoch: 3, batch: 430, loss: 0.2244,domain_loss: 0.0303 ,ce_loss: 0.2729., accu: 0.8848, speed: 1.19 step/s\n",
      "global step 10300, epoch: 3, batch: 440, loss: 0.2117,domain_loss: 0.0544 ,ce_loss: 0.2510., accu: 0.8845, speed: 1.18 step/s\n",
      "global step 10310, epoch: 3, batch: 450, loss: 0.2208,domain_loss: 0.0297 ,ce_loss: 0.2686., accu: 0.8859, speed: 1.18 step/s\n",
      "global step 10320, epoch: 3, batch: 460, loss: 0.1998,domain_loss: 0.0338 ,ce_loss: 0.2413., accu: 0.8869, speed: 1.17 step/s\n",
      "global step 10330, epoch: 3, batch: 470, loss: 0.2214,domain_loss: 0.0383 ,ce_loss: 0.2672., accu: 0.8883, speed: 1.18 step/s\n",
      "global step 10340, epoch: 3, batch: 480, loss: 0.2132,domain_loss: 0.0127 ,ce_loss: 0.2633., accu: 0.8898, speed: 1.19 step/s\n",
      "global step 10350, epoch: 3, batch: 490, loss: 0.2594,domain_loss: 0.0328 ,ce_loss: 0.3160., accu: 0.8883, speed: 1.18 step/s\n",
      "global step 10360, epoch: 3, batch: 500, loss: 0.1973,domain_loss: 0.0097 ,ce_loss: 0.2442., accu: 0.8877, speed: 1.18 step/s\n",
      "global step 10370, epoch: 3, batch: 510, loss: 0.1775,domain_loss: 0.0315 ,ce_loss: 0.2140., accu: 0.8884, speed: 1.19 step/s\n",
      "global step 10380, epoch: 3, batch: 520, loss: 0.1730,domain_loss: 0.0151 ,ce_loss: 0.2125., accu: 0.8887, speed: 1.19 step/s\n",
      "global step 10390, epoch: 3, batch: 530, loss: 0.2370,domain_loss: 0.0462 ,ce_loss: 0.2847., accu: 0.8895, speed: 1.21 step/s\n",
      "global step 10400, epoch: 3, batch: 540, loss: 0.2253,domain_loss: 0.0189 ,ce_loss: 0.2769., accu: 0.8889, speed: 1.21 step/s\n",
      "global step 10410, epoch: 3, batch: 550, loss: 0.2238,domain_loss: 0.0720 ,ce_loss: 0.2618., accu: 0.8893, speed: 1.19 step/s\n",
      "global step 10420, epoch: 3, batch: 560, loss: 0.1908,domain_loss: 0.0387 ,ce_loss: 0.2288., accu: 0.8889, speed: 1.17 step/s\n",
      "global step 10430, epoch: 3, batch: 570, loss: 0.2432,domain_loss: 0.0448 ,ce_loss: 0.2928., accu: 0.8894, speed: 1.19 step/s\n",
      "global step 10440, epoch: 3, batch: 580, loss: 0.1963,domain_loss: 0.0177 ,ce_loss: 0.2409., accu: 0.8895, speed: 1.18 step/s\n",
      "global step 10450, epoch: 3, batch: 590, loss: 0.2697,domain_loss: 0.0627 ,ce_loss: 0.3215., accu: 0.8898, speed: 1.20 step/s\n",
      "global step 10460, epoch: 3, batch: 600, loss: 0.1638,domain_loss: 0.0113 ,ce_loss: 0.2019., accu: 0.8900, speed: 1.19 step/s\n",
      "global step 10470, epoch: 3, batch: 610, loss: 0.2822,domain_loss: 0.0063 ,ce_loss: 0.3511., accu: 0.8897, speed: 1.18 step/s\n",
      "global step 10480, epoch: 3, batch: 620, loss: 0.2034,domain_loss: 0.0559 ,ce_loss: 0.2403., accu: 0.8896, speed: 1.18 step/s\n",
      "global step 10490, epoch: 3, batch: 630, loss: 0.1933,domain_loss: 0.0204 ,ce_loss: 0.2365., accu: 0.8898, speed: 1.19 step/s\n",
      "global step 10500, epoch: 3, batch: 640, loss: 0.1868,domain_loss: 0.0107 ,ce_loss: 0.2308., accu: 0.8899, speed: 1.18 step/s\n",
      "2022-09-29 02:12:01,265\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 10500, epoch: 3, batch: 640】，loss: 0.1868,domain_loss: 0.0107 ,ce_loss: 0.2308., accu: 0.8899,\n",
      "2022-09-29 02:12:01,576\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.11437, accuracy: 0.96[0.97],threshold:0.321, domain_acc:1.0,total_num:100\n",
      "global step 10510, epoch: 3, batch: 650, loss: 0.2465,domain_loss: 0.0671 ,ce_loss: 0.2913., accu: 0.8805, speed: 0.96 step/s\n",
      "global step 10520, epoch: 3, batch: 660, loss: 0.1439,domain_loss: 0.0502 ,ce_loss: 0.1673., accu: 0.8902, speed: 1.19 step/s\n",
      "global step 10530, epoch: 3, batch: 670, loss: 0.1823,domain_loss: 0.0635 ,ce_loss: 0.2120., accu: 0.8898, speed: 1.19 step/s\n",
      "global step 10540, epoch: 3, batch: 680, loss: 0.1853,domain_loss: 0.1084 ,ce_loss: 0.2045., accu: 0.8932, speed: 1.18 step/s\n",
      "global step 10550, epoch: 3, batch: 690, loss: 0.2096,domain_loss: 0.0472 ,ce_loss: 0.2502., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 10560, epoch: 3, batch: 700, loss: 0.2035,domain_loss: 0.0565 ,ce_loss: 0.2403., accu: 0.8932, speed: 1.19 step/s\n",
      "global step 10570, epoch: 3, batch: 710, loss: 0.2211,domain_loss: 0.0522 ,ce_loss: 0.2633., accu: 0.8931, speed: 1.18 step/s\n",
      "global step 10580, epoch: 3, batch: 720, loss: 0.2241,domain_loss: 0.0249 ,ce_loss: 0.2739., accu: 0.8942, speed: 1.20 step/s\n",
      "global step 10590, epoch: 3, batch: 730, loss: 0.2236,domain_loss: 0.0179 ,ce_loss: 0.2751., accu: 0.8939, speed: 1.18 step/s\n",
      "global step 10600, epoch: 3, batch: 740, loss: 0.3080,domain_loss: 0.0099 ,ce_loss: 0.3825., accu: 0.8930, speed: 1.19 step/s\n",
      "global step 10610, epoch: 3, batch: 750, loss: 0.1656,domain_loss: 0.0387 ,ce_loss: 0.1973., accu: 0.8929, speed: 1.19 step/s\n",
      "global step 10620, epoch: 3, batch: 760, loss: 0.2087,domain_loss: 0.0859 ,ce_loss: 0.2394., accu: 0.8932, speed: 1.20 step/s\n",
      "global step 10630, epoch: 3, batch: 770, loss: 0.1691,domain_loss: 0.0286 ,ce_loss: 0.2042., accu: 0.8926, speed: 1.18 step/s\n",
      "global step 10640, epoch: 3, batch: 780, loss: 0.1652,domain_loss: 0.0311 ,ce_loss: 0.1988., accu: 0.8922, speed: 1.17 step/s\n",
      "global step 10650, epoch: 3, batch: 790, loss: 0.1846,domain_loss: 0.0434 ,ce_loss: 0.2199., accu: 0.8924, speed: 1.19 step/s\n",
      "global step 10660, epoch: 3, batch: 800, loss: 0.1993,domain_loss: 0.0425 ,ce_loss: 0.2385., accu: 0.8930, speed: 1.19 step/s\n",
      "global step 10670, epoch: 3, batch: 810, loss: 0.2214,domain_loss: 0.0250 ,ce_loss: 0.2705., accu: 0.8924, speed: 1.17 step/s\n",
      "global step 10680, epoch: 3, batch: 820, loss: 0.1513,domain_loss: 0.0157 ,ce_loss: 0.1852., accu: 0.8923, speed: 1.20 step/s\n",
      "global step 10690, epoch: 3, batch: 830, loss: 0.2629,domain_loss: 0.0141 ,ce_loss: 0.3251., accu: 0.8926, speed: 1.20 step/s\n",
      "global step 10700, epoch: 3, batch: 840, loss: 0.2474,domain_loss: 0.0157 ,ce_loss: 0.3053., accu: 0.8918, speed: 1.18 step/s\n",
      "global step 10710, epoch: 3, batch: 850, loss: 0.1743,domain_loss: 0.0327 ,ce_loss: 0.2097., accu: 0.8913, speed: 1.18 step/s\n",
      "global step 10720, epoch: 3, batch: 860, loss: 0.1807,domain_loss: 0.0096 ,ce_loss: 0.2235., accu: 0.8919, speed: 1.17 step/s\n",
      "global step 10730, epoch: 3, batch: 870, loss: 0.1952,domain_loss: 0.0447 ,ce_loss: 0.2329., accu: 0.8916, speed: 1.17 step/s\n",
      "global step 10740, epoch: 3, batch: 880, loss: 0.1766,domain_loss: 0.0444 ,ce_loss: 0.2096., accu: 0.8914, speed: 1.17 step/s\n",
      "global step 10750, epoch: 3, batch: 890, loss: 0.2041,domain_loss: 0.0439 ,ce_loss: 0.2442., accu: 0.8904, speed: 1.18 step/s\n",
      "global step 10760, epoch: 3, batch: 900, loss: 0.2358,domain_loss: 0.0264 ,ce_loss: 0.2881., accu: 0.8906, speed: 1.18 step/s\n",
      "global step 10770, epoch: 3, batch: 910, loss: 0.2441,domain_loss: 0.0255 ,ce_loss: 0.2987., accu: 0.8907, speed: 1.19 step/s\n",
      "global step 10780, epoch: 3, batch: 920, loss: 0.2200,domain_loss: 0.0154 ,ce_loss: 0.2711., accu: 0.8906, speed: 1.17 step/s\n",
      "global step 10790, epoch: 3, batch: 930, loss: 0.2471,domain_loss: 0.0373 ,ce_loss: 0.2995., accu: 0.8904, speed: 1.17 step/s\n",
      "global step 10800, epoch: 3, batch: 940, loss: 0.1628,domain_loss: 0.0859 ,ce_loss: 0.1820., accu: 0.8904, speed: 1.17 step/s\n",
      "2022-09-29 02:16:17,008\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 10800, epoch: 3, batch: 940】，loss: 0.1628,domain_loss: 0.0859 ,ce_loss: 0.1820., accu: 0.8904,\n",
      "2022-09-29 02:16:17,316\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.11399, accuracy: 0.95[0.96],threshold:0.376, domain_acc:1.0,total_num:100\n",
      "2022-09-29 02:16:18,211\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 10810, epoch: 3, batch: 950, loss: 0.1269,domain_loss: 0.0110 ,ce_loss: 0.1559., accu: 0.9109, speed: 1.04 step/s\n",
      "global step 10820, epoch: 3, batch: 960, loss: 0.1953,domain_loss: 0.0204 ,ce_loss: 0.2391., accu: 0.9039, speed: 1.20 step/s\n",
      "global step 10830, epoch: 3, batch: 970, loss: 0.1763,domain_loss: 0.0251 ,ce_loss: 0.2141., accu: 0.9005, speed: 1.18 step/s\n",
      "global step 10840, epoch: 3, batch: 980, loss: 0.2072,domain_loss: 0.0209 ,ce_loss: 0.2537., accu: 0.8963, speed: 1.19 step/s\n",
      "global step 10850, epoch: 3, batch: 990, loss: 0.1968,domain_loss: 0.0574 ,ce_loss: 0.2317., accu: 0.8955, speed: 1.20 step/s\n",
      "global step 10860, epoch: 3, batch: 1000, loss: 0.1527,domain_loss: 0.0384 ,ce_loss: 0.1813., accu: 0.8973, speed: 1.20 step/s\n",
      "global step 10870, epoch: 3, batch: 1010, loss: 0.2166,domain_loss: 0.0433 ,ce_loss: 0.2600., accu: 0.8950, speed: 1.19 step/s\n",
      "global step 10880, epoch: 3, batch: 1020, loss: 0.1413,domain_loss: 0.0487 ,ce_loss: 0.1645., accu: 0.8964, speed: 1.21 step/s\n",
      "global step 10890, epoch: 3, batch: 1030, loss: 0.2209,domain_loss: 0.0883 ,ce_loss: 0.2540., accu: 0.8952, speed: 1.17 step/s\n",
      "global step 10900, epoch: 3, batch: 1040, loss: 0.2355,domain_loss: 0.0120 ,ce_loss: 0.2914., accu: 0.8955, speed: 1.18 step/s\n",
      "global step 10910, epoch: 3, batch: 1050, loss: 0.2172,domain_loss: 0.0558 ,ce_loss: 0.2576., accu: 0.8963, speed: 1.17 step/s\n",
      "global step 10920, epoch: 3, batch: 1060, loss: 0.2394,domain_loss: 0.0318 ,ce_loss: 0.2913., accu: 0.8951, speed: 1.19 step/s\n",
      "global step 10930, epoch: 3, batch: 1070, loss: 0.2018,domain_loss: 0.0689 ,ce_loss: 0.2350., accu: 0.8950, speed: 1.17 step/s\n",
      "global step 10940, epoch: 3, batch: 1080, loss: 0.2045,domain_loss: 0.0286 ,ce_loss: 0.2484., accu: 0.8945, speed: 1.17 step/s\n",
      "global step 10950, epoch: 3, batch: 1090, loss: 0.1375,domain_loss: 0.0468 ,ce_loss: 0.1602., accu: 0.8946, speed: 1.17 step/s\n",
      "global step 10960, epoch: 3, batch: 1100, loss: 0.2568,domain_loss: 0.0142 ,ce_loss: 0.3175., accu: 0.8938, speed: 1.18 step/s\n",
      "global step 10970, epoch: 3, batch: 1110, loss: 0.1936,domain_loss: 0.0104 ,ce_loss: 0.2393., accu: 0.8933, speed: 1.19 step/s\n",
      "global step 10980, epoch: 3, batch: 1120, loss: 0.2506,domain_loss: 0.0975 ,ce_loss: 0.2889., accu: 0.8933, speed: 1.19 step/s\n",
      "global step 10990, epoch: 3, batch: 1130, loss: 0.2231,domain_loss: 0.0105 ,ce_loss: 0.2763., accu: 0.8932, speed: 1.18 step/s\n",
      "global step 11000, epoch: 3, batch: 1140, loss: 0.2207,domain_loss: 0.0535 ,ce_loss: 0.2625., accu: 0.8930, speed: 1.17 step/s\n",
      "global step 11010, epoch: 3, batch: 1150, loss: 0.1741,domain_loss: 0.0684 ,ce_loss: 0.2005., accu: 0.8933, speed: 1.18 step/s\n",
      "global step 11020, epoch: 3, batch: 1160, loss: 0.1635,domain_loss: 0.0190 ,ce_loss: 0.1996., accu: 0.8942, speed: 1.19 step/s\n",
      "global step 11030, epoch: 3, batch: 1170, loss: 0.2460,domain_loss: 0.0509 ,ce_loss: 0.2948., accu: 0.8947, speed: 1.19 step/s\n",
      "global step 11040, epoch: 3, batch: 1180, loss: 0.2281,domain_loss: 0.0390 ,ce_loss: 0.2754., accu: 0.8945, speed: 1.23 step/s\n",
      "global step 11050, epoch: 3, batch: 1190, loss: 0.2870,domain_loss: 0.0040 ,ce_loss: 0.3577., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 11060, epoch: 3, batch: 1200, loss: 0.1955,domain_loss: 0.0488 ,ce_loss: 0.2322., accu: 0.8947, speed: 1.19 step/s\n",
      "global step 11070, epoch: 3, batch: 1210, loss: 0.1509,domain_loss: 0.0544 ,ce_loss: 0.1751., accu: 0.8946, speed: 1.18 step/s\n",
      "global step 11080, epoch: 3, batch: 1220, loss: 0.2758,domain_loss: 0.0331 ,ce_loss: 0.3364., accu: 0.8943, speed: 1.18 step/s\n",
      "global step 11090, epoch: 3, batch: 1230, loss: 0.2384,domain_loss: 0.0326 ,ce_loss: 0.2898., accu: 0.8942, speed: 1.17 step/s\n",
      "global step 11100, epoch: 3, batch: 1240, loss: 0.2929,domain_loss: 0.0503 ,ce_loss: 0.3535., accu: 0.8940, speed: 1.18 step/s\n",
      "2022-09-29 02:20:31,309\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 11100, epoch: 3, batch: 1240】，loss: 0.2929,domain_loss: 0.0503 ,ce_loss: 0.3535., accu: 0.8940,\n",
      "2022-09-29 02:20:31,612\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.14158, accuracy: 0.95[0.96],threshold:0.38, domain_acc:1.0,total_num:100\n",
      "global step 11110, epoch: 3, batch: 1250, loss: 0.2316,domain_loss: 0.0122 ,ce_loss: 0.2865., accu: 0.8945, speed: 1.06 step/s\n",
      "global step 11120, epoch: 3, batch: 1260, loss: 0.1391,domain_loss: 0.0081 ,ce_loss: 0.1718., accu: 0.8914, speed: 1.18 step/s\n",
      "global step 11130, epoch: 3, batch: 1270, loss: 0.1230,domain_loss: 0.0451 ,ce_loss: 0.1425., accu: 0.8906, speed: 1.17 step/s\n",
      "global step 11140, epoch: 3, batch: 1280, loss: 0.1905,domain_loss: 0.0351 ,ce_loss: 0.2293., accu: 0.8941, speed: 1.18 step/s\n",
      "global step 11150, epoch: 3, batch: 1290, loss: 0.1983,domain_loss: 0.0607 ,ce_loss: 0.2326., accu: 0.8928, speed: 1.17 step/s\n",
      "global step 11160, epoch: 3, batch: 1300, loss: 0.1215,domain_loss: 0.0163 ,ce_loss: 0.1478., accu: 0.8902, speed: 1.19 step/s\n",
      "global step 11170, epoch: 3, batch: 1310, loss: 0.1673,domain_loss: 0.0097 ,ce_loss: 0.2067., accu: 0.8907, speed: 1.18 step/s\n",
      "global step 11180, epoch: 3, batch: 1320, loss: 0.1747,domain_loss: 0.0146 ,ce_loss: 0.2147., accu: 0.8908, speed: 1.20 step/s\n",
      "global step 11190, epoch: 3, batch: 1330, loss: 0.1685,domain_loss: 0.0515 ,ce_loss: 0.1978., accu: 0.8923, speed: 1.17 step/s\n",
      "global step 11200, epoch: 3, batch: 1340, loss: 0.1130,domain_loss: 0.0062 ,ce_loss: 0.1397., accu: 0.8925, speed: 1.17 step/s\n",
      "global step 11210, epoch: 3, batch: 1350, loss: 0.1854,domain_loss: 0.0341 ,ce_loss: 0.2232., accu: 0.8911, speed: 1.17 step/s\n",
      "global step 11220, epoch: 3, batch: 1360, loss: 0.2568,domain_loss: 0.0715 ,ce_loss: 0.3032., accu: 0.8906, speed: 1.20 step/s\n",
      "global step 11230, epoch: 3, batch: 1370, loss: 0.1985,domain_loss: 0.0362 ,ce_loss: 0.2391., accu: 0.8908, speed: 1.18 step/s\n",
      "global step 11240, epoch: 3, batch: 1380, loss: 0.1795,domain_loss: 0.0145 ,ce_loss: 0.2208., accu: 0.8905, speed: 1.19 step/s\n",
      "global step 11250, epoch: 3, batch: 1390, loss: 0.2077,domain_loss: 0.0336 ,ce_loss: 0.2513., accu: 0.8905, speed: 1.18 step/s\n",
      "global step 11260, epoch: 3, batch: 1400, loss: 0.2305,domain_loss: 0.1402 ,ce_loss: 0.2531., accu: 0.8906, speed: 1.18 step/s\n",
      "global step 11270, epoch: 3, batch: 1410, loss: 0.1931,domain_loss: 0.0223 ,ce_loss: 0.2358., accu: 0.8910, speed: 1.19 step/s\n",
      "global step 11280, epoch: 3, batch: 1420, loss: 0.2819,domain_loss: 0.0528 ,ce_loss: 0.3392., accu: 0.8918, speed: 1.19 step/s\n",
      "global step 11290, epoch: 3, batch: 1430, loss: 0.1808,domain_loss: 0.0055 ,ce_loss: 0.2247., accu: 0.8918, speed: 1.16 step/s\n",
      "global step 11300, epoch: 3, batch: 1440, loss: 0.2013,domain_loss: 0.0127 ,ce_loss: 0.2485., accu: 0.8920, speed: 1.17 step/s\n",
      "global step 11310, epoch: 3, batch: 1450, loss: 0.2916,domain_loss: 0.1607 ,ce_loss: 0.3243., accu: 0.8917, speed: 1.18 step/s\n",
      "global step 11320, epoch: 3, batch: 1460, loss: 0.1718,domain_loss: 0.0253 ,ce_loss: 0.2085., accu: 0.8920, speed: 1.18 step/s\n",
      "global step 11330, epoch: 3, batch: 1470, loss: 0.1393,domain_loss: 0.0281 ,ce_loss: 0.1671., accu: 0.8928, speed: 1.20 step/s\n",
      "global step 11340, epoch: 3, batch: 1480, loss: 0.2013,domain_loss: 0.0080 ,ce_loss: 0.2496., accu: 0.8925, speed: 1.18 step/s\n",
      "global step 11350, epoch: 3, batch: 1490, loss: 0.2380,domain_loss: 0.0619 ,ce_loss: 0.2820., accu: 0.8926, speed: 1.20 step/s\n",
      "global step 11360, epoch: 3, batch: 1500, loss: 0.2415,domain_loss: 0.0373 ,ce_loss: 0.2926., accu: 0.8925, speed: 1.20 step/s\n",
      "global step 11370, epoch: 3, batch: 1510, loss: 0.2155,domain_loss: 0.0465 ,ce_loss: 0.2578., accu: 0.8926, speed: 1.20 step/s\n",
      "global step 11380, epoch: 3, batch: 1520, loss: 0.2156,domain_loss: 0.0306 ,ce_loss: 0.2618., accu: 0.8929, speed: 1.18 step/s\n",
      "global step 11390, epoch: 3, batch: 1530, loss: 0.1687,domain_loss: 0.0155 ,ce_loss: 0.2070., accu: 0.8932, speed: 1.18 step/s\n",
      "global step 11400, epoch: 3, batch: 1540, loss: 0.2823,domain_loss: 0.0186 ,ce_loss: 0.3482., accu: 0.8932, speed: 1.20 step/s\n",
      "2022-09-29 02:24:45,703\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 11400, epoch: 3, batch: 1540】，loss: 0.2823,domain_loss: 0.0186 ,ce_loss: 0.3482., accu: 0.8932,\n",
      "2022-09-29 02:24:46,006\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.13353, accuracy: 0.95[0.96],threshold:0.363, domain_acc:1.0,total_num:100\n",
      "global step 11410, epoch: 3, batch: 1550, loss: 0.2500,domain_loss: 0.0510 ,ce_loss: 0.2997., accu: 0.8828, speed: 1.03 step/s\n",
      "global step 11420, epoch: 3, batch: 1560, loss: 0.2364,domain_loss: 0.0102 ,ce_loss: 0.2929., accu: 0.8871, speed: 1.18 step/s\n",
      "global step 11430, epoch: 3, batch: 1570, loss: 0.2096,domain_loss: 0.0527 ,ce_loss: 0.2488., accu: 0.8852, speed: 1.18 step/s\n",
      "global step 11440, epoch: 3, batch: 1580, loss: 0.2287,domain_loss: 0.1146 ,ce_loss: 0.2572., accu: 0.8826, speed: 1.21 step/s\n",
      "global step 11450, epoch: 3, batch: 1590, loss: 0.1895,domain_loss: 0.0436 ,ce_loss: 0.2260., accu: 0.8839, speed: 1.17 step/s\n",
      "global step 11460, epoch: 3, batch: 1600, loss: 0.1887,domain_loss: 0.0407 ,ce_loss: 0.2257., accu: 0.8858, speed: 1.19 step/s\n",
      "global step 11470, epoch: 3, batch: 1610, loss: 0.2010,domain_loss: 0.0447 ,ce_loss: 0.2401., accu: 0.8873, speed: 1.18 step/s\n",
      "global step 11480, epoch: 3, batch: 1620, loss: 0.2263,domain_loss: 0.0393 ,ce_loss: 0.2730., accu: 0.8875, speed: 1.18 step/s\n",
      "global step 11490, epoch: 3, batch: 1630, loss: 0.2434,domain_loss: 0.0923 ,ce_loss: 0.2812., accu: 0.8872, speed: 1.17 step/s\n",
      "global step 11500, epoch: 3, batch: 1640, loss: 0.2033,domain_loss: 0.0055 ,ce_loss: 0.2527., accu: 0.8877, speed: 1.19 step/s\n",
      "global step 11510, epoch: 3, batch: 1650, loss: 0.2100,domain_loss: 0.0341 ,ce_loss: 0.2540., accu: 0.8878, speed: 1.17 step/s\n",
      "global step 11520, epoch: 3, batch: 1660, loss: 0.1823,domain_loss: 0.0355 ,ce_loss: 0.2190., accu: 0.8888, speed: 1.17 step/s\n",
      "global step 11530, epoch: 3, batch: 1670, loss: 0.2453,domain_loss: 0.0621 ,ce_loss: 0.2911., accu: 0.8892, speed: 1.17 step/s\n",
      "global step 11540, epoch: 3, batch: 1680, loss: 0.1977,domain_loss: 0.0382 ,ce_loss: 0.2375., accu: 0.8895, speed: 1.17 step/s\n",
      "global step 11550, epoch: 3, batch: 1690, loss: 0.2675,domain_loss: 0.0069 ,ce_loss: 0.3327., accu: 0.8895, speed: 1.18 step/s\n",
      "global step 11560, epoch: 3, batch: 1700, loss: 0.2221,domain_loss: 0.0077 ,ce_loss: 0.2756., accu: 0.8896, speed: 1.17 step/s\n",
      "global step 11570, epoch: 3, batch: 1710, loss: 0.2244,domain_loss: 0.0299 ,ce_loss: 0.2731., accu: 0.8901, speed: 1.17 step/s\n",
      "global step 11580, epoch: 3, batch: 1720, loss: 0.1931,domain_loss: 0.0538 ,ce_loss: 0.2279., accu: 0.8906, speed: 1.18 step/s\n",
      "global step 11590, epoch: 3, batch: 1730, loss: 0.2139,domain_loss: 0.0141 ,ce_loss: 0.2639., accu: 0.8908, speed: 1.19 step/s\n",
      "global step 11600, epoch: 3, batch: 1740, loss: 0.2624,domain_loss: 0.1000 ,ce_loss: 0.3030., accu: 0.8911, speed: 1.19 step/s\n",
      "global step 11610, epoch: 3, batch: 1750, loss: 0.2538,domain_loss: 0.0635 ,ce_loss: 0.3013., accu: 0.8911, speed: 1.17 step/s\n",
      "global step 11620, epoch: 3, batch: 1760, loss: 0.1186,domain_loss: 0.0243 ,ce_loss: 0.1422., accu: 0.8917, speed: 1.18 step/s\n",
      "global step 11630, epoch: 3, batch: 1770, loss: 0.2221,domain_loss: 0.1072 ,ce_loss: 0.2508., accu: 0.8914, speed: 1.18 step/s\n",
      "global step 11640, epoch: 3, batch: 1780, loss: 0.2210,domain_loss: 0.0311 ,ce_loss: 0.2685., accu: 0.8911, speed: 1.18 step/s\n",
      "global step 11650, epoch: 3, batch: 1790, loss: 0.1875,domain_loss: 0.0483 ,ce_loss: 0.2223., accu: 0.8913, speed: 1.20 step/s\n",
      "global step 11660, epoch: 3, batch: 1800, loss: 0.2164,domain_loss: 0.0195 ,ce_loss: 0.2656., accu: 0.8914, speed: 1.19 step/s\n",
      "global step 11670, epoch: 3, batch: 1810, loss: 0.1769,domain_loss: 0.0065 ,ce_loss: 0.2195., accu: 0.8912, speed: 1.19 step/s\n",
      "global step 11680, epoch: 3, batch: 1820, loss: 0.2321,domain_loss: 0.0332 ,ce_loss: 0.2818., accu: 0.8910, speed: 1.19 step/s\n",
      "global step 11690, epoch: 3, batch: 1830, loss: 0.2071,domain_loss: 0.0064 ,ce_loss: 0.2573., accu: 0.8911, speed: 1.18 step/s\n",
      "global step 11700, epoch: 3, batch: 1840, loss: 0.2001,domain_loss: 0.0186 ,ce_loss: 0.2455., accu: 0.8909, speed: 1.18 step/s\n",
      "2022-09-29 02:29:00,928\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 11700, epoch: 3, batch: 1840】，loss: 0.2001,domain_loss: 0.0186 ,ce_loss: 0.2455., accu: 0.8909,\n",
      "2022-09-29 02:29:01,239\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.1312, accuracy: 0.96[0.96],threshold:0.39, domain_acc:1.0,total_num:100\n",
      "global step 11710, epoch: 3, batch: 1850, loss: 0.1909,domain_loss: 0.0454 ,ce_loss: 0.2273., accu: 0.8812, speed: 1.04 step/s\n",
      "global step 11720, epoch: 3, batch: 1860, loss: 0.2179,domain_loss: 0.0172 ,ce_loss: 0.2681., accu: 0.8887, speed: 1.17 step/s\n",
      "global step 11730, epoch: 3, batch: 1870, loss: 0.1285,domain_loss: 0.0261 ,ce_loss: 0.1542., accu: 0.8901, speed: 1.18 step/s\n",
      "global step 11740, epoch: 3, batch: 1880, loss: 0.1384,domain_loss: 0.0076 ,ce_loss: 0.1711., accu: 0.8939, speed: 1.19 step/s\n",
      "global step 11750, epoch: 3, batch: 1890, loss: 0.2113,domain_loss: 0.0153 ,ce_loss: 0.2603., accu: 0.8928, speed: 1.17 step/s\n",
      "global step 11760, epoch: 3, batch: 1900, loss: 0.2759,domain_loss: 0.0255 ,ce_loss: 0.3385., accu: 0.8941, speed: 1.17 step/s\n",
      "global step 11770, epoch: 3, batch: 1910, loss: 0.1630,domain_loss: 0.0729 ,ce_loss: 0.1856., accu: 0.8946, speed: 1.18 step/s\n",
      "global step 11780, epoch: 3, batch: 1920, loss: 0.1877,domain_loss: 0.0196 ,ce_loss: 0.2297., accu: 0.8938, speed: 1.18 step/s\n",
      "global step 11790, epoch: 3, batch: 1930, loss: 0.2770,domain_loss: 0.0520 ,ce_loss: 0.3333., accu: 0.8944, speed: 1.17 step/s\n",
      "global step 11800, epoch: 3, batch: 1940, loss: 0.2664,domain_loss: 0.0335 ,ce_loss: 0.3246., accu: 0.8929, speed: 1.17 step/s\n",
      "global step 11810, epoch: 3, batch: 1950, loss: 0.1495,domain_loss: 0.0360 ,ce_loss: 0.1778., accu: 0.8928, speed: 1.18 step/s\n",
      "global step 11820, epoch: 3, batch: 1960, loss: 0.1930,domain_loss: 0.0075 ,ce_loss: 0.2394., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 11830, epoch: 3, batch: 1970, loss: 0.2051,domain_loss: 0.0068 ,ce_loss: 0.2547., accu: 0.8944, speed: 1.18 step/s\n",
      "global step 11840, epoch: 3, batch: 1980, loss: 0.2078,domain_loss: 0.0100 ,ce_loss: 0.2573., accu: 0.8944, speed: 1.18 step/s\n",
      "global step 11850, epoch: 3, batch: 1990, loss: 0.2591,domain_loss: 0.0118 ,ce_loss: 0.3209., accu: 0.8944, speed: 1.17 step/s\n",
      "global step 11860, epoch: 3, batch: 2000, loss: 0.2031,domain_loss: 0.0247 ,ce_loss: 0.2477., accu: 0.8941, speed: 1.19 step/s\n",
      "global step 11870, epoch: 3, batch: 2010, loss: 0.2418,domain_loss: 0.0403 ,ce_loss: 0.2921., accu: 0.8943, speed: 1.19 step/s\n",
      "global step 11880, epoch: 3, batch: 2020, loss: 0.1687,domain_loss: 0.0260 ,ce_loss: 0.2043., accu: 0.8941, speed: 1.20 step/s\n",
      "global step 11890, epoch: 3, batch: 2030, loss: 0.2361,domain_loss: 0.0142 ,ce_loss: 0.2916., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 11900, epoch: 3, batch: 2040, loss: 0.1691,domain_loss: 0.0223 ,ce_loss: 0.2058., accu: 0.8939, speed: 1.18 step/s\n",
      "global step 11910, epoch: 3, batch: 2050, loss: 0.2520,domain_loss: 0.0188 ,ce_loss: 0.3103., accu: 0.8938, speed: 1.17 step/s\n",
      "global step 11920, epoch: 3, batch: 2060, loss: 0.2223,domain_loss: 0.0442 ,ce_loss: 0.2668., accu: 0.8933, speed: 1.17 step/s\n",
      "global step 11930, epoch: 3, batch: 2070, loss: 0.2084,domain_loss: 0.0092 ,ce_loss: 0.2582., accu: 0.8935, speed: 1.18 step/s\n",
      "global step 11940, epoch: 3, batch: 2080, loss: 0.2887,domain_loss: 0.0368 ,ce_loss: 0.3517., accu: 0.8932, speed: 1.17 step/s\n",
      "global step 11950, epoch: 3, batch: 2090, loss: 0.1844,domain_loss: 0.0040 ,ce_loss: 0.2295., accu: 0.8933, speed: 1.18 step/s\n",
      "global step 11960, epoch: 3, batch: 2100, loss: 0.1582,domain_loss: 0.0095 ,ce_loss: 0.1954., accu: 0.8932, speed: 1.17 step/s\n",
      "global step 11970, epoch: 3, batch: 2110, loss: 0.2271,domain_loss: 0.0550 ,ce_loss: 0.2701., accu: 0.8933, speed: 1.17 step/s\n",
      "global step 11980, epoch: 3, batch: 2120, loss: 0.1658,domain_loss: 0.0476 ,ce_loss: 0.1953., accu: 0.8936, speed: 1.19 step/s\n",
      "global step 11990, epoch: 3, batch: 2130, loss: 0.1473,domain_loss: 0.0514 ,ce_loss: 0.1713., accu: 0.8938, speed: 1.19 step/s\n",
      "global step 12000, epoch: 3, batch: 2140, loss: 0.2011,domain_loss: 0.0063 ,ce_loss: 0.2498., accu: 0.8938, speed: 1.18 step/s\n",
      "2022-09-29 02:33:16,563\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 12000, epoch: 3, batch: 2140】，loss: 0.2011,domain_loss: 0.0063 ,ce_loss: 0.2498., accu: 0.8938,\n",
      "2022-09-29 02:33:16,871\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.1296, accuracy: 0.95[0.96],threshold:0.279, domain_acc:1.0,total_num:100\n",
      "2022-09-29 02:33:17,743\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 12010, epoch: 3, batch: 2150, loss: 0.1344,domain_loss: 0.0384 ,ce_loss: 0.1584., accu: 0.9047, speed: 1.05 step/s\n",
      "global step 12020, epoch: 3, batch: 2160, loss: 0.1610,domain_loss: 0.0668 ,ce_loss: 0.1845., accu: 0.9031, speed: 1.17 step/s\n",
      "global step 12030, epoch: 3, batch: 2170, loss: 0.1467,domain_loss: 0.0073 ,ce_loss: 0.1816., accu: 0.8997, speed: 1.19 step/s\n",
      "global step 12040, epoch: 3, batch: 2180, loss: 0.2634,domain_loss: 0.0146 ,ce_loss: 0.3256., accu: 0.8928, speed: 1.18 step/s\n",
      "global step 12050, epoch: 3, batch: 2190, loss: 0.1590,domain_loss: 0.0661 ,ce_loss: 0.1822., accu: 0.8931, speed: 1.17 step/s\n",
      "global step 12060, epoch: 3, batch: 2200, loss: 0.1765,domain_loss: 0.0262 ,ce_loss: 0.2140., accu: 0.8934, speed: 1.17 step/s\n",
      "global step 12070, epoch: 3, batch: 2210, loss: 0.2107,domain_loss: 0.0263 ,ce_loss: 0.2568., accu: 0.8924, speed: 1.17 step/s\n",
      "global step 12080, epoch: 3, batch: 2220, loss: 0.2709,domain_loss: 0.0457 ,ce_loss: 0.3272., accu: 0.8939, speed: 1.17 step/s\n",
      "global step 12090, epoch: 3, batch: 2230, loss: 0.2190,domain_loss: 0.0165 ,ce_loss: 0.2697., accu: 0.8941, speed: 1.18 step/s\n",
      "global step 12100, epoch: 3, batch: 2240, loss: 0.1482,domain_loss: 0.0039 ,ce_loss: 0.1843., accu: 0.8955, speed: 1.17 step/s\n",
      "global step 12110, epoch: 3, batch: 2250, loss: 0.1776,domain_loss: 0.0036 ,ce_loss: 0.2211., accu: 0.8947, speed: 1.21 step/s\n",
      "global step 12120, epoch: 3, batch: 2260, loss: 0.2444,domain_loss: 0.1061 ,ce_loss: 0.2790., accu: 0.8954, speed: 1.18 step/s\n",
      "global step 12130, epoch: 3, batch: 2270, loss: 0.2340,domain_loss: 0.0158 ,ce_loss: 0.2885., accu: 0.8956, speed: 1.18 step/s\n",
      "global step 12140, epoch: 3, batch: 2280, loss: 0.1661,domain_loss: 0.0163 ,ce_loss: 0.2036., accu: 0.8948, speed: 1.18 step/s\n",
      "global step 12150, epoch: 3, batch: 2290, loss: 0.1606,domain_loss: 0.0023 ,ce_loss: 0.2002., accu: 0.8935, speed: 1.18 step/s\n",
      "global step 12160, epoch: 3, batch: 2300, loss: 0.2275,domain_loss: 0.0265 ,ce_loss: 0.2777., accu: 0.8933, speed: 1.17 step/s\n",
      "global step 12170, epoch: 3, batch: 2310, loss: 0.2393,domain_loss: 0.0313 ,ce_loss: 0.2913., accu: 0.8927, speed: 1.18 step/s\n",
      "global step 12180, epoch: 3, batch: 2320, loss: 0.2002,domain_loss: 0.0416 ,ce_loss: 0.2398., accu: 0.8927, speed: 1.18 step/s\n",
      "global step 12190, epoch: 3, batch: 2330, loss: 0.1332,domain_loss: 0.0524 ,ce_loss: 0.1534., accu: 0.8935, speed: 1.19 step/s\n",
      "global step 12200, epoch: 3, batch: 2340, loss: 0.1313,domain_loss: 0.0501 ,ce_loss: 0.1516., accu: 0.8933, speed: 1.17 step/s\n",
      "global step 12210, epoch: 3, batch: 2350, loss: 0.1641,domain_loss: 0.0175 ,ce_loss: 0.2008., accu: 0.8936, speed: 1.18 step/s\n",
      "global step 12220, epoch: 3, batch: 2360, loss: 0.1942,domain_loss: 0.0274 ,ce_loss: 0.2359., accu: 0.8938, speed: 1.19 step/s\n",
      "global step 12230, epoch: 3, batch: 2370, loss: 0.1490,domain_loss: 0.1121 ,ce_loss: 0.1582., accu: 0.8944, speed: 1.19 step/s\n",
      "global step 12240, epoch: 3, batch: 2380, loss: 0.1381,domain_loss: 0.0257 ,ce_loss: 0.1663., accu: 0.8944, speed: 1.17 step/s\n",
      "global step 12250, epoch: 3, batch: 2390, loss: 0.1629,domain_loss: 0.0211 ,ce_loss: 0.1984., accu: 0.8949, speed: 1.19 step/s\n",
      "global step 12260, epoch: 3, batch: 2400, loss: 0.1898,domain_loss: 0.0512 ,ce_loss: 0.2244., accu: 0.8953, speed: 1.18 step/s\n",
      "global step 12270, epoch: 3, batch: 2410, loss: 0.2291,domain_loss: 0.0086 ,ce_loss: 0.2843., accu: 0.8949, speed: 1.17 step/s\n",
      "global step 12280, epoch: 3, batch: 2420, loss: 0.1690,domain_loss: 0.0379 ,ce_loss: 0.2017., accu: 0.8949, speed: 1.19 step/s\n",
      "global step 12290, epoch: 3, batch: 2430, loss: 0.2482,domain_loss: 0.0368 ,ce_loss: 0.3010., accu: 0.8949, speed: 1.17 step/s\n",
      "global step 12300, epoch: 3, batch: 2440, loss: 0.1893,domain_loss: 0.0559 ,ce_loss: 0.2226., accu: 0.8943, speed: 1.18 step/s\n",
      "2022-09-29 02:37:31,915\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 12300, epoch: 3, batch: 2440】，loss: 0.1893,domain_loss: 0.0559 ,ce_loss: 0.2226., accu: 0.8943,\n",
      "2022-09-29 02:37:32,221\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.11602, accuracy: 0.96[0.97],threshold:0.259, domain_acc:1.0,total_num:100\n",
      "global step 12310, epoch: 3, batch: 2450, loss: 0.1762,domain_loss: 0.0296 ,ce_loss: 0.2129., accu: 0.8922, speed: 1.06 step/s\n",
      "global step 12320, epoch: 3, batch: 2460, loss: 0.1967,domain_loss: 0.0976 ,ce_loss: 0.2215., accu: 0.8848, speed: 1.20 step/s\n",
      "global step 12330, epoch: 3, batch: 2470, loss: 0.1682,domain_loss: 0.0520 ,ce_loss: 0.1972., accu: 0.8893, speed: 1.17 step/s\n",
      "global step 12340, epoch: 3, batch: 2480, loss: 0.1789,domain_loss: 0.0293 ,ce_loss: 0.2163., accu: 0.8908, speed: 1.19 step/s\n",
      "global step 12350, epoch: 3, batch: 2490, loss: 0.2212,domain_loss: 0.0550 ,ce_loss: 0.2627., accu: 0.8900, speed: 1.18 step/s\n",
      "global step 12360, epoch: 3, batch: 2500, loss: 0.1533,domain_loss: 0.0123 ,ce_loss: 0.1885., accu: 0.8914, speed: 1.20 step/s\n",
      "global step 12370, epoch: 3, batch: 2510, loss: 0.2504,domain_loss: 0.0587 ,ce_loss: 0.2983., accu: 0.8914, speed: 1.19 step/s\n",
      "global step 12380, epoch: 3, batch: 2520, loss: 0.2273,domain_loss: 0.0377 ,ce_loss: 0.2747., accu: 0.8912, speed: 1.17 step/s\n",
      "global step 12390, epoch: 3, batch: 2530, loss: 0.2543,domain_loss: 0.0972 ,ce_loss: 0.2936., accu: 0.8906, speed: 1.19 step/s\n",
      "global step 12400, epoch: 3, batch: 2540, loss: 0.2032,domain_loss: 0.0462 ,ce_loss: 0.2425., accu: 0.8909, speed: 1.17 step/s\n",
      "global step 12410, epoch: 3, batch: 2550, loss: 0.2731,domain_loss: 0.0093 ,ce_loss: 0.3390., accu: 0.8911, speed: 1.22 step/s\n",
      "global step 12420, epoch: 3, batch: 2560, loss: 0.2075,domain_loss: 0.0228 ,ce_loss: 0.2537., accu: 0.8918, speed: 1.19 step/s\n",
      "global step 12430, epoch: 3, batch: 2570, loss: 0.2183,domain_loss: 0.0458 ,ce_loss: 0.2615., accu: 0.8906, speed: 1.18 step/s\n",
      "global step 12440, epoch: 3, batch: 2580, loss: 0.2034,domain_loss: 0.0638 ,ce_loss: 0.2383., accu: 0.8906, speed: 1.18 step/s\n",
      "global step 12450, epoch: 3, batch: 2590, loss: 0.1538,domain_loss: 0.0098 ,ce_loss: 0.1898., accu: 0.8915, speed: 1.17 step/s\n",
      "global step 12460, epoch: 3, batch: 2600, loss: 0.1768,domain_loss: 0.0127 ,ce_loss: 0.2178., accu: 0.8916, speed: 1.19 step/s\n",
      "global step 12470, epoch: 3, batch: 2610, loss: 0.2015,domain_loss: 0.0128 ,ce_loss: 0.2486., accu: 0.8914, speed: 1.19 step/s\n",
      "global step 12480, epoch: 3, batch: 2620, loss: 0.2161,domain_loss: 0.0337 ,ce_loss: 0.2617., accu: 0.8918, speed: 1.17 step/s\n",
      "global step 12490, epoch: 3, batch: 2630, loss: 0.2037,domain_loss: 0.0417 ,ce_loss: 0.2442., accu: 0.8914, speed: 1.18 step/s\n",
      "global step 12500, epoch: 3, batch: 2640, loss: 0.1706,domain_loss: 0.0100 ,ce_loss: 0.2108., accu: 0.8915, speed: 1.17 step/s\n",
      "global step 12510, epoch: 3, batch: 2650, loss: 0.2658,domain_loss: 0.0169 ,ce_loss: 0.3281., accu: 0.8916, speed: 1.18 step/s\n",
      "global step 12520, epoch: 3, batch: 2660, loss: 0.1455,domain_loss: 0.0077 ,ce_loss: 0.1799., accu: 0.8917, speed: 1.18 step/s\n",
      "global step 12530, epoch: 3, batch: 2670, loss: 0.2378,domain_loss: 0.0228 ,ce_loss: 0.2915., accu: 0.8916, speed: 1.17 step/s\n",
      "global step 12540, epoch: 3, batch: 2680, loss: 0.1713,domain_loss: 0.0587 ,ce_loss: 0.1994., accu: 0.8916, speed: 1.18 step/s\n",
      "global step 12550, epoch: 3, batch: 2690, loss: 0.2013,domain_loss: 0.0507 ,ce_loss: 0.2390., accu: 0.8920, speed: 1.17 step/s\n",
      "global step 12560, epoch: 3, batch: 2700, loss: 0.2293,domain_loss: 0.0233 ,ce_loss: 0.2808., accu: 0.8913, speed: 1.17 step/s\n",
      "global step 12570, epoch: 3, batch: 2710, loss: 0.2176,domain_loss: 0.0112 ,ce_loss: 0.2693., accu: 0.8913, speed: 1.18 step/s\n",
      "global step 12580, epoch: 3, batch: 2720, loss: 0.2023,domain_loss: 0.0045 ,ce_loss: 0.2517., accu: 0.8911, speed: 1.18 step/s\n",
      "global step 12590, epoch: 3, batch: 2730, loss: 0.1960,domain_loss: 0.0179 ,ce_loss: 0.2405., accu: 0.8914, speed: 1.17 step/s\n",
      "global step 12600, epoch: 3, batch: 2740, loss: 0.2570,domain_loss: 0.0198 ,ce_loss: 0.3163., accu: 0.8915, speed: 1.19 step/s\n",
      "2022-09-29 02:41:46,786\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 12600, epoch: 3, batch: 2740】，loss: 0.2570,domain_loss: 0.0198 ,ce_loss: 0.3163., accu: 0.8915,\n",
      "2022-09-29 02:41:47,101\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.11882, accuracy: 0.96[0.96],threshold:0.303, domain_acc:1.0,total_num:100\n",
      "global step 12610, epoch: 3, batch: 2750, loss: 0.1837,domain_loss: 0.0223 ,ce_loss: 0.2240., accu: 0.8977, speed: 1.05 step/s\n",
      "global step 12620, epoch: 3, batch: 2760, loss: 0.2595,domain_loss: 0.0143 ,ce_loss: 0.3208., accu: 0.8941, speed: 1.19 step/s\n",
      "global step 12630, epoch: 3, batch: 2770, loss: 0.2025,domain_loss: 0.0087 ,ce_loss: 0.2509., accu: 0.8956, speed: 1.18 step/s\n",
      "global step 12640, epoch: 3, batch: 2780, loss: 0.1713,domain_loss: 0.0440 ,ce_loss: 0.2032., accu: 0.8967, speed: 1.18 step/s\n",
      "global step 12650, epoch: 3, batch: 2790, loss: 0.1737,domain_loss: 0.0272 ,ce_loss: 0.2103., accu: 0.8948, speed: 1.19 step/s\n",
      "global step 12660, epoch: 3, batch: 2800, loss: 0.2313,domain_loss: 0.0809 ,ce_loss: 0.2689., accu: 0.8938, speed: 1.19 step/s\n",
      "global step 12670, epoch: 3, batch: 2810, loss: 0.1804,domain_loss: 0.0123 ,ce_loss: 0.2224., accu: 0.8922, speed: 1.18 step/s\n",
      "global step 12680, epoch: 3, batch: 2820, loss: 0.2175,domain_loss: 0.0164 ,ce_loss: 0.2678., accu: 0.8926, speed: 1.18 step/s\n",
      "global step 12690, epoch: 3, batch: 2830, loss: 0.1417,domain_loss: 0.0192 ,ce_loss: 0.1724., accu: 0.8948, speed: 1.19 step/s\n",
      "global step 12700, epoch: 3, batch: 2840, loss: 0.2189,domain_loss: 0.0331 ,ce_loss: 0.2653., accu: 0.8948, speed: 1.18 step/s\n",
      "global step 12710, epoch: 3, batch: 2850, loss: 0.1397,domain_loss: 0.0141 ,ce_loss: 0.1711., accu: 0.8945, speed: 1.17 step/s\n",
      "global step 12720, epoch: 3, batch: 2860, loss: 0.1432,domain_loss: 0.0412 ,ce_loss: 0.1687., accu: 0.8945, speed: 1.20 step/s\n",
      "global step 12730, epoch: 3, batch: 2870, loss: 0.1589,domain_loss: 0.0755 ,ce_loss: 0.1798., accu: 0.8944, speed: 1.17 step/s\n",
      "global step 12740, epoch: 3, batch: 2880, loss: 0.2294,domain_loss: 0.0701 ,ce_loss: 0.2693., accu: 0.8946, speed: 1.18 step/s\n",
      "global step 12750, epoch: 3, batch: 2890, loss: 0.2705,domain_loss: 0.0910 ,ce_loss: 0.3153., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 12760, epoch: 3, batch: 2900, loss: 0.1807,domain_loss: 0.0143 ,ce_loss: 0.2222., accu: 0.8946, speed: 1.17 step/s\n",
      "global step 12770, epoch: 3, batch: 2910, loss: 0.1935,domain_loss: 0.0312 ,ce_loss: 0.2341., accu: 0.8951, speed: 1.18 step/s\n",
      "global step 12780, epoch: 3, batch: 2920, loss: 0.1762,domain_loss: 0.0648 ,ce_loss: 0.2040., accu: 0.8952, speed: 1.18 step/s\n",
      "global step 12790, epoch: 3, batch: 2930, loss: 0.2268,domain_loss: 0.0998 ,ce_loss: 0.2586., accu: 0.8954, speed: 1.17 step/s\n",
      "global step 12800, epoch: 3, batch: 2940, loss: 0.2155,domain_loss: 0.0413 ,ce_loss: 0.2590., accu: 0.8954, speed: 1.22 step/s\n",
      "global step 12810, epoch: 3, batch: 2950, loss: 0.2365,domain_loss: 0.0032 ,ce_loss: 0.2948., accu: 0.8948, speed: 1.18 step/s\n",
      "global step 12820, epoch: 3, batch: 2960, loss: 0.1872,domain_loss: 0.0103 ,ce_loss: 0.2314., accu: 0.8950, speed: 1.18 step/s\n",
      "global step 12830, epoch: 3, batch: 2970, loss: 0.1636,domain_loss: 0.0171 ,ce_loss: 0.2003., accu: 0.8952, speed: 1.22 step/s\n",
      "global step 12840, epoch: 3, batch: 2980, loss: 0.2605,domain_loss: 0.0606 ,ce_loss: 0.3105., accu: 0.8951, speed: 1.21 step/s\n",
      "global step 12850, epoch: 3, batch: 2990, loss: 0.1585,domain_loss: 0.0536 ,ce_loss: 0.1847., accu: 0.8957, speed: 1.19 step/s\n",
      "global step 12860, epoch: 3, batch: 3000, loss: 0.1745,domain_loss: 0.0833 ,ce_loss: 0.1973., accu: 0.8959, speed: 1.17 step/s\n",
      "global step 12870, epoch: 3, batch: 3010, loss: 0.1641,domain_loss: 0.0072 ,ce_loss: 0.2033., accu: 0.8961, speed: 1.20 step/s\n",
      "global step 12880, epoch: 3, batch: 3020, loss: 0.1789,domain_loss: 0.0599 ,ce_loss: 0.2086., accu: 0.8960, speed: 1.18 step/s\n",
      "global step 12890, epoch: 3, batch: 3030, loss: 0.1699,domain_loss: 0.0289 ,ce_loss: 0.2052., accu: 0.8965, speed: 1.17 step/s\n",
      "global step 12900, epoch: 3, batch: 3040, loss: 0.1920,domain_loss: 0.0242 ,ce_loss: 0.2340., accu: 0.8961, speed: 1.17 step/s\n",
      "2022-09-29 02:46:01,149\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 12900, epoch: 3, batch: 3040】，loss: 0.1920,domain_loss: 0.0242 ,ce_loss: 0.2340., accu: 0.8961,\n",
      "2022-09-29 02:46:01,460\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.10843, accuracy: 0.96[0.96],threshold:0.371, domain_acc:1.0,total_num:100\n",
      "global step 12910, epoch: 3, batch: 3050, loss: 0.1715,domain_loss: 0.0139 ,ce_loss: 0.2108., accu: 0.9039, speed: 1.03 step/s\n",
      "global step 12920, epoch: 3, batch: 3060, loss: 0.1288,domain_loss: 0.0152 ,ce_loss: 0.1572., accu: 0.8953, speed: 1.19 step/s\n",
      "global step 12930, epoch: 3, batch: 3070, loss: 0.2030,domain_loss: 0.0107 ,ce_loss: 0.2511., accu: 0.8945, speed: 1.20 step/s\n",
      "global step 12940, epoch: 3, batch: 3080, loss: 0.2111,domain_loss: 0.0654 ,ce_loss: 0.2475., accu: 0.8957, speed: 1.17 step/s\n",
      "global step 12950, epoch: 3, batch: 3090, loss: 0.1638,domain_loss: 0.0642 ,ce_loss: 0.1886., accu: 0.8980, speed: 1.19 step/s\n",
      "global step 12960, epoch: 3, batch: 3100, loss: 0.2271,domain_loss: 0.0342 ,ce_loss: 0.2753., accu: 0.8990, speed: 1.19 step/s\n",
      "global step 12970, epoch: 3, batch: 3110, loss: 0.1376,domain_loss: 0.0455 ,ce_loss: 0.1606., accu: 0.8965, speed: 1.18 step/s\n",
      "global step 12980, epoch: 3, batch: 3120, loss: 0.1928,domain_loss: 0.0042 ,ce_loss: 0.2400., accu: 0.8970, speed: 1.21 step/s\n",
      "global step 12990, epoch: 3, batch: 3130, loss: 0.3123,domain_loss: 0.0442 ,ce_loss: 0.3794., accu: 0.8955, speed: 1.18 step/s\n",
      "global step 13000, epoch: 3, batch: 3140, loss: 0.1900,domain_loss: 0.0189 ,ce_loss: 0.2328., accu: 0.8964, speed: 1.19 step/s\n",
      "global step 13010, epoch: 3, batch: 3150, loss: 0.1878,domain_loss: 0.1015 ,ce_loss: 0.2094., accu: 0.8947, speed: 1.20 step/s\n",
      "global step 13020, epoch: 3, batch: 3160, loss: 0.2708,domain_loss: 0.0242 ,ce_loss: 0.3324., accu: 0.8954, speed: 1.20 step/s\n",
      "global step 13030, epoch: 3, batch: 3170, loss: 0.2236,domain_loss: 0.0214 ,ce_loss: 0.2741., accu: 0.8948, speed: 1.19 step/s\n",
      "global step 13040, epoch: 3, batch: 3180, loss: 0.2101,domain_loss: 0.0353 ,ce_loss: 0.2538., accu: 0.8950, speed: 1.18 step/s\n",
      "global step 13050, epoch: 3, batch: 3190, loss: 0.1706,domain_loss: 0.0241 ,ce_loss: 0.2072., accu: 0.8953, speed: 1.19 step/s\n",
      "global step 13060, epoch: 3, batch: 3200, loss: 0.2330,domain_loss: 0.0170 ,ce_loss: 0.2870., accu: 0.8952, speed: 1.18 step/s\n",
      "global step 13070, epoch: 3, batch: 3210, loss: 0.1850,domain_loss: 0.0206 ,ce_loss: 0.2260., accu: 0.8947, speed: 1.18 step/s\n",
      "global step 13080, epoch: 3, batch: 3220, loss: 0.1702,domain_loss: 0.0419 ,ce_loss: 0.2022., accu: 0.8949, speed: 1.17 step/s\n",
      "global step 13090, epoch: 3, batch: 3230, loss: 0.1709,domain_loss: 0.0116 ,ce_loss: 0.2108., accu: 0.8947, speed: 1.17 step/s\n",
      "global step 13100, epoch: 3, batch: 3240, loss: 0.2220,domain_loss: 0.0190 ,ce_loss: 0.2728., accu: 0.8944, speed: 1.17 step/s\n",
      "global step 13110, epoch: 3, batch: 3250, loss: 0.1245,domain_loss: 0.0053 ,ce_loss: 0.1543., accu: 0.8948, speed: 1.17 step/s\n",
      "global step 13120, epoch: 3, batch: 3260, loss: 0.2066,domain_loss: 0.0255 ,ce_loss: 0.2518., accu: 0.8945, speed: 1.17 step/s\n",
      "global step 13130, epoch: 3, batch: 3270, loss: 0.2411,domain_loss: 0.0393 ,ce_loss: 0.2916., accu: 0.8947, speed: 1.18 step/s\n",
      "global step 13140, epoch: 3, batch: 3280, loss: 0.2024,domain_loss: 0.0304 ,ce_loss: 0.2454., accu: 0.8944, speed: 1.18 step/s\n",
      "global step 13150, epoch: 3, batch: 3290, loss: 0.2412,domain_loss: 0.0107 ,ce_loss: 0.2988., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 13160, epoch: 3, batch: 3300, loss: 0.1894,domain_loss: 0.0340 ,ce_loss: 0.2282., accu: 0.8946, speed: 1.19 step/s\n",
      "global step 13170, epoch: 3, batch: 3310, loss: 0.1987,domain_loss: 0.0673 ,ce_loss: 0.2316., accu: 0.8946, speed: 1.19 step/s\n",
      "global step 13180, epoch: 3, batch: 3320, loss: 0.1905,domain_loss: 0.0258 ,ce_loss: 0.2317., accu: 0.8943, speed: 1.18 step/s\n",
      "global step 13190, epoch: 3, batch: 3330, loss: 0.1529,domain_loss: 0.0642 ,ce_loss: 0.1750., accu: 0.8945, speed: 1.18 step/s\n",
      "global step 13200, epoch: 3, batch: 3340, loss: 0.1991,domain_loss: 0.0179 ,ce_loss: 0.2444., accu: 0.8947, speed: 1.19 step/s\n",
      "2022-09-29 02:50:15,726\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 13200, epoch: 3, batch: 3340】，loss: 0.1991,domain_loss: 0.0179 ,ce_loss: 0.2444., accu: 0.8947,\n",
      "2022-09-29 02:50:16,038\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.10404, accuracy: 0.96[0.97],threshold:0.364, domain_acc:1.0,total_num:100\n",
      "global step 13210, epoch: 3, batch: 3350, loss: 0.1783,domain_loss: 0.0118 ,ce_loss: 0.2200., accu: 0.8883, speed: 1.04 step/s\n",
      "global step 13220, epoch: 3, batch: 3360, loss: 0.2604,domain_loss: 0.0078 ,ce_loss: 0.3235., accu: 0.8879, speed: 1.20 step/s\n",
      "global step 13230, epoch: 3, batch: 3370, loss: 0.2155,domain_loss: 0.0257 ,ce_loss: 0.2629., accu: 0.8854, speed: 1.18 step/s\n",
      "global step 13240, epoch: 3, batch: 3380, loss: 0.1841,domain_loss: 0.0205 ,ce_loss: 0.2250., accu: 0.8893, speed: 1.17 step/s\n",
      "global step 13250, epoch: 3, batch: 3390, loss: 0.1956,domain_loss: 0.0065 ,ce_loss: 0.2429., accu: 0.8895, speed: 1.17 step/s\n",
      "global step 13260, epoch: 3, batch: 3400, loss: 0.2716,domain_loss: 0.0452 ,ce_loss: 0.3282., accu: 0.8898, speed: 1.19 step/s\n",
      "global step 13270, epoch: 3, batch: 3410, loss: 0.1665,domain_loss: 0.0109 ,ce_loss: 0.2054., accu: 0.8891, speed: 1.19 step/s\n",
      "global step 13280, epoch: 3, batch: 3420, loss: 0.1798,domain_loss: 0.0356 ,ce_loss: 0.2159., accu: 0.8920, speed: 1.18 step/s\n",
      "global step 13290, epoch: 3, batch: 3430, loss: 0.2181,domain_loss: 0.0309 ,ce_loss: 0.2648., accu: 0.8924, speed: 1.19 step/s\n",
      "global step 13300, epoch: 3, batch: 3440, loss: 0.2180,domain_loss: 0.0307 ,ce_loss: 0.2649., accu: 0.8932, speed: 1.17 step/s\n",
      "global step 13310, epoch: 3, batch: 3450, loss: 0.1786,domain_loss: 0.0163 ,ce_loss: 0.2192., accu: 0.8920, speed: 1.17 step/s\n",
      "global step 13320, epoch: 3, batch: 3460, loss: 0.1940,domain_loss: 0.0548 ,ce_loss: 0.2288., accu: 0.8921, speed: 1.18 step/s\n",
      "global step 13330, epoch: 3, batch: 3470, loss: 0.1619,domain_loss: 0.0143 ,ce_loss: 0.1989., accu: 0.8927, speed: 1.18 step/s\n",
      "global step 13340, epoch: 3, batch: 3480, loss: 0.2330,domain_loss: 0.0369 ,ce_loss: 0.2820., accu: 0.8932, speed: 1.18 step/s\n",
      "global step 13350, epoch: 3, batch: 3490, loss: 0.2904,domain_loss: 0.0239 ,ce_loss: 0.3570., accu: 0.8939, speed: 1.18 step/s\n",
      "global step 13360, epoch: 3, batch: 3500, loss: 0.1760,domain_loss: 0.0925 ,ce_loss: 0.1969., accu: 0.8944, speed: 1.20 step/s\n",
      "global step 13370, epoch: 3, batch: 3510, loss: 0.1851,domain_loss: 0.0382 ,ce_loss: 0.2218., accu: 0.8942, speed: 1.17 step/s\n",
      "global step 13380, epoch: 3, batch: 3520, loss: 0.1694,domain_loss: 0.0922 ,ce_loss: 0.1887., accu: 0.8938, speed: 1.17 step/s\n",
      "global step 13390, epoch: 3, batch: 3530, loss: 0.1945,domain_loss: 0.0358 ,ce_loss: 0.2342., accu: 0.8940, speed: 1.18 step/s\n",
      "global step 13400, epoch: 3, batch: 3540, loss: 0.2404,domain_loss: 0.0697 ,ce_loss: 0.2830., accu: 0.8938, speed: 1.18 step/s\n",
      "global step 13410, epoch: 3, batch: 3550, loss: 0.2239,domain_loss: 0.0496 ,ce_loss: 0.2675., accu: 0.8941, speed: 1.19 step/s\n",
      "global step 13420, epoch: 3, batch: 3560, loss: 0.2094,domain_loss: 0.0252 ,ce_loss: 0.2554., accu: 0.8944, speed: 1.19 step/s\n",
      "global step 13430, epoch: 3, batch: 3570, loss: 0.2201,domain_loss: 0.0213 ,ce_loss: 0.2698., accu: 0.8937, speed: 1.18 step/s\n",
      "global step 13440, epoch: 3, batch: 3580, loss: 0.2458,domain_loss: 0.0305 ,ce_loss: 0.2996., accu: 0.8937, speed: 1.19 step/s\n",
      "global step 13450, epoch: 3, batch: 3590, loss: 0.2258,domain_loss: 0.0344 ,ce_loss: 0.2737., accu: 0.8934, speed: 1.21 step/s\n",
      "global step 13460, epoch: 3, batch: 3600, loss: 0.1664,domain_loss: 0.0305 ,ce_loss: 0.2004., accu: 0.8939, speed: 1.19 step/s\n",
      "global step 13470, epoch: 3, batch: 3610, loss: 0.2421,domain_loss: 0.0303 ,ce_loss: 0.2950., accu: 0.8937, speed: 1.18 step/s\n",
      "global step 13480, epoch: 3, batch: 3620, loss: 0.1979,domain_loss: 0.0100 ,ce_loss: 0.2449., accu: 0.8937, speed: 1.20 step/s\n",
      "global step 13490, epoch: 3, batch: 3630, loss: 0.2550,domain_loss: 0.0663 ,ce_loss: 0.3022., accu: 0.8938, speed: 1.19 step/s\n",
      "global step 13500, epoch: 3, batch: 3640, loss: 0.1729,domain_loss: 0.0515 ,ce_loss: 0.2032., accu: 0.8946, speed: 1.18 step/s\n",
      "2022-09-29 02:54:30,433\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 13500, epoch: 3, batch: 3640】，loss: 0.1729,domain_loss: 0.0515 ,ce_loss: 0.2032., accu: 0.8946,\n",
      "2022-09-29 02:54:30,746\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.12081, accuracy: 0.96[0.97],threshold:0.428, domain_acc:1.0,total_num:100\n",
      "global step 13510, epoch: 3, batch: 3650, loss: 0.1835,domain_loss: 0.0516 ,ce_loss: 0.2165., accu: 0.8961, speed: 1.05 step/s\n",
      "global step 13520, epoch: 3, batch: 3660, loss: 0.1461,domain_loss: 0.0072 ,ce_loss: 0.1808., accu: 0.8891, speed: 1.17 step/s\n",
      "global step 13530, epoch: 3, batch: 3670, loss: 0.2067,domain_loss: 0.0393 ,ce_loss: 0.2486., accu: 0.8906, speed: 1.20 step/s\n",
      "global step 13540, epoch: 3, batch: 3680, loss: 0.1403,domain_loss: 0.0105 ,ce_loss: 0.1728., accu: 0.8939, speed: 1.17 step/s\n",
      "global step 13550, epoch: 3, batch: 3690, loss: 0.2410,domain_loss: 0.0043 ,ce_loss: 0.3002., accu: 0.8939, speed: 1.18 step/s\n",
      "global step 13560, epoch: 3, batch: 3700, loss: 0.1795,domain_loss: 0.0651 ,ce_loss: 0.2081., accu: 0.8952, speed: 1.17 step/s\n",
      "global step 13570, epoch: 3, batch: 3710, loss: 0.2387,domain_loss: 0.0232 ,ce_loss: 0.2925., accu: 0.8970, speed: 1.18 step/s\n",
      "global step 13580, epoch: 3, batch: 3720, loss: 0.2404,domain_loss: 0.0293 ,ce_loss: 0.2932., accu: 0.8962, speed: 1.18 step/s\n",
      "global step 13590, epoch: 3, batch: 3730, loss: 0.1626,domain_loss: 0.0269 ,ce_loss: 0.1965., accu: 0.8962, speed: 1.18 step/s\n",
      "global step 13600, epoch: 3, batch: 3740, loss: 0.1803,domain_loss: 0.0127 ,ce_loss: 0.2222., accu: 0.8972, speed: 1.18 step/s\n",
      "global step 13610, epoch: 3, batch: 3750, loss: 0.1647,domain_loss: 0.0285 ,ce_loss: 0.1987., accu: 0.8960, speed: 1.18 step/s\n",
      "global step 13620, epoch: 3, batch: 3760, loss: 0.1539,domain_loss: 0.0268 ,ce_loss: 0.1856., accu: 0.8967, speed: 1.17 step/s\n",
      "global step 13630, epoch: 3, batch: 3770, loss: 0.1978,domain_loss: 0.1220 ,ce_loss: 0.2167., accu: 0.8962, speed: 1.18 step/s\n",
      "global step 13640, epoch: 3, batch: 3780, loss: 0.1984,domain_loss: 0.0052 ,ce_loss: 0.2467., accu: 0.8960, speed: 1.18 step/s\n",
      "global step 13650, epoch: 3, batch: 3790, loss: 0.2169,domain_loss: 0.0159 ,ce_loss: 0.2672., accu: 0.8962, speed: 1.21 step/s\n",
      "global step 13660, epoch: 3, batch: 3800, loss: 0.1816,domain_loss: 0.0080 ,ce_loss: 0.2250., accu: 0.8965, speed: 1.17 step/s\n",
      "global step 13670, epoch: 3, batch: 3810, loss: 0.1800,domain_loss: 0.0071 ,ce_loss: 0.2233., accu: 0.8966, speed: 1.18 step/s\n",
      "global step 13680, epoch: 3, batch: 3820, loss: 0.2405,domain_loss: 0.0317 ,ce_loss: 0.2927., accu: 0.8970, speed: 1.18 step/s\n",
      "global step 13690, epoch: 3, batch: 3830, loss: 0.2091,domain_loss: 0.0337 ,ce_loss: 0.2530., accu: 0.8968, speed: 1.20 step/s\n",
      "global step 13700, epoch: 3, batch: 3840, loss: 0.2548,domain_loss: 0.0793 ,ce_loss: 0.2986., accu: 0.8967, speed: 1.18 step/s\n",
      "global step 13710, epoch: 3, batch: 3850, loss: 0.1827,domain_loss: 0.1003 ,ce_loss: 0.2033., accu: 0.8968, speed: 1.18 step/s\n",
      "global step 13720, epoch: 3, batch: 3860, loss: 0.2256,domain_loss: 0.0964 ,ce_loss: 0.2579., accu: 0.8978, speed: 1.18 step/s\n",
      "global step 13730, epoch: 3, batch: 3870, loss: 0.1430,domain_loss: 0.0520 ,ce_loss: 0.1658., accu: 0.8982, speed: 1.18 step/s\n",
      "global step 13740, epoch: 3, batch: 3880, loss: 0.1636,domain_loss: 0.1079 ,ce_loss: 0.1775., accu: 0.8983, speed: 1.17 step/s\n",
      "global step 13750, epoch: 3, batch: 3890, loss: 0.2161,domain_loss: 0.0571 ,ce_loss: 0.2558., accu: 0.8985, speed: 1.17 step/s\n",
      "global step 13760, epoch: 3, batch: 3900, loss: 0.2755,domain_loss: 0.0542 ,ce_loss: 0.3309., accu: 0.8985, speed: 1.20 step/s\n",
      "global step 13770, epoch: 3, batch: 3910, loss: 0.1689,domain_loss: 0.0334 ,ce_loss: 0.2027., accu: 0.8983, speed: 1.18 step/s\n",
      "global step 13780, epoch: 3, batch: 3920, loss: 0.1959,domain_loss: 0.0122 ,ce_loss: 0.2418., accu: 0.8983, speed: 1.18 step/s\n",
      "global step 13790, epoch: 3, batch: 3930, loss: 0.2159,domain_loss: 0.0977 ,ce_loss: 0.2454., accu: 0.8982, speed: 1.18 step/s\n",
      "global step 13800, epoch: 3, batch: 3940, loss: 0.1681,domain_loss: 0.0029 ,ce_loss: 0.2094., accu: 0.8981, speed: 1.20 step/s\n",
      "2022-09-29 02:58:45,402\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 13800, epoch: 3, batch: 3940】，loss: 0.1681,domain_loss: 0.0029 ,ce_loss: 0.2094., accu: 0.8981,\n",
      "2022-09-29 02:58:45,702\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.08306, accuracy: 0.98[0.98],threshold:0.348, domain_acc:0.99,total_num:100\n",
      "global step 13810, epoch: 3, batch: 3950, loss: 0.2343,domain_loss: 0.0162 ,ce_loss: 0.2888., accu: 0.8789, speed: 0.96 step/s\n",
      "global step 13820, epoch: 3, batch: 3960, loss: 0.1307,domain_loss: 0.0479 ,ce_loss: 0.1514., accu: 0.8836, speed: 1.18 step/s\n",
      "global step 13830, epoch: 3, batch: 3970, loss: 0.1613,domain_loss: 0.0534 ,ce_loss: 0.1882., accu: 0.8898, speed: 1.19 step/s\n",
      "global step 13840, epoch: 3, batch: 3980, loss: 0.2091,domain_loss: 0.0618 ,ce_loss: 0.2459., accu: 0.8896, speed: 1.19 step/s\n",
      "global step 13850, epoch: 3, batch: 3990, loss: 0.1989,domain_loss: 0.0091 ,ce_loss: 0.2463., accu: 0.8897, speed: 1.18 step/s\n",
      "global step 13860, epoch: 3, batch: 4000, loss: 0.2544,domain_loss: 0.0376 ,ce_loss: 0.3086., accu: 0.8918, speed: 1.19 step/s\n",
      "global step 13870, epoch: 3, batch: 4010, loss: 0.1797,domain_loss: 0.0111 ,ce_loss: 0.2219., accu: 0.8916, speed: 1.19 step/s\n",
      "global step 13880, epoch: 3, batch: 4020, loss: 0.1364,domain_loss: 0.0088 ,ce_loss: 0.1683., accu: 0.8923, speed: 1.18 step/s\n",
      "global step 13890, epoch: 3, batch: 4030, loss: 0.1818,domain_loss: 0.0231 ,ce_loss: 0.2215., accu: 0.8931, speed: 1.18 step/s\n",
      "global step 13900, epoch: 3, batch: 4040, loss: 0.2532,domain_loss: 0.0537 ,ce_loss: 0.3030., accu: 0.8923, speed: 1.23 step/s\n",
      "global step 13910, epoch: 3, batch: 4050, loss: 0.1774,domain_loss: 0.0205 ,ce_loss: 0.2166., accu: 0.8917, speed: 1.19 step/s\n",
      "global step 13920, epoch: 3, batch: 4060, loss: 0.2387,domain_loss: 0.0216 ,ce_loss: 0.2930., accu: 0.8910, speed: 1.17 step/s\n",
      "global step 13930, epoch: 3, batch: 4070, loss: 0.2045,domain_loss: 0.0481 ,ce_loss: 0.2436., accu: 0.8919, speed: 1.18 step/s\n",
      "global step 13940, epoch: 3, batch: 4080, loss: 0.2714,domain_loss: 0.0062 ,ce_loss: 0.3377., accu: 0.8909, speed: 1.18 step/s\n",
      "global step 13950, epoch: 3, batch: 4090, loss: 0.2098,domain_loss: 0.0304 ,ce_loss: 0.2547., accu: 0.8917, speed: 1.18 step/s\n",
      "global step 13960, epoch: 3, batch: 4100, loss: 0.1694,domain_loss: 0.0133 ,ce_loss: 0.2084., accu: 0.8924, speed: 1.18 step/s\n",
      "global step 13970, epoch: 3, batch: 4110, loss: 0.2105,domain_loss: 0.0100 ,ce_loss: 0.2606., accu: 0.8929, speed: 1.18 step/s\n",
      "global step 13980, epoch: 3, batch: 4120, loss: 0.2279,domain_loss: 0.0094 ,ce_loss: 0.2825., accu: 0.8920, speed: 1.18 step/s\n",
      "global step 13990, epoch: 3, batch: 4130, loss: 0.2248,domain_loss: 0.0185 ,ce_loss: 0.2764., accu: 0.8917, speed: 1.17 step/s\n",
      "global step 14000, epoch: 3, batch: 4140, loss: 0.2238,domain_loss: 0.0278 ,ce_loss: 0.2728., accu: 0.8917, speed: 1.18 step/s\n",
      "global step 14010, epoch: 3, batch: 4150, loss: 0.2450,domain_loss: 0.0241 ,ce_loss: 0.3002., accu: 0.8918, speed: 1.17 step/s\n",
      "global step 14020, epoch: 3, batch: 4160, loss: 0.2228,domain_loss: 0.0238 ,ce_loss: 0.2726., accu: 0.8924, speed: 1.18 step/s\n",
      "global step 14030, epoch: 3, batch: 4170, loss: 0.2271,domain_loss: 0.0292 ,ce_loss: 0.2765., accu: 0.8931, speed: 1.17 step/s\n",
      "global step 14040, epoch: 3, batch: 4180, loss: 0.1618,domain_loss: 0.0279 ,ce_loss: 0.1953., accu: 0.8943, speed: 1.23 step/s\n",
      "global step 14050, epoch: 3, batch: 4190, loss: 0.1450,domain_loss: 0.0418 ,ce_loss: 0.1708., accu: 0.8943, speed: 1.18 step/s\n",
      "global step 14060, epoch: 3, batch: 4200, loss: 0.1585,domain_loss: 0.0152 ,ce_loss: 0.1943., accu: 0.8941, speed: 1.19 step/s\n",
      "global step 14070, epoch: 3, batch: 4210, loss: 0.1835,domain_loss: 0.0709 ,ce_loss: 0.2117., accu: 0.8946, speed: 1.18 step/s\n",
      "global step 14080, epoch: 3, batch: 4220, loss: 0.1997,domain_loss: 0.0102 ,ce_loss: 0.2471., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 14090, epoch: 3, batch: 4230, loss: 0.2002,domain_loss: 0.0617 ,ce_loss: 0.2349., accu: 0.8943, speed: 1.19 step/s\n",
      "global step 14100, epoch: 3, batch: 4240, loss: 0.1830,domain_loss: 0.0723 ,ce_loss: 0.2107., accu: 0.8943, speed: 1.17 step/s\n",
      "2022-09-29 03:03:00,773\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 14100, epoch: 3, batch: 4240】，loss: 0.1830,domain_loss: 0.0723 ,ce_loss: 0.2107., accu: 0.8943,\n",
      "2022-09-29 03:03:01,084\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.11111, accuracy: 0.96[0.96],threshold:0.299, domain_acc:1.0,total_num:100\n",
      "2022-09-29 03:03:01,974\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 14110, epoch: 3, batch: 4250, loss: 0.2159,domain_loss: 0.0379 ,ce_loss: 0.2604., accu: 0.8867, speed: 1.03 step/s\n",
      "global step 14120, epoch: 3, batch: 4260, loss: 0.2056,domain_loss: 0.0275 ,ce_loss: 0.2501., accu: 0.8906, speed: 1.20 step/s\n",
      "global step 14130, epoch: 3, batch: 4270, loss: 0.2051,domain_loss: 0.0358 ,ce_loss: 0.2474., accu: 0.8901, speed: 1.19 step/s\n",
      "global step 14140, epoch: 3, batch: 4280, loss: 0.1977,domain_loss: 0.0160 ,ce_loss: 0.2431., accu: 0.8898, speed: 1.19 step/s\n",
      "global step 14150, epoch: 3, batch: 4290, loss: 0.2040,domain_loss: 0.0335 ,ce_loss: 0.2467., accu: 0.8919, speed: 1.19 step/s\n",
      "global step 14160, epoch: 3, batch: 4300, loss: 0.1965,domain_loss: 0.0249 ,ce_loss: 0.2394., accu: 0.8945, speed: 1.18 step/s\n",
      "global step 14170, epoch: 3, batch: 4310, loss: 0.1827,domain_loss: 0.0176 ,ce_loss: 0.2239., accu: 0.8948, speed: 1.18 step/s\n",
      "global step 14180, epoch: 3, batch: 4320, loss: 0.1601,domain_loss: 0.0040 ,ce_loss: 0.1991., accu: 0.8940, speed: 1.21 step/s\n",
      "global step 14190, epoch: 3, batch: 4330, loss: 0.2027,domain_loss: 0.0302 ,ce_loss: 0.2458., accu: 0.8957, speed: 1.18 step/s\n",
      "global step 14200, epoch: 3, batch: 4340, loss: 0.1737,domain_loss: 0.0828 ,ce_loss: 0.1965., accu: 0.8953, speed: 1.18 step/s\n",
      "global step 14210, epoch: 3, batch: 4350, loss: 0.2040,domain_loss: 0.0153 ,ce_loss: 0.2512., accu: 0.8961, speed: 1.18 step/s\n",
      "global step 14220, epoch: 3, batch: 4360, loss: 0.3256,domain_loss: 0.1012 ,ce_loss: 0.3817., accu: 0.8958, speed: 1.19 step/s\n",
      "global step 14230, epoch: 3, batch: 4370, loss: 0.1845,domain_loss: 0.0224 ,ce_loss: 0.2250., accu: 0.8950, speed: 1.19 step/s\n",
      "global step 14240, epoch: 3, batch: 4380, loss: 0.2267,domain_loss: 0.0532 ,ce_loss: 0.2700., accu: 0.8959, speed: 1.20 step/s\n",
      "global step 14250, epoch: 3, batch: 4390, loss: 0.1715,domain_loss: 0.0200 ,ce_loss: 0.2094., accu: 0.8962, speed: 1.17 step/s\n",
      "global step 14260, epoch: 3, batch: 4400, loss: 0.1854,domain_loss: 0.0083 ,ce_loss: 0.2297., accu: 0.8967, speed: 1.17 step/s\n",
      "global step 14270, epoch: 3, batch: 4410, loss: 0.2137,domain_loss: 0.0665 ,ce_loss: 0.2505., accu: 0.8971, speed: 1.18 step/s\n",
      "global step 14280, epoch: 3, batch: 4420, loss: 0.2171,domain_loss: 0.0314 ,ce_loss: 0.2635., accu: 0.8955, speed: 1.18 step/s\n",
      "global step 14290, epoch: 3, batch: 4430, loss: 0.1481,domain_loss: 0.0532 ,ce_loss: 0.1719., accu: 0.8962, speed: 1.17 step/s\n",
      "global step 14300, epoch: 3, batch: 4440, loss: 0.1946,domain_loss: 0.0109 ,ce_loss: 0.2405., accu: 0.8960, speed: 1.18 step/s\n",
      "global step 14310, epoch: 3, batch: 4450, loss: 0.1436,domain_loss: 0.0053 ,ce_loss: 0.1781., accu: 0.8966, speed: 1.19 step/s\n",
      "global step 14320, epoch: 3, batch: 4460, loss: 0.2981,domain_loss: 0.0151 ,ce_loss: 0.3688., accu: 0.8964, speed: 1.19 step/s\n",
      "global step 14330, epoch: 3, batch: 4470, loss: 0.1987,domain_loss: 0.0514 ,ce_loss: 0.2355., accu: 0.8970, speed: 1.17 step/s\n",
      "global step 14340, epoch: 3, batch: 4480, loss: 0.2049,domain_loss: 0.0384 ,ce_loss: 0.2465., accu: 0.8968, speed: 1.18 step/s\n",
      "global step 14350, epoch: 3, batch: 4490, loss: 0.1606,domain_loss: 0.0253 ,ce_loss: 0.1944., accu: 0.8970, speed: 1.19 step/s\n",
      "global step 14360, epoch: 3, batch: 4500, loss: 0.2488,domain_loss: 0.1370 ,ce_loss: 0.2767., accu: 0.8967, speed: 1.18 step/s\n",
      "global step 14370, epoch: 3, batch: 4510, loss: 0.1808,domain_loss: 0.0291 ,ce_loss: 0.2187., accu: 0.8969, speed: 1.20 step/s\n",
      "global step 14380, epoch: 3, batch: 4520, loss: 0.1706,domain_loss: 0.0201 ,ce_loss: 0.2083., accu: 0.8968, speed: 1.18 step/s\n",
      "global step 14390, epoch: 3, batch: 4530, loss: 0.1725,domain_loss: 0.0479 ,ce_loss: 0.2037., accu: 0.8966, speed: 1.18 step/s\n",
      "global step 14400, epoch: 3, batch: 4540, loss: 0.1720,domain_loss: 0.0318 ,ce_loss: 0.2071., accu: 0.8964, speed: 1.17 step/s\n",
      "2022-09-29 03:07:15,342\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 14400, epoch: 3, batch: 4540】，loss: 0.1720,domain_loss: 0.0318 ,ce_loss: 0.2071., accu: 0.8964,\n",
      "2022-09-29 03:07:15,658\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.096144, accuracy: 0.95[0.97],threshold:0.351, domain_acc:1.0,total_num:100\n",
      "global step 14410, epoch: 3, batch: 4550, loss: 0.1998,domain_loss: 0.0049 ,ce_loss: 0.2485., accu: 0.8859, speed: 1.05 step/s\n",
      "global step 14420, epoch: 3, batch: 4560, loss: 0.1983,domain_loss: 0.0159 ,ce_loss: 0.2440., accu: 0.8902, speed: 1.19 step/s\n",
      "global step 14430, epoch: 3, batch: 4570, loss: 0.1799,domain_loss: 0.0697 ,ce_loss: 0.2074., accu: 0.8922, speed: 1.18 step/s\n",
      "global step 14440, epoch: 3, batch: 4580, loss: 0.1859,domain_loss: 0.0056 ,ce_loss: 0.2309., accu: 0.8926, speed: 1.18 step/s\n",
      "global step 14450, epoch: 3, batch: 4590, loss: 0.1967,domain_loss: 0.0155 ,ce_loss: 0.2420., accu: 0.8936, speed: 1.20 step/s\n",
      "global step 14460, epoch: 3, batch: 4600, loss: 0.1746,domain_loss: 0.0130 ,ce_loss: 0.2149., accu: 0.8941, speed: 1.17 step/s\n",
      "global step 14470, epoch: 3, batch: 4610, loss: 0.1724,domain_loss: 0.0317 ,ce_loss: 0.2076., accu: 0.8950, speed: 1.17 step/s\n",
      "global step 14480, epoch: 3, batch: 4620, loss: 0.2263,domain_loss: 0.0556 ,ce_loss: 0.2690., accu: 0.8949, speed: 1.18 step/s\n",
      "global step 14490, epoch: 3, batch: 4630, loss: 0.1820,domain_loss: 0.0822 ,ce_loss: 0.2070., accu: 0.8942, speed: 1.18 step/s\n",
      "global step 14500, epoch: 3, batch: 4640, loss: 0.1757,domain_loss: 0.0440 ,ce_loss: 0.2086., accu: 0.8931, speed: 1.18 step/s\n",
      "global step 14510, epoch: 3, batch: 4650, loss: 0.1449,domain_loss: 0.0225 ,ce_loss: 0.1755., accu: 0.8935, speed: 1.19 step/s\n",
      "global step 14520, epoch: 3, batch: 4660, loss: 0.2033,domain_loss: 0.0286 ,ce_loss: 0.2470., accu: 0.8938, speed: 1.18 step/s\n",
      "global step 14530, epoch: 3, batch: 4670, loss: 0.1800,domain_loss: 0.0072 ,ce_loss: 0.2232., accu: 0.8944, speed: 1.19 step/s\n",
      "global step 14540, epoch: 3, batch: 4680, loss: 0.1764,domain_loss: 0.0675 ,ce_loss: 0.2037., accu: 0.8954, speed: 1.17 step/s\n",
      "global step 14550, epoch: 3, batch: 4690, loss: 0.2255,domain_loss: 0.0569 ,ce_loss: 0.2676., accu: 0.8957, speed: 1.18 step/s\n",
      "global step 14560, epoch: 3, batch: 4700, loss: 0.1842,domain_loss: 0.0468 ,ce_loss: 0.2185., accu: 0.8960, speed: 1.18 step/s\n",
      "global step 14570, epoch: 3, batch: 4710, loss: 0.1737,domain_loss: 0.0166 ,ce_loss: 0.2129., accu: 0.8960, speed: 1.17 step/s\n",
      "global step 14580, epoch: 3, batch: 4720, loss: 0.2436,domain_loss: 0.0257 ,ce_loss: 0.2981., accu: 0.8966, speed: 1.19 step/s\n",
      "global step 14590, epoch: 3, batch: 4730, loss: 0.2178,domain_loss: 0.0533 ,ce_loss: 0.2589., accu: 0.8966, speed: 1.19 step/s\n",
      "global step 14600, epoch: 3, batch: 4740, loss: 0.1660,domain_loss: 0.0015 ,ce_loss: 0.2071., accu: 0.8972, speed: 1.19 step/s\n",
      "global step 14610, epoch: 3, batch: 4750, loss: 0.2236,domain_loss: 0.0189 ,ce_loss: 0.2748., accu: 0.8967, speed: 1.17 step/s\n",
      "global step 14620, epoch: 3, batch: 4760, loss: 0.1854,domain_loss: 0.0661 ,ce_loss: 0.2152., accu: 0.8972, speed: 1.18 step/s\n",
      "global step 14630, epoch: 3, batch: 4770, loss: 0.2331,domain_loss: 0.0043 ,ce_loss: 0.2904., accu: 0.8971, speed: 1.20 step/s\n",
      "global step 14640, epoch: 3, batch: 4780, loss: 0.2399,domain_loss: 0.0049 ,ce_loss: 0.2987., accu: 0.8971, speed: 1.18 step/s\n",
      "global step 14650, epoch: 3, batch: 4790, loss: 0.2034,domain_loss: 0.0051 ,ce_loss: 0.2530., accu: 0.8970, speed: 1.18 step/s\n",
      "global step 14660, epoch: 3, batch: 4800, loss: 0.1890,domain_loss: 0.0563 ,ce_loss: 0.2221., accu: 0.8973, speed: 1.19 step/s\n",
      "global step 14670, epoch: 3, batch: 4810, loss: 0.2380,domain_loss: 0.0793 ,ce_loss: 0.2777., accu: 0.8977, speed: 1.17 step/s\n",
      "global step 14680, epoch: 3, batch: 4820, loss: 0.1271,domain_loss: 0.0314 ,ce_loss: 0.1510., accu: 0.8979, speed: 1.17 step/s\n",
      "global step 14690, epoch: 3, batch: 4830, loss: 0.2407,domain_loss: 0.0188 ,ce_loss: 0.2961., accu: 0.8980, speed: 1.18 step/s\n",
      "global step 14700, epoch: 3, batch: 4840, loss: 0.2106,domain_loss: 0.0156 ,ce_loss: 0.2594., accu: 0.8983, speed: 1.18 step/s\n",
      "2022-09-29 03:11:30,202\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 14700, epoch: 3, batch: 4840】，loss: 0.2106,domain_loss: 0.0156 ,ce_loss: 0.2594., accu: 0.8983,\n",
      "2022-09-29 03:11:30,513\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.090754, accuracy: 0.96[0.97],threshold:0.39, domain_acc:1.0,total_num:100\n",
      "global step 14710, epoch: 3, batch: 4850, loss: 0.1442,domain_loss: 0.0357 ,ce_loss: 0.1714., accu: 0.9055, speed: 1.05 step/s\n",
      "global step 14720, epoch: 3, batch: 4860, loss: 0.1797,domain_loss: 0.0191 ,ce_loss: 0.2199., accu: 0.9000, speed: 1.19 step/s\n",
      "global step 14730, epoch: 3, batch: 4870, loss: 0.1428,domain_loss: 0.0119 ,ce_loss: 0.1755., accu: 0.8992, speed: 1.18 step/s\n",
      "global step 14740, epoch: 3, batch: 4880, loss: 0.1823,domain_loss: 0.0297 ,ce_loss: 0.2204., accu: 0.8979, speed: 1.17 step/s\n",
      "global step 14750, epoch: 3, batch: 4890, loss: 0.1958,domain_loss: 0.0306 ,ce_loss: 0.2371., accu: 0.8995, speed: 1.17 step/s\n",
      "global step 14760, epoch: 3, batch: 4900, loss: 0.1721,domain_loss: 0.0063 ,ce_loss: 0.2135., accu: 0.9007, speed: 1.18 step/s\n",
      "global step 14770, epoch: 3, batch: 4910, loss: 0.1633,domain_loss: 0.0180 ,ce_loss: 0.1997., accu: 0.9020, speed: 1.18 step/s\n",
      "global step 14780, epoch: 3, batch: 4920, loss: 0.2318,domain_loss: 0.0087 ,ce_loss: 0.2876., accu: 0.9028, speed: 1.18 step/s\n",
      "global step 14790, epoch: 3, batch: 4930, loss: 0.0983,domain_loss: 0.0076 ,ce_loss: 0.1210., accu: 0.9035, speed: 1.29 step/s\n",
      " 60%|███████████████████████▍               | 3/5 [3:29:13<2:19:30, 4185.34s/it]global step 14800, epoch: 4, batch: 10, loss: 0.1585,domain_loss: 0.0368 ,ce_loss: 0.1889., accu: 0.9050, speed: 1.15 step/s\n",
      "global step 14810, epoch: 4, batch: 20, loss: 0.2138,domain_loss: 0.0444 ,ce_loss: 0.2562., accu: 0.9058, speed: 1.18 step/s\n",
      "global step 14820, epoch: 4, batch: 30, loss: 0.1682,domain_loss: 0.0275 ,ce_loss: 0.2034., accu: 0.9077, speed: 1.20 step/s\n",
      "global step 14830, epoch: 4, batch: 40, loss: 0.1650,domain_loss: 0.0049 ,ce_loss: 0.2051., accu: 0.9073, speed: 1.19 step/s\n",
      "global step 14840, epoch: 4, batch: 50, loss: 0.1704,domain_loss: 0.0077 ,ce_loss: 0.2110., accu: 0.9083, speed: 1.17 step/s\n",
      "global step 14850, epoch: 4, batch: 60, loss: 0.1605,domain_loss: 0.0065 ,ce_loss: 0.1990., accu: 0.9078, speed: 1.19 step/s\n",
      "global step 14860, epoch: 4, batch: 70, loss: 0.1121,domain_loss: 0.0083 ,ce_loss: 0.1381., accu: 0.9083, speed: 1.17 step/s\n",
      "global step 14870, epoch: 4, batch: 80, loss: 0.1436,domain_loss: 0.0221 ,ce_loss: 0.1740., accu: 0.9083, speed: 1.18 step/s\n",
      "global step 14880, epoch: 4, batch: 90, loss: 0.1559,domain_loss: 0.0362 ,ce_loss: 0.1858., accu: 0.9084, speed: 1.17 step/s\n",
      "global step 14890, epoch: 4, batch: 100, loss: 0.1422,domain_loss: 0.0797 ,ce_loss: 0.1578., accu: 0.9087, speed: 1.17 step/s\n",
      "global step 14900, epoch: 4, batch: 110, loss: 0.1740,domain_loss: 0.0382 ,ce_loss: 0.2080., accu: 0.9081, speed: 1.18 step/s\n",
      "global step 14910, epoch: 4, batch: 120, loss: 0.1210,domain_loss: 0.0041 ,ce_loss: 0.1502., accu: 0.9080, speed: 1.19 step/s\n",
      "global step 14920, epoch: 4, batch: 130, loss: 0.1759,domain_loss: 0.0228 ,ce_loss: 0.2142., accu: 0.9083, speed: 1.19 step/s\n",
      "global step 14930, epoch: 4, batch: 140, loss: 0.1971,domain_loss: 0.0722 ,ce_loss: 0.2283., accu: 0.9085, speed: 1.19 step/s\n",
      "global step 14940, epoch: 4, batch: 150, loss: 0.2373,domain_loss: 0.0136 ,ce_loss: 0.2933., accu: 0.9086, speed: 1.18 step/s\n",
      "global step 14950, epoch: 4, batch: 160, loss: 0.1944,domain_loss: 0.0127 ,ce_loss: 0.2398., accu: 0.9082, speed: 1.19 step/s\n",
      "global step 14960, epoch: 4, batch: 170, loss: 0.1934,domain_loss: 0.0223 ,ce_loss: 0.2362., accu: 0.9086, speed: 1.18 step/s\n",
      "global step 14970, epoch: 4, batch: 180, loss: 0.1498,domain_loss: 0.0100 ,ce_loss: 0.1847., accu: 0.9090, speed: 1.19 step/s\n",
      "global step 14980, epoch: 4, batch: 190, loss: 0.1225,domain_loss: 0.0032 ,ce_loss: 0.1524., accu: 0.9094, speed: 1.17 step/s\n",
      "global step 14990, epoch: 4, batch: 200, loss: 0.1717,domain_loss: 0.0075 ,ce_loss: 0.2128., accu: 0.9090, speed: 1.18 step/s\n",
      "global step 15000, epoch: 4, batch: 210, loss: 0.1569,domain_loss: 0.0264 ,ce_loss: 0.1895., accu: 0.9092, speed: 1.18 step/s\n",
      "2022-09-29 03:15:44,662\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 15000, epoch: 4, batch: 210】，loss: 0.1569,domain_loss: 0.0264 ,ce_loss: 0.1895., accu: 0.9092,\n",
      "2022-09-29 03:15:44,970\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.11095, accuracy: 0.96[0.98],threshold:0.553, domain_acc:1.0,total_num:100\n",
      "global step 15010, epoch: 4, batch: 220, loss: 0.1826,domain_loss: 0.0288 ,ce_loss: 0.2211., accu: 0.9250, speed: 1.05 step/s\n",
      "global step 15020, epoch: 4, batch: 230, loss: 0.1118,domain_loss: 0.0064 ,ce_loss: 0.1381., accu: 0.9168, speed: 1.18 step/s\n",
      "global step 15030, epoch: 4, batch: 240, loss: 0.2045,domain_loss: 0.0199 ,ce_loss: 0.2507., accu: 0.9122, speed: 1.18 step/s\n",
      "global step 15040, epoch: 4, batch: 250, loss: 0.1671,domain_loss: 0.1310 ,ce_loss: 0.1761., accu: 0.9150, speed: 1.18 step/s\n",
      "global step 15050, epoch: 4, batch: 260, loss: 0.1728,domain_loss: 0.0243 ,ce_loss: 0.2099., accu: 0.9141, speed: 1.18 step/s\n",
      "global step 15060, epoch: 4, batch: 270, loss: 0.2063,domain_loss: 0.0216 ,ce_loss: 0.2525., accu: 0.9138, speed: 1.17 step/s\n",
      "global step 15070, epoch: 4, batch: 280, loss: 0.1437,domain_loss: 0.0425 ,ce_loss: 0.1690., accu: 0.9142, speed: 1.19 step/s\n",
      "global step 15080, epoch: 4, batch: 290, loss: 0.1252,domain_loss: 0.0291 ,ce_loss: 0.1492., accu: 0.9126, speed: 1.21 step/s\n",
      "global step 15090, epoch: 4, batch: 300, loss: 0.2159,domain_loss: 0.0173 ,ce_loss: 0.2655., accu: 0.9117, speed: 1.17 step/s\n",
      "global step 15100, epoch: 4, batch: 310, loss: 0.1093,domain_loss: 0.0215 ,ce_loss: 0.1313., accu: 0.9126, speed: 1.19 step/s\n",
      "global step 15110, epoch: 4, batch: 320, loss: 0.2153,domain_loss: 0.0132 ,ce_loss: 0.2658., accu: 0.9128, speed: 1.20 step/s\n",
      "global step 15120, epoch: 4, batch: 330, loss: 0.1896,domain_loss: 0.0982 ,ce_loss: 0.2125., accu: 0.9122, speed: 1.20 step/s\n",
      "global step 15130, epoch: 4, batch: 340, loss: 0.1034,domain_loss: 0.0136 ,ce_loss: 0.1259., accu: 0.9132, speed: 1.18 step/s\n",
      "global step 15140, epoch: 4, batch: 350, loss: 0.2156,domain_loss: 0.0609 ,ce_loss: 0.2542., accu: 0.9125, speed: 1.19 step/s\n",
      "global step 15150, epoch: 4, batch: 360, loss: 0.1965,domain_loss: 0.0327 ,ce_loss: 0.2375., accu: 0.9115, speed: 1.18 step/s\n",
      "global step 15160, epoch: 4, batch: 370, loss: 0.2183,domain_loss: 0.0151 ,ce_loss: 0.2691., accu: 0.9114, speed: 1.18 step/s\n",
      "global step 15170, epoch: 4, batch: 380, loss: 0.1468,domain_loss: 0.0507 ,ce_loss: 0.1708., accu: 0.9109, speed: 1.19 step/s\n",
      "global step 15180, epoch: 4, batch: 390, loss: 0.1451,domain_loss: 0.0061 ,ce_loss: 0.1799., accu: 0.9107, speed: 1.18 step/s\n",
      "global step 15190, epoch: 4, batch: 400, loss: 0.1692,domain_loss: 0.0047 ,ce_loss: 0.2103., accu: 0.9112, speed: 1.18 step/s\n",
      "global step 15200, epoch: 4, batch: 410, loss: 0.1597,domain_loss: 0.0119 ,ce_loss: 0.1967., accu: 0.9111, speed: 1.20 step/s\n",
      "global step 15210, epoch: 4, batch: 420, loss: 0.1552,domain_loss: 0.0189 ,ce_loss: 0.1892., accu: 0.9110, speed: 1.18 step/s\n",
      "global step 15220, epoch: 4, batch: 430, loss: 0.1528,domain_loss: 0.0150 ,ce_loss: 0.1872., accu: 0.9112, speed: 1.19 step/s\n",
      "global step 15230, epoch: 4, batch: 440, loss: 0.1957,domain_loss: 0.0478 ,ce_loss: 0.2327., accu: 0.9109, speed: 1.20 step/s\n",
      "global step 15240, epoch: 4, batch: 450, loss: 0.1452,domain_loss: 0.0081 ,ce_loss: 0.1794., accu: 0.9108, speed: 1.18 step/s\n",
      "global step 15250, epoch: 4, batch: 460, loss: 0.1698,domain_loss: 0.0183 ,ce_loss: 0.2077., accu: 0.9113, speed: 1.18 step/s\n",
      "global step 15260, epoch: 4, batch: 470, loss: 0.1770,domain_loss: 0.0426 ,ce_loss: 0.2105., accu: 0.9111, speed: 1.17 step/s\n",
      "global step 15270, epoch: 4, batch: 480, loss: 0.1850,domain_loss: 0.0148 ,ce_loss: 0.2276., accu: 0.9111, speed: 1.19 step/s\n",
      "global step 15280, epoch: 4, batch: 490, loss: 0.2055,domain_loss: 0.0220 ,ce_loss: 0.2514., accu: 0.9112, speed: 1.17 step/s\n",
      "global step 15290, epoch: 4, batch: 500, loss: 0.1425,domain_loss: 0.0257 ,ce_loss: 0.1717., accu: 0.9112, speed: 1.18 step/s\n",
      "global step 15300, epoch: 4, batch: 510, loss: 0.2442,domain_loss: 0.0332 ,ce_loss: 0.2970., accu: 0.9115, speed: 1.18 step/s\n",
      "2022-09-29 03:19:59,072\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 15300, epoch: 4, batch: 510】，loss: 0.2442,domain_loss: 0.0332 ,ce_loss: 0.2970., accu: 0.9115,\n",
      "2022-09-29 03:19:59,381\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.10892, accuracy: 0.95[0.97],threshold:0.462, domain_acc:1.0,total_num:100\n",
      "2022-09-29 03:20:00,246\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 15310, epoch: 4, batch: 520, loss: 0.2223,domain_loss: 0.0313 ,ce_loss: 0.2701., accu: 0.8953, speed: 1.04 step/s\n",
      "global step 15320, epoch: 4, batch: 530, loss: 0.1965,domain_loss: 0.0230 ,ce_loss: 0.2399., accu: 0.8941, speed: 1.17 step/s\n",
      "global step 15330, epoch: 4, batch: 540, loss: 0.2284,domain_loss: 0.0259 ,ce_loss: 0.2790., accu: 0.8969, speed: 1.19 step/s\n",
      "global step 15340, epoch: 4, batch: 550, loss: 0.1728,domain_loss: 0.0280 ,ce_loss: 0.2090., accu: 0.9002, speed: 1.18 step/s\n",
      "global step 15350, epoch: 4, batch: 560, loss: 0.1426,domain_loss: 0.0307 ,ce_loss: 0.1706., accu: 0.9025, speed: 1.20 step/s\n",
      "global step 15360, epoch: 4, batch: 570, loss: 0.1500,domain_loss: 0.0696 ,ce_loss: 0.1700., accu: 0.9035, speed: 1.19 step/s\n",
      "global step 15370, epoch: 4, batch: 580, loss: 0.1244,domain_loss: 0.0983 ,ce_loss: 0.1310., accu: 0.9055, speed: 1.18 step/s\n",
      "global step 15380, epoch: 4, batch: 590, loss: 0.2674,domain_loss: 0.0221 ,ce_loss: 0.3288., accu: 0.9062, speed: 1.17 step/s\n",
      "global step 15390, epoch: 4, batch: 600, loss: 0.2068,domain_loss: 0.0179 ,ce_loss: 0.2541., accu: 0.9056, speed: 1.18 step/s\n",
      "global step 15400, epoch: 4, batch: 610, loss: 0.2041,domain_loss: 0.0410 ,ce_loss: 0.2448., accu: 0.9064, speed: 1.22 step/s\n",
      "global step 15410, epoch: 4, batch: 620, loss: 0.1331,domain_loss: 0.0080 ,ce_loss: 0.1644., accu: 0.9073, speed: 1.19 step/s\n",
      "global step 15420, epoch: 4, batch: 630, loss: 0.1780,domain_loss: 0.0880 ,ce_loss: 0.2005., accu: 0.9072, speed: 1.18 step/s\n",
      "global step 15430, epoch: 4, batch: 640, loss: 0.1488,domain_loss: 0.0050 ,ce_loss: 0.1848., accu: 0.9077, speed: 1.17 step/s\n",
      "global step 15440, epoch: 4, batch: 650, loss: 0.1472,domain_loss: 0.0104 ,ce_loss: 0.1814., accu: 0.9076, speed: 1.18 step/s\n",
      "global step 15450, epoch: 4, batch: 660, loss: 0.1755,domain_loss: 0.1484 ,ce_loss: 0.1823., accu: 0.9077, speed: 1.19 step/s\n",
      "global step 15460, epoch: 4, batch: 670, loss: 0.1965,domain_loss: 0.0463 ,ce_loss: 0.2341., accu: 0.9079, speed: 1.19 step/s\n",
      "global step 15470, epoch: 4, batch: 680, loss: 0.2156,domain_loss: 0.0500 ,ce_loss: 0.2570., accu: 0.9077, speed: 1.17 step/s\n",
      "global step 15480, epoch: 4, batch: 690, loss: 0.1436,domain_loss: 0.0051 ,ce_loss: 0.1783., accu: 0.9077, speed: 1.18 step/s\n",
      "global step 15490, epoch: 4, batch: 700, loss: 0.1382,domain_loss: 0.0137 ,ce_loss: 0.1694., accu: 0.9082, speed: 1.17 step/s\n",
      "global step 15500, epoch: 4, batch: 710, loss: 0.2119,domain_loss: 0.0035 ,ce_loss: 0.2640., accu: 0.9086, speed: 1.18 step/s\n",
      "global step 15510, epoch: 4, batch: 720, loss: 0.1434,domain_loss: 0.0510 ,ce_loss: 0.1665., accu: 0.9087, speed: 1.18 step/s\n",
      "global step 15520, epoch: 4, batch: 730, loss: 0.1987,domain_loss: 0.0406 ,ce_loss: 0.2382., accu: 0.9085, speed: 1.17 step/s\n",
      "global step 15530, epoch: 4, batch: 740, loss: 0.1168,domain_loss: 0.0168 ,ce_loss: 0.1418., accu: 0.9087, speed: 1.18 step/s\n",
      "global step 15540, epoch: 4, batch: 750, loss: 0.1618,domain_loss: 0.0054 ,ce_loss: 0.2009., accu: 0.9087, speed: 1.20 step/s\n",
      "global step 15550, epoch: 4, batch: 760, loss: 0.2108,domain_loss: 0.0397 ,ce_loss: 0.2535., accu: 0.9090, speed: 1.18 step/s\n",
      "global step 15560, epoch: 4, batch: 770, loss: 0.1709,domain_loss: 0.0129 ,ce_loss: 0.2103., accu: 0.9091, speed: 1.19 step/s\n",
      "global step 15570, epoch: 4, batch: 780, loss: 0.1092,domain_loss: 0.0036 ,ce_loss: 0.1356., accu: 0.9090, speed: 1.19 step/s\n",
      "global step 15580, epoch: 4, batch: 790, loss: 0.1621,domain_loss: 0.0140 ,ce_loss: 0.1992., accu: 0.9090, speed: 1.18 step/s\n",
      "global step 15590, epoch: 4, batch: 800, loss: 0.2164,domain_loss: 0.0206 ,ce_loss: 0.2654., accu: 0.9089, speed: 1.19 step/s\n",
      "global step 15600, epoch: 4, batch: 810, loss: 0.1863,domain_loss: 0.0813 ,ce_loss: 0.2125., accu: 0.9091, speed: 1.19 step/s\n",
      "2022-09-29 03:24:13,623\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 15600, epoch: 4, batch: 810】，loss: 0.1863,domain_loss: 0.0813 ,ce_loss: 0.2125., accu: 0.9091,\n",
      "2022-09-29 03:24:13,927\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.086506, accuracy: 0.97[0.98],threshold:0.421, domain_acc:1.0,total_num:100\n",
      "global step 15610, epoch: 4, batch: 820, loss: 0.2082,domain_loss: 0.0440 ,ce_loss: 0.2492., accu: 0.8953, speed: 1.05 step/s\n",
      "global step 15620, epoch: 4, batch: 830, loss: 0.1768,domain_loss: 0.0044 ,ce_loss: 0.2199., accu: 0.8984, speed: 1.19 step/s\n",
      "global step 15630, epoch: 4, batch: 840, loss: 0.1735,domain_loss: 0.0126 ,ce_loss: 0.2137., accu: 0.9003, speed: 1.18 step/s\n",
      "global step 15640, epoch: 4, batch: 850, loss: 0.2426,domain_loss: 0.0878 ,ce_loss: 0.2813., accu: 0.9055, speed: 1.18 step/s\n",
      "global step 15650, epoch: 4, batch: 860, loss: 0.1260,domain_loss: 0.0818 ,ce_loss: 0.1371., accu: 0.9072, speed: 1.23 step/s\n",
      "global step 15660, epoch: 4, batch: 870, loss: 0.1415,domain_loss: 0.0382 ,ce_loss: 0.1673., accu: 0.9072, speed: 1.18 step/s\n",
      "global step 15670, epoch: 4, batch: 880, loss: 0.2352,domain_loss: 0.0595 ,ce_loss: 0.2791., accu: 0.9090, speed: 1.18 step/s\n",
      "global step 15680, epoch: 4, batch: 890, loss: 0.1856,domain_loss: 0.0133 ,ce_loss: 0.2287., accu: 0.9103, speed: 1.17 step/s\n",
      "global step 15690, epoch: 4, batch: 900, loss: 0.1489,domain_loss: 0.0252 ,ce_loss: 0.1798., accu: 0.9112, speed: 1.19 step/s\n",
      "global step 15700, epoch: 4, batch: 910, loss: 0.1755,domain_loss: 0.0229 ,ce_loss: 0.2137., accu: 0.9118, speed: 1.18 step/s\n",
      "global step 15710, epoch: 4, batch: 920, loss: 0.1076,domain_loss: 0.0097 ,ce_loss: 0.1321., accu: 0.9123, speed: 1.19 step/s\n",
      "global step 15720, epoch: 4, batch: 930, loss: 0.2367,domain_loss: 0.0066 ,ce_loss: 0.2942., accu: 0.9121, speed: 1.18 step/s\n",
      "global step 15730, epoch: 4, batch: 940, loss: 0.1841,domain_loss: 0.0496 ,ce_loss: 0.2177., accu: 0.9123, speed: 1.18 step/s\n",
      "global step 15740, epoch: 4, batch: 950, loss: 0.1690,domain_loss: 0.0484 ,ce_loss: 0.1991., accu: 0.9129, speed: 1.21 step/s\n",
      "global step 15750, epoch: 4, batch: 960, loss: 0.1321,domain_loss: 0.0092 ,ce_loss: 0.1629., accu: 0.9135, speed: 1.17 step/s\n",
      "global step 15760, epoch: 4, batch: 970, loss: 0.0893,domain_loss: 0.0195 ,ce_loss: 0.1068., accu: 0.9136, speed: 1.20 step/s\n",
      "global step 15770, epoch: 4, batch: 980, loss: 0.0989,domain_loss: 0.0048 ,ce_loss: 0.1224., accu: 0.9136, speed: 1.18 step/s\n",
      "global step 15780, epoch: 4, batch: 990, loss: 0.1821,domain_loss: 0.0533 ,ce_loss: 0.2143., accu: 0.9135, speed: 1.19 step/s\n",
      "global step 15790, epoch: 4, batch: 1000, loss: 0.1262,domain_loss: 0.0442 ,ce_loss: 0.1467., accu: 0.9137, speed: 1.19 step/s\n",
      "global step 15800, epoch: 4, batch: 1010, loss: 0.1412,domain_loss: 0.0378 ,ce_loss: 0.1670., accu: 0.9135, speed: 1.19 step/s\n",
      "global step 15810, epoch: 4, batch: 1020, loss: 0.2462,domain_loss: 0.0277 ,ce_loss: 0.3008., accu: 0.9130, speed: 1.19 step/s\n",
      "global step 15820, epoch: 4, batch: 1030, loss: 0.2418,domain_loss: 0.0319 ,ce_loss: 0.2943., accu: 0.9126, speed: 1.19 step/s\n",
      "global step 15830, epoch: 4, batch: 1040, loss: 0.1515,domain_loss: 0.0433 ,ce_loss: 0.1785., accu: 0.9122, speed: 1.18 step/s\n",
      "global step 15840, epoch: 4, batch: 1050, loss: 0.1859,domain_loss: 0.0279 ,ce_loss: 0.2254., accu: 0.9123, speed: 1.17 step/s\n",
      "global step 15850, epoch: 4, batch: 1060, loss: 0.2023,domain_loss: 0.0698 ,ce_loss: 0.2355., accu: 0.9119, speed: 1.17 step/s\n",
      "global step 15860, epoch: 4, batch: 1070, loss: 0.1280,domain_loss: 0.0122 ,ce_loss: 0.1569., accu: 0.9115, speed: 1.17 step/s\n",
      "global step 15870, epoch: 4, batch: 1080, loss: 0.2087,domain_loss: 0.0129 ,ce_loss: 0.2577., accu: 0.9118, speed: 1.18 step/s\n",
      "global step 15880, epoch: 4, batch: 1090, loss: 0.1967,domain_loss: 0.0765 ,ce_loss: 0.2268., accu: 0.9114, speed: 1.19 step/s\n",
      "global step 15890, epoch: 4, batch: 1100, loss: 0.1664,domain_loss: 0.0093 ,ce_loss: 0.2057., accu: 0.9112, speed: 1.18 step/s\n",
      "global step 15900, epoch: 4, batch: 1110, loss: 0.1702,domain_loss: 0.0034 ,ce_loss: 0.2119., accu: 0.9109, speed: 1.19 step/s\n",
      "2022-09-29 03:28:27,663\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 15900, epoch: 4, batch: 1110】，loss: 0.1702,domain_loss: 0.0034 ,ce_loss: 0.2119., accu: 0.9109,\n",
      "2022-09-29 03:28:27,956\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.071052, accuracy: 0.98[0.98],threshold:0.326, domain_acc:1.0,total_num:100\n",
      "global step 15910, epoch: 4, batch: 1120, loss: 0.1299,domain_loss: 0.0146 ,ce_loss: 0.1587., accu: 0.9125, speed: 1.04 step/s\n",
      "global step 15920, epoch: 4, batch: 1130, loss: 0.2333,domain_loss: 0.0079 ,ce_loss: 0.2896., accu: 0.9027, speed: 1.18 step/s\n",
      "global step 15930, epoch: 4, batch: 1140, loss: 0.1254,domain_loss: 0.0300 ,ce_loss: 0.1493., accu: 0.9057, speed: 1.17 step/s\n",
      "global step 15940, epoch: 4, batch: 1150, loss: 0.2401,domain_loss: 0.0162 ,ce_loss: 0.2961., accu: 0.9074, speed: 1.18 step/s\n",
      "global step 15950, epoch: 4, batch: 1160, loss: 0.1686,domain_loss: 0.0248 ,ce_loss: 0.2046., accu: 0.9058, speed: 1.18 step/s\n",
      "global step 15960, epoch: 4, batch: 1170, loss: 0.2204,domain_loss: 0.0331 ,ce_loss: 0.2672., accu: 0.9076, speed: 1.19 step/s\n",
      "global step 15970, epoch: 4, batch: 1180, loss: 0.1455,domain_loss: 0.0387 ,ce_loss: 0.1723., accu: 0.9089, speed: 1.19 step/s\n",
      "global step 15980, epoch: 4, batch: 1190, loss: 0.1718,domain_loss: 0.0065 ,ce_loss: 0.2131., accu: 0.9079, speed: 1.18 step/s\n",
      "global step 15990, epoch: 4, batch: 1200, loss: 0.1497,domain_loss: 0.1028 ,ce_loss: 0.1614., accu: 0.9100, speed: 1.17 step/s\n",
      "global step 16000, epoch: 4, batch: 1210, loss: 0.1496,domain_loss: 0.0267 ,ce_loss: 0.1803., accu: 0.9105, speed: 1.19 step/s\n",
      "global step 16010, epoch: 4, batch: 1220, loss: 0.1900,domain_loss: 0.0531 ,ce_loss: 0.2242., accu: 0.9097, speed: 1.18 step/s\n",
      "global step 16020, epoch: 4, batch: 1230, loss: 0.1427,domain_loss: 0.0299 ,ce_loss: 0.1709., accu: 0.9094, speed: 1.19 step/s\n",
      "global step 16030, epoch: 4, batch: 1240, loss: 0.1118,domain_loss: 0.0133 ,ce_loss: 0.1364., accu: 0.9100, speed: 1.18 step/s\n",
      "global step 16040, epoch: 4, batch: 1250, loss: 0.1791,domain_loss: 0.0380 ,ce_loss: 0.2144., accu: 0.9108, speed: 1.18 step/s\n",
      "global step 16050, epoch: 4, batch: 1260, loss: 0.1229,domain_loss: 0.0156 ,ce_loss: 0.1497., accu: 0.9102, speed: 1.19 step/s\n",
      "global step 16060, epoch: 4, batch: 1270, loss: 0.1724,domain_loss: 0.0183 ,ce_loss: 0.2109., accu: 0.9101, speed: 1.20 step/s\n",
      "global step 16070, epoch: 4, batch: 1280, loss: 0.1306,domain_loss: 0.0048 ,ce_loss: 0.1620., accu: 0.9101, speed: 1.18 step/s\n",
      "global step 16080, epoch: 4, batch: 1290, loss: 0.1140,domain_loss: 0.0094 ,ce_loss: 0.1402., accu: 0.9101, speed: 1.18 step/s\n",
      "global step 16090, epoch: 4, batch: 1300, loss: 0.2120,domain_loss: 0.0536 ,ce_loss: 0.2516., accu: 0.9098, speed: 1.21 step/s\n",
      "global step 16100, epoch: 4, batch: 1310, loss: 0.1560,domain_loss: 0.0196 ,ce_loss: 0.1901., accu: 0.9096, speed: 1.19 step/s\n",
      "global step 16110, epoch: 4, batch: 1320, loss: 0.1809,domain_loss: 0.0106 ,ce_loss: 0.2235., accu: 0.9092, speed: 1.18 step/s\n",
      "global step 16120, epoch: 4, batch: 1330, loss: 0.1315,domain_loss: 0.0918 ,ce_loss: 0.1414., accu: 0.9099, speed: 1.17 step/s\n",
      "global step 16130, epoch: 4, batch: 1340, loss: 0.1493,domain_loss: 0.0254 ,ce_loss: 0.1802., accu: 0.9101, speed: 1.18 step/s\n",
      "global step 16140, epoch: 4, batch: 1350, loss: 0.1350,domain_loss: 0.0403 ,ce_loss: 0.1587., accu: 0.9104, speed: 1.18 step/s\n",
      "global step 16150, epoch: 4, batch: 1360, loss: 0.1752,domain_loss: 0.0749 ,ce_loss: 0.2002., accu: 0.9100, speed: 1.18 step/s\n",
      "global step 16160, epoch: 4, batch: 1370, loss: 0.1707,domain_loss: 0.0067 ,ce_loss: 0.2117., accu: 0.9096, speed: 1.18 step/s\n",
      "global step 16170, epoch: 4, batch: 1380, loss: 0.1950,domain_loss: 0.0776 ,ce_loss: 0.2244., accu: 0.9090, speed: 1.18 step/s\n",
      "global step 16180, epoch: 4, batch: 1390, loss: 0.1622,domain_loss: 0.0501 ,ce_loss: 0.1902., accu: 0.9089, speed: 1.17 step/s\n",
      "global step 16190, epoch: 4, batch: 1400, loss: 0.1373,domain_loss: 0.0231 ,ce_loss: 0.1659., accu: 0.9088, speed: 1.18 step/s\n",
      "global step 16200, epoch: 4, batch: 1410, loss: 0.1401,domain_loss: 0.0095 ,ce_loss: 0.1728., accu: 0.9088, speed: 1.19 step/s\n",
      "2022-09-29 03:32:42,401\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 16200, epoch: 4, batch: 1410】，loss: 0.1401,domain_loss: 0.0095 ,ce_loss: 0.1728., accu: 0.9088,\n",
      "2022-09-29 03:32:42,733\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.088121, accuracy: 0.97[0.98],threshold:0.253, domain_acc:1.0,total_num:100\n",
      "2022-09-29 03:32:43,640\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 16210, epoch: 4, batch: 1420, loss: 0.2049,domain_loss: 0.0933 ,ce_loss: 0.2328., accu: 0.9102, speed: 1.03 step/s\n",
      "global step 16220, epoch: 4, batch: 1430, loss: 0.1630,domain_loss: 0.0126 ,ce_loss: 0.2006., accu: 0.9066, speed: 1.18 step/s\n",
      "global step 16230, epoch: 4, batch: 1440, loss: 0.2269,domain_loss: 0.0254 ,ce_loss: 0.2773., accu: 0.9062, speed: 1.18 step/s\n",
      "global step 16240, epoch: 4, batch: 1450, loss: 0.1714,domain_loss: 0.0476 ,ce_loss: 0.2023., accu: 0.9068, speed: 1.18 step/s\n",
      "global step 16250, epoch: 4, batch: 1460, loss: 0.2039,domain_loss: 0.0076 ,ce_loss: 0.2529., accu: 0.9075, speed: 1.20 step/s\n",
      "global step 16260, epoch: 4, batch: 1470, loss: 0.1513,domain_loss: 0.0467 ,ce_loss: 0.1774., accu: 0.9085, speed: 1.18 step/s\n",
      "global step 16270, epoch: 4, batch: 1480, loss: 0.1331,domain_loss: 0.0056 ,ce_loss: 0.1650., accu: 0.9080, speed: 1.18 step/s\n",
      "global step 16280, epoch: 4, batch: 1490, loss: 0.1609,domain_loss: 0.0213 ,ce_loss: 0.1957., accu: 0.9076, speed: 1.18 step/s\n",
      "global step 16290, epoch: 4, batch: 1500, loss: 0.1516,domain_loss: 0.0496 ,ce_loss: 0.1771., accu: 0.9073, speed: 1.19 step/s\n",
      "global step 16300, epoch: 4, batch: 1510, loss: 0.2731,domain_loss: 0.0338 ,ce_loss: 0.3329., accu: 0.9070, speed: 1.19 step/s\n",
      "global step 16310, epoch: 4, batch: 1520, loss: 0.1425,domain_loss: 0.0065 ,ce_loss: 0.1765., accu: 0.9074, speed: 1.18 step/s\n",
      "global step 16320, epoch: 4, batch: 1530, loss: 0.1741,domain_loss: 0.0016 ,ce_loss: 0.2173., accu: 0.9072, speed: 1.18 step/s\n",
      "global step 16330, epoch: 4, batch: 1540, loss: 0.1623,domain_loss: 0.0262 ,ce_loss: 0.1963., accu: 0.9075, speed: 1.17 step/s\n",
      "global step 16340, epoch: 4, batch: 1550, loss: 0.1279,domain_loss: 0.0156 ,ce_loss: 0.1560., accu: 0.9070, speed: 1.18 step/s\n",
      "global step 16350, epoch: 4, batch: 1560, loss: 0.1286,domain_loss: 0.0415 ,ce_loss: 0.1504., accu: 0.9078, speed: 1.23 step/s\n",
      "global step 16360, epoch: 4, batch: 1570, loss: 0.1706,domain_loss: 0.0027 ,ce_loss: 0.2125., accu: 0.9079, speed: 1.18 step/s\n",
      "global step 16370, epoch: 4, batch: 1580, loss: 0.1799,domain_loss: 0.0644 ,ce_loss: 0.2088., accu: 0.9079, speed: 1.19 step/s\n",
      "global step 16380, epoch: 4, batch: 1590, loss: 0.2149,domain_loss: 0.0404 ,ce_loss: 0.2585., accu: 0.9072, speed: 1.17 step/s\n",
      "global step 16390, epoch: 4, batch: 1600, loss: 0.1754,domain_loss: 0.0092 ,ce_loss: 0.2170., accu: 0.9080, speed: 1.19 step/s\n",
      "global step 16400, epoch: 4, batch: 1610, loss: 0.1742,domain_loss: 0.0080 ,ce_loss: 0.2158., accu: 0.9083, speed: 1.20 step/s\n",
      "global step 16410, epoch: 4, batch: 1620, loss: 0.1598,domain_loss: 0.0106 ,ce_loss: 0.1972., accu: 0.9082, speed: 1.17 step/s\n",
      "global step 16420, epoch: 4, batch: 1630, loss: 0.1848,domain_loss: 0.0308 ,ce_loss: 0.2233., accu: 0.9077, speed: 1.17 step/s\n",
      "global step 16430, epoch: 4, batch: 1640, loss: 0.1311,domain_loss: 0.0264 ,ce_loss: 0.1573., accu: 0.9085, speed: 1.18 step/s\n",
      "global step 16440, epoch: 4, batch: 1650, loss: 0.1643,domain_loss: 0.0099 ,ce_loss: 0.2029., accu: 0.9090, speed: 1.19 step/s\n",
      "global step 16450, epoch: 4, batch: 1660, loss: 0.1825,domain_loss: 0.0297 ,ce_loss: 0.2207., accu: 0.9084, speed: 1.20 step/s\n",
      "global step 16460, epoch: 4, batch: 1670, loss: 0.1529,domain_loss: 0.0082 ,ce_loss: 0.1890., accu: 0.9083, speed: 1.18 step/s\n",
      "global step 16470, epoch: 4, batch: 1680, loss: 0.1579,domain_loss: 0.0107 ,ce_loss: 0.1947., accu: 0.9086, speed: 1.17 step/s\n",
      "global step 16480, epoch: 4, batch: 1690, loss: 0.1525,domain_loss: 0.0850 ,ce_loss: 0.1694., accu: 0.9093, speed: 1.17 step/s\n",
      "global step 16490, epoch: 4, batch: 1700, loss: 0.2067,domain_loss: 0.0558 ,ce_loss: 0.2444., accu: 0.9093, speed: 1.18 step/s\n",
      "global step 16500, epoch: 4, batch: 1710, loss: 0.1027,domain_loss: 0.0241 ,ce_loss: 0.1223., accu: 0.9091, speed: 1.21 step/s\n",
      "2022-09-29 03:36:56,896\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 16500, epoch: 4, batch: 1710】，loss: 0.1027,domain_loss: 0.0241 ,ce_loss: 0.1223., accu: 0.9091,\n",
      "2022-09-29 03:36:57,206\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.062026, accuracy: 0.98[0.98],threshold:0.226, domain_acc:1.0,total_num:100\n",
      "global step 16510, epoch: 4, batch: 1720, loss: 0.1402,domain_loss: 0.0275 ,ce_loss: 0.1683., accu: 0.9070, speed: 1.07 step/s\n",
      "global step 16520, epoch: 4, batch: 1730, loss: 0.1402,domain_loss: 0.0101 ,ce_loss: 0.1728., accu: 0.9086, speed: 1.18 step/s\n",
      "global step 16530, epoch: 4, batch: 1740, loss: 0.1759,domain_loss: 0.0876 ,ce_loss: 0.1980., accu: 0.9083, speed: 1.17 step/s\n",
      "global step 16540, epoch: 4, batch: 1750, loss: 0.1510,domain_loss: 0.0084 ,ce_loss: 0.1866., accu: 0.9066, speed: 1.19 step/s\n",
      "global step 16550, epoch: 4, batch: 1760, loss: 0.1855,domain_loss: 0.0394 ,ce_loss: 0.2220., accu: 0.9044, speed: 1.18 step/s\n",
      "global step 16560, epoch: 4, batch: 1770, loss: 0.2150,domain_loss: 0.0118 ,ce_loss: 0.2658., accu: 0.9060, speed: 1.17 step/s\n",
      "global step 16570, epoch: 4, batch: 1780, loss: 0.1676,domain_loss: 0.0897 ,ce_loss: 0.1870., accu: 0.9071, speed: 1.19 step/s\n",
      "global step 16580, epoch: 4, batch: 1790, loss: 0.1766,domain_loss: 0.0673 ,ce_loss: 0.2039., accu: 0.9075, speed: 1.21 step/s\n",
      "global step 16590, epoch: 4, batch: 1800, loss: 0.2337,domain_loss: 0.0411 ,ce_loss: 0.2819., accu: 0.9085, speed: 1.18 step/s\n",
      "global step 16600, epoch: 4, batch: 1810, loss: 0.2049,domain_loss: 0.0025 ,ce_loss: 0.2555., accu: 0.9084, speed: 1.17 step/s\n",
      "global step 16610, epoch: 4, batch: 1820, loss: 0.1951,domain_loss: 0.0028 ,ce_loss: 0.2431., accu: 0.9076, speed: 1.19 step/s\n",
      "global step 16620, epoch: 4, batch: 1830, loss: 0.1105,domain_loss: 0.0218 ,ce_loss: 0.1326., accu: 0.9095, speed: 1.18 step/s\n",
      "global step 16630, epoch: 4, batch: 1840, loss: 0.2060,domain_loss: 0.0151 ,ce_loss: 0.2537., accu: 0.9092, speed: 1.18 step/s\n",
      "global step 16640, epoch: 4, batch: 1850, loss: 0.2225,domain_loss: 0.0616 ,ce_loss: 0.2627., accu: 0.9089, speed: 1.21 step/s\n",
      "global step 16650, epoch: 4, batch: 1860, loss: 0.1740,domain_loss: 0.0378 ,ce_loss: 0.2080., accu: 0.9096, speed: 1.18 step/s\n",
      "global step 16660, epoch: 4, batch: 1870, loss: 0.2029,domain_loss: 0.1000 ,ce_loss: 0.2286., accu: 0.9089, speed: 1.18 step/s\n",
      "global step 16670, epoch: 4, batch: 1880, loss: 0.1247,domain_loss: 0.0044 ,ce_loss: 0.1548., accu: 0.9085, speed: 1.18 step/s\n",
      "global step 16680, epoch: 4, batch: 1890, loss: 0.1594,domain_loss: 0.0362 ,ce_loss: 0.1903., accu: 0.9086, speed: 1.18 step/s\n",
      "global step 16690, epoch: 4, batch: 1900, loss: 0.1474,domain_loss: 0.0146 ,ce_loss: 0.1805., accu: 0.9085, speed: 1.18 step/s\n",
      "global step 16700, epoch: 4, batch: 1910, loss: 0.1149,domain_loss: 0.0046 ,ce_loss: 0.1425., accu: 0.9091, speed: 1.17 step/s\n",
      "global step 16710, epoch: 4, batch: 1920, loss: 0.1794,domain_loss: 0.0536 ,ce_loss: 0.2108., accu: 0.9090, speed: 1.17 step/s\n",
      "global step 16720, epoch: 4, batch: 1930, loss: 0.1963,domain_loss: 0.0667 ,ce_loss: 0.2287., accu: 0.9091, speed: 1.18 step/s\n",
      "global step 16730, epoch: 4, batch: 1940, loss: 0.2155,domain_loss: 0.0618 ,ce_loss: 0.2539., accu: 0.9085, speed: 1.18 step/s\n",
      "global step 16740, epoch: 4, batch: 1950, loss: 0.1468,domain_loss: 0.0834 ,ce_loss: 0.1627., accu: 0.9081, speed: 1.19 step/s\n",
      "global step 16750, epoch: 4, batch: 1960, loss: 0.1493,domain_loss: 0.0139 ,ce_loss: 0.1832., accu: 0.9078, speed: 1.18 step/s\n",
      "global step 16760, epoch: 4, batch: 1970, loss: 0.1536,domain_loss: 0.0337 ,ce_loss: 0.1835., accu: 0.9082, speed: 1.18 step/s\n",
      "global step 16770, epoch: 4, batch: 1980, loss: 0.1262,domain_loss: 0.0087 ,ce_loss: 0.1556., accu: 0.9082, speed: 1.18 step/s\n",
      "global step 16780, epoch: 4, batch: 1990, loss: 0.1606,domain_loss: 0.0904 ,ce_loss: 0.1782., accu: 0.9082, speed: 1.21 step/s\n",
      "global step 16790, epoch: 4, batch: 2000, loss: 0.1196,domain_loss: 0.0053 ,ce_loss: 0.1481., accu: 0.9085, speed: 1.20 step/s\n",
      "global step 16800, epoch: 4, batch: 2010, loss: 0.1702,domain_loss: 0.0288 ,ce_loss: 0.2056., accu: 0.9086, speed: 1.18 step/s\n",
      "2022-09-29 03:41:11,173\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 16800, epoch: 4, batch: 2010】，loss: 0.1702,domain_loss: 0.0288 ,ce_loss: 0.2056., accu: 0.9086,\n",
      "2022-09-29 03:41:11,486\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.076332, accuracy: 0.97[0.97],threshold:0.258, domain_acc:1.0,total_num:100\n",
      "2022-09-29 03:41:12,385\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 16810, epoch: 4, batch: 2020, loss: 0.1416,domain_loss: 0.0205 ,ce_loss: 0.1719., accu: 0.9141, speed: 1.04 step/s\n",
      "global step 16820, epoch: 4, batch: 2030, loss: 0.1619,domain_loss: 0.0076 ,ce_loss: 0.2005., accu: 0.9062, speed: 1.18 step/s\n",
      "global step 16830, epoch: 4, batch: 2040, loss: 0.2071,domain_loss: 0.0073 ,ce_loss: 0.2570., accu: 0.9073, speed: 1.18 step/s\n",
      "global step 16840, epoch: 4, batch: 2050, loss: 0.2092,domain_loss: 0.0452 ,ce_loss: 0.2501., accu: 0.9057, speed: 1.18 step/s\n",
      "global step 16850, epoch: 4, batch: 2060, loss: 0.2067,domain_loss: 0.0420 ,ce_loss: 0.2479., accu: 0.9080, speed: 1.18 step/s\n",
      "global step 16860, epoch: 4, batch: 2070, loss: 0.2284,domain_loss: 0.0663 ,ce_loss: 0.2689., accu: 0.9083, speed: 1.18 step/s\n",
      "global step 16870, epoch: 4, batch: 2080, loss: 0.1949,domain_loss: 0.0037 ,ce_loss: 0.2427., accu: 0.9081, speed: 1.19 step/s\n",
      "global step 16880, epoch: 4, batch: 2090, loss: 0.2072,domain_loss: 0.0456 ,ce_loss: 0.2477., accu: 0.9091, speed: 1.17 step/s\n",
      "global step 16890, epoch: 4, batch: 2100, loss: 0.1859,domain_loss: 0.0154 ,ce_loss: 0.2285., accu: 0.9086, speed: 1.19 step/s\n",
      "global step 16900, epoch: 4, batch: 2110, loss: 0.1815,domain_loss: 0.0161 ,ce_loss: 0.2229., accu: 0.9091, speed: 1.20 step/s\n",
      "global step 16910, epoch: 4, batch: 2120, loss: 0.1962,domain_loss: 0.0020 ,ce_loss: 0.2448., accu: 0.9084, speed: 1.18 step/s\n",
      "global step 16920, epoch: 4, batch: 2130, loss: 0.1742,domain_loss: 0.0347 ,ce_loss: 0.2091., accu: 0.9089, speed: 1.17 step/s\n",
      "global step 16930, epoch: 4, batch: 2140, loss: 0.1492,domain_loss: 0.0199 ,ce_loss: 0.1815., accu: 0.9084, speed: 1.18 step/s\n",
      "global step 16940, epoch: 4, batch: 2150, loss: 0.1941,domain_loss: 0.0328 ,ce_loss: 0.2344., accu: 0.9081, speed: 1.19 step/s\n",
      "global step 16950, epoch: 4, batch: 2160, loss: 0.3022,domain_loss: 0.0225 ,ce_loss: 0.3721., accu: 0.9085, speed: 1.21 step/s\n",
      "global step 16960, epoch: 4, batch: 2170, loss: 0.1860,domain_loss: 0.0049 ,ce_loss: 0.2312., accu: 0.9094, speed: 1.20 step/s\n",
      "global step 16970, epoch: 4, batch: 2180, loss: 0.1018,domain_loss: 0.0057 ,ce_loss: 0.1258., accu: 0.9101, speed: 1.17 step/s\n",
      "global step 16980, epoch: 4, batch: 2190, loss: 0.1805,domain_loss: 0.1257 ,ce_loss: 0.1942., accu: 0.9094, speed: 1.18 step/s\n",
      "global step 16990, epoch: 4, batch: 2200, loss: 0.1515,domain_loss: 0.0095 ,ce_loss: 0.1870., accu: 0.9094, speed: 1.20 step/s\n",
      "global step 17000, epoch: 4, batch: 2210, loss: 0.1312,domain_loss: 0.0833 ,ce_loss: 0.1432., accu: 0.9096, speed: 1.19 step/s\n",
      "global step 17010, epoch: 4, batch: 2220, loss: 0.1924,domain_loss: 0.0360 ,ce_loss: 0.2315., accu: 0.9092, speed: 1.18 step/s\n",
      "global step 17020, epoch: 4, batch: 2230, loss: 0.2206,domain_loss: 0.0090 ,ce_loss: 0.2735., accu: 0.9096, speed: 1.18 step/s\n",
      "global step 17030, epoch: 4, batch: 2240, loss: 0.1522,domain_loss: 0.0444 ,ce_loss: 0.1792., accu: 0.9102, speed: 1.18 step/s\n",
      "global step 17040, epoch: 4, batch: 2250, loss: 0.1422,domain_loss: 0.0190 ,ce_loss: 0.1730., accu: 0.9103, speed: 1.18 step/s\n",
      "global step 17050, epoch: 4, batch: 2260, loss: 0.1459,domain_loss: 0.0108 ,ce_loss: 0.1797., accu: 0.9104, speed: 1.20 step/s\n",
      "global step 17060, epoch: 4, batch: 2270, loss: 0.1031,domain_loss: 0.0232 ,ce_loss: 0.1231., accu: 0.9105, speed: 1.20 step/s\n",
      "global step 17070, epoch: 4, batch: 2280, loss: 0.1765,domain_loss: 0.0461 ,ce_loss: 0.2091., accu: 0.9105, speed: 1.18 step/s\n",
      "global step 17080, epoch: 4, batch: 2290, loss: 0.1638,domain_loss: 0.0348 ,ce_loss: 0.1960., accu: 0.9107, speed: 1.18 step/s\n",
      "global step 17090, epoch: 4, batch: 2300, loss: 0.2163,domain_loss: 0.0469 ,ce_loss: 0.2587., accu: 0.9107, speed: 1.19 step/s\n",
      "global step 17100, epoch: 4, batch: 2310, loss: 0.1824,domain_loss: 0.0307 ,ce_loss: 0.2203., accu: 0.9106, speed: 1.18 step/s\n",
      "2022-09-29 03:45:25,449\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 17100, epoch: 4, batch: 2310】，loss: 0.1824,domain_loss: 0.0307 ,ce_loss: 0.2203., accu: 0.9106,\n",
      "2022-09-29 03:45:25,771\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.089439, accuracy: 0.96[0.98],threshold:0.224, domain_acc:1.0,total_num:100\n",
      "global step 17110, epoch: 4, batch: 2320, loss: 0.1936,domain_loss: 0.0081 ,ce_loss: 0.2400., accu: 0.9008, speed: 1.06 step/s\n",
      "global step 17120, epoch: 4, batch: 2330, loss: 0.1598,domain_loss: 0.0201 ,ce_loss: 0.1947., accu: 0.9051, speed: 1.18 step/s\n",
      "global step 17130, epoch: 4, batch: 2340, loss: 0.1699,domain_loss: 0.0906 ,ce_loss: 0.1898., accu: 0.9099, speed: 1.18 step/s\n",
      "global step 17140, epoch: 4, batch: 2350, loss: 0.1329,domain_loss: 0.0158 ,ce_loss: 0.1622., accu: 0.9096, speed: 1.18 step/s\n",
      "global step 17150, epoch: 4, batch: 2360, loss: 0.1802,domain_loss: 0.0109 ,ce_loss: 0.2226., accu: 0.9084, speed: 1.17 step/s\n",
      "global step 17160, epoch: 4, batch: 2370, loss: 0.1960,domain_loss: 0.0136 ,ce_loss: 0.2416., accu: 0.9091, speed: 1.19 step/s\n",
      "global step 17170, epoch: 4, batch: 2380, loss: 0.1687,domain_loss: 0.0259 ,ce_loss: 0.2044., accu: 0.9088, speed: 1.19 step/s\n",
      "global step 17180, epoch: 4, batch: 2390, loss: 0.1795,domain_loss: 0.0106 ,ce_loss: 0.2217., accu: 0.9077, speed: 1.19 step/s\n",
      "global step 17190, epoch: 4, batch: 2400, loss: 0.2559,domain_loss: 0.0246 ,ce_loss: 0.3137., accu: 0.9076, speed: 1.18 step/s\n",
      "global step 17200, epoch: 4, batch: 2410, loss: 0.2191,domain_loss: 0.0216 ,ce_loss: 0.2685., accu: 0.9077, speed: 1.18 step/s\n",
      "global step 17210, epoch: 4, batch: 2420, loss: 0.1711,domain_loss: 0.0353 ,ce_loss: 0.2050., accu: 0.9075, speed: 1.17 step/s\n",
      "global step 17220, epoch: 4, batch: 2430, loss: 0.1305,domain_loss: 0.0127 ,ce_loss: 0.1599., accu: 0.9079, speed: 1.20 step/s\n",
      "global step 17230, epoch: 4, batch: 2440, loss: 0.1072,domain_loss: 0.0172 ,ce_loss: 0.1297., accu: 0.9094, speed: 1.19 step/s\n",
      "global step 17240, epoch: 4, batch: 2450, loss: 0.1629,domain_loss: 0.0669 ,ce_loss: 0.1869., accu: 0.9092, speed: 1.19 step/s\n",
      "global step 17250, epoch: 4, batch: 2460, loss: 0.1454,domain_loss: 0.0392 ,ce_loss: 0.1719., accu: 0.9096, speed: 1.18 step/s\n",
      "global step 17260, epoch: 4, batch: 2470, loss: 0.2196,domain_loss: 0.0178 ,ce_loss: 0.2701., accu: 0.9097, speed: 1.19 step/s\n",
      "global step 17270, epoch: 4, batch: 2480, loss: 0.1527,domain_loss: 0.0047 ,ce_loss: 0.1897., accu: 0.9099, speed: 1.17 step/s\n",
      "global step 17280, epoch: 4, batch: 2490, loss: 0.1758,domain_loss: 0.0323 ,ce_loss: 0.2117., accu: 0.9099, speed: 1.18 step/s\n",
      "global step 17290, epoch: 4, batch: 2500, loss: 0.1636,domain_loss: 0.0210 ,ce_loss: 0.1993., accu: 0.9105, speed: 1.17 step/s\n",
      "global step 17300, epoch: 4, batch: 2510, loss: 0.1967,domain_loss: 0.0025 ,ce_loss: 0.2452., accu: 0.9101, speed: 1.18 step/s\n",
      "global step 17310, epoch: 4, batch: 2520, loss: 0.2295,domain_loss: 0.0972 ,ce_loss: 0.2626., accu: 0.9094, speed: 1.18 step/s\n",
      "global step 17320, epoch: 4, batch: 2530, loss: 0.1441,domain_loss: 0.0208 ,ce_loss: 0.1749., accu: 0.9095, speed: 1.18 step/s\n",
      "global step 17330, epoch: 4, batch: 2540, loss: 0.1483,domain_loss: 0.0088 ,ce_loss: 0.1832., accu: 0.9102, speed: 1.18 step/s\n",
      "global step 17340, epoch: 4, batch: 2550, loss: 0.1333,domain_loss: 0.0193 ,ce_loss: 0.1618., accu: 0.9107, speed: 1.19 step/s\n",
      "global step 17350, epoch: 4, batch: 2560, loss: 0.1826,domain_loss: 0.0812 ,ce_loss: 0.2080., accu: 0.9107, speed: 1.18 step/s\n",
      "global step 17360, epoch: 4, batch: 2570, loss: 0.1289,domain_loss: 0.0022 ,ce_loss: 0.1606., accu: 0.9109, speed: 1.17 step/s\n",
      "global step 17370, epoch: 4, batch: 2580, loss: 0.1928,domain_loss: 0.0699 ,ce_loss: 0.2235., accu: 0.9109, speed: 1.18 step/s\n",
      "global step 17380, epoch: 4, batch: 2590, loss: 0.1332,domain_loss: 0.0455 ,ce_loss: 0.1551., accu: 0.9111, speed: 1.20 step/s\n",
      "global step 17390, epoch: 4, batch: 2600, loss: 0.2213,domain_loss: 0.0271 ,ce_loss: 0.2698., accu: 0.9110, speed: 1.17 step/s\n",
      "global step 17400, epoch: 4, batch: 2610, loss: 0.0968,domain_loss: 0.0507 ,ce_loss: 0.1083., accu: 0.9113, speed: 1.20 step/s\n",
      "2022-09-29 03:49:40,055\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 17400, epoch: 4, batch: 2610】，loss: 0.0968,domain_loss: 0.0507 ,ce_loss: 0.1083., accu: 0.9113,\n",
      "2022-09-29 03:49:40,354\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.072871, accuracy: 0.97[0.97],threshold:0.22, domain_acc:1.0,total_num:100\n",
      "global step 17410, epoch: 4, batch: 2620, loss: 0.2162,domain_loss: 0.0069 ,ce_loss: 0.2685., accu: 0.9195, speed: 1.05 step/s\n",
      "global step 17420, epoch: 4, batch: 2630, loss: 0.1702,domain_loss: 0.0193 ,ce_loss: 0.2079., accu: 0.9168, speed: 1.19 step/s\n",
      "global step 17430, epoch: 4, batch: 2640, loss: 0.1730,domain_loss: 0.0081 ,ce_loss: 0.2142., accu: 0.9187, speed: 1.18 step/s\n",
      "global step 17440, epoch: 4, batch: 2650, loss: 0.2210,domain_loss: 0.0239 ,ce_loss: 0.2703., accu: 0.9166, speed: 1.22 step/s\n",
      "global step 17450, epoch: 4, batch: 2660, loss: 0.1845,domain_loss: 0.0056 ,ce_loss: 0.2292., accu: 0.9156, speed: 1.19 step/s\n",
      "global step 17460, epoch: 4, batch: 2670, loss: 0.1335,domain_loss: 0.0084 ,ce_loss: 0.1648., accu: 0.9137, speed: 1.19 step/s\n",
      "global step 17470, epoch: 4, batch: 2680, loss: 0.1461,domain_loss: 0.0227 ,ce_loss: 0.1770., accu: 0.9127, speed: 1.18 step/s\n",
      "global step 17480, epoch: 4, batch: 2690, loss: 0.2111,domain_loss: 0.0207 ,ce_loss: 0.2587., accu: 0.9132, speed: 1.19 step/s\n",
      "global step 17490, epoch: 4, batch: 2700, loss: 0.1472,domain_loss: 0.0522 ,ce_loss: 0.1709., accu: 0.9128, speed: 1.18 step/s\n",
      "global step 17500, epoch: 4, batch: 2710, loss: 0.1688,domain_loss: 0.0050 ,ce_loss: 0.2097., accu: 0.9119, speed: 1.17 step/s\n",
      "global step 17510, epoch: 4, batch: 2720, loss: 0.1684,domain_loss: 0.0057 ,ce_loss: 0.2091., accu: 0.9126, speed: 1.20 step/s\n",
      "global step 17520, epoch: 4, batch: 2730, loss: 0.1587,domain_loss: 0.0129 ,ce_loss: 0.1951., accu: 0.9122, speed: 1.17 step/s\n",
      "global step 17530, epoch: 4, batch: 2740, loss: 0.1551,domain_loss: 0.0045 ,ce_loss: 0.1928., accu: 0.9133, speed: 1.19 step/s\n",
      "global step 17540, epoch: 4, batch: 2750, loss: 0.1463,domain_loss: 0.0466 ,ce_loss: 0.1712., accu: 0.9132, speed: 1.17 step/s\n",
      "global step 17550, epoch: 4, batch: 2760, loss: 0.1801,domain_loss: 0.0295 ,ce_loss: 0.2177., accu: 0.9132, speed: 1.19 step/s\n",
      "global step 17560, epoch: 4, batch: 2770, loss: 0.1347,domain_loss: 0.0121 ,ce_loss: 0.1654., accu: 0.9128, speed: 1.20 step/s\n",
      "global step 17570, epoch: 4, batch: 2780, loss: 0.1117,domain_loss: 0.0233 ,ce_loss: 0.1338., accu: 0.9120, speed: 1.19 step/s\n",
      "global step 17580, epoch: 4, batch: 2790, loss: 0.1423,domain_loss: 0.0054 ,ce_loss: 0.1766., accu: 0.9119, speed: 1.18 step/s\n",
      "global step 17590, epoch: 4, batch: 2800, loss: 0.2465,domain_loss: 0.0023 ,ce_loss: 0.3076., accu: 0.9117, speed: 1.18 step/s\n",
      "global step 17600, epoch: 4, batch: 2810, loss: 0.1882,domain_loss: 0.0053 ,ce_loss: 0.2339., accu: 0.9116, speed: 1.17 step/s\n",
      "global step 17610, epoch: 4, batch: 2820, loss: 0.1461,domain_loss: 0.0034 ,ce_loss: 0.1818., accu: 0.9114, speed: 1.17 step/s\n",
      "global step 17620, epoch: 4, batch: 2830, loss: 0.2610,domain_loss: 0.0280 ,ce_loss: 0.3193., accu: 0.9109, speed: 1.19 step/s\n",
      "global step 17630, epoch: 4, batch: 2840, loss: 0.1362,domain_loss: 0.0182 ,ce_loss: 0.1657., accu: 0.9108, speed: 1.18 step/s\n",
      "global step 17640, epoch: 4, batch: 2850, loss: 0.2249,domain_loss: 0.0115 ,ce_loss: 0.2783., accu: 0.9109, speed: 1.17 step/s\n",
      "global step 17650, epoch: 4, batch: 2860, loss: 0.1063,domain_loss: 0.0301 ,ce_loss: 0.1253., accu: 0.9113, speed: 1.19 step/s\n",
      "global step 17660, epoch: 4, batch: 2870, loss: 0.1725,domain_loss: 0.0471 ,ce_loss: 0.2039., accu: 0.9118, speed: 1.18 step/s\n",
      "global step 17670, epoch: 4, batch: 2880, loss: 0.1422,domain_loss: 0.0239 ,ce_loss: 0.1717., accu: 0.9116, speed: 1.17 step/s\n",
      "global step 17680, epoch: 4, batch: 2890, loss: 0.2079,domain_loss: 0.0394 ,ce_loss: 0.2500., accu: 0.9122, speed: 1.18 step/s\n",
      "global step 17690, epoch: 4, batch: 2900, loss: 0.1974,domain_loss: 0.0370 ,ce_loss: 0.2375., accu: 0.9126, speed: 1.18 step/s\n",
      "global step 17700, epoch: 4, batch: 2910, loss: 0.1903,domain_loss: 0.0077 ,ce_loss: 0.2360., accu: 0.9122, speed: 1.19 step/s\n",
      "2022-09-29 03:53:54,484\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 17700, epoch: 4, batch: 2910】，loss: 0.1903,domain_loss: 0.0077 ,ce_loss: 0.2360., accu: 0.9122,\n",
      "2022-09-29 03:53:54,794\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.086422, accuracy: 0.96[0.97],threshold:0.252, domain_acc:1.0,total_num:100\n",
      "2022-09-29 03:53:55,656\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 17710, epoch: 4, batch: 2920, loss: 0.1370,domain_loss: 0.0224 ,ce_loss: 0.1656., accu: 0.9242, speed: 1.03 step/s\n",
      "global step 17720, epoch: 4, batch: 2930, loss: 0.1919,domain_loss: 0.0085 ,ce_loss: 0.2378., accu: 0.9148, speed: 1.17 step/s\n",
      "global step 17730, epoch: 4, batch: 2940, loss: 0.1633,domain_loss: 0.0208 ,ce_loss: 0.1989., accu: 0.9120, speed: 1.21 step/s\n",
      "global step 17740, epoch: 4, batch: 2950, loss: 0.1973,domain_loss: 0.0901 ,ce_loss: 0.2241., accu: 0.9127, speed: 1.17 step/s\n",
      "global step 17750, epoch: 4, batch: 2960, loss: 0.1586,domain_loss: 0.0115 ,ce_loss: 0.1953., accu: 0.9114, speed: 1.18 step/s\n",
      "global step 17760, epoch: 4, batch: 2970, loss: 0.1337,domain_loss: 0.0264 ,ce_loss: 0.1605., accu: 0.9130, speed: 1.17 step/s\n",
      "global step 17770, epoch: 4, batch: 2980, loss: 0.1791,domain_loss: 0.0207 ,ce_loss: 0.2186., accu: 0.9122, speed: 1.17 step/s\n",
      "global step 17780, epoch: 4, batch: 2990, loss: 0.1190,domain_loss: 0.0610 ,ce_loss: 0.1335., accu: 0.9106, speed: 1.18 step/s\n",
      "global step 17790, epoch: 4, batch: 3000, loss: 0.2304,domain_loss: 0.0207 ,ce_loss: 0.2828., accu: 0.9102, speed: 1.19 step/s\n",
      "global step 17800, epoch: 4, batch: 3010, loss: 0.1575,domain_loss: 0.0337 ,ce_loss: 0.1884., accu: 0.9104, speed: 1.19 step/s\n",
      "global step 17810, epoch: 4, batch: 3020, loss: 0.1693,domain_loss: 0.0438 ,ce_loss: 0.2006., accu: 0.9097, speed: 1.17 step/s\n",
      "global step 17820, epoch: 4, batch: 3030, loss: 0.1345,domain_loss: 0.0225 ,ce_loss: 0.1624., accu: 0.9103, speed: 1.17 step/s\n",
      "global step 17830, epoch: 4, batch: 3040, loss: 0.1784,domain_loss: 0.0193 ,ce_loss: 0.2181., accu: 0.9111, speed: 1.18 step/s\n",
      "global step 17840, epoch: 4, batch: 3050, loss: 0.1448,domain_loss: 0.0114 ,ce_loss: 0.1781., accu: 0.9107, speed: 1.17 step/s\n",
      "global step 17850, epoch: 4, batch: 3060, loss: 0.1568,domain_loss: 0.0079 ,ce_loss: 0.1940., accu: 0.9110, speed: 1.17 step/s\n",
      "global step 17860, epoch: 4, batch: 3070, loss: 0.1709,domain_loss: 0.0260 ,ce_loss: 0.2071., accu: 0.9111, speed: 1.19 step/s\n",
      "global step 17870, epoch: 4, batch: 3080, loss: 0.1082,domain_loss: 0.0266 ,ce_loss: 0.1286., accu: 0.9106, speed: 1.19 step/s\n",
      "global step 17880, epoch: 4, batch: 3090, loss: 0.1614,domain_loss: 0.0029 ,ce_loss: 0.2010., accu: 0.9109, speed: 1.17 step/s\n",
      "global step 17890, epoch: 4, batch: 3100, loss: 0.1568,domain_loss: 0.0354 ,ce_loss: 0.1871., accu: 0.9114, speed: 1.19 step/s\n",
      "global step 17900, epoch: 4, batch: 3110, loss: 0.1993,domain_loss: 0.0281 ,ce_loss: 0.2421., accu: 0.9123, speed: 1.18 step/s\n",
      "global step 17910, epoch: 4, batch: 3120, loss: 0.1344,domain_loss: 0.0049 ,ce_loss: 0.1667., accu: 0.9118, speed: 1.17 step/s\n",
      "global step 17920, epoch: 4, batch: 3130, loss: 0.1703,domain_loss: 0.0027 ,ce_loss: 0.2122., accu: 0.9113, speed: 1.19 step/s\n",
      "global step 17930, epoch: 4, batch: 3140, loss: 0.1563,domain_loss: 0.0427 ,ce_loss: 0.1847., accu: 0.9114, speed: 1.18 step/s\n",
      "global step 17940, epoch: 4, batch: 3150, loss: 0.1832,domain_loss: 0.0017 ,ce_loss: 0.2286., accu: 0.9114, speed: 1.18 step/s\n",
      "global step 17950, epoch: 4, batch: 3160, loss: 0.1895,domain_loss: 0.0293 ,ce_loss: 0.2295., accu: 0.9114, speed: 1.18 step/s\n",
      "global step 17960, epoch: 4, batch: 3170, loss: 0.1625,domain_loss: 0.0647 ,ce_loss: 0.1870., accu: 0.9113, speed: 1.18 step/s\n",
      "global step 17970, epoch: 4, batch: 3180, loss: 0.1908,domain_loss: 0.0197 ,ce_loss: 0.2335., accu: 0.9113, speed: 1.17 step/s\n",
      "global step 17980, epoch: 4, batch: 3190, loss: 0.2573,domain_loss: 0.0408 ,ce_loss: 0.3114., accu: 0.9113, speed: 1.18 step/s\n",
      "global step 17990, epoch: 4, batch: 3200, loss: 0.1461,domain_loss: 0.0185 ,ce_loss: 0.1780., accu: 0.9113, speed: 1.18 step/s\n",
      "global step 18000, epoch: 4, batch: 3210, loss: 0.1512,domain_loss: 0.0460 ,ce_loss: 0.1775., accu: 0.9111, speed: 1.17 step/s\n",
      "2022-09-29 03:58:10,040\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 18000, epoch: 4, batch: 3210】，loss: 0.1512,domain_loss: 0.0460 ,ce_loss: 0.1775., accu: 0.9111,\n",
      "2022-09-29 03:58:10,351\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.087631, accuracy: 0.96[0.97],threshold:0.26, domain_acc:1.0,total_num:100\n",
      "global step 18010, epoch: 4, batch: 3220, loss: 0.1873,domain_loss: 0.0206 ,ce_loss: 0.2289., accu: 0.8953, speed: 1.06 step/s\n",
      "global step 18020, epoch: 4, batch: 3230, loss: 0.2997,domain_loss: 0.0720 ,ce_loss: 0.3566., accu: 0.8965, speed: 1.19 step/s\n",
      "global step 18030, epoch: 4, batch: 3240, loss: 0.2362,domain_loss: 0.0366 ,ce_loss: 0.2861., accu: 0.9016, speed: 1.18 step/s\n",
      "global step 18040, epoch: 4, batch: 3250, loss: 0.1291,domain_loss: 0.0020 ,ce_loss: 0.1609., accu: 0.9047, speed: 1.17 step/s\n",
      "global step 18050, epoch: 4, batch: 3260, loss: 0.2246,domain_loss: 0.1039 ,ce_loss: 0.2548., accu: 0.9052, speed: 1.17 step/s\n",
      "global step 18060, epoch: 4, batch: 3270, loss: 0.1435,domain_loss: 0.0384 ,ce_loss: 0.1698., accu: 0.9051, speed: 1.18 step/s\n",
      "global step 18070, epoch: 4, batch: 3280, loss: 0.2025,domain_loss: 0.0040 ,ce_loss: 0.2521., accu: 0.9045, speed: 1.17 step/s\n",
      "global step 18080, epoch: 4, batch: 3290, loss: 0.1297,domain_loss: 0.0051 ,ce_loss: 0.1609., accu: 0.9047, speed: 1.17 step/s\n",
      "global step 18090, epoch: 4, batch: 3300, loss: 0.1389,domain_loss: 0.0066 ,ce_loss: 0.1720., accu: 0.9057, speed: 1.18 step/s\n",
      "global step 18100, epoch: 4, batch: 3310, loss: 0.1899,domain_loss: 0.0387 ,ce_loss: 0.2276., accu: 0.9066, speed: 1.17 step/s\n",
      "global step 18110, epoch: 4, batch: 3320, loss: 0.2010,domain_loss: 0.0106 ,ce_loss: 0.2486., accu: 0.9067, speed: 1.18 step/s\n",
      "global step 18120, epoch: 4, batch: 3330, loss: 0.2265,domain_loss: 0.0415 ,ce_loss: 0.2727., accu: 0.9064, speed: 1.18 step/s\n",
      "global step 18130, epoch: 4, batch: 3340, loss: 0.2097,domain_loss: 0.0043 ,ce_loss: 0.2611., accu: 0.9058, speed: 1.19 step/s\n",
      "global step 18140, epoch: 4, batch: 3350, loss: 0.1835,domain_loss: 0.0493 ,ce_loss: 0.2171., accu: 0.9057, speed: 1.19 step/s\n",
      "global step 18150, epoch: 4, batch: 3360, loss: 0.1980,domain_loss: 0.0165 ,ce_loss: 0.2434., accu: 0.9060, speed: 1.18 step/s\n",
      "global step 18160, epoch: 4, batch: 3370, loss: 0.2821,domain_loss: 0.0606 ,ce_loss: 0.3375., accu: 0.9062, speed: 1.17 step/s\n",
      "global step 18170, epoch: 4, batch: 3380, loss: 0.1356,domain_loss: 0.0032 ,ce_loss: 0.1687., accu: 0.9064, speed: 1.19 step/s\n",
      "global step 18180, epoch: 4, batch: 3390, loss: 0.1629,domain_loss: 0.0456 ,ce_loss: 0.1922., accu: 0.9069, speed: 1.17 step/s\n",
      "global step 18190, epoch: 4, batch: 3400, loss: 0.1268,domain_loss: 0.0346 ,ce_loss: 0.1498., accu: 0.9076, speed: 1.17 step/s\n",
      "global step 18200, epoch: 4, batch: 3410, loss: 0.1727,domain_loss: 0.0588 ,ce_loss: 0.2012., accu: 0.9073, speed: 1.18 step/s\n",
      "global step 18210, epoch: 4, batch: 3420, loss: 0.1200,domain_loss: 0.0021 ,ce_loss: 0.1495., accu: 0.9077, speed: 1.17 step/s\n",
      "global step 18220, epoch: 4, batch: 3430, loss: 0.1281,domain_loss: 0.0066 ,ce_loss: 0.1584., accu: 0.9077, speed: 1.19 step/s\n",
      "global step 18230, epoch: 4, batch: 3440, loss: 0.1576,domain_loss: 0.0297 ,ce_loss: 0.1895., accu: 0.9078, speed: 1.18 step/s\n",
      "global step 18240, epoch: 4, batch: 3450, loss: 0.1889,domain_loss: 0.0416 ,ce_loss: 0.2257., accu: 0.9075, speed: 1.17 step/s\n",
      "global step 18250, epoch: 4, batch: 3460, loss: 0.1850,domain_loss: 0.0021 ,ce_loss: 0.2307., accu: 0.9079, speed: 1.18 step/s\n",
      "global step 18260, epoch: 4, batch: 3470, loss: 0.1270,domain_loss: 0.0055 ,ce_loss: 0.1574., accu: 0.9078, speed: 1.17 step/s\n",
      "global step 18270, epoch: 4, batch: 3480, loss: 0.1735,domain_loss: 0.0064 ,ce_loss: 0.2153., accu: 0.9080, speed: 1.18 step/s\n",
      "global step 18280, epoch: 4, batch: 3490, loss: 0.1657,domain_loss: 0.0445 ,ce_loss: 0.1960., accu: 0.9080, speed: 1.19 step/s\n",
      "global step 18290, epoch: 4, batch: 3500, loss: 0.1608,domain_loss: 0.0027 ,ce_loss: 0.2004., accu: 0.9080, speed: 1.18 step/s\n",
      "global step 18300, epoch: 4, batch: 3510, loss: 0.1786,domain_loss: 0.0697 ,ce_loss: 0.2058., accu: 0.9082, speed: 1.21 step/s\n",
      "2022-09-29 04:02:25,328\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 18300, epoch: 4, batch: 3510】，loss: 0.1786,domain_loss: 0.0697 ,ce_loss: 0.2058., accu: 0.9082,\n",
      "2022-09-29 04:02:25,639\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.097088, accuracy: 0.95[0.97],threshold:0.21, domain_acc:1.0,total_num:100\n",
      "2022-09-29 04:02:26,521\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 18310, epoch: 4, batch: 3520, loss: 0.1649,domain_loss: 0.0179 ,ce_loss: 0.2016., accu: 0.8969, speed: 1.04 step/s\n",
      "global step 18320, epoch: 4, batch: 3530, loss: 0.1666,domain_loss: 0.0557 ,ce_loss: 0.1943., accu: 0.9023, speed: 1.17 step/s\n",
      "global step 18330, epoch: 4, batch: 3540, loss: 0.1735,domain_loss: 0.0043 ,ce_loss: 0.2158., accu: 0.9076, speed: 1.18 step/s\n",
      "global step 18340, epoch: 4, batch: 3550, loss: 0.1585,domain_loss: 0.0712 ,ce_loss: 0.1803., accu: 0.9053, speed: 1.17 step/s\n",
      "global step 18350, epoch: 4, batch: 3560, loss: 0.1768,domain_loss: 0.0257 ,ce_loss: 0.2145., accu: 0.9080, speed: 1.18 step/s\n",
      "global step 18360, epoch: 4, batch: 3570, loss: 0.1203,domain_loss: 0.0104 ,ce_loss: 0.1478., accu: 0.9073, speed: 1.17 step/s\n",
      "global step 18370, epoch: 4, batch: 3580, loss: 0.1767,domain_loss: 0.0400 ,ce_loss: 0.2109., accu: 0.9073, speed: 1.17 step/s\n",
      "global step 18380, epoch: 4, batch: 3590, loss: 0.1901,domain_loss: 0.0291 ,ce_loss: 0.2304., accu: 0.9066, speed: 1.17 step/s\n",
      "global step 18390, epoch: 4, batch: 3600, loss: 0.1757,domain_loss: 0.0227 ,ce_loss: 0.2139., accu: 0.9069, speed: 1.17 step/s\n",
      "global step 18400, epoch: 4, batch: 3610, loss: 0.2031,domain_loss: 0.0348 ,ce_loss: 0.2451., accu: 0.9054, speed: 1.18 step/s\n",
      "global step 18410, epoch: 4, batch: 3620, loss: 0.2148,domain_loss: 0.0551 ,ce_loss: 0.2548., accu: 0.9065, speed: 1.18 step/s\n",
      "global step 18420, epoch: 4, batch: 3630, loss: 0.1359,domain_loss: 0.0162 ,ce_loss: 0.1658., accu: 0.9055, speed: 1.18 step/s\n",
      "global step 18430, epoch: 4, batch: 3640, loss: 0.1674,domain_loss: 0.0092 ,ce_loss: 0.2069., accu: 0.9056, speed: 1.17 step/s\n",
      "global step 18440, epoch: 4, batch: 3650, loss: 0.2174,domain_loss: 0.0566 ,ce_loss: 0.2576., accu: 0.9057, speed: 1.18 step/s\n",
      "global step 18450, epoch: 4, batch: 3660, loss: 0.1531,domain_loss: 0.0164 ,ce_loss: 0.1872., accu: 0.9062, speed: 1.18 step/s\n",
      "global step 18460, epoch: 4, batch: 3670, loss: 0.2066,domain_loss: 0.0066 ,ce_loss: 0.2566., accu: 0.9064, speed: 1.17 step/s\n",
      "global step 18470, epoch: 4, batch: 3680, loss: 0.1991,domain_loss: 0.0653 ,ce_loss: 0.2325., accu: 0.9064, speed: 1.17 step/s\n",
      "global step 18480, epoch: 4, batch: 3690, loss: 0.1315,domain_loss: 0.0140 ,ce_loss: 0.1609., accu: 0.9062, speed: 1.18 step/s\n",
      "global step 18490, epoch: 4, batch: 3700, loss: 0.1730,domain_loss: 0.0358 ,ce_loss: 0.2073., accu: 0.9064, speed: 1.18 step/s\n",
      "global step 18500, epoch: 4, batch: 3710, loss: 0.1230,domain_loss: 0.0042 ,ce_loss: 0.1527., accu: 0.9073, speed: 1.18 step/s\n",
      "global step 18510, epoch: 4, batch: 3720, loss: 0.1506,domain_loss: 0.0273 ,ce_loss: 0.1815., accu: 0.9076, speed: 1.17 step/s\n",
      "global step 18520, epoch: 4, batch: 3730, loss: 0.1515,domain_loss: 0.0236 ,ce_loss: 0.1835., accu: 0.9080, speed: 1.17 step/s\n",
      "global step 18530, epoch: 4, batch: 3740, loss: 0.1518,domain_loss: 0.0055 ,ce_loss: 0.1884., accu: 0.9084, speed: 1.17 step/s\n",
      "global step 18540, epoch: 4, batch: 3750, loss: 0.1802,domain_loss: 0.0057 ,ce_loss: 0.2238., accu: 0.9084, speed: 1.18 step/s\n",
      "global step 18550, epoch: 4, batch: 3760, loss: 0.1133,domain_loss: 0.0179 ,ce_loss: 0.1371., accu: 0.9091, speed: 1.19 step/s\n",
      "global step 18560, epoch: 4, batch: 3770, loss: 0.1582,domain_loss: 0.0362 ,ce_loss: 0.1887., accu: 0.9095, speed: 1.18 step/s\n",
      "global step 18570, epoch: 4, batch: 3780, loss: 0.1384,domain_loss: 0.0238 ,ce_loss: 0.1671., accu: 0.9098, speed: 1.18 step/s\n",
      "global step 18580, epoch: 4, batch: 3790, loss: 0.2146,domain_loss: 0.0472 ,ce_loss: 0.2565., accu: 0.9100, speed: 1.20 step/s\n",
      "global step 18590, epoch: 4, batch: 3800, loss: 0.1409,domain_loss: 0.0307 ,ce_loss: 0.1684., accu: 0.9098, speed: 1.18 step/s\n",
      "global step 18600, epoch: 4, batch: 3810, loss: 0.1736,domain_loss: 0.0372 ,ce_loss: 0.2077., accu: 0.9098, speed: 1.17 step/s\n",
      "2022-09-29 04:06:41,230\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 18600, epoch: 4, batch: 3810】，loss: 0.1736,domain_loss: 0.0372 ,ce_loss: 0.2077., accu: 0.9098,\n",
      "2022-09-29 04:06:41,533\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.076123, accuracy: 0.97[0.98],threshold:0.492, domain_acc:1.0,total_num:100\n",
      "global step 18610, epoch: 4, batch: 3820, loss: 0.1599,domain_loss: 0.0448 ,ce_loss: 0.1887., accu: 0.8945, speed: 1.09 step/s\n",
      "global step 18620, epoch: 4, batch: 3830, loss: 0.2194,domain_loss: 0.0039 ,ce_loss: 0.2733., accu: 0.8965, speed: 1.19 step/s\n",
      "global step 18630, epoch: 4, batch: 3840, loss: 0.1811,domain_loss: 0.0103 ,ce_loss: 0.2237., accu: 0.8971, speed: 1.17 step/s\n",
      "global step 18640, epoch: 4, batch: 3850, loss: 0.1281,domain_loss: 0.0148 ,ce_loss: 0.1564., accu: 0.9035, speed: 1.17 step/s\n",
      "global step 18650, epoch: 4, batch: 3860, loss: 0.2377,domain_loss: 0.0077 ,ce_loss: 0.2952., accu: 0.9055, speed: 1.17 step/s\n",
      "global step 18660, epoch: 4, batch: 3870, loss: 0.1575,domain_loss: 0.0153 ,ce_loss: 0.1931., accu: 0.9070, speed: 1.19 step/s\n",
      "global step 18670, epoch: 4, batch: 3880, loss: 0.2138,domain_loss: 0.0237 ,ce_loss: 0.2614., accu: 0.9068, speed: 1.17 step/s\n",
      "global step 18680, epoch: 4, batch: 3890, loss: 0.1485,domain_loss: 0.0149 ,ce_loss: 0.1820., accu: 0.9055, speed: 1.17 step/s\n",
      "global step 18690, epoch: 4, batch: 3900, loss: 0.1743,domain_loss: 0.1028 ,ce_loss: 0.1921., accu: 0.9066, speed: 1.18 step/s\n",
      "global step 18700, epoch: 4, batch: 3910, loss: 0.1013,domain_loss: 0.0039 ,ce_loss: 0.1257., accu: 0.9082, speed: 1.19 step/s\n",
      "global step 18710, epoch: 4, batch: 3920, loss: 0.2047,domain_loss: 0.0121 ,ce_loss: 0.2528., accu: 0.9080, speed: 1.19 step/s\n",
      "global step 18720, epoch: 4, batch: 3930, loss: 0.2089,domain_loss: 0.0104 ,ce_loss: 0.2586., accu: 0.9084, speed: 1.18 step/s\n",
      "global step 18730, epoch: 4, batch: 3940, loss: 0.1661,domain_loss: 0.0066 ,ce_loss: 0.2060., accu: 0.9075, speed: 1.17 step/s\n",
      "global step 18740, epoch: 4, batch: 3950, loss: 0.1465,domain_loss: 0.0448 ,ce_loss: 0.1719., accu: 0.9073, speed: 1.19 step/s\n",
      "global step 18750, epoch: 4, batch: 3960, loss: 0.1294,domain_loss: 0.0238 ,ce_loss: 0.1558., accu: 0.9078, speed: 1.19 step/s\n",
      "global step 18760, epoch: 4, batch: 3970, loss: 0.1327,domain_loss: 0.0188 ,ce_loss: 0.1612., accu: 0.9078, speed: 1.18 step/s\n",
      "global step 18770, epoch: 4, batch: 3980, loss: 0.1587,domain_loss: 0.0270 ,ce_loss: 0.1916., accu: 0.9077, speed: 1.18 step/s\n",
      "global step 18780, epoch: 4, batch: 3990, loss: 0.1484,domain_loss: 0.0055 ,ce_loss: 0.1842., accu: 0.9072, speed: 1.18 step/s\n",
      "global step 18790, epoch: 4, batch: 4000, loss: 0.1298,domain_loss: 0.0312 ,ce_loss: 0.1544., accu: 0.9073, speed: 1.17 step/s\n",
      "global step 18800, epoch: 4, batch: 4010, loss: 0.1744,domain_loss: 0.0455 ,ce_loss: 0.2066., accu: 0.9069, speed: 1.17 step/s\n",
      "global step 18810, epoch: 4, batch: 4020, loss: 0.1336,domain_loss: 0.0278 ,ce_loss: 0.1600., accu: 0.9067, speed: 1.17 step/s\n",
      "global step 18820, epoch: 4, batch: 4030, loss: 0.1470,domain_loss: 0.0443 ,ce_loss: 0.1727., accu: 0.9074, speed: 1.17 step/s\n",
      "global step 18830, epoch: 4, batch: 4040, loss: 0.1419,domain_loss: 0.0210 ,ce_loss: 0.1722., accu: 0.9071, speed: 1.19 step/s\n",
      "global step 18840, epoch: 4, batch: 4050, loss: 0.2163,domain_loss: 0.0604 ,ce_loss: 0.2552., accu: 0.9073, speed: 1.20 step/s\n",
      "global step 18850, epoch: 4, batch: 4060, loss: 0.1586,domain_loss: 0.0234 ,ce_loss: 0.1924., accu: 0.9074, speed: 1.17 step/s\n",
      "global step 18860, epoch: 4, batch: 4070, loss: 0.1362,domain_loss: 0.0205 ,ce_loss: 0.1651., accu: 0.9081, speed: 1.19 step/s\n",
      "global step 18870, epoch: 4, batch: 4080, loss: 0.1596,domain_loss: 0.0179 ,ce_loss: 0.1950., accu: 0.9086, speed: 1.19 step/s\n",
      "global step 18880, epoch: 4, batch: 4090, loss: 0.1689,domain_loss: 0.0101 ,ce_loss: 0.2086., accu: 0.9085, speed: 1.17 step/s\n",
      "global step 18890, epoch: 4, batch: 4100, loss: 0.1806,domain_loss: 0.0038 ,ce_loss: 0.2249., accu: 0.9085, speed: 1.18 step/s\n",
      "global step 18900, epoch: 4, batch: 4110, loss: 0.1934,domain_loss: 0.0418 ,ce_loss: 0.2313., accu: 0.9083, speed: 1.18 step/s\n",
      "2022-09-29 04:10:56,163\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 18900, epoch: 4, batch: 4110】，loss: 0.1934,domain_loss: 0.0418 ,ce_loss: 0.2313., accu: 0.9083,\n",
      "2022-09-29 04:10:56,469\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.088036, accuracy: 0.96[0.98],threshold:0.562, domain_acc:1.0,total_num:100\n",
      "2022-09-29 04:10:57,294\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 18910, epoch: 4, batch: 4120, loss: 0.1832,domain_loss: 0.0210 ,ce_loss: 0.2237., accu: 0.9133, speed: 1.04 step/s\n",
      "global step 18920, epoch: 4, batch: 4130, loss: 0.1611,domain_loss: 0.0089 ,ce_loss: 0.1992., accu: 0.9145, speed: 1.23 step/s\n",
      "global step 18930, epoch: 4, batch: 4140, loss: 0.1057,domain_loss: 0.0727 ,ce_loss: 0.1140., accu: 0.9169, speed: 1.17 step/s\n",
      "global step 18940, epoch: 4, batch: 4150, loss: 0.1277,domain_loss: 0.0062 ,ce_loss: 0.1581., accu: 0.9150, speed: 1.17 step/s\n",
      "global step 18950, epoch: 4, batch: 4160, loss: 0.1547,domain_loss: 0.0267 ,ce_loss: 0.1867., accu: 0.9161, speed: 1.17 step/s\n",
      "global step 18960, epoch: 4, batch: 4170, loss: 0.1234,domain_loss: 0.0211 ,ce_loss: 0.1490., accu: 0.9147, speed: 1.19 step/s\n",
      "global step 18970, epoch: 4, batch: 4180, loss: 0.1296,domain_loss: 0.0143 ,ce_loss: 0.1585., accu: 0.9127, speed: 1.20 step/s\n",
      "global step 18980, epoch: 4, batch: 4190, loss: 0.1520,domain_loss: 0.0036 ,ce_loss: 0.1891., accu: 0.9128, speed: 1.19 step/s\n",
      "global step 18990, epoch: 4, batch: 4200, loss: 0.2055,domain_loss: 0.1010 ,ce_loss: 0.2316., accu: 0.9136, speed: 1.22 step/s\n",
      "global step 19000, epoch: 4, batch: 4210, loss: 0.1407,domain_loss: 0.0255 ,ce_loss: 0.1695., accu: 0.9140, speed: 1.18 step/s\n",
      "global step 19010, epoch: 4, batch: 4220, loss: 0.1906,domain_loss: 0.0031 ,ce_loss: 0.2375., accu: 0.9135, speed: 1.18 step/s\n",
      "global step 19020, epoch: 4, batch: 4230, loss: 0.1959,domain_loss: 0.0204 ,ce_loss: 0.2398., accu: 0.9135, speed: 1.20 step/s\n",
      "global step 19030, epoch: 4, batch: 4240, loss: 0.1346,domain_loss: 0.0051 ,ce_loss: 0.1670., accu: 0.9135, speed: 1.22 step/s\n",
      "global step 19040, epoch: 4, batch: 4250, loss: 0.1096,domain_loss: 0.0184 ,ce_loss: 0.1324., accu: 0.9139, speed: 1.18 step/s\n",
      "global step 19050, epoch: 4, batch: 4260, loss: 0.2173,domain_loss: 0.0679 ,ce_loss: 0.2547., accu: 0.9124, speed: 1.19 step/s\n",
      "global step 19060, epoch: 4, batch: 4270, loss: 0.1141,domain_loss: 0.0144 ,ce_loss: 0.1390., accu: 0.9129, speed: 1.18 step/s\n",
      "global step 19070, epoch: 4, batch: 4280, loss: 0.1992,domain_loss: 0.0193 ,ce_loss: 0.2441., accu: 0.9125, speed: 1.18 step/s\n",
      "global step 19080, epoch: 4, batch: 4290, loss: 0.2457,domain_loss: 0.0433 ,ce_loss: 0.2963., accu: 0.9119, speed: 1.17 step/s\n",
      "global step 19090, epoch: 4, batch: 4300, loss: 0.1216,domain_loss: 0.0478 ,ce_loss: 0.1401., accu: 0.9120, speed: 1.20 step/s\n",
      "global step 19100, epoch: 4, batch: 4310, loss: 0.1715,domain_loss: 0.0085 ,ce_loss: 0.2122., accu: 0.9117, speed: 1.22 step/s\n",
      "global step 19110, epoch: 4, batch: 4320, loss: 0.1478,domain_loss: 0.0215 ,ce_loss: 0.1793., accu: 0.9123, speed: 1.17 step/s\n",
      "global step 19120, epoch: 4, batch: 4330, loss: 0.2048,domain_loss: 0.0191 ,ce_loss: 0.2513., accu: 0.9124, speed: 1.17 step/s\n",
      "global step 19130, epoch: 4, batch: 4340, loss: 0.1545,domain_loss: 0.0032 ,ce_loss: 0.1923., accu: 0.9128, speed: 1.18 step/s\n",
      "global step 19140, epoch: 4, batch: 4350, loss: 0.2213,domain_loss: 0.0208 ,ce_loss: 0.2715., accu: 0.9129, speed: 1.18 step/s\n",
      "global step 19150, epoch: 4, batch: 4360, loss: 0.1868,domain_loss: 0.0333 ,ce_loss: 0.2252., accu: 0.9125, speed: 1.18 step/s\n",
      "global step 19160, epoch: 4, batch: 4370, loss: 0.2035,domain_loss: 0.0341 ,ce_loss: 0.2458., accu: 0.9123, speed: 1.17 step/s\n",
      "global step 19170, epoch: 4, batch: 4380, loss: 0.1468,domain_loss: 0.0284 ,ce_loss: 0.1764., accu: 0.9120, speed: 1.18 step/s\n",
      "global step 19180, epoch: 4, batch: 4390, loss: 0.1413,domain_loss: 0.0460 ,ce_loss: 0.1651., accu: 0.9120, speed: 1.19 step/s\n",
      "global step 19190, epoch: 4, batch: 4400, loss: 0.2011,domain_loss: 0.0175 ,ce_loss: 0.2470., accu: 0.9120, speed: 1.17 step/s\n",
      "global step 19200, epoch: 4, batch: 4410, loss: 0.1554,domain_loss: 0.0094 ,ce_loss: 0.1919., accu: 0.9118, speed: 1.17 step/s\n",
      "2022-09-29 04:15:10,181\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 19200, epoch: 4, batch: 4410】，loss: 0.1554,domain_loss: 0.0094 ,ce_loss: 0.1919., accu: 0.9118,\n",
      "2022-09-29 04:15:10,488\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.083668, accuracy: 0.96[0.97],threshold:0.272, domain_acc:1.0,total_num:100\n",
      "global step 19210, epoch: 4, batch: 4420, loss: 0.2271,domain_loss: 0.0219 ,ce_loss: 0.2784., accu: 0.9141, speed: 1.06 step/s\n",
      "global step 19220, epoch: 4, batch: 4430, loss: 0.1893,domain_loss: 0.0587 ,ce_loss: 0.2220., accu: 0.9152, speed: 1.18 step/s\n",
      "global step 19230, epoch: 4, batch: 4440, loss: 0.1614,domain_loss: 0.0267 ,ce_loss: 0.1951., accu: 0.9146, speed: 1.18 step/s\n",
      "global step 19240, epoch: 4, batch: 4450, loss: 0.1538,domain_loss: 0.0132 ,ce_loss: 0.1889., accu: 0.9166, speed: 1.18 step/s\n",
      "global step 19250, epoch: 4, batch: 4460, loss: 0.2013,domain_loss: 0.0436 ,ce_loss: 0.2407., accu: 0.9166, speed: 1.17 step/s\n",
      "global step 19260, epoch: 4, batch: 4470, loss: 0.1330,domain_loss: 0.0324 ,ce_loss: 0.1582., accu: 0.9169, speed: 1.22 step/s\n",
      "global step 19270, epoch: 4, batch: 4480, loss: 0.2045,domain_loss: 0.0500 ,ce_loss: 0.2431., accu: 0.9174, speed: 1.19 step/s\n",
      "global step 19280, epoch: 4, batch: 4490, loss: 0.2159,domain_loss: 0.0351 ,ce_loss: 0.2611., accu: 0.9162, speed: 1.18 step/s\n",
      "global step 19290, epoch: 4, batch: 4500, loss: 0.1560,domain_loss: 0.0398 ,ce_loss: 0.1851., accu: 0.9158, speed: 1.18 step/s\n",
      "global step 19300, epoch: 4, batch: 4510, loss: 0.1236,domain_loss: 0.0076 ,ce_loss: 0.1526., accu: 0.9155, speed: 1.18 step/s\n",
      "global step 19310, epoch: 4, batch: 4520, loss: 0.1172,domain_loss: 0.0138 ,ce_loss: 0.1431., accu: 0.9162, speed: 1.18 step/s\n",
      "global step 19320, epoch: 4, batch: 4530, loss: 0.1695,domain_loss: 0.0538 ,ce_loss: 0.1985., accu: 0.9163, speed: 1.18 step/s\n",
      "global step 19330, epoch: 4, batch: 4540, loss: 0.1583,domain_loss: 0.0498 ,ce_loss: 0.1854., accu: 0.9160, speed: 1.16 step/s\n",
      "global step 19340, epoch: 4, batch: 4550, loss: 0.1836,domain_loss: 0.0107 ,ce_loss: 0.2269., accu: 0.9161, speed: 1.22 step/s\n",
      "global step 19350, epoch: 4, batch: 4560, loss: 0.1575,domain_loss: 0.0124 ,ce_loss: 0.1938., accu: 0.9157, speed: 1.18 step/s\n",
      "global step 19360, epoch: 4, batch: 4570, loss: 0.1464,domain_loss: 0.0317 ,ce_loss: 0.1751., accu: 0.9151, speed: 1.18 step/s\n",
      "global step 19370, epoch: 4, batch: 4580, loss: 0.1662,domain_loss: 0.0175 ,ce_loss: 0.2033., accu: 0.9153, speed: 1.19 step/s\n",
      "global step 19380, epoch: 4, batch: 4590, loss: 0.1254,domain_loss: 0.0085 ,ce_loss: 0.1546., accu: 0.9152, speed: 1.18 step/s\n",
      "global step 19390, epoch: 4, batch: 4600, loss: 0.1306,domain_loss: 0.0146 ,ce_loss: 0.1596., accu: 0.9152, speed: 1.17 step/s\n",
      "global step 19400, epoch: 4, batch: 4610, loss: 0.1473,domain_loss: 0.0728 ,ce_loss: 0.1660., accu: 0.9147, speed: 1.17 step/s\n",
      "global step 19410, epoch: 4, batch: 4620, loss: 0.1433,domain_loss: 0.0099 ,ce_loss: 0.1766., accu: 0.9138, speed: 1.18 step/s\n",
      "global step 19420, epoch: 4, batch: 4630, loss: 0.2154,domain_loss: 0.0446 ,ce_loss: 0.2581., accu: 0.9136, speed: 1.17 step/s\n",
      "global step 19430, epoch: 4, batch: 4640, loss: 0.1482,domain_loss: 0.0353 ,ce_loss: 0.1764., accu: 0.9135, speed: 1.20 step/s\n",
      "global step 19440, epoch: 4, batch: 4650, loss: 0.1275,domain_loss: 0.0043 ,ce_loss: 0.1583., accu: 0.9137, speed: 1.18 step/s\n",
      "global step 19450, epoch: 4, batch: 4660, loss: 0.2326,domain_loss: 0.0146 ,ce_loss: 0.2870., accu: 0.9135, speed: 1.18 step/s\n",
      "global step 19460, epoch: 4, batch: 4670, loss: 0.1467,domain_loss: 0.0180 ,ce_loss: 0.1789., accu: 0.9138, speed: 1.17 step/s\n",
      "global step 19470, epoch: 4, batch: 4680, loss: 0.2074,domain_loss: 0.0476 ,ce_loss: 0.2473., accu: 0.9135, speed: 1.19 step/s\n",
      "global step 19480, epoch: 4, batch: 4690, loss: 0.2070,domain_loss: 0.0143 ,ce_loss: 0.2552., accu: 0.9133, speed: 1.19 step/s\n",
      "global step 19490, epoch: 4, batch: 4700, loss: 0.1805,domain_loss: 0.0040 ,ce_loss: 0.2246., accu: 0.9133, speed: 1.19 step/s\n",
      "global step 19500, epoch: 4, batch: 4710, loss: 0.1335,domain_loss: 0.0069 ,ce_loss: 0.1651., accu: 0.9134, speed: 1.17 step/s\n",
      "2022-09-29 04:19:25,011\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 19500, epoch: 4, batch: 4710】，loss: 0.1335,domain_loss: 0.0069 ,ce_loss: 0.1651., accu: 0.9134,\n",
      "2022-09-29 04:19:25,331\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.081014, accuracy: 0.96[0.97],threshold:0.219, domain_acc:1.0,total_num:100\n",
      "global step 19510, epoch: 4, batch: 4720, loss: 0.0862,domain_loss: 0.0110 ,ce_loss: 0.1050., accu: 0.9258, speed: 1.04 step/s\n",
      "global step 19520, epoch: 4, batch: 4730, loss: 0.1910,domain_loss: 0.0179 ,ce_loss: 0.2343., accu: 0.9168, speed: 1.19 step/s\n",
      "global step 19530, epoch: 4, batch: 4740, loss: 0.1451,domain_loss: 0.0015 ,ce_loss: 0.1810., accu: 0.9154, speed: 1.21 step/s\n",
      "global step 19540, epoch: 4, batch: 4750, loss: 0.2407,domain_loss: 0.0148 ,ce_loss: 0.2972., accu: 0.9105, speed: 1.17 step/s\n",
      "global step 19550, epoch: 4, batch: 4760, loss: 0.1354,domain_loss: 0.0378 ,ce_loss: 0.1598., accu: 0.9119, speed: 1.18 step/s\n",
      "global step 19560, epoch: 4, batch: 4770, loss: 0.1527,domain_loss: 0.0229 ,ce_loss: 0.1852., accu: 0.9129, speed: 1.18 step/s\n",
      "global step 19570, epoch: 4, batch: 4780, loss: 0.1305,domain_loss: 0.0093 ,ce_loss: 0.1608., accu: 0.9126, speed: 1.19 step/s\n",
      "global step 19580, epoch: 4, batch: 4790, loss: 0.2469,domain_loss: 0.0134 ,ce_loss: 0.3053., accu: 0.9102, speed: 1.18 step/s\n",
      "global step 19590, epoch: 4, batch: 4800, loss: 0.2044,domain_loss: 0.0517 ,ce_loss: 0.2425., accu: 0.9091, speed: 1.20 step/s\n",
      "global step 19600, epoch: 4, batch: 4810, loss: 0.1274,domain_loss: 0.0379 ,ce_loss: 0.1498., accu: 0.9102, speed: 1.18 step/s\n",
      "global step 19610, epoch: 4, batch: 4820, loss: 0.1715,domain_loss: 0.0054 ,ce_loss: 0.2131., accu: 0.9112, speed: 1.18 step/s\n",
      "global step 19620, epoch: 4, batch: 4830, loss: 0.1795,domain_loss: 0.0799 ,ce_loss: 0.2044., accu: 0.9105, speed: 1.19 step/s\n",
      "global step 19630, epoch: 4, batch: 4840, loss: 0.1622,domain_loss: 0.0047 ,ce_loss: 0.2016., accu: 0.9099, speed: 1.18 step/s\n",
      "global step 19640, epoch: 4, batch: 4850, loss: 0.1571,domain_loss: 0.0241 ,ce_loss: 0.1903., accu: 0.9104, speed: 1.18 step/s\n",
      "global step 19650, epoch: 4, batch: 4860, loss: 0.2389,domain_loss: 0.0273 ,ce_loss: 0.2918., accu: 0.9105, speed: 1.19 step/s\n",
      "global step 19660, epoch: 4, batch: 4870, loss: 0.1767,domain_loss: 0.0206 ,ce_loss: 0.2158., accu: 0.9104, speed: 1.21 step/s\n",
      "global step 19670, epoch: 4, batch: 4880, loss: 0.2164,domain_loss: 0.0392 ,ce_loss: 0.2608., accu: 0.9094, speed: 1.19 step/s\n",
      "global step 19680, epoch: 4, batch: 4890, loss: 0.1909,domain_loss: 0.0928 ,ce_loss: 0.2155., accu: 0.9092, speed: 1.19 step/s\n",
      "global step 19690, epoch: 4, batch: 4900, loss: 0.1608,domain_loss: 0.0101 ,ce_loss: 0.1985., accu: 0.9093, speed: 1.18 step/s\n",
      "global step 19700, epoch: 4, batch: 4910, loss: 0.1600,domain_loss: 0.0117 ,ce_loss: 0.1971., accu: 0.9095, speed: 1.19 step/s\n",
      "global step 19710, epoch: 4, batch: 4920, loss: 0.1311,domain_loss: 0.0544 ,ce_loss: 0.1503., accu: 0.9096, speed: 1.18 step/s\n",
      "global step 19720, epoch: 4, batch: 4930, loss: 0.1893,domain_loss: 0.0344 ,ce_loss: 0.2280., accu: 0.9100, speed: 1.28 step/s\n",
      " 80%|███████████████████████████████▏       | 4/5 [4:38:57<1:09:44, 4184.93s/it]global step 19730, epoch: 5, batch: 10, loss: 0.1185,domain_loss: 0.0230 ,ce_loss: 0.1424., accu: 0.9107, speed: 1.16 step/s\n",
      "global step 19740, epoch: 5, batch: 20, loss: 0.1758,domain_loss: 0.0077 ,ce_loss: 0.2179., accu: 0.9110, speed: 1.18 step/s\n",
      "global step 19750, epoch: 5, batch: 30, loss: 0.2263,domain_loss: 0.0184 ,ce_loss: 0.2783., accu: 0.9112, speed: 1.20 step/s\n",
      "global step 19760, epoch: 5, batch: 40, loss: 0.1610,domain_loss: 0.0038 ,ce_loss: 0.2003., accu: 0.9121, speed: 1.19 step/s\n",
      "global step 19770, epoch: 5, batch: 50, loss: 0.1296,domain_loss: 0.0106 ,ce_loss: 0.1594., accu: 0.9125, speed: 1.18 step/s\n",
      "global step 19780, epoch: 5, batch: 60, loss: 0.2112,domain_loss: 0.0518 ,ce_loss: 0.2510., accu: 0.9125, speed: 1.18 step/s\n",
      "global step 19790, epoch: 5, batch: 70, loss: 0.1870,domain_loss: 0.0087 ,ce_loss: 0.2316., accu: 0.9126, speed: 1.18 step/s\n",
      "global step 19800, epoch: 5, batch: 80, loss: 0.1530,domain_loss: 0.0338 ,ce_loss: 0.1828., accu: 0.9132, speed: 1.19 step/s\n",
      "2022-09-29 04:23:38,756\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 19800, epoch: 5, batch: 80】，loss: 0.1530,domain_loss: 0.0338 ,ce_loss: 0.1828., accu: 0.9132,\n",
      "2022-09-29 04:23:39,051\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.05755, accuracy: 0.98[0.99],threshold:0.449, domain_acc:1.0,total_num:100\n",
      "global step 19810, epoch: 5, batch: 90, loss: 0.1858,domain_loss: 0.0256 ,ce_loss: 0.2258., accu: 0.9219, speed: 1.03 step/s\n",
      "global step 19820, epoch: 5, batch: 100, loss: 0.1353,domain_loss: 0.0172 ,ce_loss: 0.1649., accu: 0.9223, speed: 1.18 step/s\n",
      "global step 19830, epoch: 5, batch: 110, loss: 0.1337,domain_loss: 0.0136 ,ce_loss: 0.1637., accu: 0.9240, speed: 1.18 step/s\n",
      "global step 19840, epoch: 5, batch: 120, loss: 0.1648,domain_loss: 0.0637 ,ce_loss: 0.1901., accu: 0.9234, speed: 1.18 step/s\n",
      "global step 19850, epoch: 5, batch: 130, loss: 0.1953,domain_loss: 0.0419 ,ce_loss: 0.2337., accu: 0.9220, speed: 1.18 step/s\n",
      "global step 19860, epoch: 5, batch: 140, loss: 0.2172,domain_loss: 0.0042 ,ce_loss: 0.2704., accu: 0.9208, speed: 1.19 step/s\n",
      "global step 19870, epoch: 5, batch: 150, loss: 0.0978,domain_loss: 0.0263 ,ce_loss: 0.1157., accu: 0.9215, speed: 1.19 step/s\n",
      "global step 19880, epoch: 5, batch: 160, loss: 0.1758,domain_loss: 0.0594 ,ce_loss: 0.2049., accu: 0.9199, speed: 1.19 step/s\n",
      "global step 19890, epoch: 5, batch: 170, loss: 0.1390,domain_loss: 0.0250 ,ce_loss: 0.1675., accu: 0.9205, speed: 1.19 step/s\n",
      "global step 19900, epoch: 5, batch: 180, loss: 0.2487,domain_loss: 0.0528 ,ce_loss: 0.2977., accu: 0.9199, speed: 1.17 step/s\n",
      "global step 19910, epoch: 5, batch: 190, loss: 0.1404,domain_loss: 0.0160 ,ce_loss: 0.1714., accu: 0.9202, speed: 1.21 step/s\n",
      "global step 19920, epoch: 5, batch: 200, loss: 0.1596,domain_loss: 0.0342 ,ce_loss: 0.1909., accu: 0.9203, speed: 1.17 step/s\n",
      "global step 19930, epoch: 5, batch: 210, loss: 0.1477,domain_loss: 0.0265 ,ce_loss: 0.1779., accu: 0.9197, speed: 1.18 step/s\n",
      "global step 19940, epoch: 5, batch: 220, loss: 0.2055,domain_loss: 0.0269 ,ce_loss: 0.2501., accu: 0.9201, speed: 1.18 step/s\n",
      "global step 19950, epoch: 5, batch: 230, loss: 0.1127,domain_loss: 0.0254 ,ce_loss: 0.1345., accu: 0.9208, speed: 1.21 step/s\n",
      "global step 19960, epoch: 5, batch: 240, loss: 0.1080,domain_loss: 0.0047 ,ce_loss: 0.1338., accu: 0.9211, speed: 1.17 step/s\n",
      "global step 19970, epoch: 5, batch: 250, loss: 0.1039,domain_loss: 0.0088 ,ce_loss: 0.1277., accu: 0.9213, speed: 1.18 step/s\n",
      "global step 19980, epoch: 5, batch: 260, loss: 0.1798,domain_loss: 0.0373 ,ce_loss: 0.2155., accu: 0.9215, speed: 1.20 step/s\n",
      "global step 19990, epoch: 5, batch: 270, loss: 0.1340,domain_loss: 0.0458 ,ce_loss: 0.1561., accu: 0.9219, speed: 1.18 step/s\n",
      "global step 20000, epoch: 5, batch: 280, loss: 0.1618,domain_loss: 0.0759 ,ce_loss: 0.1833., accu: 0.9219, speed: 1.18 step/s\n",
      "global step 20010, epoch: 5, batch: 290, loss: 0.1512,domain_loss: 0.0033 ,ce_loss: 0.1882., accu: 0.9222, speed: 1.18 step/s\n",
      "global step 20020, epoch: 5, batch: 300, loss: 0.1463,domain_loss: 0.0349 ,ce_loss: 0.1741., accu: 0.9224, speed: 1.17 step/s\n",
      "global step 20030, epoch: 5, batch: 310, loss: 0.1966,domain_loss: 0.0222 ,ce_loss: 0.2402., accu: 0.9224, speed: 1.20 step/s\n",
      "global step 20040, epoch: 5, batch: 320, loss: 0.1183,domain_loss: 0.0037 ,ce_loss: 0.1470., accu: 0.9229, speed: 1.17 step/s\n",
      "global step 20050, epoch: 5, batch: 330, loss: 0.1551,domain_loss: 0.0175 ,ce_loss: 0.1894., accu: 0.9231, speed: 1.18 step/s\n",
      "global step 20060, epoch: 5, batch: 340, loss: 0.1484,domain_loss: 0.0051 ,ce_loss: 0.1842., accu: 0.9231, speed: 1.20 step/s\n",
      "global step 20070, epoch: 5, batch: 350, loss: 0.1178,domain_loss: 0.0621 ,ce_loss: 0.1318., accu: 0.9231, speed: 1.17 step/s\n",
      "global step 20080, epoch: 5, batch: 360, loss: 0.1619,domain_loss: 0.0483 ,ce_loss: 0.1903., accu: 0.9231, speed: 1.20 step/s\n",
      "global step 20090, epoch: 5, batch: 370, loss: 0.1062,domain_loss: 0.0325 ,ce_loss: 0.1246., accu: 0.9236, speed: 1.17 step/s\n",
      "global step 20100, epoch: 5, batch: 380, loss: 0.1689,domain_loss: 0.0542 ,ce_loss: 0.1976., accu: 0.9233, speed: 1.21 step/s\n",
      "2022-09-29 04:27:53,241\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 20100, epoch: 5, batch: 380】，loss: 0.1689,domain_loss: 0.0542 ,ce_loss: 0.1976., accu: 0.9233,\n",
      "2022-09-29 04:27:53,550\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.066306, accuracy: 0.97[0.98],threshold:0.389, domain_acc:1.0,total_num:100\n",
      "2022-09-29 04:27:54,461\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 20110, epoch: 5, batch: 390, loss: 0.1308,domain_loss: 0.0036 ,ce_loss: 0.1627., accu: 0.9242, speed: 1.03 step/s\n",
      "global step 20120, epoch: 5, batch: 400, loss: 0.2020,domain_loss: 0.0374 ,ce_loss: 0.2432., accu: 0.9266, speed: 1.19 step/s\n",
      "global step 20130, epoch: 5, batch: 410, loss: 0.2575,domain_loss: 0.0025 ,ce_loss: 0.3212., accu: 0.9227, speed: 1.19 step/s\n",
      "global step 20140, epoch: 5, batch: 420, loss: 0.2170,domain_loss: 0.0055 ,ce_loss: 0.2699., accu: 0.9229, speed: 1.18 step/s\n",
      "global step 20150, epoch: 5, batch: 430, loss: 0.2237,domain_loss: 0.0589 ,ce_loss: 0.2649., accu: 0.9245, speed: 1.18 step/s\n",
      "global step 20160, epoch: 5, batch: 440, loss: 0.1782,domain_loss: 0.0078 ,ce_loss: 0.2208., accu: 0.9249, speed: 1.18 step/s\n",
      "global step 20170, epoch: 5, batch: 450, loss: 0.1475,domain_loss: 0.0185 ,ce_loss: 0.1797., accu: 0.9267, speed: 1.19 step/s\n",
      "global step 20180, epoch: 5, batch: 460, loss: 0.0929,domain_loss: 0.0072 ,ce_loss: 0.1143., accu: 0.9259, speed: 1.17 step/s\n",
      "global step 20190, epoch: 5, batch: 470, loss: 0.1312,domain_loss: 0.0019 ,ce_loss: 0.1635., accu: 0.9260, speed: 1.17 step/s\n",
      "global step 20200, epoch: 5, batch: 480, loss: 0.1225,domain_loss: 0.0518 ,ce_loss: 0.1401., accu: 0.9260, speed: 1.19 step/s\n",
      "global step 20210, epoch: 5, batch: 490, loss: 0.1424,domain_loss: 0.0134 ,ce_loss: 0.1746., accu: 0.9251, speed: 1.18 step/s\n",
      "global step 20220, epoch: 5, batch: 500, loss: 0.1765,domain_loss: 0.0161 ,ce_loss: 0.2166., accu: 0.9242, speed: 1.18 step/s\n",
      "global step 20230, epoch: 5, batch: 510, loss: 0.1415,domain_loss: 0.0052 ,ce_loss: 0.1756., accu: 0.9239, speed: 1.18 step/s\n",
      "global step 20240, epoch: 5, batch: 520, loss: 0.1292,domain_loss: 0.0065 ,ce_loss: 0.1598., accu: 0.9239, speed: 1.18 step/s\n",
      "global step 20250, epoch: 5, batch: 530, loss: 0.1936,domain_loss: 0.1273 ,ce_loss: 0.2101., accu: 0.9243, speed: 1.18 step/s\n",
      "global step 20260, epoch: 5, batch: 540, loss: 0.1528,domain_loss: 0.0017 ,ce_loss: 0.1906., accu: 0.9238, speed: 1.19 step/s\n",
      "global step 20270, epoch: 5, batch: 550, loss: 0.1700,domain_loss: 0.0176 ,ce_loss: 0.2081., accu: 0.9237, speed: 1.17 step/s\n",
      "global step 20280, epoch: 5, batch: 560, loss: 0.1394,domain_loss: 0.0175 ,ce_loss: 0.1698., accu: 0.9240, speed: 1.18 step/s\n",
      "global step 20290, epoch: 5, batch: 570, loss: 0.1512,domain_loss: 0.0191 ,ce_loss: 0.1842., accu: 0.9233, speed: 1.19 step/s\n",
      "global step 20300, epoch: 5, batch: 580, loss: 0.1414,domain_loss: 0.0100 ,ce_loss: 0.1742., accu: 0.9228, speed: 1.19 step/s\n",
      "global step 20310, epoch: 5, batch: 590, loss: 0.1750,domain_loss: 0.0847 ,ce_loss: 0.1976., accu: 0.9225, speed: 1.17 step/s\n",
      "global step 20320, epoch: 5, batch: 600, loss: 0.1431,domain_loss: 0.0142 ,ce_loss: 0.1753., accu: 0.9226, speed: 1.18 step/s\n",
      "global step 20330, epoch: 5, batch: 610, loss: 0.1306,domain_loss: 0.0356 ,ce_loss: 0.1544., accu: 0.9226, speed: 1.20 step/s\n",
      "global step 20340, epoch: 5, batch: 620, loss: 0.1071,domain_loss: 0.0101 ,ce_loss: 0.1313., accu: 0.9227, speed: 1.18 step/s\n",
      "global step 20350, epoch: 5, batch: 630, loss: 0.1682,domain_loss: 0.0557 ,ce_loss: 0.1963., accu: 0.9226, speed: 1.17 step/s\n",
      "global step 20360, epoch: 5, batch: 640, loss: 0.1393,domain_loss: 0.0142 ,ce_loss: 0.1706., accu: 0.9225, speed: 1.17 step/s\n",
      "global step 20370, epoch: 5, batch: 650, loss: 0.1460,domain_loss: 0.0078 ,ce_loss: 0.1806., accu: 0.9223, speed: 1.17 step/s\n",
      "global step 20380, epoch: 5, batch: 660, loss: 0.1050,domain_loss: 0.0189 ,ce_loss: 0.1266., accu: 0.9222, speed: 1.18 step/s\n",
      "global step 20390, epoch: 5, batch: 670, loss: 0.1227,domain_loss: 0.0495 ,ce_loss: 0.1410., accu: 0.9224, speed: 1.19 step/s\n",
      "global step 20400, epoch: 5, batch: 680, loss: 0.0948,domain_loss: 0.0133 ,ce_loss: 0.1152., accu: 0.9222, speed: 1.18 step/s\n",
      "2022-09-29 04:32:08,455\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 20400, epoch: 5, batch: 680】，loss: 0.0948,domain_loss: 0.0133 ,ce_loss: 0.1152., accu: 0.9222,\n",
      "2022-09-29 04:32:08,761\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.074822, accuracy: 0.98[0.98],threshold:0.356, domain_acc:1.0,total_num:100\n",
      "global step 20410, epoch: 5, batch: 690, loss: 0.1209,domain_loss: 0.0214 ,ce_loss: 0.1458., accu: 0.9180, speed: 1.07 step/s\n",
      "global step 20420, epoch: 5, batch: 700, loss: 0.1048,domain_loss: 0.0141 ,ce_loss: 0.1274., accu: 0.9238, speed: 1.20 step/s\n",
      "global step 20430, epoch: 5, batch: 710, loss: 0.1787,domain_loss: 0.0106 ,ce_loss: 0.2208., accu: 0.9260, speed: 1.21 step/s\n",
      "global step 20440, epoch: 5, batch: 720, loss: 0.1660,domain_loss: 0.0099 ,ce_loss: 0.2051., accu: 0.9248, speed: 1.18 step/s\n",
      "global step 20450, epoch: 5, batch: 730, loss: 0.1803,domain_loss: 0.0158 ,ce_loss: 0.2214., accu: 0.9252, speed: 1.17 step/s\n",
      "global step 20460, epoch: 5, batch: 740, loss: 0.1500,domain_loss: 0.0078 ,ce_loss: 0.1855., accu: 0.9257, speed: 1.18 step/s\n",
      "global step 20470, epoch: 5, batch: 750, loss: 0.1370,domain_loss: 0.0190 ,ce_loss: 0.1665., accu: 0.9246, speed: 1.18 step/s\n",
      "global step 20480, epoch: 5, batch: 760, loss: 0.1237,domain_loss: 0.0236 ,ce_loss: 0.1487., accu: 0.9258, speed: 1.20 step/s\n",
      "global step 20490, epoch: 5, batch: 770, loss: 0.0775,domain_loss: 0.0102 ,ce_loss: 0.0943., accu: 0.9256, speed: 1.18 step/s\n",
      "global step 20500, epoch: 5, batch: 780, loss: 0.0870,domain_loss: 0.0071 ,ce_loss: 0.1070., accu: 0.9249, speed: 1.19 step/s\n",
      "global step 20510, epoch: 5, batch: 790, loss: 0.1974,domain_loss: 0.0161 ,ce_loss: 0.2427., accu: 0.9250, speed: 1.18 step/s\n",
      "global step 20520, epoch: 5, batch: 800, loss: 0.2123,domain_loss: 0.0178 ,ce_loss: 0.2610., accu: 0.9249, speed: 1.19 step/s\n",
      "global step 20530, epoch: 5, batch: 810, loss: 0.1136,domain_loss: 0.0339 ,ce_loss: 0.1335., accu: 0.9255, speed: 1.20 step/s\n",
      "global step 20540, epoch: 5, batch: 820, loss: 0.1922,domain_loss: 0.1016 ,ce_loss: 0.2149., accu: 0.9257, speed: 1.20 step/s\n",
      "global step 20550, epoch: 5, batch: 830, loss: 0.1523,domain_loss: 0.0058 ,ce_loss: 0.1890., accu: 0.9256, speed: 1.20 step/s\n",
      "global step 20560, epoch: 5, batch: 840, loss: 0.1323,domain_loss: 0.0088 ,ce_loss: 0.1632., accu: 0.9252, speed: 1.18 step/s\n",
      "global step 20570, epoch: 5, batch: 850, loss: 0.1957,domain_loss: 0.0205 ,ce_loss: 0.2395., accu: 0.9247, speed: 1.18 step/s\n",
      "global step 20580, epoch: 5, batch: 860, loss: 0.1740,domain_loss: 0.0895 ,ce_loss: 0.1951., accu: 0.9246, speed: 1.20 step/s\n",
      "global step 20590, epoch: 5, batch: 870, loss: 0.2078,domain_loss: 0.0643 ,ce_loss: 0.2436., accu: 0.9249, speed: 1.18 step/s\n",
      "global step 20600, epoch: 5, batch: 880, loss: 0.1543,domain_loss: 0.0280 ,ce_loss: 0.1859., accu: 0.9250, speed: 1.19 step/s\n",
      "global step 20610, epoch: 5, batch: 890, loss: 0.0959,domain_loss: 0.0146 ,ce_loss: 0.1163., accu: 0.9250, speed: 1.17 step/s\n",
      "global step 20620, epoch: 5, batch: 900, loss: 0.2165,domain_loss: 0.0212 ,ce_loss: 0.2653., accu: 0.9251, speed: 1.19 step/s\n",
      "global step 20630, epoch: 5, batch: 910, loss: 0.1801,domain_loss: 0.0079 ,ce_loss: 0.2231., accu: 0.9249, speed: 1.20 step/s\n",
      "global step 20640, epoch: 5, batch: 920, loss: 0.1732,domain_loss: 0.0991 ,ce_loss: 0.1917., accu: 0.9244, speed: 1.17 step/s\n",
      "global step 20650, epoch: 5, batch: 930, loss: 0.1264,domain_loss: 0.0306 ,ce_loss: 0.1504., accu: 0.9239, speed: 1.17 step/s\n",
      "global step 20660, epoch: 5, batch: 940, loss: 0.1979,domain_loss: 0.0037 ,ce_loss: 0.2464., accu: 0.9239, speed: 1.18 step/s\n",
      "global step 20670, epoch: 5, batch: 950, loss: 0.1692,domain_loss: 0.0453 ,ce_loss: 0.2002., accu: 0.9237, speed: 1.17 step/s\n",
      "global step 20680, epoch: 5, batch: 960, loss: 0.2210,domain_loss: 0.0275 ,ce_loss: 0.2694., accu: 0.9236, speed: 1.18 step/s\n",
      "global step 20690, epoch: 5, batch: 970, loss: 0.1769,domain_loss: 0.0275 ,ce_loss: 0.2143., accu: 0.9235, speed: 1.19 step/s\n",
      "global step 20700, epoch: 5, batch: 980, loss: 0.1854,domain_loss: 0.1005 ,ce_loss: 0.2067., accu: 0.9233, speed: 1.19 step/s\n",
      "2022-09-29 04:36:22,165\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 20700, epoch: 5, batch: 980】，loss: 0.1854,domain_loss: 0.1005 ,ce_loss: 0.2067., accu: 0.9233,\n",
      "2022-09-29 04:36:22,477\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.082483, accuracy: 0.96[0.98],threshold:0.456, domain_acc:1.0,total_num:100\n",
      "2022-09-29 04:36:23,318\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 20710, epoch: 5, batch: 990, loss: 0.1557,domain_loss: 0.0186 ,ce_loss: 0.1899., accu: 0.9258, speed: 1.05 step/s\n",
      "global step 20720, epoch: 5, batch: 1000, loss: 0.1543,domain_loss: 0.0268 ,ce_loss: 0.1861., accu: 0.9246, speed: 1.18 step/s\n",
      "global step 20730, epoch: 5, batch: 1010, loss: 0.1054,domain_loss: 0.0079 ,ce_loss: 0.1298., accu: 0.9247, speed: 1.17 step/s\n",
      "global step 20740, epoch: 5, batch: 1020, loss: 0.1261,domain_loss: 0.0037 ,ce_loss: 0.1566., accu: 0.9230, speed: 1.18 step/s\n",
      "global step 20750, epoch: 5, batch: 1030, loss: 0.1690,domain_loss: 0.0170 ,ce_loss: 0.2070., accu: 0.9213, speed: 1.19 step/s\n",
      "global step 20760, epoch: 5, batch: 1040, loss: 0.1255,domain_loss: 0.0081 ,ce_loss: 0.1549., accu: 0.9217, speed: 1.17 step/s\n",
      "global step 20770, epoch: 5, batch: 1050, loss: 0.1319,domain_loss: 0.0090 ,ce_loss: 0.1627., accu: 0.9223, speed: 1.18 step/s\n",
      "global step 20780, epoch: 5, batch: 1060, loss: 0.1785,domain_loss: 0.0067 ,ce_loss: 0.2214., accu: 0.9223, speed: 1.17 step/s\n",
      "global step 20790, epoch: 5, batch: 1070, loss: 0.1535,domain_loss: 0.0522 ,ce_loss: 0.1788., accu: 0.9213, speed: 1.17 step/s\n",
      "global step 20800, epoch: 5, batch: 1080, loss: 0.1998,domain_loss: 0.0091 ,ce_loss: 0.2475., accu: 0.9208, speed: 1.17 step/s\n",
      "global step 20810, epoch: 5, batch: 1090, loss: 0.2496,domain_loss: 0.0100 ,ce_loss: 0.3095., accu: 0.9210, speed: 1.18 step/s\n",
      "global step 20820, epoch: 5, batch: 1100, loss: 0.1160,domain_loss: 0.0135 ,ce_loss: 0.1416., accu: 0.9199, speed: 1.18 step/s\n",
      "global step 20830, epoch: 5, batch: 1110, loss: 0.1918,domain_loss: 0.0237 ,ce_loss: 0.2339., accu: 0.9193, speed: 1.19 step/s\n",
      "global step 20840, epoch: 5, batch: 1120, loss: 0.1374,domain_loss: 0.0105 ,ce_loss: 0.1691., accu: 0.9182, speed: 1.19 step/s\n",
      "global step 20850, epoch: 5, batch: 1130, loss: 0.1528,domain_loss: 0.0183 ,ce_loss: 0.1865., accu: 0.9186, speed: 1.19 step/s\n",
      "global step 20860, epoch: 5, batch: 1140, loss: 0.1518,domain_loss: 0.0476 ,ce_loss: 0.1779., accu: 0.9191, speed: 1.17 step/s\n",
      "global step 20870, epoch: 5, batch: 1150, loss: 0.1681,domain_loss: 0.0779 ,ce_loss: 0.1907., accu: 0.9190, speed: 1.19 step/s\n",
      "global step 20880, epoch: 5, batch: 1160, loss: 0.1791,domain_loss: 0.0232 ,ce_loss: 0.2181., accu: 0.9191, speed: 1.19 step/s\n",
      "global step 20890, epoch: 5, batch: 1170, loss: 0.1484,domain_loss: 0.0110 ,ce_loss: 0.1827., accu: 0.9198, speed: 1.18 step/s\n",
      "global step 20900, epoch: 5, batch: 1180, loss: 0.2206,domain_loss: 0.0158 ,ce_loss: 0.2718., accu: 0.9193, speed: 1.20 step/s\n",
      "global step 20910, epoch: 5, batch: 1190, loss: 0.1609,domain_loss: 0.0152 ,ce_loss: 0.1973., accu: 0.9195, speed: 1.19 step/s\n",
      "global step 20920, epoch: 5, batch: 1200, loss: 0.1250,domain_loss: 0.0097 ,ce_loss: 0.1538., accu: 0.9203, speed: 1.18 step/s\n",
      "global step 20930, epoch: 5, batch: 1210, loss: 0.1466,domain_loss: 0.0128 ,ce_loss: 0.1800., accu: 0.9202, speed: 1.19 step/s\n",
      "global step 20940, epoch: 5, batch: 1220, loss: 0.1372,domain_loss: 0.0148 ,ce_loss: 0.1678., accu: 0.9205, speed: 1.20 step/s\n",
      "global step 20950, epoch: 5, batch: 1230, loss: 0.1195,domain_loss: 0.0460 ,ce_loss: 0.1379., accu: 0.9208, speed: 1.19 step/s\n",
      "global step 20960, epoch: 5, batch: 1240, loss: 0.2134,domain_loss: 0.0442 ,ce_loss: 0.2557., accu: 0.9209, speed: 1.17 step/s\n",
      "global step 20970, epoch: 5, batch: 1250, loss: 0.1223,domain_loss: 0.0095 ,ce_loss: 0.1505., accu: 0.9207, speed: 1.18 step/s\n",
      "global step 20980, epoch: 5, batch: 1260, loss: 0.1261,domain_loss: 0.0062 ,ce_loss: 0.1560., accu: 0.9208, speed: 1.18 step/s\n",
      "global step 20990, epoch: 5, batch: 1270, loss: 0.1387,domain_loss: 0.0028 ,ce_loss: 0.1726., accu: 0.9204, speed: 1.19 step/s\n",
      "global step 21000, epoch: 5, batch: 1280, loss: 0.1353,domain_loss: 0.0687 ,ce_loss: 0.1520., accu: 0.9207, speed: 1.17 step/s\n",
      "2022-09-29 04:40:36,689\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 21000, epoch: 5, batch: 1280】，loss: 0.1353,domain_loss: 0.0687 ,ce_loss: 0.1520., accu: 0.9207,\n",
      "2022-09-29 04:40:36,994\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.075748, accuracy: 0.97[0.98],threshold:0.435, domain_acc:1.0,total_num:100\n",
      "global step 21010, epoch: 5, batch: 1290, loss: 0.1151,domain_loss: 0.0029 ,ce_loss: 0.1431., accu: 0.9219, speed: 1.05 step/s\n",
      "global step 21020, epoch: 5, batch: 1300, loss: 0.1342,domain_loss: 0.0332 ,ce_loss: 0.1595., accu: 0.9172, speed: 1.18 step/s\n",
      "global step 21030, epoch: 5, batch: 1310, loss: 0.2068,domain_loss: 0.0238 ,ce_loss: 0.2526., accu: 0.9156, speed: 1.21 step/s\n",
      "global step 21040, epoch: 5, batch: 1320, loss: 0.1869,domain_loss: 0.0056 ,ce_loss: 0.2322., accu: 0.9152, speed: 1.18 step/s\n",
      "global step 21050, epoch: 5, batch: 1330, loss: 0.1729,domain_loss: 0.0105 ,ce_loss: 0.2135., accu: 0.9141, speed: 1.19 step/s\n",
      "global step 21060, epoch: 5, batch: 1340, loss: 0.1764,domain_loss: 0.0426 ,ce_loss: 0.2098., accu: 0.9169, speed: 1.21 step/s\n",
      "global step 21070, epoch: 5, batch: 1350, loss: 0.1305,domain_loss: 0.0157 ,ce_loss: 0.1592., accu: 0.9170, speed: 1.18 step/s\n",
      "global step 21080, epoch: 5, batch: 1360, loss: 0.1154,domain_loss: 0.0073 ,ce_loss: 0.1424., accu: 0.9171, speed: 1.18 step/s\n",
      "global step 21090, epoch: 5, batch: 1370, loss: 0.1302,domain_loss: 0.0352 ,ce_loss: 0.1539., accu: 0.9173, speed: 1.18 step/s\n",
      "global step 21100, epoch: 5, batch: 1380, loss: 0.1124,domain_loss: 0.0015 ,ce_loss: 0.1401., accu: 0.9178, speed: 1.21 step/s\n",
      "global step 21110, epoch: 5, batch: 1390, loss: 0.1462,domain_loss: 0.0078 ,ce_loss: 0.1808., accu: 0.9194, speed: 1.19 step/s\n",
      "global step 21120, epoch: 5, batch: 1400, loss: 0.1828,domain_loss: 0.0139 ,ce_loss: 0.2250., accu: 0.9195, speed: 1.18 step/s\n",
      "global step 21130, epoch: 5, batch: 1410, loss: 0.1798,domain_loss: 0.0797 ,ce_loss: 0.2049., accu: 0.9203, speed: 1.17 step/s\n",
      "global step 21140, epoch: 5, batch: 1420, loss: 0.1298,domain_loss: 0.0262 ,ce_loss: 0.1557., accu: 0.9205, speed: 1.20 step/s\n",
      "global step 21150, epoch: 5, batch: 1430, loss: 0.1885,domain_loss: 0.0188 ,ce_loss: 0.2309., accu: 0.9208, speed: 1.17 step/s\n",
      "global step 21160, epoch: 5, batch: 1440, loss: 0.2042,domain_loss: 0.0456 ,ce_loss: 0.2438., accu: 0.9207, speed: 1.17 step/s\n",
      "global step 21170, epoch: 5, batch: 1450, loss: 0.1487,domain_loss: 0.0008 ,ce_loss: 0.1857., accu: 0.9206, speed: 1.18 step/s\n",
      "global step 21180, epoch: 5, batch: 1460, loss: 0.1374,domain_loss: 0.0838 ,ce_loss: 0.1508., accu: 0.9210, speed: 1.19 step/s\n",
      "global step 21190, epoch: 5, batch: 1470, loss: 0.1920,domain_loss: 0.0089 ,ce_loss: 0.2377., accu: 0.9213, speed: 1.17 step/s\n",
      "global step 21200, epoch: 5, batch: 1480, loss: 0.1387,domain_loss: 0.0496 ,ce_loss: 0.1610., accu: 0.9211, speed: 1.18 step/s\n",
      "global step 21210, epoch: 5, batch: 1490, loss: 0.1730,domain_loss: 0.0310 ,ce_loss: 0.2085., accu: 0.9216, speed: 1.20 step/s\n",
      "global step 21220, epoch: 5, batch: 1500, loss: 0.1340,domain_loss: 0.0355 ,ce_loss: 0.1587., accu: 0.9215, speed: 1.18 step/s\n",
      "global step 21230, epoch: 5, batch: 1510, loss: 0.1866,domain_loss: 0.0889 ,ce_loss: 0.2110., accu: 0.9211, speed: 1.18 step/s\n",
      "global step 21240, epoch: 5, batch: 1520, loss: 0.1108,domain_loss: 0.0034 ,ce_loss: 0.1377., accu: 0.9212, speed: 1.17 step/s\n",
      "global step 21250, epoch: 5, batch: 1530, loss: 0.1689,domain_loss: 0.0700 ,ce_loss: 0.1936., accu: 0.9209, speed: 1.18 step/s\n",
      "global step 21260, epoch: 5, batch: 1540, loss: 0.1499,domain_loss: 0.0800 ,ce_loss: 0.1674., accu: 0.9209, speed: 1.18 step/s\n",
      "global step 21270, epoch: 5, batch: 1550, loss: 0.1803,domain_loss: 0.0061 ,ce_loss: 0.2238., accu: 0.9203, speed: 1.19 step/s\n",
      "global step 21280, epoch: 5, batch: 1560, loss: 0.1664,domain_loss: 0.0168 ,ce_loss: 0.2038., accu: 0.9203, speed: 1.17 step/s\n",
      "global step 21290, epoch: 5, batch: 1570, loss: 0.2023,domain_loss: 0.0062 ,ce_loss: 0.2513., accu: 0.9205, speed: 1.18 step/s\n",
      "global step 21300, epoch: 5, batch: 1580, loss: 0.2075,domain_loss: 0.0522 ,ce_loss: 0.2464., accu: 0.9205, speed: 1.17 step/s\n",
      "2022-09-29 04:44:51,145\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 21300, epoch: 5, batch: 1580】，loss: 0.2075,domain_loss: 0.0522 ,ce_loss: 0.2464., accu: 0.9205,\n",
      "2022-09-29 04:44:51,452\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.072654, accuracy: 0.97[0.98],threshold:0.384, domain_acc:1.0,total_num:100\n",
      "global step 21310, epoch: 5, batch: 1590, loss: 0.1518,domain_loss: 0.0621 ,ce_loss: 0.1742., accu: 0.9086, speed: 1.04 step/s\n",
      "global step 21320, epoch: 5, batch: 1600, loss: 0.1173,domain_loss: 0.0097 ,ce_loss: 0.1442., accu: 0.9117, speed: 1.17 step/s\n",
      "global step 21330, epoch: 5, batch: 1610, loss: 0.1161,domain_loss: 0.0499 ,ce_loss: 0.1327., accu: 0.9138, speed: 1.17 step/s\n",
      "global step 21340, epoch: 5, batch: 1620, loss: 0.1491,domain_loss: 0.0245 ,ce_loss: 0.1802., accu: 0.9162, speed: 1.20 step/s\n",
      "global step 21350, epoch: 5, batch: 1630, loss: 0.1206,domain_loss: 0.0739 ,ce_loss: 0.1323., accu: 0.9195, speed: 1.19 step/s\n",
      "global step 21360, epoch: 5, batch: 1640, loss: 0.1496,domain_loss: 0.0200 ,ce_loss: 0.1820., accu: 0.9207, speed: 1.18 step/s\n",
      "global step 21370, epoch: 5, batch: 1650, loss: 0.1614,domain_loss: 0.0248 ,ce_loss: 0.1955., accu: 0.9223, speed: 1.21 step/s\n",
      "global step 21380, epoch: 5, batch: 1660, loss: 0.1629,domain_loss: 0.0374 ,ce_loss: 0.1943., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 21390, epoch: 5, batch: 1670, loss: 0.1247,domain_loss: 0.0216 ,ce_loss: 0.1505., accu: 0.9232, speed: 1.20 step/s\n",
      "global step 21400, epoch: 5, batch: 1680, loss: 0.1500,domain_loss: 0.0536 ,ce_loss: 0.1741., accu: 0.9236, speed: 1.19 step/s\n",
      "global step 21410, epoch: 5, batch: 1690, loss: 0.1317,domain_loss: 0.0099 ,ce_loss: 0.1621., accu: 0.9241, speed: 1.18 step/s\n",
      "global step 21420, epoch: 5, batch: 1700, loss: 0.1019,domain_loss: 0.0052 ,ce_loss: 0.1260., accu: 0.9239, speed: 1.19 step/s\n",
      "global step 21430, epoch: 5, batch: 1710, loss: 0.1683,domain_loss: 0.0102 ,ce_loss: 0.2078., accu: 0.9248, speed: 1.17 step/s\n",
      "global step 21440, epoch: 5, batch: 1720, loss: 0.0793,domain_loss: 0.0065 ,ce_loss: 0.0975., accu: 0.9252, speed: 1.21 step/s\n",
      "global step 21450, epoch: 5, batch: 1730, loss: 0.1310,domain_loss: 0.0154 ,ce_loss: 0.1600., accu: 0.9245, speed: 1.17 step/s\n",
      "global step 21460, epoch: 5, batch: 1740, loss: 0.1549,domain_loss: 0.0598 ,ce_loss: 0.1787., accu: 0.9236, speed: 1.18 step/s\n",
      "global step 21470, epoch: 5, batch: 1750, loss: 0.1764,domain_loss: 0.0068 ,ce_loss: 0.2188., accu: 0.9232, speed: 1.17 step/s\n",
      "global step 21480, epoch: 5, batch: 1760, loss: 0.1115,domain_loss: 0.0187 ,ce_loss: 0.1348., accu: 0.9230, speed: 1.18 step/s\n",
      "global step 21490, epoch: 5, batch: 1770, loss: 0.1101,domain_loss: 0.0125 ,ce_loss: 0.1345., accu: 0.9230, speed: 1.19 step/s\n",
      "global step 21500, epoch: 5, batch: 1780, loss: 0.1375,domain_loss: 0.0047 ,ce_loss: 0.1707., accu: 0.9227, speed: 1.18 step/s\n",
      "global step 21510, epoch: 5, batch: 1790, loss: 0.1327,domain_loss: 0.0105 ,ce_loss: 0.1632., accu: 0.9219, speed: 1.17 step/s\n",
      "global step 21520, epoch: 5, batch: 1800, loss: 0.1603,domain_loss: 0.0102 ,ce_loss: 0.1978., accu: 0.9217, speed: 1.17 step/s\n",
      "global step 21530, epoch: 5, batch: 1810, loss: 0.2424,domain_loss: 0.0605 ,ce_loss: 0.2878., accu: 0.9216, speed: 1.19 step/s\n",
      "global step 21540, epoch: 5, batch: 1820, loss: 0.1783,domain_loss: 0.0436 ,ce_loss: 0.2120., accu: 0.9208, speed: 1.19 step/s\n",
      "global step 21550, epoch: 5, batch: 1830, loss: 0.1351,domain_loss: 0.0084 ,ce_loss: 0.1667., accu: 0.9212, speed: 1.18 step/s\n",
      "global step 21560, epoch: 5, batch: 1840, loss: 0.1852,domain_loss: 0.0177 ,ce_loss: 0.2271., accu: 0.9214, speed: 1.19 step/s\n",
      "global step 21570, epoch: 5, batch: 1850, loss: 0.1830,domain_loss: 0.0910 ,ce_loss: 0.2060., accu: 0.9214, speed: 1.23 step/s\n",
      "global step 21580, epoch: 5, batch: 1860, loss: 0.1062,domain_loss: 0.0028 ,ce_loss: 0.1321., accu: 0.9214, speed: 1.17 step/s\n",
      "global step 21590, epoch: 5, batch: 1870, loss: 0.1261,domain_loss: 0.0086 ,ce_loss: 0.1555., accu: 0.9215, speed: 1.19 step/s\n",
      "global step 21600, epoch: 5, batch: 1880, loss: 0.1283,domain_loss: 0.0174 ,ce_loss: 0.1560., accu: 0.9215, speed: 1.18 step/s\n",
      "2022-09-29 04:49:05,276\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 21600, epoch: 5, batch: 1880】，loss: 0.1283,domain_loss: 0.0174 ,ce_loss: 0.1560., accu: 0.9215,\n",
      "2022-09-29 04:49:05,584\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.055958, accuracy: 0.97[0.98],threshold:0.442, domain_acc:1.0,total_num:100\n",
      "global step 21610, epoch: 5, batch: 1890, loss: 0.1082,domain_loss: 0.0292 ,ce_loss: 0.1280., accu: 0.9195, speed: 1.03 step/s\n",
      "global step 21620, epoch: 5, batch: 1900, loss: 0.1561,domain_loss: 0.0328 ,ce_loss: 0.1869., accu: 0.9262, speed: 1.18 step/s\n",
      "global step 21630, epoch: 5, batch: 1910, loss: 0.1903,domain_loss: 0.0020 ,ce_loss: 0.2373., accu: 0.9234, speed: 1.17 step/s\n",
      "global step 21640, epoch: 5, batch: 1920, loss: 0.1036,domain_loss: 0.0511 ,ce_loss: 0.1167., accu: 0.9240, speed: 1.20 step/s\n",
      "global step 21650, epoch: 5, batch: 1930, loss: 0.1390,domain_loss: 0.0140 ,ce_loss: 0.1703., accu: 0.9250, speed: 1.17 step/s\n",
      "global step 21660, epoch: 5, batch: 1940, loss: 0.1222,domain_loss: 0.0058 ,ce_loss: 0.1513., accu: 0.9259, speed: 1.19 step/s\n",
      "global step 21670, epoch: 5, batch: 1950, loss: 0.1307,domain_loss: 0.0286 ,ce_loss: 0.1562., accu: 0.9257, speed: 1.17 step/s\n",
      "global step 21680, epoch: 5, batch: 1960, loss: 0.1705,domain_loss: 0.0570 ,ce_loss: 0.1989., accu: 0.9265, speed: 1.18 step/s\n",
      "global step 21690, epoch: 5, batch: 1970, loss: 0.1712,domain_loss: 0.0196 ,ce_loss: 0.2091., accu: 0.9265, speed: 1.19 step/s\n",
      "global step 21700, epoch: 5, batch: 1980, loss: 0.1590,domain_loss: 0.0057 ,ce_loss: 0.1973., accu: 0.9251, speed: 1.19 step/s\n",
      "global step 21710, epoch: 5, batch: 1990, loss: 0.1869,domain_loss: 0.0624 ,ce_loss: 0.2181., accu: 0.9239, speed: 1.17 step/s\n",
      "global step 21720, epoch: 5, batch: 2000, loss: 0.1306,domain_loss: 0.0322 ,ce_loss: 0.1552., accu: 0.9243, speed: 1.18 step/s\n",
      "global step 21730, epoch: 5, batch: 2010, loss: 0.1316,domain_loss: 0.0026 ,ce_loss: 0.1639., accu: 0.9233, speed: 1.17 step/s\n",
      "global step 21740, epoch: 5, batch: 2020, loss: 0.1231,domain_loss: 0.0115 ,ce_loss: 0.1510., accu: 0.9238, speed: 1.20 step/s\n",
      "global step 21750, epoch: 5, batch: 2030, loss: 0.0869,domain_loss: 0.0022 ,ce_loss: 0.1080., accu: 0.9236, speed: 1.17 step/s\n",
      "global step 21760, epoch: 5, batch: 2040, loss: 0.2032,domain_loss: 0.0216 ,ce_loss: 0.2485., accu: 0.9237, speed: 1.19 step/s\n",
      "global step 21770, epoch: 5, batch: 2050, loss: 0.1650,domain_loss: 0.0144 ,ce_loss: 0.2027., accu: 0.9232, speed: 1.19 step/s\n",
      "global step 21780, epoch: 5, batch: 2060, loss: 0.1769,domain_loss: 0.0043 ,ce_loss: 0.2200., accu: 0.9237, speed: 1.19 step/s\n",
      "global step 21790, epoch: 5, batch: 2070, loss: 0.0813,domain_loss: 0.0085 ,ce_loss: 0.0995., accu: 0.9236, speed: 1.18 step/s\n",
      "global step 21800, epoch: 5, batch: 2080, loss: 0.1955,domain_loss: 0.0322 ,ce_loss: 0.2363., accu: 0.9234, speed: 1.17 step/s\n",
      "global step 21810, epoch: 5, batch: 2090, loss: 0.1562,domain_loss: 0.0582 ,ce_loss: 0.1807., accu: 0.9225, speed: 1.19 step/s\n",
      "global step 21820, epoch: 5, batch: 2100, loss: 0.1482,domain_loss: 0.0098 ,ce_loss: 0.1828., accu: 0.9228, speed: 1.20 step/s\n",
      "global step 21830, epoch: 5, batch: 2110, loss: 0.0996,domain_loss: 0.0054 ,ce_loss: 0.1232., accu: 0.9230, speed: 1.17 step/s\n",
      "global step 21840, epoch: 5, batch: 2120, loss: 0.1610,domain_loss: 0.0519 ,ce_loss: 0.1883., accu: 0.9232, speed: 1.17 step/s\n",
      "global step 21850, epoch: 5, batch: 2130, loss: 0.2329,domain_loss: 0.0175 ,ce_loss: 0.2868., accu: 0.9233, speed: 1.18 step/s\n",
      "global step 21860, epoch: 5, batch: 2140, loss: 0.1813,domain_loss: 0.0220 ,ce_loss: 0.2211., accu: 0.9233, speed: 1.19 step/s\n",
      "global step 21870, epoch: 5, batch: 2150, loss: 0.1170,domain_loss: 0.0282 ,ce_loss: 0.1392., accu: 0.9235, speed: 1.17 step/s\n",
      "global step 21880, epoch: 5, batch: 2160, loss: 0.1523,domain_loss: 0.0409 ,ce_loss: 0.1802., accu: 0.9233, speed: 1.19 step/s\n",
      "global step 21890, epoch: 5, batch: 2170, loss: 0.1790,domain_loss: 0.0095 ,ce_loss: 0.2214., accu: 0.9234, speed: 1.17 step/s\n",
      "global step 21900, epoch: 5, batch: 2180, loss: 0.1375,domain_loss: 0.0329 ,ce_loss: 0.1637., accu: 0.9230, speed: 1.19 step/s\n",
      "2022-09-29 04:53:20,286\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 21900, epoch: 5, batch: 2180】，loss: 0.1375,domain_loss: 0.0329 ,ce_loss: 0.1637., accu: 0.9230,\n",
      "2022-09-29 04:53:20,585\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.066656, accuracy: 0.97[0.99],threshold:0.449, domain_acc:1.0,total_num:100\n",
      "global step 21910, epoch: 5, batch: 2190, loss: 0.1217,domain_loss: 0.0041 ,ce_loss: 0.1512., accu: 0.9289, speed: 1.04 step/s\n",
      "global step 21920, epoch: 5, batch: 2200, loss: 0.1445,domain_loss: 0.0322 ,ce_loss: 0.1725., accu: 0.9242, speed: 1.18 step/s\n",
      "global step 21930, epoch: 5, batch: 2210, loss: 0.1396,domain_loss: 0.0213 ,ce_loss: 0.1691., accu: 0.9182, speed: 1.18 step/s\n",
      "global step 21940, epoch: 5, batch: 2220, loss: 0.1675,domain_loss: 0.0399 ,ce_loss: 0.1994., accu: 0.9189, speed: 1.19 step/s\n",
      "global step 21950, epoch: 5, batch: 2230, loss: 0.2885,domain_loss: 0.0585 ,ce_loss: 0.3460., accu: 0.9184, speed: 1.21 step/s\n",
      "global step 21960, epoch: 5, batch: 2240, loss: 0.1035,domain_loss: 0.0086 ,ce_loss: 0.1272., accu: 0.9195, speed: 1.18 step/s\n",
      "global step 21970, epoch: 5, batch: 2250, loss: 0.1649,domain_loss: 0.0243 ,ce_loss: 0.2001., accu: 0.9202, speed: 1.18 step/s\n",
      "global step 21980, epoch: 5, batch: 2260, loss: 0.1598,domain_loss: 0.0109 ,ce_loss: 0.1970., accu: 0.9192, speed: 1.19 step/s\n",
      "global step 21990, epoch: 5, batch: 2270, loss: 0.1716,domain_loss: 0.0066 ,ce_loss: 0.2128., accu: 0.9194, speed: 1.18 step/s\n",
      "global step 22000, epoch: 5, batch: 2280, loss: 0.1837,domain_loss: 0.0050 ,ce_loss: 0.2283., accu: 0.9193, speed: 1.18 step/s\n",
      "global step 22010, epoch: 5, batch: 2290, loss: 0.1176,domain_loss: 0.0066 ,ce_loss: 0.1453., accu: 0.9192, speed: 1.19 step/s\n",
      "global step 22020, epoch: 5, batch: 2300, loss: 0.1785,domain_loss: 0.0013 ,ce_loss: 0.2228., accu: 0.9186, speed: 1.19 step/s\n",
      "global step 22030, epoch: 5, batch: 2310, loss: 0.2035,domain_loss: 0.0083 ,ce_loss: 0.2522., accu: 0.9194, speed: 1.17 step/s\n",
      "global step 22040, epoch: 5, batch: 2320, loss: 0.1496,domain_loss: 0.0051 ,ce_loss: 0.1857., accu: 0.9198, speed: 1.18 step/s\n",
      "global step 22050, epoch: 5, batch: 2330, loss: 0.1588,domain_loss: 0.0250 ,ce_loss: 0.1923., accu: 0.9195, speed: 1.19 step/s\n",
      "global step 22060, epoch: 5, batch: 2340, loss: 0.0804,domain_loss: 0.0012 ,ce_loss: 0.1002., accu: 0.9202, speed: 1.20 step/s\n",
      "global step 22070, epoch: 5, batch: 2350, loss: 0.1565,domain_loss: 0.0341 ,ce_loss: 0.1871., accu: 0.9199, speed: 1.18 step/s\n",
      "global step 22080, epoch: 5, batch: 2360, loss: 0.1372,domain_loss: 0.0205 ,ce_loss: 0.1664., accu: 0.9195, speed: 1.19 step/s\n",
      "global step 22090, epoch: 5, batch: 2370, loss: 0.1111,domain_loss: 0.0200 ,ce_loss: 0.1339., accu: 0.9196, speed: 1.21 step/s\n",
      "global step 22100, epoch: 5, batch: 2380, loss: 0.1914,domain_loss: 0.0263 ,ce_loss: 0.2327., accu: 0.9201, speed: 1.19 step/s\n",
      "global step 22110, epoch: 5, batch: 2390, loss: 0.1404,domain_loss: 0.0359 ,ce_loss: 0.1666., accu: 0.9198, speed: 1.17 step/s\n",
      "global step 22120, epoch: 5, batch: 2400, loss: 0.0978,domain_loss: 0.0182 ,ce_loss: 0.1177., accu: 0.9202, speed: 1.17 step/s\n",
      "global step 22130, epoch: 5, batch: 2410, loss: 0.1344,domain_loss: 0.0093 ,ce_loss: 0.1657., accu: 0.9202, speed: 1.18 step/s\n",
      "global step 22140, epoch: 5, batch: 2420, loss: 0.1060,domain_loss: 0.0180 ,ce_loss: 0.1279., accu: 0.9201, speed: 1.18 step/s\n",
      "global step 22150, epoch: 5, batch: 2430, loss: 0.1706,domain_loss: 0.0403 ,ce_loss: 0.2031., accu: 0.9203, speed: 1.17 step/s\n",
      "global step 22160, epoch: 5, batch: 2440, loss: 0.1104,domain_loss: 0.0046 ,ce_loss: 0.1368., accu: 0.9203, speed: 1.22 step/s\n",
      "global step 22170, epoch: 5, batch: 2450, loss: 0.1310,domain_loss: 0.0154 ,ce_loss: 0.1599., accu: 0.9199, speed: 1.18 step/s\n",
      "global step 22180, epoch: 5, batch: 2460, loss: 0.1891,domain_loss: 0.0114 ,ce_loss: 0.2335., accu: 0.9202, speed: 1.20 step/s\n",
      "global step 22190, epoch: 5, batch: 2470, loss: 0.1872,domain_loss: 0.0225 ,ce_loss: 0.2284., accu: 0.9204, speed: 1.19 step/s\n",
      "global step 22200, epoch: 5, batch: 2480, loss: 0.1661,domain_loss: 0.0087 ,ce_loss: 0.2055., accu: 0.9207, speed: 1.18 step/s\n",
      "2022-09-29 04:57:34,383\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 22200, epoch: 5, batch: 2480】，loss: 0.1661,domain_loss: 0.0087 ,ce_loss: 0.2055., accu: 0.9207,\n",
      "2022-09-29 04:57:34,697\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.055344, accuracy: 0.97[0.98],threshold:0.412, domain_acc:1.0,total_num:100\n",
      "global step 22210, epoch: 5, batch: 2490, loss: 0.1089,domain_loss: 0.0158 ,ce_loss: 0.1322., accu: 0.9102, speed: 1.03 step/s\n",
      "global step 22220, epoch: 5, batch: 2500, loss: 0.1522,domain_loss: 0.0322 ,ce_loss: 0.1822., accu: 0.9129, speed: 1.18 step/s\n",
      "global step 22230, epoch: 5, batch: 2510, loss: 0.1772,domain_loss: 0.0124 ,ce_loss: 0.2184., accu: 0.9180, speed: 1.17 step/s\n",
      "global step 22240, epoch: 5, batch: 2520, loss: 0.1275,domain_loss: 0.0526 ,ce_loss: 0.1462., accu: 0.9207, speed: 1.17 step/s\n",
      "global step 22250, epoch: 5, batch: 2530, loss: 0.1563,domain_loss: 0.0084 ,ce_loss: 0.1932., accu: 0.9220, speed: 1.18 step/s\n",
      "global step 22260, epoch: 5, batch: 2540, loss: 0.1046,domain_loss: 0.0279 ,ce_loss: 0.1237., accu: 0.9254, speed: 1.18 step/s\n",
      "global step 22270, epoch: 5, batch: 2550, loss: 0.1782,domain_loss: 0.0493 ,ce_loss: 0.2105., accu: 0.9257, speed: 1.20 step/s\n",
      "global step 22280, epoch: 5, batch: 2560, loss: 0.1546,domain_loss: 0.0226 ,ce_loss: 0.1876., accu: 0.9258, speed: 1.19 step/s\n",
      "global step 22290, epoch: 5, batch: 2570, loss: 0.1968,domain_loss: 0.0066 ,ce_loss: 0.2443., accu: 0.9258, speed: 1.20 step/s\n",
      "global step 22300, epoch: 5, batch: 2580, loss: 0.0954,domain_loss: 0.0135 ,ce_loss: 0.1159., accu: 0.9259, speed: 1.21 step/s\n",
      "global step 22310, epoch: 5, batch: 2590, loss: 0.1357,domain_loss: 0.0036 ,ce_loss: 0.1687., accu: 0.9258, speed: 1.18 step/s\n",
      "global step 22320, epoch: 5, batch: 2600, loss: 0.0742,domain_loss: 0.0445 ,ce_loss: 0.0817., accu: 0.9260, speed: 1.18 step/s\n",
      "global step 22330, epoch: 5, batch: 2610, loss: 0.0992,domain_loss: 0.0081 ,ce_loss: 0.1219., accu: 0.9263, speed: 1.17 step/s\n",
      "global step 22340, epoch: 5, batch: 2620, loss: 0.1228,domain_loss: 0.0423 ,ce_loss: 0.1429., accu: 0.9257, speed: 1.18 step/s\n",
      "global step 22350, epoch: 5, batch: 2630, loss: 0.1246,domain_loss: 0.0330 ,ce_loss: 0.1475., accu: 0.9265, speed: 1.19 step/s\n",
      "global step 22360, epoch: 5, batch: 2640, loss: 0.1586,domain_loss: 0.0033 ,ce_loss: 0.1974., accu: 0.9262, speed: 1.19 step/s\n",
      "global step 22370, epoch: 5, batch: 2650, loss: 0.1281,domain_loss: 0.0340 ,ce_loss: 0.1516., accu: 0.9261, speed: 1.19 step/s\n",
      "global step 22380, epoch: 5, batch: 2660, loss: 0.1932,domain_loss: 0.0302 ,ce_loss: 0.2339., accu: 0.9257, speed: 1.19 step/s\n",
      "global step 22390, epoch: 5, batch: 2670, loss: 0.1611,domain_loss: 0.0166 ,ce_loss: 0.1972., accu: 0.9257, speed: 1.20 step/s\n",
      "global step 22400, epoch: 5, batch: 2680, loss: 0.0988,domain_loss: 0.0398 ,ce_loss: 0.1136., accu: 0.9252, speed: 1.17 step/s\n",
      "global step 22410, epoch: 5, batch: 2690, loss: 0.0838,domain_loss: 0.0110 ,ce_loss: 0.1020., accu: 0.9251, speed: 1.19 step/s\n",
      "global step 22420, epoch: 5, batch: 2700, loss: 0.1129,domain_loss: 0.0168 ,ce_loss: 0.1369., accu: 0.9249, speed: 1.17 step/s\n",
      "global step 22430, epoch: 5, batch: 2710, loss: 0.1058,domain_loss: 0.0123 ,ce_loss: 0.1292., accu: 0.9244, speed: 1.17 step/s\n",
      "global step 22440, epoch: 5, batch: 2720, loss: 0.1843,domain_loss: 0.0090 ,ce_loss: 0.2281., accu: 0.9244, speed: 1.17 step/s\n",
      "global step 22450, epoch: 5, batch: 2730, loss: 0.1294,domain_loss: 0.0174 ,ce_loss: 0.1575., accu: 0.9241, speed: 1.19 step/s\n",
      "global step 22460, epoch: 5, batch: 2740, loss: 0.2066,domain_loss: 0.0032 ,ce_loss: 0.2575., accu: 0.9239, speed: 1.18 step/s\n",
      "global step 22470, epoch: 5, batch: 2750, loss: 0.1986,domain_loss: 0.0059 ,ce_loss: 0.2468., accu: 0.9239, speed: 1.18 step/s\n",
      "global step 22480, epoch: 5, batch: 2760, loss: 0.1388,domain_loss: 0.0274 ,ce_loss: 0.1666., accu: 0.9241, speed: 1.20 step/s\n",
      "global step 22490, epoch: 5, batch: 2770, loss: 0.1309,domain_loss: 0.0014 ,ce_loss: 0.1633., accu: 0.9242, speed: 1.19 step/s\n",
      "global step 22500, epoch: 5, batch: 2780, loss: 0.1462,domain_loss: 0.0078 ,ce_loss: 0.1808., accu: 0.9240, speed: 1.18 step/s\n",
      "2022-09-29 05:01:48,951\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 22500, epoch: 5, batch: 2780】，loss: 0.1462,domain_loss: 0.0078 ,ce_loss: 0.1808., accu: 0.9240,\n",
      "2022-09-29 05:01:49,250\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.055848, accuracy: 0.97[0.99],threshold:0.517, domain_acc:1.0,total_num:100\n",
      "global step 22510, epoch: 5, batch: 2790, loss: 0.1573,domain_loss: 0.0020 ,ce_loss: 0.1961., accu: 0.9078, speed: 1.04 step/s\n",
      "global step 22520, epoch: 5, batch: 2800, loss: 0.1009,domain_loss: 0.0153 ,ce_loss: 0.1223., accu: 0.9141, speed: 1.18 step/s\n",
      "global step 22530, epoch: 5, batch: 2810, loss: 0.1587,domain_loss: 0.0122 ,ce_loss: 0.1953., accu: 0.9148, speed: 1.18 step/s\n",
      "global step 22540, epoch: 5, batch: 2820, loss: 0.1131,domain_loss: 0.0143 ,ce_loss: 0.1378., accu: 0.9186, speed: 1.18 step/s\n",
      "global step 22550, epoch: 5, batch: 2830, loss: 0.1067,domain_loss: 0.0292 ,ce_loss: 0.1261., accu: 0.9184, speed: 1.18 step/s\n",
      "global step 22560, epoch: 5, batch: 2840, loss: 0.1628,domain_loss: 0.0357 ,ce_loss: 0.1945., accu: 0.9177, speed: 1.18 step/s\n",
      "global step 22570, epoch: 5, batch: 2850, loss: 0.1539,domain_loss: 0.0195 ,ce_loss: 0.1875., accu: 0.9184, speed: 1.19 step/s\n",
      "global step 22580, epoch: 5, batch: 2860, loss: 0.1748,domain_loss: 0.0015 ,ce_loss: 0.2181., accu: 0.9198, speed: 1.18 step/s\n",
      "global step 22590, epoch: 5, batch: 2870, loss: 0.1404,domain_loss: 0.1087 ,ce_loss: 0.1483., accu: 0.9206, speed: 1.18 step/s\n",
      "global step 22600, epoch: 5, batch: 2880, loss: 0.1460,domain_loss: 0.0403 ,ce_loss: 0.1725., accu: 0.9205, speed: 1.18 step/s\n",
      "global step 22610, epoch: 5, batch: 2890, loss: 0.1553,domain_loss: 0.0106 ,ce_loss: 0.1915., accu: 0.9211, speed: 1.19 step/s\n",
      "global step 22620, epoch: 5, batch: 2900, loss: 0.1567,domain_loss: 0.0047 ,ce_loss: 0.1947., accu: 0.9217, speed: 1.19 step/s\n",
      "global step 22630, epoch: 5, batch: 2910, loss: 0.1344,domain_loss: 0.0231 ,ce_loss: 0.1623., accu: 0.9223, speed: 1.17 step/s\n",
      "global step 22640, epoch: 5, batch: 2920, loss: 0.1436,domain_loss: 0.0022 ,ce_loss: 0.1789., accu: 0.9228, speed: 1.19 step/s\n",
      "global step 22650, epoch: 5, batch: 2930, loss: 0.1259,domain_loss: 0.0035 ,ce_loss: 0.1565., accu: 0.9230, speed: 1.18 step/s\n",
      "global step 22660, epoch: 5, batch: 2940, loss: 0.1964,domain_loss: 0.0243 ,ce_loss: 0.2395., accu: 0.9232, speed: 1.18 step/s\n",
      "global step 22670, epoch: 5, batch: 2950, loss: 0.1605,domain_loss: 0.0522 ,ce_loss: 0.1875., accu: 0.9238, speed: 1.17 step/s\n",
      "global step 22680, epoch: 5, batch: 2960, loss: 0.2237,domain_loss: 0.0199 ,ce_loss: 0.2746., accu: 0.9238, speed: 1.20 step/s\n",
      "global step 22690, epoch: 5, batch: 2970, loss: 0.1499,domain_loss: 0.0084 ,ce_loss: 0.1852., accu: 0.9236, speed: 1.18 step/s\n",
      "global step 22700, epoch: 5, batch: 2980, loss: 0.2449,domain_loss: 0.0078 ,ce_loss: 0.3041., accu: 0.9231, speed: 1.18 step/s\n",
      "global step 22710, epoch: 5, batch: 2990, loss: 0.1467,domain_loss: 0.0419 ,ce_loss: 0.1730., accu: 0.9235, speed: 1.18 step/s\n",
      "global step 22720, epoch: 5, batch: 3000, loss: 0.1315,domain_loss: 0.0299 ,ce_loss: 0.1569., accu: 0.9230, speed: 1.19 step/s\n",
      "global step 22730, epoch: 5, batch: 3010, loss: 0.1043,domain_loss: 0.0085 ,ce_loss: 0.1283., accu: 0.9224, speed: 1.18 step/s\n",
      "global step 22740, epoch: 5, batch: 3020, loss: 0.1426,domain_loss: 0.0122 ,ce_loss: 0.1752., accu: 0.9225, speed: 1.18 step/s\n",
      "global step 22750, epoch: 5, batch: 3030, loss: 0.1191,domain_loss: 0.0422 ,ce_loss: 0.1384., accu: 0.9232, speed: 1.19 step/s\n",
      "global step 22760, epoch: 5, batch: 3040, loss: 0.1459,domain_loss: 0.0056 ,ce_loss: 0.1809., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 22770, epoch: 5, batch: 3050, loss: 0.1371,domain_loss: 0.0028 ,ce_loss: 0.1707., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 22780, epoch: 5, batch: 3060, loss: 0.2072,domain_loss: 0.0627 ,ce_loss: 0.2433., accu: 0.9238, speed: 1.19 step/s\n",
      "global step 22790, epoch: 5, batch: 3070, loss: 0.1559,domain_loss: 0.0584 ,ce_loss: 0.1803., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 22800, epoch: 5, batch: 3080, loss: 0.1164,domain_loss: 0.0715 ,ce_loss: 0.1276., accu: 0.9234, speed: 1.18 step/s\n",
      "2022-09-29 05:06:03,837\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 22800, epoch: 5, batch: 3080】，loss: 0.1164,domain_loss: 0.0715 ,ce_loss: 0.1276., accu: 0.9234,\n",
      "2022-09-29 05:06:04,144\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.059226, accuracy: 0.97[0.99],threshold:0.498, domain_acc:1.0,total_num:100\n",
      "global step 22810, epoch: 5, batch: 3090, loss: 0.1263,domain_loss: 0.0482 ,ce_loss: 0.1458., accu: 0.9234, speed: 1.05 step/s\n",
      "global step 22820, epoch: 5, batch: 3100, loss: 0.1866,domain_loss: 0.0029 ,ce_loss: 0.2325., accu: 0.9215, speed: 1.19 step/s\n",
      "global step 22830, epoch: 5, batch: 3110, loss: 0.1492,domain_loss: 0.0120 ,ce_loss: 0.1835., accu: 0.9234, speed: 1.18 step/s\n",
      "global step 22840, epoch: 5, batch: 3120, loss: 0.1794,domain_loss: 0.0194 ,ce_loss: 0.2194., accu: 0.9180, speed: 1.18 step/s\n",
      "global step 22850, epoch: 5, batch: 3130, loss: 0.1742,domain_loss: 0.0438 ,ce_loss: 0.2067., accu: 0.9189, speed: 1.19 step/s\n",
      "global step 22860, epoch: 5, batch: 3140, loss: 0.2065,domain_loss: 0.0321 ,ce_loss: 0.2501., accu: 0.9174, speed: 1.19 step/s\n",
      "global step 22870, epoch: 5, batch: 3150, loss: 0.1206,domain_loss: 0.0167 ,ce_loss: 0.1466., accu: 0.9187, speed: 1.18 step/s\n",
      "global step 22880, epoch: 5, batch: 3160, loss: 0.1980,domain_loss: 0.0050 ,ce_loss: 0.2463., accu: 0.9169, speed: 1.19 step/s\n",
      "global step 22890, epoch: 5, batch: 3170, loss: 0.1399,domain_loss: 0.0123 ,ce_loss: 0.1719., accu: 0.9170, speed: 1.18 step/s\n",
      "global step 22900, epoch: 5, batch: 3180, loss: 0.1390,domain_loss: 0.0568 ,ce_loss: 0.1596., accu: 0.9177, speed: 1.20 step/s\n",
      "global step 22910, epoch: 5, batch: 3190, loss: 0.1388,domain_loss: 0.0044 ,ce_loss: 0.1724., accu: 0.9181, speed: 1.18 step/s\n",
      "global step 22920, epoch: 5, batch: 3200, loss: 0.1830,domain_loss: 0.0029 ,ce_loss: 0.2280., accu: 0.9190, speed: 1.18 step/s\n",
      "global step 22930, epoch: 5, batch: 3210, loss: 0.1969,domain_loss: 0.0082 ,ce_loss: 0.2441., accu: 0.9188, speed: 1.18 step/s\n",
      "global step 22940, epoch: 5, batch: 3220, loss: 0.1128,domain_loss: 0.0045 ,ce_loss: 0.1399., accu: 0.9189, speed: 1.18 step/s\n",
      "global step 22950, epoch: 5, batch: 3230, loss: 0.1853,domain_loss: 0.0096 ,ce_loss: 0.2292., accu: 0.9194, speed: 1.19 step/s\n",
      "global step 22960, epoch: 5, batch: 3240, loss: 0.0905,domain_loss: 0.0036 ,ce_loss: 0.1122., accu: 0.9187, speed: 1.18 step/s\n",
      "global step 22970, epoch: 5, batch: 3250, loss: 0.1735,domain_loss: 0.0359 ,ce_loss: 0.2079., accu: 0.9193, speed: 1.17 step/s\n",
      "global step 22980, epoch: 5, batch: 3260, loss: 0.1508,domain_loss: 0.0208 ,ce_loss: 0.1833., accu: 0.9194, speed: 1.18 step/s\n",
      "global step 22990, epoch: 5, batch: 3270, loss: 0.1567,domain_loss: 0.0988 ,ce_loss: 0.1711., accu: 0.9188, speed: 1.19 step/s\n",
      "global step 23000, epoch: 5, batch: 3280, loss: 0.1559,domain_loss: 0.0043 ,ce_loss: 0.1938., accu: 0.9189, speed: 1.20 step/s\n",
      "global step 23010, epoch: 5, batch: 3290, loss: 0.1209,domain_loss: 0.0715 ,ce_loss: 0.1333., accu: 0.9188, speed: 1.19 step/s\n",
      "global step 23020, epoch: 5, batch: 3300, loss: 0.1479,domain_loss: 0.0057 ,ce_loss: 0.1835., accu: 0.9184, speed: 1.21 step/s\n",
      "global step 23030, epoch: 5, batch: 3310, loss: 0.1648,domain_loss: 0.0579 ,ce_loss: 0.1915., accu: 0.9178, speed: 1.19 step/s\n",
      "global step 23040, epoch: 5, batch: 3320, loss: 0.1267,domain_loss: 0.0176 ,ce_loss: 0.1540., accu: 0.9180, speed: 1.18 step/s\n",
      "global step 23050, epoch: 5, batch: 3330, loss: 0.1916,domain_loss: 0.0246 ,ce_loss: 0.2333., accu: 0.9179, speed: 1.18 step/s\n",
      "global step 23060, epoch: 5, batch: 3340, loss: 0.1514,domain_loss: 0.0575 ,ce_loss: 0.1749., accu: 0.9177, speed: 1.20 step/s\n",
      "global step 23070, epoch: 5, batch: 3350, loss: 0.1490,domain_loss: 0.0074 ,ce_loss: 0.1844., accu: 0.9179, speed: 1.18 step/s\n",
      "global step 23080, epoch: 5, batch: 3360, loss: 0.1177,domain_loss: 0.0895 ,ce_loss: 0.1248., accu: 0.9186, speed: 1.18 step/s\n",
      "global step 23090, epoch: 5, batch: 3370, loss: 0.2099,domain_loss: 0.0168 ,ce_loss: 0.2581., accu: 0.9186, speed: 1.18 step/s\n",
      "global step 23100, epoch: 5, batch: 3380, loss: 0.1299,domain_loss: 0.0191 ,ce_loss: 0.1576., accu: 0.9186, speed: 1.18 step/s\n",
      "2022-09-29 05:10:18,162\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 23100, epoch: 5, batch: 3380】，loss: 0.1299,domain_loss: 0.0191 ,ce_loss: 0.1576., accu: 0.9186,\n",
      "2022-09-29 05:10:18,473\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.058665, accuracy: 0.98[0.98],threshold:0.342, domain_acc:1.0,total_num:100\n",
      "global step 23110, epoch: 5, batch: 3390, loss: 0.1489,domain_loss: 0.0426 ,ce_loss: 0.1754., accu: 0.9273, speed: 1.05 step/s\n",
      "global step 23120, epoch: 5, batch: 3400, loss: 0.1344,domain_loss: 0.0193 ,ce_loss: 0.1632., accu: 0.9262, speed: 1.17 step/s\n",
      "global step 23130, epoch: 5, batch: 3410, loss: 0.1451,domain_loss: 0.0033 ,ce_loss: 0.1805., accu: 0.9281, speed: 1.20 step/s\n",
      "global step 23140, epoch: 5, batch: 3420, loss: 0.1552,domain_loss: 0.0032 ,ce_loss: 0.1932., accu: 0.9293, speed: 1.19 step/s\n",
      "global step 23150, epoch: 5, batch: 3430, loss: 0.1019,domain_loss: 0.0027 ,ce_loss: 0.1266., accu: 0.9275, speed: 1.18 step/s\n",
      "global step 23160, epoch: 5, batch: 3440, loss: 0.1410,domain_loss: 0.0041 ,ce_loss: 0.1752., accu: 0.9253, speed: 1.18 step/s\n",
      "global step 23170, epoch: 5, batch: 3450, loss: 0.2456,domain_loss: 0.0442 ,ce_loss: 0.2959., accu: 0.9248, speed: 1.18 step/s\n",
      "global step 23180, epoch: 5, batch: 3460, loss: 0.0967,domain_loss: 0.0386 ,ce_loss: 0.1112., accu: 0.9253, speed: 1.18 step/s\n",
      "global step 23190, epoch: 5, batch: 3470, loss: 0.1366,domain_loss: 0.0072 ,ce_loss: 0.1689., accu: 0.9235, speed: 1.18 step/s\n",
      "global step 23200, epoch: 5, batch: 3480, loss: 0.1567,domain_loss: 0.0142 ,ce_loss: 0.1923., accu: 0.9242, speed: 1.17 step/s\n",
      "global step 23210, epoch: 5, batch: 3490, loss: 0.1139,domain_loss: 0.0072 ,ce_loss: 0.1406., accu: 0.9241, speed: 1.19 step/s\n",
      "global step 23220, epoch: 5, batch: 3500, loss: 0.1227,domain_loss: 0.0242 ,ce_loss: 0.1473., accu: 0.9242, speed: 1.19 step/s\n",
      "global step 23230, epoch: 5, batch: 3510, loss: 0.1313,domain_loss: 0.0105 ,ce_loss: 0.1616., accu: 0.9237, speed: 1.18 step/s\n",
      "global step 23240, epoch: 5, batch: 3520, loss: 0.1541,domain_loss: 0.0029 ,ce_loss: 0.1919., accu: 0.9235, speed: 1.17 step/s\n",
      "global step 23250, epoch: 5, batch: 3530, loss: 0.1822,domain_loss: 0.0084 ,ce_loss: 0.2256., accu: 0.9233, speed: 1.18 step/s\n",
      "global step 23260, epoch: 5, batch: 3540, loss: 0.1544,domain_loss: 0.0321 ,ce_loss: 0.1849., accu: 0.9230, speed: 1.18 step/s\n",
      "global step 23270, epoch: 5, batch: 3550, loss: 0.1176,domain_loss: 0.0306 ,ce_loss: 0.1393., accu: 0.9232, speed: 1.18 step/s\n",
      "global step 23280, epoch: 5, batch: 3560, loss: 0.1605,domain_loss: 0.0126 ,ce_loss: 0.1974., accu: 0.9235, speed: 1.20 step/s\n",
      "global step 23290, epoch: 5, batch: 3570, loss: 0.1285,domain_loss: 0.0046 ,ce_loss: 0.1594., accu: 0.9234, speed: 1.18 step/s\n",
      "global step 23300, epoch: 5, batch: 3580, loss: 0.1730,domain_loss: 0.0029 ,ce_loss: 0.2155., accu: 0.9237, speed: 1.19 step/s\n",
      "global step 23310, epoch: 5, batch: 3590, loss: 0.2494,domain_loss: 0.0132 ,ce_loss: 0.3085., accu: 0.9233, speed: 1.19 step/s\n",
      "global step 23320, epoch: 5, batch: 3600, loss: 0.1515,domain_loss: 0.0651 ,ce_loss: 0.1731., accu: 0.9232, speed: 1.18 step/s\n",
      "global step 23330, epoch: 5, batch: 3610, loss: 0.1499,domain_loss: 0.0066 ,ce_loss: 0.1857., accu: 0.9229, speed: 1.19 step/s\n",
      "global step 23340, epoch: 5, batch: 3620, loss: 0.1313,domain_loss: 0.0033 ,ce_loss: 0.1632., accu: 0.9230, speed: 1.18 step/s\n",
      "global step 23350, epoch: 5, batch: 3630, loss: 0.1030,domain_loss: 0.0071 ,ce_loss: 0.1269., accu: 0.9225, speed: 1.20 step/s\n",
      "global step 23360, epoch: 5, batch: 3640, loss: 0.1277,domain_loss: 0.0171 ,ce_loss: 0.1554., accu: 0.9229, speed: 1.18 step/s\n",
      "global step 23370, epoch: 5, batch: 3650, loss: 0.1535,domain_loss: 0.0202 ,ce_loss: 0.1868., accu: 0.9226, speed: 1.17 step/s\n",
      "global step 23380, epoch: 5, batch: 3660, loss: 0.1531,domain_loss: 0.0071 ,ce_loss: 0.1896., accu: 0.9227, speed: 1.18 step/s\n",
      "global step 23390, epoch: 5, batch: 3670, loss: 0.1532,domain_loss: 0.0132 ,ce_loss: 0.1882., accu: 0.9232, speed: 1.18 step/s\n",
      "global step 23400, epoch: 5, batch: 3680, loss: 0.1004,domain_loss: 0.0012 ,ce_loss: 0.1252., accu: 0.9236, speed: 1.20 step/s\n",
      "2022-09-29 05:14:32,655\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 23400, epoch: 5, batch: 3680】，loss: 0.1004,domain_loss: 0.0012 ,ce_loss: 0.1252., accu: 0.9236,\n",
      "2022-09-29 05:14:32,960\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.059064, accuracy: 0.97[0.99],threshold:0.521, domain_acc:1.0,total_num:100\n",
      "2022-09-29 05:14:33,812\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 23410, epoch: 5, batch: 3690, loss: 0.1584,domain_loss: 0.0213 ,ce_loss: 0.1926., accu: 0.9195, speed: 1.06 step/s\n",
      "global step 23420, epoch: 5, batch: 3700, loss: 0.1771,domain_loss: 0.0056 ,ce_loss: 0.2200., accu: 0.9184, speed: 1.17 step/s\n",
      "global step 23430, epoch: 5, batch: 3710, loss: 0.2181,domain_loss: 0.0437 ,ce_loss: 0.2616., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 23440, epoch: 5, batch: 3720, loss: 0.1778,domain_loss: 0.0659 ,ce_loss: 0.2058., accu: 0.9264, speed: 1.19 step/s\n",
      "global step 23450, epoch: 5, batch: 3730, loss: 0.1215,domain_loss: 0.0024 ,ce_loss: 0.1513., accu: 0.9244, speed: 1.20 step/s\n",
      "global step 23460, epoch: 5, batch: 3740, loss: 0.1279,domain_loss: 0.0686 ,ce_loss: 0.1428., accu: 0.9243, speed: 1.18 step/s\n",
      "global step 23470, epoch: 5, batch: 3750, loss: 0.2042,domain_loss: 0.0307 ,ce_loss: 0.2476., accu: 0.9225, speed: 1.18 step/s\n",
      "global step 23480, epoch: 5, batch: 3760, loss: 0.1121,domain_loss: 0.0031 ,ce_loss: 0.1394., accu: 0.9233, speed: 1.18 step/s\n",
      "global step 23490, epoch: 5, batch: 3770, loss: 0.1459,domain_loss: 0.0094 ,ce_loss: 0.1800., accu: 0.9236, speed: 1.19 step/s\n",
      "global step 23500, epoch: 5, batch: 3780, loss: 0.1422,domain_loss: 0.0146 ,ce_loss: 0.1741., accu: 0.9231, speed: 1.20 step/s\n",
      "global step 23510, epoch: 5, batch: 3790, loss: 0.1044,domain_loss: 0.0306 ,ce_loss: 0.1229., accu: 0.9237, speed: 1.18 step/s\n",
      "global step 23520, epoch: 5, batch: 3800, loss: 0.1244,domain_loss: 0.0149 ,ce_loss: 0.1518., accu: 0.9241, speed: 1.18 step/s\n",
      "global step 23530, epoch: 5, batch: 3810, loss: 0.1765,domain_loss: 0.0098 ,ce_loss: 0.2182., accu: 0.9250, speed: 1.19 step/s\n",
      "global step 23540, epoch: 5, batch: 3820, loss: 0.1447,domain_loss: 0.0093 ,ce_loss: 0.1786., accu: 0.9252, speed: 1.19 step/s\n",
      "global step 23550, epoch: 5, batch: 3830, loss: 0.1016,domain_loss: 0.0140 ,ce_loss: 0.1235., accu: 0.9257, speed: 1.18 step/s\n",
      "global step 23560, epoch: 5, batch: 3840, loss: 0.1632,domain_loss: 0.0185 ,ce_loss: 0.1994., accu: 0.9255, speed: 1.18 step/s\n",
      "global step 23570, epoch: 5, batch: 3850, loss: 0.0986,domain_loss: 0.0145 ,ce_loss: 0.1196., accu: 0.9256, speed: 1.18 step/s\n",
      "global step 23580, epoch: 5, batch: 3860, loss: 0.1263,domain_loss: 0.0159 ,ce_loss: 0.1539., accu: 0.9255, speed: 1.18 step/s\n",
      "global step 23590, epoch: 5, batch: 3870, loss: 0.2017,domain_loss: 0.0108 ,ce_loss: 0.2494., accu: 0.9245, speed: 1.19 step/s\n",
      "global step 23600, epoch: 5, batch: 3880, loss: 0.2347,domain_loss: 0.0171 ,ce_loss: 0.2891., accu: 0.9237, speed: 1.18 step/s\n",
      "global step 23610, epoch: 5, batch: 3890, loss: 0.2410,domain_loss: 0.0881 ,ce_loss: 0.2792., accu: 0.9229, speed: 1.18 step/s\n",
      "global step 23620, epoch: 5, batch: 3900, loss: 0.1012,domain_loss: 0.0221 ,ce_loss: 0.1210., accu: 0.9235, speed: 1.17 step/s\n",
      "global step 23630, epoch: 5, batch: 3910, loss: 0.1877,domain_loss: 0.0173 ,ce_loss: 0.2302., accu: 0.9232, speed: 1.21 step/s\n",
      "global step 23640, epoch: 5, batch: 3920, loss: 0.1339,domain_loss: 0.0302 ,ce_loss: 0.1598., accu: 0.9231, speed: 1.19 step/s\n",
      "global step 23650, epoch: 5, batch: 3930, loss: 0.1295,domain_loss: 0.0389 ,ce_loss: 0.1521., accu: 0.9227, speed: 1.17 step/s\n",
      "global step 23660, epoch: 5, batch: 3940, loss: 0.1987,domain_loss: 0.0777 ,ce_loss: 0.2290., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 23670, epoch: 5, batch: 3950, loss: 0.1270,domain_loss: 0.0097 ,ce_loss: 0.1564., accu: 0.9238, speed: 1.19 step/s\n",
      "global step 23680, epoch: 5, batch: 3960, loss: 0.1545,domain_loss: 0.0079 ,ce_loss: 0.1911., accu: 0.9238, speed: 1.18 step/s\n",
      "global step 23690, epoch: 5, batch: 3970, loss: 0.1580,domain_loss: 0.0084 ,ce_loss: 0.1954., accu: 0.9242, speed: 1.19 step/s\n",
      "global step 23700, epoch: 5, batch: 3980, loss: 0.1838,domain_loss: 0.0107 ,ce_loss: 0.2270., accu: 0.9242, speed: 1.18 step/s\n",
      "2022-09-29 05:18:46,965\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 23700, epoch: 5, batch: 3980】，loss: 0.1838,domain_loss: 0.0107 ,ce_loss: 0.2270., accu: 0.9242,\n",
      "2022-09-29 05:18:48,728\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.05231, accuracy: 0.98[0.99],threshold:0.589, domain_acc:1.0,total_num:100\n",
      "global step 23710, epoch: 5, batch: 3990, loss: 0.1672,domain_loss: 0.0018 ,ce_loss: 0.2086., accu: 0.9102, speed: 0.92 step/s\n",
      "global step 23720, epoch: 5, batch: 4000, loss: 0.1323,domain_loss: 0.0056 ,ce_loss: 0.1639., accu: 0.9113, speed: 1.18 step/s\n",
      "global step 23730, epoch: 5, batch: 4010, loss: 0.2028,domain_loss: 0.0423 ,ce_loss: 0.2430., accu: 0.9164, speed: 1.19 step/s\n",
      "global step 23740, epoch: 5, batch: 4020, loss: 0.1611,domain_loss: 0.0545 ,ce_loss: 0.1877., accu: 0.9174, speed: 1.18 step/s\n",
      "global step 23750, epoch: 5, batch: 4030, loss: 0.1621,domain_loss: 0.0059 ,ce_loss: 0.2011., accu: 0.9186, speed: 1.18 step/s\n",
      "global step 23760, epoch: 5, batch: 4040, loss: 0.1783,domain_loss: 0.0254 ,ce_loss: 0.2165., accu: 0.9184, speed: 1.18 step/s\n",
      "global step 23770, epoch: 5, batch: 4050, loss: 0.1119,domain_loss: 0.0171 ,ce_loss: 0.1357., accu: 0.9196, speed: 1.18 step/s\n",
      "global step 23780, epoch: 5, batch: 4060, loss: 0.1871,domain_loss: 0.0042 ,ce_loss: 0.2328., accu: 0.9207, speed: 1.18 step/s\n",
      "global step 23790, epoch: 5, batch: 4070, loss: 0.1346,domain_loss: 0.0139 ,ce_loss: 0.1648., accu: 0.9204, speed: 1.17 step/s\n",
      "global step 23800, epoch: 5, batch: 4080, loss: 0.1753,domain_loss: 0.1238 ,ce_loss: 0.1882., accu: 0.9205, speed: 1.19 step/s\n",
      "global step 23810, epoch: 5, batch: 4090, loss: 0.1221,domain_loss: 0.0722 ,ce_loss: 0.1346., accu: 0.9213, speed: 1.18 step/s\n",
      "global step 23820, epoch: 5, batch: 4100, loss: 0.1307,domain_loss: 0.0020 ,ce_loss: 0.1629., accu: 0.9217, speed: 1.18 step/s\n",
      "global step 23830, epoch: 5, batch: 4110, loss: 0.1985,domain_loss: 0.0198 ,ce_loss: 0.2431., accu: 0.9218, speed: 1.20 step/s\n",
      "global step 23840, epoch: 5, batch: 4120, loss: 0.1107,domain_loss: 0.0062 ,ce_loss: 0.1368., accu: 0.9215, speed: 1.20 step/s\n",
      "global step 23850, epoch: 5, batch: 4130, loss: 0.1507,domain_loss: 0.0249 ,ce_loss: 0.1821., accu: 0.9217, speed: 1.18 step/s\n",
      "global step 23860, epoch: 5, batch: 4140, loss: 0.1238,domain_loss: 0.0047 ,ce_loss: 0.1536., accu: 0.9224, speed: 1.18 step/s\n",
      "global step 23870, epoch: 5, batch: 4150, loss: 0.1607,domain_loss: 0.0074 ,ce_loss: 0.1991., accu: 0.9224, speed: 1.19 step/s\n",
      "global step 23880, epoch: 5, batch: 4160, loss: 0.1312,domain_loss: 0.0109 ,ce_loss: 0.1613., accu: 0.9220, speed: 1.18 step/s\n",
      "global step 23890, epoch: 5, batch: 4170, loss: 0.1291,domain_loss: 0.0464 ,ce_loss: 0.1497., accu: 0.9225, speed: 1.18 step/s\n",
      "global step 23900, epoch: 5, batch: 4180, loss: 0.1647,domain_loss: 0.0148 ,ce_loss: 0.2022., accu: 0.9232, speed: 1.18 step/s\n",
      "global step 23910, epoch: 5, batch: 4190, loss: 0.1656,domain_loss: 0.0027 ,ce_loss: 0.2064., accu: 0.9230, speed: 1.19 step/s\n",
      "global step 23920, epoch: 5, batch: 4200, loss: 0.1278,domain_loss: 0.0212 ,ce_loss: 0.1544., accu: 0.9231, speed: 1.19 step/s\n",
      "global step 23930, epoch: 5, batch: 4210, loss: 0.1165,domain_loss: 0.0147 ,ce_loss: 0.1420., accu: 0.9228, speed: 1.19 step/s\n",
      "global step 23940, epoch: 5, batch: 4220, loss: 0.1345,domain_loss: 0.0083 ,ce_loss: 0.1661., accu: 0.9232, speed: 1.19 step/s\n",
      "global step 23950, epoch: 5, batch: 4230, loss: 0.1541,domain_loss: 0.0049 ,ce_loss: 0.1914., accu: 0.9231, speed: 1.19 step/s\n",
      "global step 23960, epoch: 5, batch: 4240, loss: 0.1508,domain_loss: 0.0228 ,ce_loss: 0.1827., accu: 0.9229, speed: 1.17 step/s\n",
      "global step 23970, epoch: 5, batch: 4250, loss: 0.1722,domain_loss: 0.0188 ,ce_loss: 0.2106., accu: 0.9225, speed: 1.19 step/s\n",
      "global step 23980, epoch: 5, batch: 4260, loss: 0.1675,domain_loss: 0.0029 ,ce_loss: 0.2086., accu: 0.9227, speed: 1.17 step/s\n",
      "global step 23990, epoch: 5, batch: 4270, loss: 0.1389,domain_loss: 0.0141 ,ce_loss: 0.1701., accu: 0.9226, speed: 1.20 step/s\n",
      "global step 24000, epoch: 5, batch: 4280, loss: 0.1004,domain_loss: 0.0168 ,ce_loss: 0.1213., accu: 0.9226, speed: 1.17 step/s\n",
      "2022-09-29 05:23:02,751\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 24000, epoch: 5, batch: 4280】，loss: 0.1004,domain_loss: 0.0168 ,ce_loss: 0.1213., accu: 0.9226,\n",
      "2022-09-29 05:23:03,052\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.056613, accuracy: 0.97[0.98],threshold:0.414, domain_acc:1.0,total_num:100\n",
      "2022-09-29 05:23:03,888\t[train.py-do_train_multitask]-[line:307]-INFO:save ckpt at this step!\n",
      "global step 24010, epoch: 5, batch: 4290, loss: 0.1516,domain_loss: 0.0130 ,ce_loss: 0.1862., accu: 0.9203, speed: 1.04 step/s\n",
      "global step 24020, epoch: 5, batch: 4300, loss: 0.1731,domain_loss: 0.0665 ,ce_loss: 0.1998., accu: 0.9238, speed: 1.19 step/s\n",
      "global step 24030, epoch: 5, batch: 4310, loss: 0.1318,domain_loss: 0.0102 ,ce_loss: 0.1622., accu: 0.9187, speed: 1.18 step/s\n",
      "global step 24040, epoch: 5, batch: 4320, loss: 0.1996,domain_loss: 0.0449 ,ce_loss: 0.2382., accu: 0.9217, speed: 1.17 step/s\n",
      "global step 24050, epoch: 5, batch: 4330, loss: 0.1456,domain_loss: 0.0344 ,ce_loss: 0.1734., accu: 0.9231, speed: 1.19 step/s\n",
      "global step 24060, epoch: 5, batch: 4340, loss: 0.1628,domain_loss: 0.0232 ,ce_loss: 0.1977., accu: 0.9224, speed: 1.18 step/s\n",
      "global step 24070, epoch: 5, batch: 4350, loss: 0.1495,domain_loss: 0.0506 ,ce_loss: 0.1742., accu: 0.9241, speed: 1.18 step/s\n",
      "global step 24080, epoch: 5, batch: 4360, loss: 0.1358,domain_loss: 0.0598 ,ce_loss: 0.1548., accu: 0.9234, speed: 1.17 step/s\n",
      "global step 24090, epoch: 5, batch: 4370, loss: 0.1474,domain_loss: 0.0050 ,ce_loss: 0.1830., accu: 0.9239, speed: 1.17 step/s\n",
      "global step 24100, epoch: 5, batch: 4380, loss: 0.1383,domain_loss: 0.0457 ,ce_loss: 0.1615., accu: 0.9224, speed: 1.21 step/s\n",
      "global step 24110, epoch: 5, batch: 4390, loss: 0.1278,domain_loss: 0.0591 ,ce_loss: 0.1450., accu: 0.9227, speed: 1.18 step/s\n",
      "global step 24120, epoch: 5, batch: 4400, loss: 0.1331,domain_loss: 0.0194 ,ce_loss: 0.1615., accu: 0.9225, speed: 1.19 step/s\n",
      "global step 24130, epoch: 5, batch: 4410, loss: 0.1444,domain_loss: 0.0055 ,ce_loss: 0.1792., accu: 0.9226, speed: 1.18 step/s\n",
      "global step 24140, epoch: 5, batch: 4420, loss: 0.2248,domain_loss: 0.0212 ,ce_loss: 0.2757., accu: 0.9224, speed: 1.18 step/s\n",
      "global step 24150, epoch: 5, batch: 4430, loss: 0.1830,domain_loss: 0.0146 ,ce_loss: 0.2251., accu: 0.9217, speed: 1.19 step/s\n",
      "global step 24160, epoch: 5, batch: 4440, loss: 0.1719,domain_loss: 0.0641 ,ce_loss: 0.1988., accu: 0.9218, speed: 1.18 step/s\n",
      "global step 24170, epoch: 5, batch: 4450, loss: 0.1061,domain_loss: 0.0028 ,ce_loss: 0.1320., accu: 0.9224, speed: 1.19 step/s\n",
      "global step 24180, epoch: 5, batch: 4460, loss: 0.1235,domain_loss: 0.0102 ,ce_loss: 0.1518., accu: 0.9227, speed: 1.18 step/s\n",
      "global step 24190, epoch: 5, batch: 4470, loss: 0.1266,domain_loss: 0.0017 ,ce_loss: 0.1579., accu: 0.9226, speed: 1.19 step/s\n",
      "global step 24200, epoch: 5, batch: 4480, loss: 0.1265,domain_loss: 0.0066 ,ce_loss: 0.1565., accu: 0.9227, speed: 1.20 step/s\n",
      "global step 24210, epoch: 5, batch: 4490, loss: 0.1148,domain_loss: 0.0063 ,ce_loss: 0.1419., accu: 0.9231, speed: 1.17 step/s\n",
      "global step 24220, epoch: 5, batch: 4500, loss: 0.1159,domain_loss: 0.0076 ,ce_loss: 0.1430., accu: 0.9236, speed: 1.17 step/s\n",
      "global step 24230, epoch: 5, batch: 4510, loss: 0.1300,domain_loss: 0.0243 ,ce_loss: 0.1564., accu: 0.9232, speed: 1.20 step/s\n",
      "global step 24240, epoch: 5, batch: 4520, loss: 0.1653,domain_loss: 0.0171 ,ce_loss: 0.2023., accu: 0.9230, speed: 1.18 step/s\n",
      "global step 24250, epoch: 5, batch: 4530, loss: 0.1588,domain_loss: 0.0059 ,ce_loss: 0.1971., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 24260, epoch: 5, batch: 4540, loss: 0.0897,domain_loss: 0.0112 ,ce_loss: 0.1093., accu: 0.9236, speed: 1.22 step/s\n",
      "global step 24270, epoch: 5, batch: 4550, loss: 0.1668,domain_loss: 0.0169 ,ce_loss: 0.2043., accu: 0.9234, speed: 1.18 step/s\n",
      "global step 24280, epoch: 5, batch: 4560, loss: 0.0823,domain_loss: 0.0046 ,ce_loss: 0.1017., accu: 0.9234, speed: 1.19 step/s\n",
      "global step 24290, epoch: 5, batch: 4570, loss: 0.1117,domain_loss: 0.0715 ,ce_loss: 0.1217., accu: 0.9232, speed: 1.17 step/s\n",
      "global step 24300, epoch: 5, batch: 4580, loss: 0.1717,domain_loss: 0.0051 ,ce_loss: 0.2133., accu: 0.9237, speed: 1.17 step/s\n",
      "2022-09-29 05:27:16,998\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 24300, epoch: 5, batch: 4580】，loss: 0.1717,domain_loss: 0.0051 ,ce_loss: 0.2133., accu: 0.9237,\n",
      "2022-09-29 05:27:17,304\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.056348, accuracy: 0.97[0.98],threshold:0.361, domain_acc:1.0,total_num:100\n",
      "global step 24310, epoch: 5, batch: 4590, loss: 0.1309,domain_loss: 0.0019 ,ce_loss: 0.1632., accu: 0.9203, speed: 1.06 step/s\n",
      "global step 24320, epoch: 5, batch: 4600, loss: 0.1770,domain_loss: 0.0241 ,ce_loss: 0.2152., accu: 0.9270, speed: 1.17 step/s\n",
      "global step 24330, epoch: 5, batch: 4610, loss: 0.1156,domain_loss: 0.0114 ,ce_loss: 0.1417., accu: 0.9247, speed: 1.20 step/s\n",
      "global step 24340, epoch: 5, batch: 4620, loss: 0.1635,domain_loss: 0.0243 ,ce_loss: 0.1983., accu: 0.9232, speed: 1.18 step/s\n",
      "global step 24350, epoch: 5, batch: 4630, loss: 0.1573,domain_loss: 0.0029 ,ce_loss: 0.1959., accu: 0.9230, speed: 1.19 step/s\n",
      "global step 24360, epoch: 5, batch: 4640, loss: 0.1534,domain_loss: 0.0357 ,ce_loss: 0.1828., accu: 0.9245, speed: 1.19 step/s\n",
      "global step 24370, epoch: 5, batch: 4650, loss: 0.1665,domain_loss: 0.0239 ,ce_loss: 0.2022., accu: 0.9251, speed: 1.17 step/s\n",
      "global step 24380, epoch: 5, batch: 4660, loss: 0.1478,domain_loss: 0.0300 ,ce_loss: 0.1773., accu: 0.9259, speed: 1.19 step/s\n",
      "global step 24390, epoch: 5, batch: 4670, loss: 0.0989,domain_loss: 0.0099 ,ce_loss: 0.1212., accu: 0.9250, speed: 1.17 step/s\n",
      "global step 24400, epoch: 5, batch: 4680, loss: 0.1415,domain_loss: 0.0022 ,ce_loss: 0.1763., accu: 0.9243, speed: 1.17 step/s\n",
      "global step 24410, epoch: 5, batch: 4690, loss: 0.1203,domain_loss: 0.0072 ,ce_loss: 0.1485., accu: 0.9238, speed: 1.18 step/s\n",
      "global step 24420, epoch: 5, batch: 4700, loss: 0.1913,domain_loss: 0.0023 ,ce_loss: 0.2385., accu: 0.9247, speed: 1.23 step/s\n",
      "global step 24430, epoch: 5, batch: 4710, loss: 0.1718,domain_loss: 0.0267 ,ce_loss: 0.2080., accu: 0.9248, speed: 1.17 step/s\n",
      "global step 24440, epoch: 5, batch: 4720, loss: 0.1410,domain_loss: 0.0109 ,ce_loss: 0.1735., accu: 0.9252, speed: 1.18 step/s\n",
      "global step 24450, epoch: 5, batch: 4730, loss: 0.1410,domain_loss: 0.0166 ,ce_loss: 0.1721., accu: 0.9249, speed: 1.18 step/s\n",
      "global step 24460, epoch: 5, batch: 4740, loss: 0.1500,domain_loss: 0.0161 ,ce_loss: 0.1835., accu: 0.9241, speed: 1.18 step/s\n",
      "global step 24470, epoch: 5, batch: 4750, loss: 0.1789,domain_loss: 0.0168 ,ce_loss: 0.2194., accu: 0.9245, speed: 1.20 step/s\n",
      "global step 24480, epoch: 5, batch: 4760, loss: 0.1714,domain_loss: 0.0101 ,ce_loss: 0.2117., accu: 0.9245, speed: 1.18 step/s\n",
      "global step 24490, epoch: 5, batch: 4770, loss: 0.1694,domain_loss: 0.0265 ,ce_loss: 0.2051., accu: 0.9248, speed: 1.18 step/s\n",
      "global step 24500, epoch: 5, batch: 4780, loss: 0.1186,domain_loss: 0.0334 ,ce_loss: 0.1399., accu: 0.9253, speed: 1.17 step/s\n",
      "global step 24510, epoch: 5, batch: 4790, loss: 0.1567,domain_loss: 0.0183 ,ce_loss: 0.1913., accu: 0.9252, speed: 1.18 step/s\n",
      "global step 24520, epoch: 5, batch: 4800, loss: 0.1296,domain_loss: 0.0141 ,ce_loss: 0.1585., accu: 0.9252, speed: 1.18 step/s\n",
      "global step 24530, epoch: 5, batch: 4810, loss: 0.0971,domain_loss: 0.0048 ,ce_loss: 0.1202., accu: 0.9247, speed: 1.19 step/s\n",
      "global step 24540, epoch: 5, batch: 4820, loss: 0.1845,domain_loss: 0.0279 ,ce_loss: 0.2236., accu: 0.9251, speed: 1.21 step/s\n",
      "global step 24550, epoch: 5, batch: 4830, loss: 0.1678,domain_loss: 0.0541 ,ce_loss: 0.1963., accu: 0.9249, speed: 1.20 step/s\n",
      "global step 24560, epoch: 5, batch: 4840, loss: 0.1837,domain_loss: 0.0156 ,ce_loss: 0.2258., accu: 0.9247, speed: 1.18 step/s\n",
      "global step 24570, epoch: 5, batch: 4850, loss: 0.1423,domain_loss: 0.0129 ,ce_loss: 0.1747., accu: 0.9242, speed: 1.19 step/s\n",
      "global step 24580, epoch: 5, batch: 4860, loss: 0.1325,domain_loss: 0.0151 ,ce_loss: 0.1619., accu: 0.9242, speed: 1.18 step/s\n",
      "global step 24590, epoch: 5, batch: 4870, loss: 0.2777,domain_loss: 0.0739 ,ce_loss: 0.3287., accu: 0.9244, speed: 1.20 step/s\n",
      "global step 24600, epoch: 5, batch: 4880, loss: 0.0926,domain_loss: 0.0077 ,ce_loss: 0.1138., accu: 0.9246, speed: 1.18 step/s\n",
      "2022-09-29 05:31:30,913\t[train.py-do_train_multitask]-[line:288]-INFO:【global step 24600, epoch: 5, batch: 4880】，loss: 0.0926,domain_loss: 0.0077 ,ce_loss: 0.1138., accu: 0.9246,\n",
      "2022-09-29 05:31:31,221\t[train.py-evaluate_multitask]-[line:105]-INFO:dev_loss: 0.062269, accuracy: 0.97[0.99],threshold:0.561, domain_acc:1.0,total_num:100\n",
      "global step 24610, epoch: 5, batch: 4890, loss: 0.2346,domain_loss: 0.0831 ,ce_loss: 0.2725., accu: 0.9297, speed: 1.04 step/s\n",
      "global step 24620, epoch: 5, batch: 4900, loss: 0.1340,domain_loss: 0.0297 ,ce_loss: 0.1601., accu: 0.9297, speed: 1.19 step/s\n",
      "global step 24630, epoch: 5, batch: 4910, loss: 0.1743,domain_loss: 0.0094 ,ce_loss: 0.2155., accu: 0.9268, speed: 1.18 step/s\n",
      "global step 24640, epoch: 5, batch: 4920, loss: 0.2152,domain_loss: 0.0030 ,ce_loss: 0.2682., accu: 0.9281, speed: 1.21 step/s\n",
      "global step 24650, epoch: 5, batch: 4930, loss: 0.1882,domain_loss: 0.0084 ,ce_loss: 0.2331., accu: 0.9282, speed: 1.30 step/s\n",
      "100%|█████████████████████████████████████████| 5/5 [5:48:40<00:00, 4184.00s/it]\n",
      "2022-09-29 05:32:14,164\t[train.py-do_train_multitask]-[line:318]-INFO:BEST SCORE ACC: 0.98 \n"
     ]
    }
   ],
   "source": [
    "!python run_multitask.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0929 09:37:00.523996  7443 analysis_predictor.cc:1736] Deprecated. Please use CreatePredictor instead.\n",
      "\u001b[32m[2022-09-29 09:37:00,745] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-09-29 09:37:00,755] [    INFO]\u001b[0m - tokenizer config file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-09-29 09:37:00,755] [    INFO]\u001b[0m - Special tokens file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2022-09-29 09:37:00,755] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\u001b[0m\n",
      "init data set ,lac feat!\n",
      "预测中:   0%|                                             | 0/1 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.636 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "[0.00990793 0.25917116 0.8570032  ... 0.88855815 0.06058262 0.02775844]\n",
      "预测中: 100%|█████████████████████████████████████| 1/1 [00:46<00:00, 46.67s/it]\n",
      "init data set ,lac feat!\n",
      "预测中:   0%|                                             | 0/1 [00:00<?, ?it/s][0.01024498 0.27767438 0.8529127  ... 0.886362   0.08628369 0.03122196]\n",
      "预测中: 100%|█████████████████████████████████████| 1/1 [00:42<00:00, 42.77s/it]\n",
      "####################################1.概率融合####################################\n",
      "阈值划分 0.3\n",
      "总计正样本数： 17693\n",
      "####################################2.投票融合####################################\n",
      "各模型预测个数分别为：\n",
      "17676\n",
      "票数：1\n",
      "总计正样本数： 0\n"
     ]
    }
   ],
   "source": [
    "!python infer_att_cv.py --model_name attention_fgm --input_file  ./data_new/cuted_testB.csv --result_file ../prediction_result/attention_fgm_tta --threshold 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W0929 11:17:38.832425 14746 analysis_predictor.cc:1736] Deprecated. Please use CreatePredictor instead.\n",
      "\u001b[32m[2022-09-29 11:17:39,048] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/vocab.txt\u001b[0m\n",
      "\u001b[32m[2022-09-29 11:17:39,058] [    INFO]\u001b[0m - tokenizer config file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/tokenizer_config.json\u001b[0m\n",
      "\u001b[32m[2022-09-29 11:17:39,058] [    INFO]\u001b[0m - Special tokens file saved in /home/chelinwei/.paddlenlp/models/ernie-gram-zh/special_tokens_map.json\u001b[0m\n",
      "\u001b[32m[2022-09-29 11:17:39,058] [    INFO]\u001b[0m - Already cached /home/chelinwei/.paddlenlp/models/ernie-gram-zh/ernie_gram_zh.pdparams\u001b[0m\n",
      "init data set ,lac feat!\n",
      "预测中:   0%|                                             | 0/6 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.634 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "预测中: 100%|█████████████████████████████████████| 6/6 [04:23<00:00, 43.90s/it]\n",
      "init data set ,lac feat!\n",
      "预测中: 100%|█████████████████████████████████████| 6/6 [04:20<00:00, 43.47s/it]\n",
      "####################################1.概率融合####################################\n",
      "阈值划分 0.5\n",
      "总计正样本数： 16739\n",
      "🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕 read test data: ../data/test_A.tsv \n",
      "规则处理ing: 100%|█████████████████████| 50000/50000 [00:01<00:00, 25729.97it/s]\n",
      "566\n",
      "纠正后正样本数： 17305\n",
      "####################################2.投票融合####################################\n",
      "各模型预测个数分别为：\n",
      "17126\n",
      "17202\n",
      "14107\n",
      "17260\n",
      "17285\n",
      "17291\n",
      "17181\n",
      "17176\n",
      "14142\n",
      "17297\n",
      "17293\n",
      "17298\n",
      "票数：6\n",
      "总计正样本数： 16940\n",
      "🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕🐕 read test data: ../data/test_A.tsv \n",
      "规则处理ing: 100%|█████████████████████| 50000/50000 [00:01<00:00, 25890.72it/s]\n",
      "560\n",
      "纠正后正样本数： 17500\n"
     ]
    }
   ],
   "source": [
    "!python infer_multitask.py --model_name  mutitask --input_file  ./data_new/cuted_testB.csv --result_file ../prediction_result/mutitask --threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data =pd.read_csv('/data/students/CHE/matching2021/prediction_result/submission_B_1122.csv')\n",
    "np.save('/data/students/CHE/matching2021/prediction_result/sub_id_B_nezha-large_0.519.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 5 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "100%|██████████████████████████████████| 50000/50000 [00:03<00:00, 14424.93it/s]\n",
      "100%|██████████████████████████████████| 50000/50000 [00:02<00:00, 16962.85it/s]\n",
      "16343\n",
      "post2.py:398: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  find = df[(df.text_a.str.contains(text_a) &\n",
      "重庆至杭州特价机票\t杭州至重庆特价机票\t0.48510491847991943\t1\n",
      "济南到成都高铁票\t成都到济南高铁票\t0.18308979272842407\t1\n",
      "枣庄到黄山高铁时刻表\t黄山到枣庄高铁时刻表\t0.6244474649429321\t1\n",
      "深圳飞金边的航班时刻表\t金边飞深圳的航班时刻表\t0.13024212419986725\t1\n",
      "许昌至万州火车票\t万州至许昌火车票\t0.6652865409851074\t1\n",
      "商丘到廊坊的火车票\t廊坊到商丘的火车票\t0.21551594138145447\t1\n",
      "台北至成都航班时刻表\t成都至台北航班时刻表\t0.45054304599761963\t1\n",
      "长兴至商丘火车时刻表\t商丘至长兴火车时刻表\t0.6316533088684082\t1\n",
      "扬州到重庆飞机时刻表\t重庆到扬州飞机时刻表\t0.16469725966453552\t1\n",
      "本溪到敦化高铁时刻表\t敦化到本溪高铁时刻表\t0.49777135252952576\t1\n",
      "post2.py:405: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df.loc[(df.text_a.str.contains(text_a) &\n",
      "c1 : 【负样本：15 正样本:10 change 【10】 to 0   gate: 0.05】\n",
      "post2.py:400: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df.operation.str.contains(operation) &\n",
      "龙眼和荔枝哪个好吃\t荔枝和龙眼哪个好吃\t0.9412206411361694\t0\n",
      "线索是内容上还是结构上\t线索是结构上还是内容上\t0.928273618221283\t0\n",
      "海绵宝宝住的是菠萝还是凤梨\t海绵宝宝住的是凤梨还是菠萝\t0.9031844735145569\t0\n",
      "鼻咽癌与鼻咽炎的区别\t鼻咽炎与鼻咽癌的区别\t0.9279448986053467\t0\n",
      "宗旨和目的的区别\t目的和宗旨的区别\t0.8929026126861572\t0\n",
      "姓氏重要还是户口重要\t户口重要还是姓氏重要\t0.9398077726364136\t0\n",
      "铂金贵还是黄金贵\t黄金贵还是铂金贵\t0.8812614679336548\t0\n",
      "豆腐和鸡蛋的家常做法\t鸡蛋和豆腐的家常做法\t0.8917336463928223\t0\n",
      "接口与抽象类有什么区别\t抽象类与接口有什么区别\t0.9415016174316406\t0\n",
      "社保跟五险有区别吗\t五险跟社保有区别吗\t0.9375925064086914\t0\n",
      "西瓜和梨可以一起吃吗\t梨和西瓜可以一起吃吗\t0.8792926073074341\t0\n",
      "太阳和彩虹的位置\t彩虹和太阳的位置\t0.9193541407585144\t0\n",
      "助人为乐的高尚品格还是风格\t助人为乐的高尚风格还是品格\t0.9214881658554077\t0\n",
      "氨气和过量氯气反应\t氯气和过量氨气反应\t0.7520279884338379\t0\n",
      "颈椎和腰椎不好怎么办\t腰椎和颈椎不好怎么办\t0.9312431812286377\t0\n",
      "咽炎和咽喉炎的区别\t咽喉炎和咽炎的区别\t0.8910401463508606\t0\n",
      "阴虚与阳虚怎么区分\t阳虚与阴虚怎么区分\t0.9429738521575928\t0\n",
      "西红柿是水果还是蔬菜\t西红柿是蔬菜还是水果\t0.9324128031730652\t0\n",
      "直发和卷发哪个是显性基因\t卷发和直发哪个是显性基因\t0.9434934854507446\t0\n",
      "黄瓜能和茭白一起炒吗\t茭白能和黄瓜一起炒吗\t0.8891854286193848\t0\n",
      "西梅的功效与作用\t西梅的作用与功效\t0.9348453283309937\t0\n",
      "工作重要还是朋友重要\t朋友重要还是工作重要\t0.9045319557189941\t0\n",
      "分公司和子公司有什么区别\t子公司和分公司有什么区别\t0.900749921798706\t0\n",
      "大气压与温度关系\t温度与大气压关系\t0.9135810136795044\t0\n",
      "太阳与火星的距离是多少\t火星与太阳的距离是多少\t0.8152533769607544\t0\n",
      "电脑和电磁炉哪个辐射大\t电磁炉和电脑哪个辐射大\t0.9414846301078796\t0\n",
      "荷叶的功效与作用\t荷叶的作用与功效\t0.9261089563369751\t0\n",
      "葡萄干的功效及作用\t葡萄干的作用及功效\t0.9325313568115234\t0\n",
      "花生跟牛肉可以一起吃吗\t牛肉跟花生可以一起吃吗\t0.8896774053573608\t0\n",
      "长方形的面积和周长有什么规律\t长方形的周长和面积有什么规律\t0.8644469380378723\t0\n",
      "学舞蹈好还是学音乐好\t学音乐好还是学舞蹈好\t0.910592794418335\t0\n",
      "藕是荷花的根还是茎\t藕是荷花的茎还是根\t0.9179133176803589\t0\n",
      "氨纶和锦纶的优缺点\t锦纶和氨纶的优缺点\t0.919554591178894\t0\n",
      "红糖的功效与作用\t红糖的作用与功效\t0.9345113039016724\t0\n",
      "白萝卜可以和芝麻一起吃吗\t芝麻可以和白萝卜一起吃吗\t0.8796130418777466\t0\n",
      "老奸巨猾是褒义词还是贬义词\t老奸巨猾是贬义词还是褒义词\t0.9067384004592896\t0\n",
      "猪肝能和西红柿一起吃吗\t西红柿能和猪肝一起吃吗\t0.8690668344497681\t0\n",
      "决明子的功效与作用\t决明子的作用与功效\t0.9234949350357056\t0\n",
      "热量和光照有什么区别\t光照和热量有什么区别\t0.9698231220245361\t0\n",
      "乳胶和凝胶床垫哪个好\t凝胶和乳胶床垫哪个好\t0.853529691696167\t0\n",
      "阳历和阴历的区别\t阴历和阳历的区别\t0.9414399862289429\t0\n",
      "求阴影部分周长和面积\t求阴影部分面积和周长\t0.8999989032745361\t0\n",
      "玫瑰是草本植物还是木本\t玫瑰是木本还是草本植物\t0.9595643281936646\t0\n",
      "宇宙大还是黑洞大?\t黑洞大还是宇宙大?\t0.9528487920761108\t0\n",
      "交组词和拼音怎么写\t交拼音和组词怎么写\t0.9187157154083252\t0\n",
      "花甲和豆腐能一起吃吗\t豆腐和花甲能一起吃吗\t0.9112803936004639\t0\n",
      "西瓜能和奶一起吃吗\t奶能和西瓜一起吃吗\t0.8859973549842834\t0\n",
      "虾可以跟花生米一起吃吗\t花生米可以跟虾一起吃吗\t0.8504857420921326\t0\n",
      "客服与客户之间的对话\t客户与客服之间的对话\t0.6810824871063232\t0\n",
      "狗肉可以和西瓜一起吃吗\t西瓜可以和狗肉一起吃吗\t0.8715764284133911\t0\n",
      "牛奶是碱性还是酸性\t牛奶是酸性还是碱性\t0.9330863952636719\t0\n",
      "女人阳虚和阴虚的区别\t女人阴虚和阳虚的区别\t0.9321370124816895\t0\n",
      "银杏果的功效与作用\t银杏果的作用与功效\t0.9083963632583618\t0\n",
      "山竹可以和榴莲一起吃吗?\t榴莲可以和山竹一起吃吗?\t0.8883267641067505\t0\n",
      "酒精呈酸性还是碱性\t酒精呈碱性还是酸性\t0.9465850591659546\t0\n",
      "柚子的功效与作用\t柚子的作用与功效\t0.9305605888366699\t0\n",
      "丹参的功效与作用\t丹参的作用与功效\t0.9175030589103699\t0\n",
      "怎么区分胃炎和肠炎\t怎么区分肠炎和胃炎\t0.9655853509902954\t0\n",
      "抛物线准线和焦点的关系\t抛物线焦点和准线的关系\t0.8556814789772034\t0\n",
      "属羊和属马婚姻相配吗\t属马和属羊婚姻相配吗\t0.3857315182685852\t0\n",
      "属马和属鼠的能结婚吗\t属鼠和属马的能结婚吗\t0.6400855779647827\t0\n",
      "侄女和大伯是什么关系\t大伯和侄女是什么关系\t0.9275729656219482\t0\n",
      "post2.py:407: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (df.operation.str.contains(operation) &\n",
      "c2 : 【负样本：62 正样本:34 change 【62】 to 1   gate: 0.05】\n",
      "金阳县到西昌有多少公里\t西昌到金阳县有多少公里\t0.2234114110469818\t0\n",
      "张店到新泰多少公里\t新泰到张店多少公里\t0.6050264835357666\t0\n",
      "宜春到金溪多少公里\t金溪到宜春多少公里\t0.21903786063194275\t0\n",
      "临朐到沂水多少公里\t沂水到临朐多少公里\t0.3595360219478607\t0\n",
      "青州到梁山多少公里\t梁山到青州多少公里\t0.3868892192840576\t0\n",
      "丽江到昭通多少公里\t昭通到丽江多少公里\t0.35903483629226685\t0\n",
      "新县到许昌有多少公里\t许昌到新县有多少公里\t0.4884411096572876\t0\n",
      "抚州到金溪有多少公里\t金溪到抚州有多少公里\t0.24676057696342468\t0\n",
      "北京到武汉高铁多久\t武汉到北京高铁多久\t0.11079524457454681\t0\n",
      "乌鲁木齐离塔城多远\t塔城离乌鲁木齐多远\t0.6747057437896729\t0\n",
      "南宁到湖州快递要多久\t湖州到南宁快递要多久\t0.12089228630065918\t0\n",
      "西安到洋县多少公里\t洋县到西安多少公里\t0.18267682194709778\t0\n",
      "韶关到新丰有多少公里\t新丰到韶关有多少公里\t0.25340884923934937\t0\n",
      "襄阳到武汉开车多久\t武汉到襄阳开车多久\t0.31589198112487793\t0\n",
      "宝鸡到云南多少公里\t云南到宝鸡多少公里\t0.11723558604717255\t0\n",
      "丹霞山到韶关多少公里\t韶关到丹霞山多少公里\t0.23151688277721405\t0\n",
      "铁岭到沈阳多久\t沈阳到铁岭多久\t0.25256961584091187\t0\n",
      "郑州西站离荥阳有多远\t荥阳离郑州西站有多远\t0.7454274892807007\t0\n",
      "商丘到延安有多少公里\t延安到商丘有多少公里\t0.23084940016269684\t0\n",
      "c3 : 【负样本：19 正样本:11 change 【19】 to 1   gate: 0.05】\n",
      "浅蓝色裤子配什么颜色的衣服\t浅蓝色衣服配什么颜色的裤子\t0.07046478986740112\t1\n",
      "淡蓝色短袖配什么裤子\t淡蓝色裤子配什么短袖\t0.09576192498207092\t1\n",
      "c4 : 【负样本：5 正样本:2 change 【2】 to 0   gate: 0.05】\n",
      "剖腹产比顺产好吗\t顺产比剖腹产好吗\t0.8694162368774414\t1\n",
      "c5 : 【负样本：3 正样本:1 change 【1】 to 0   gate: 0.05】\n",
      "c6 : 【负样本：4 正样本:0 change 【0】 to 0   gate: 0.05】\n",
      "南阳到焦作的火车时刻表查询\t焦作到南阳的火车时刻表查询\t0.4139825105667114\t1\n",
      "沁阳到郑州汽车时刻表/汽车票查询\t郑州到沁阳汽车时刻表/汽车票查询\t0.08086417615413666\t1\n",
      "九江到株洲火车时刻表查询\t株洲到九江火车时刻表查询\t0.2980629801750183\t1\n",
      "c7 : 【负样本：26 正样本:3 change 【3】 to 0   gate: 0.05】\n",
      "地球离太阳有多远\t太阳离地球有多远\t0.791299045085907\t0\n",
      "南伞到云县有多少公里\t云县到南伞有多少公里\t0.42676734924316406\t0\n",
      "c8 : 【负样本：2 正样本:21 change 【2】 to 1   gate: 0.05】\n",
      "swap 处理完毕！\n",
      "16406\n",
      "post2.py:507: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  change_index_120 = (data.operation_c.str.contains('insert:(啤|带有|的形状|唐|宋)'))\n",
      "['月经最后一天可以喝啤酒吗', '月经最后一天可以喝酒吗', 1, 'insert:啤']\n",
      "['带有鸳鸯的诗句', '鸳鸯的诗句', 1, 'insert:带有']\n",
      "['黄连上清丸能喝啤酒吗', '黄连上清丸能喝酒吗', 1, 'insert:啤']\n",
      "['橡皮怎么描述', '橡皮的形状怎么描述', 1, 'insert:的形状']\n",
      "post2.py:513: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  change_index_021 = (data.operation_c.str.contains('insert:(多远)') & (~data.text_a.str.contains('到')))\n",
      "['西安距离重庆多远', '西安距离重庆', 0, 'insert:多远']\n",
      "['廊坊离北京多远距离', '廊坊离北京距离', 0, 'insert:多远']\n",
      "insert 处理完毕！\n",
      "16404\n",
      "融合前： 16404\n",
      "中性二字网名\t中性2字网名\t0\treplace:二(数量词)替换为2(数量词)，他们的关系是其他\n",
      "2020年5月suv汽车销量\t2020年五月suv汽车销量\t0\tother\n",
      "四个月的宝宝才11斤\t4个月的宝宝才11斤\t0\tother\n",
      "二指灵敏度无陀螺仪\t2指灵敏度无陀螺仪\t0\treplace:二(数量词)替换为2(数量词)，他们的关系是其他\n",
      "咖啡能加红茶吗\t咖啡能加红茶吗\t0\tother\n",
      "打4价疫苗之前注意事项\t打四价疫苗之前注意事项\t0\treplace:4价(数量词)替换为四价(普通名词)，他们的关系是其他\n",
      "a加b的六次方\ta加b的6次方\t0\treplace:六次方(普通名词)替换为6次方(数量词)，他们的关系是其他\n",
      "二手车保值率排行\t2手车保值率排行\t0\tother\n",
      "背诵有什么好处\t背诵有什么好处\t0\tother\n",
      "6月黄道吉日\t六月黄道吉日\t0\treplace:6月(时间)替换为六月(时间)，他们的关系是其他\n",
      "孕7月躺下呼吸困难\t孕七月躺下呼吸困难\t0\tother\n",
      "五万兆流量等于多少G\t5万兆流量等于多少G\t0\tother\n",
      "10到30之间的合数\t10到30之间的合数\t0\tother\n",
      "一繁体字是什么样的\t1繁体字是什么样的\t0\treplace:一(数量词)替换为1(数量词)，他们的关系是其他\n",
      "小米八换个内屏要多少钱\t小米8换个内屏要多少钱\t0\treplace:小米八(其他专名)替换为小米8(其他专名)，他们的关系是其他\n",
      "1砖多少金\t一砖多少金\t0\tother\n",
      "小米九后盖怎么拆\t小米9后盖怎么拆\t0\treplace:九(数量词)替换为9(数量词)，他们的关系是其他\n",
      "属蛇7月出生好不好\t属蛇七月出生好不好\t0\tother\n",
      "三个字的游戏名字情侣\t3个字的游戏名字情侣\t0\tother\n",
      "oppoa5支持全局吗\toppoa五支持全局吗\t0\treplace:oppoa5(其他专名)替换为oppoa五(数量词)，他们的关系是其他\n",
      "苹果八plus怎么样\t苹果8plus怎么样\t0\tother\n",
      "1毫巴等于多少帕斯卡\t一毫巴等于多少帕斯卡\t0\tother\n",
      "优酷会员首3月6元是什么意思\t优酷会员首三月6元是什么意思\t0\treplace:优酷会员首3月6元是什么意思(作品名)替换为优酷会员首三月6元是什么意思(作品名)，他们的关系是其他\n",
      "小数有哪3部分组成\t小数有哪三部分组成\t0\tother\n",
      "3月是什么节气\t三月是什么节气\t0\treplace:3月(时间)替换为三月(时间)，他们的关系是其他\n",
      "战地二为什么被禁\t战地2为什么被禁\t0\tother\n",
      "一分米长的物体有什么\t1分米长的物体有什么\t0\tother\n",
      "1995年农历8月初3是什么星座\t1995年农历8月初三是什么星座\t0\tother\n",
      "中国前十大上市公司\t中国前十大上市公司\t0\tother\n",
      "一茶匙是多少毫升\t1茶匙是多少毫升\t0\tother\n",
      "1港币等于多少人民币\t一港币等于多少人民币\t0\treplace:1(数量词)替换为一(数量词)，他们的关系是其他\n",
      "广西有那些好的大专\t广西有那些好的大专\t0\tother\n",
      "1平方等于多少吨\t一平方等于多少吨\t0\treplace:1平方(数量词)替换为一平方(数量词)，他们的关系是其他\n",
      "正当防卫四手机版怎么下\t正当防卫4手机版怎么下\t0\tother\n",
      "田字格二字怎么写\t田字格2字怎么写\t0\treplace:二(数量词)替换为2(数量词)，他们的关系是其他\n",
      "加七等于多少\t加7等于多少\t0\tother\n",
      "老式显微镜有收藏的吗\t老式显微镜有收藏的吗\t0\tother\n",
      "1994年10月初8是什么命\t1994年10月初八是什么命\t0\tother\n",
      "冰雪奇缘二所有的歌曲\t冰雪奇缘2所有的歌曲\t0\tother\n",
      "生化危机二重制版千斤顶在哪\t生化危机2重制版千斤顶在哪\t0\tother\n",
      "十月份属什么\t十月份属于什么\t0\treplace:属(普通动词)替换为属于(普通动词)，他们的关系是同义词\n",
      "高粱成熟了拟人句\t高粱熟了拟人句\t0\treplace:成熟(形容词)替换为熟(形容词)，他们的关系是同义词\n",
      "怀孕前肚子会不会痛\t怀孕前肚子会不会疼\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "医用酒精能灭真菌吗\t医用酒精能消灭真菌吗\t0\treplace:灭(普通动词)替换为消灭(普通动词)，他们的关系是同义词\n",
      "王勃最有名的诗句\t王勃最有名的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "梦见别人打电话给我\t梦别人打电话给我\t0\treplace:梦见(普通动词)替换为梦(普通名词)，他们的关系是同义词\n",
      "描写海底的成语\t形容海底的成语\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "赞兰花的诗句\t赞兰花的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "肝功能异常如何治疗\t肝功能不正常如何治疗\t0\treplace:异常(副词)替换为不正常(副词)，他们的关系是同义词\n",
      "小猫喝酸奶拉肚子怎么办\t小猫喝酸奶拉稀怎么办\t0\treplace:拉肚子(普通动词)替换为拉稀(普通动词)，他们的关系是同义词\n",
      "关掉照相机\t关掉相机\t0\treplace:照相机(普通名词)替换为相机(普通名词)，他们的关系是同义词\n",
      "家里无线网信号太弱怎么办\t家里无线网信号太差怎么办\t0\treplace:弱(形容词)替换为差(形容词)，他们的关系是同义词\n",
      "有什么不对\t有啥不对\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "床上有跳蚤怎么灭\t床上有跳蚤怎么除\t0\treplace:灭(普通动词)替换为除(普通动词)，他们的关系是同义词\n",
      "水变成水蒸气是什么变化\t水变成蒸汽是什么变化\t0\treplace:水蒸气(普通名词)替换为蒸汽(普通名词)，他们的关系是同义词\n",
      "谁是被害人在线观看\t谁是被害者在线观看\t0\treplace:被害人(普通名词)替换为被害者(普通名词)，他们的关系是同义词\n",
      "你认得杨紫吗\t你认识杨紫吗\t0\treplace:认得(普通动词)替换为认识(普通动词)，他们的关系是同义词\n",
      "身体受风了怎么排出去\t身体受风了怎么排出来\t0\treplace:出去(普通动词)替换为出来(普通动词)，他们的关系是同义词\n",
      "脸形胖的适合什么发型\t脸型胖的适合什么发型\t0\treplace:脸形(普通名词)替换为脸型(普通名词)，他们的关系是同义词\n",
      "职工考核细则\t员工考核细则\t0\treplace:职工(普通名词)替换为员工(普通名词)，他们的关系是同义词\n",
      "表达建功立业的诗句\t表达建功立业的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "怎么用卡纸叠钱包\t怎么用卡纸折钱包\t0\treplace:叠(普通动词)替换为折(普通动词)，他们的关系是同义词\n",
      "你吃什么呢\t你吃啥呢\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "ps怎么转换图片格式\tps怎么换图片格式\t0\treplace:转换(普通动词)替换为换(普通动词)，他们的关系是同义词\n",
      "时区怎么划分的\t时区怎么分的\t0\treplace:划分(普通动词)替换为分(普通动词)，他们的关系是同义词\n",
      "对肺有好处的穴位\t对肺部有好处的穴位\t0\treplace:肺(普通名词)替换为肺部(普通名词)，他们的关系是同义词\n",
      "动森服饰代码\t动森服装代码\t0\treplace:服饰(普通名词)替换为服装(普通名词)，他们的关系是同义词\n",
      "孕妇感到热\t怀孕感到热\t0\treplace:孕妇(普通名词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "小米如何改变图标大小\t小米如何改图标大小\t0\treplace:改变(普通动词)替换为改(普通动词)，他们的关系是同义词\n",
      "猪腰花是哪个部位\t猪腰子是哪个部位\t0\treplace:猪腰花(其他专名)替换为猪腰子(普通名词)，他们的关系是同义词\n",
      "招聘的网址\t招工的网址\t0\treplace:招聘(普通动词)替换为招工(普通动词)，他们的关系是同义词\n",
      "牙龈出血肝\t牙龈出血肝脏\t0\treplace:肝(普通名词)替换为肝脏(普通名词)，他们的关系是同义词\n",
      "牛皮鞋分类\t牛皮鞋种类\t0\treplace:分类(普通动词)替换为种类(普通名词)，他们的关系是同义词\n",
      "食道癌会干咳吗\t食道癌会咳嗽吗\t0\treplace:干咳(普通动词)替换为咳嗽(普通动词)，他们的关系是同义词\n",
      "二叉树类型\t二叉树种类\t0\treplace:类型(普通名词)替换为种类(普通名词)，他们的关系是同义词\n",
      "小朋友骗人怎么办\t小孩骗人怎么办\t0\treplace:小朋友(普通名词)替换为小孩(普通名词)，他们的关系是同义词\n",
      "火罐多久拔一次比较好\t拔罐多久拔一次比较好\t0\treplace:火罐(普通名词)替换为拔罐(普通动词)，他们的关系是同义词\n",
      "播放李荣浩的歌\t播放李荣浩的歌曲\t0\treplace:歌(普通名词)替换为歌曲(普通名词)，他们的关系是同义词\n",
      "孕30周sd值多少正常\t怀孕30周sd值多少正常\t0\treplace:孕(普通动词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "詹天佑的后人\t詹天佑的后代\t0\treplace:后人(普通名词)替换为后代(普通名词)，他们的关系是同义词\n",
      "法国人爱吃的菜肴\t法国人爱吃的菜\t0\treplace:菜肴(普通名词)替换为菜(普通名词)，他们的关系是同义词\n",
      "水果坏了能不能吃\t水果烂了能不能吃\t0\treplace:坏(普通动词)替换为烂(形容词)，他们的关系是同义词\n",
      "南红有什么功效\t南红有什么好处\t0\treplace:功效(普通名词)替换为好处(普通名词)，他们的关系是同义词\n",
      "怀孕肚脐左侧疼痛怎么回事\t孕妇肚脐左侧疼痛怎么回事\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "充电器真假\t充电器真伪\t0\treplace:真假(普通名词)替换为真伪(普通名词)，他们的关系是同义词\n",
      "东四牌楼东共多少集\t东四牌楼东一共多少集\t0\treplace:共(副词)替换为一共(副词)，他们的关系是同义词\n",
      "右侧肋骨下面疼痛\t右侧肋骨下面疼\t0\treplace:疼痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "快递到哪了\t快递到哪里了\t0\treplace:哪(代词)替换为哪里(代词)，他们的关系是同义词\n",
      "手脚发麻怎么缓解\t手脚发麻怎么解决\t0\treplace:缓解(普通动词)替换为解决(普通动词)，他们的关系是同义词\n",
      "手机上怎么查询话费\t手机上怎么查询电话费\t0\treplace:话费(普通名词)替换为电话费(普通名词)，他们的关系是同义词\n",
      "谁是被害人在线观看\t谁是受害者在线观看\t0\treplace:被害人(普通名词)替换为受害者(普通名词)，他们的关系是同义词\n",
      "08年大地震死了多少人\t2008大地震死了多少人\t0\treplace:08年(时间)替换为2008(数量词)，他们的关系是同义词\n",
      "凤铝怎么分辨真伪\t凤铝怎么辨别真伪\t0\treplace:分辨(普通动词)替换为辨别(普通动词)，他们的关系是同义词\n",
      "眼皮里疼痛是怎么回事\t眼皮里疼是怎么回事\t0\treplace:疼痛(名形词)替换为疼(形容词)，他们的关系是同义词\n",
      "整牙很痛吗\t整牙很疼吗\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "如何填写邮箱地址\t怎么填写邮箱地址\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "壳聚糖可以消毒吗\t壳聚糖可以杀菌吗\t0\treplace:消毒(普通动词)替换为杀菌(普通动词)，他们的关系是同义词\n",
      "遗嘱公证费\t遗书公证费\t0\treplace:遗嘱(普通名词)替换为遗书(普通名词)，他们的关系是同义词\n",
      "手掌肉疼痛怎么回事\t手掌肉疼怎么回事\t0\treplace:疼痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "2020年是属什么年\t2020年是属于什么年\t0\treplace:属(普通动词)替换为属于(普通动词)，他们的关系是同义词\n",
      "谁还不是个小孩呢\t谁还不是个小孩子呢\t0\treplace:小孩(普通名词)替换为小孩子(普通名词)，他们的关系是同义词\n",
      "鸟可以活几年\t小鸟可以活几年\t0\treplace:鸟(普通名词)替换为小鸟(普通名词)，他们的关系是同义词\n",
      "酒与女人的诗句\t酒与女人的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "oppo手机有打电话变声功能吗\toppo手机有通话变声功能吗\t0\treplace:打电话(名动词)替换为通话(名动词)，他们的关系是同义词\n",
      "拖拉机怎么做\t拖拉机怎么制作\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "射手座今天运势\t射手座今日运势\t0\treplace:今天(时间)替换为今日(时间)，他们的关系是同义词\n",
      "手法的概念\t手法的定义\t0\treplace:概念(普通名词)替换为定义(普通名词)，他们的关系是同义词\n",
      "QQ邮箱怎么搞\tQQ邮箱怎么做\t0\treplace:搞(普通动词)替换为做(普通动词)，他们的关系是同义词\n",
      "你能帮我做什么\t你能帮我做啥\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "云南烟草工资\t云南烟草薪资\t0\treplace:工资(普通名词)替换为薪资(普通名词)，他们的关系是同义词\n",
      "松下蒸烤箱 菜谱\t松下蒸烤箱 食谱\t0\treplace:菜谱(普通名词)替换为食谱(普通名词)，他们的关系是同义词\n",
      "26个字母有什么\t26个字母有哪些\t0\treplace:什么(代词)替换为哪些(代词)，他们的关系是同义词\n",
      "原装耳机怎么使用\t原装耳机怎么用\t0\treplace:使用(普通动词)替换为用(普通动词)，他们的关系是同义词\n",
      "电视屏幕很黑\t电视屏幕很暗\t0\treplace:黑(形容词)替换为暗(形容词)，他们的关系是同义词\n",
      "我要干什么\t我要干啥\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "猫咪传腹是什么症状\t猫猫传腹是什么症状\t0\treplace:猫咪(普通名词)替换为猫猫(普通名词)，他们的关系是同义词\n",
      "茉莉用英语怎么读\t茉莉花用英语怎么读\t0\treplace:茉莉(普通名词)替换为茉莉花(普通名词)，他们的关系是同义词\n",
      "红领巾怎么系才漂亮\t红领巾怎么系才好看\t0\treplace:漂亮(形容词)替换为好看(形容词)，他们的关系是同义词\n",
      "月经喝柠檬\t生理期喝柠檬\t0\treplace:月经(普通名词)替换为生理期(普通名词)，他们的关系是同义词\n",
      "猫猫在家里找不到了\t猫咪在家里找不到了\t0\treplace:猫猫(普通名词)替换为猫咪(普通名词)，他们的关系是同义词\n",
      "倍他乐克的用途\t倍他乐克的好处\t0\treplace:用途(普通名词)替换为好处(普通名词)，他们的关系是同义词\n",
      "蟹老板为什么那么爱钱第几集\t蟹老板为什么那么喜欢钱第几集\t0\treplace:爱(普通动词)替换为喜欢(普通动词)，他们的关系是同义词\n",
      "生理期会水肿\t大姨妈会水肿\t0\treplace:生理期(普通名词)替换为大姨妈(普通名词)，他们的关系是同义词\n",
      "怎么使用手机VPN\t怎么用手机VPN\t0\treplace:使用(普通动词)替换为用(介词)，他们的关系是同义词\n",
      "神经病吃什么死的快\t精神病吃什么死的快\t0\treplace:神经病(普通名词)替换为精神病(普通名词)，他们的关系是同义词\n",
      "怎么看股息\t怎么看股利\t0\treplace:股息(普通名词)替换为股利(普通名词)，他们的关系是同义词\n",
      "怀孕家里能养仓鼠吗\t孕妇家里能养仓鼠吗\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "怎么辨别艾蒿\t怎么辨别艾草\t0\treplace:艾蒿(普通名词)替换为艾草(普通名词)，他们的关系是同义词\n",
      "穷人的食物\t贫民的食物\t0\treplace:穷人(普通名词)替换为贫民(普通名词)，他们的关系是同义词\n",
      "如何克制不玩手机\t如何控制不玩手机\t0\treplace:克制(普通动词)替换为控制(普通动词)，他们的关系是同义词\n",
      "这到底是什么\t这究竟是什么\t0\treplace:到底(副词)替换为究竟(副词)，他们的关系是同义词\n",
      "2020年换大门的吉日\t2020年换大门的好日子\t0\treplace:吉日(普通名词)替换为好日子(普通名词)，他们的关系是同义词\n",
      "仓库退货单怎么写\t库房退货单怎么写\t0\treplace:仓库(普通名词)替换为库房(普通名词)，他们的关系是同义词\n",
      "怀孕能用筋膜枪吗\t孕妇能用筋膜枪吗\t0\treplace:怀孕(名动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "头发稀少剪短发好看吗\t头发少剪短发好看吗\t0\treplace:稀少(副形词)替换为少(副形词)，他们的关系是同义词\n",
      "大拇指第二节疼痛是怎么回事\t大拇指第二节疼是怎么回事\t0\treplace:疼痛(名形词)替换为疼(名形词)，他们的关系是同义词\n",
      "剖腹产前多久不能进食\t破腹产前多久不能进食\t0\treplace:剖腹产(普通名词)替换为破腹产(普通动词)，他们的关系是同义词\n",
      "拔罐减肥有效吗\t拔罐减肥有用吗\t0\treplace:有效(形容词)替换为有用(形容词)，他们的关系是同义词\n",
      "女孩子摆摊卖什么赚钱\t女孩子摆摊卖什么挣钱\t0\treplace:赚钱(普通动词)替换为挣钱(普通动词)，他们的关系是同义词\n",
      "手机qq视频怎么关闭声音\t手机qq视频怎么关掉声音\t0\treplace:关闭(普通动词)替换为关掉(普通动词)，他们的关系是同义词\n",
      "五千加五千等于几\t五千加五千等于多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "怀孕六个月食欲不振\t孕六个月食欲不振\t0\treplace:怀孕(普通动词)替换为孕(名动词)，他们的关系是同义词\n",
      "中国艺人有多少\t中国演员有多少\t0\treplace:艺人(普通名词)替换为演员(普通名词)，他们的关系是同义词\n",
      "上海哪个地方最繁华\t上海哪个地方最繁荣\t0\treplace:繁华(形容词)替换为繁荣(形容词)，他们的关系是同义词\n",
      "暴走英雄坛怎么学绝招\t暴走英雄坛怎么学习绝招\t0\treplace:学(普通动词)替换为学习(普通动词)，他们的关系是同义词\n",
      "爱奇艺VIP怎么关闭自动续费?\t爱奇艺VIP怎么关自动续费?\t0\treplace:关闭(普通动词)替换为关(普通动词)，他们的关系是同义词\n",
      "如何查看医院是否正规\t如何查看诊所是否正规\t0\treplace:医院(普通名词)替换为诊所(普通名词)，他们的关系是同义词\n",
      "你知道我父亲是谁吗\t你知道我爸爸是谁吗\t0\treplace:父亲(普通名词)替换为爸爸(普通名词)，他们的关系是同义词\n",
      "人格的概念\t人格的定义\t0\treplace:概念(普通名词)替换为定义(普通名词)，他们的关系是同义词\n",
      "高血压会引起手痛吗\t高血压会引起手疼吗\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "怀孕60天没有胎心胎芽怎么办\t孕60天没有胎心胎芽怎么办\t0\treplace:怀孕(普通动词)替换为孕(普通动词)，他们的关系是同义词\n",
      "三加二减五等于几\t三加二减五等于多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "西方最漂亮的女人\t西方最漂亮的女性\t0\treplace:女人(普通名词)替换为女性(普通名词)，他们的关系是同义词\n",
      "眼镜片怎么分辨好坏\t眼镜片怎么辨别好坏\t0\treplace:分辨(普通动词)替换为辨别(普通动词)，他们的关系是同义词\n",
      "晨会日志怎么写\t早会日志怎么写\t0\treplace:晨(时间)替换为早(副形词)，他们的关系是同义词\n",
      "拉肚子有泡沫是怎么回事\t拉肚子有泡泡是怎么回事\t0\treplace:泡沫(普通名词)替换为泡泡(普通名词)，他们的关系是同义词\n",
      "暮色森林怎么打开?\t暮色森林怎么开启?\t0\treplace:打开(普通动词)替换为开启(普通动词)，他们的关系是同义词\n",
      "找到删除的照片\t找出删除的照片\t0\treplace:找到(普通动词)替换为找出(普通动词)，他们的关系是同义词\n",
      "小孩的痔疮\t小孩子的痔疮\t0\treplace:小孩(普通名词)替换为小孩子(普通名词)，他们的关系是同义词\n",
      "肚子疼痛是怎么回事\t肚子疼是怎么回事\t0\treplace:疼痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "建筑中水的概念\t建筑中水的定义\t0\treplace:概念(普通名词)替换为定义(普通名词)，他们的关系是同义词\n",
      "眼睛发红疼痛\t眼睛发红疼\t0\treplace:疼痛(名形词)替换为疼(形容词)，他们的关系是同义词\n",
      "牛黄清胃丸功效\t牛黄清胃丸功能\t0\treplace:功效(普通名词)替换为功能(普通名词)，他们的关系是同义词\n",
      "照相机vr是什么意思\t摄像机vr是什么意思\t0\treplace:照相机(普通名词)替换为摄像机(普通名词)，他们的关系是同义词\n",
      "吃橘子会回奶吗\t吃桔子会回奶吗\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "老是打嗝是什么原因\t老是打呃是什么原因\t0\treplace:打嗝(普通动词)替换为打呃(普通动词)，他们的关系是同义词\n",
      "中药价格走势\t中药材价格走势\t0\treplace:中药(普通名词)替换为中药材(普通名词)，他们的关系是同义词\n",
      "什么花代表着温柔\t什么花象征着温柔\t0\treplace:代表(普通动词)替换为象征(普通动词)，他们的关系是同义词\n",
      "职务工资是什么\t岗位工资是什么\t0\treplace:职务(普通名词)替换为岗位(普通名词)，他们的关系是同义词\n",
      "频繁溃疡是什么原因\t总是溃疡是什么原因\t0\treplace:频繁(副形词)替换为总是(副词)，他们的关系是同义词\n",
      "交强险医疗赔偿多少\t交强险医疗赔多少\t0\treplace:赔偿(普通动词)替换为赔(普通动词)，他们的关系是同义词\n",
      "什么快递速度快\t什么快递很快\t0\treplace:速度快(形容词)替换为很快(形容词)，他们的关系是同义词\n",
      "在括号里填上合适的数\t在括号里填上适当的数\t0\treplace:合适(形容词)替换为适当(形容词)，他们的关系是同义词\n",
      "怎么分辨屏幕排列\t怎么辨别屏幕排列\t0\treplace:分辨(普通动词)替换为辨别(普通动词)，他们的关系是同义词\n",
      "ins连不上\tins连接不上\t0\treplace:连(副词)替换为连接(普通动词)，他们的关系是同义词\n",
      "月经提前8天的原因\t大姨妈提前8天的原因\t0\treplace:月经(普通名词)替换为大姨妈(普通名词)，他们的关系是同义词\n",
      "月经一直不干净是怎么回事\t例假一直不干净是怎么回事\t0\treplace:月经(普通名词)替换为例假(普通名词)，他们的关系是同义词\n",
      "比较虐的电视剧\t较虐的电视剧\t0\treplace:比较(副词)替换为较(副词)，他们的关系是同义词\n",
      "无纺布是怎么做出来的\t无纺布是怎么制作出来的\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "家用风扇什么牌子好\t家用电扇什么牌子好\t0\treplace:风扇(普通名词)替换为电扇(普通名词)，他们的关系是同义词\n",
      "怎么进入wlan设置\t怎么进入无线网设置\t0\treplace:wlan(普通名词)替换为无线网(其他专名)，他们的关系是同义词\n",
      "小孩腹泻吃什么药好得快\t小孩拉稀吃什么药好得快\t0\treplace:腹泻(普通动词)替换为拉稀(普通动词)，他们的关系是同义词\n",
      "你长什么样\t您长什么样\t0\treplace:你(代词)替换为您(代词)，他们的关系是同义词\n",
      "如何联系运营商\t怎么联系运营商\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "奶油融了还能吃吗\t奶油融化了还能吃吗\t0\treplace:融(普通动词)替换为融化(普通动词)，他们的关系是同义词\n",
      "伤口结痂很痒怎么止痒\t伤口结疤很痒怎么止痒\t0\treplace:结痂(普通动词)替换为结疤(普通动词)，他们的关系是同义词\n",
      "浑身疼怎么办\t全身疼怎么办\t0\treplace:浑身(普通名词)替换为全身(普通名词)，他们的关系是同义词\n",
      "十二生肖对应植物\t十二生肖相应植物\t0\treplace:对应(普通动词)替换为相应(名动词)，他们的关系是同义词\n",
      "怀孕周期准吗\t怀孕周期准确吗\t0\treplace:准(形容词)替换为准确(形容词)，他们的关系是同义词\n",
      "姓令狐的读音是什么\t姓氏令狐的读音是什么\t0\treplace:姓(普通动词)替换为姓氏(普通名词)，他们的关系是同义词\n",
      "华为怎么开启位置定位\t华为怎么打开位置定位\t0\treplace:开启(普通动词)替换为打开(普通动词)，他们的关系是同义词\n",
      "怎么识别玉器\t怎么辨别玉器\t0\treplace:识别(普通动词)替换为辨别(普通动词)，他们的关系是同义词\n",
      "小孩子脾气暴躁\t小孩脾气暴躁\t0\treplace:小孩子(普通名词)替换为小孩(普通名词)，他们的关系是同义词\n",
      "描写飞机起飞的声音\t形容飞机起飞的声音\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "梦见破纸币\t梦见破钞票\t0\treplace:纸币(普通名词)替换为钞票(普通名词)，他们的关系是同义词\n",
      "如何做纸花\t如何制作纸花\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "180加180等于几\t180加180等于多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "野鸡害怕什么颜色\t野鸡怕什么颜色\t0\treplace:害怕(普通动词)替换为怕(普通动词)，他们的关系是同义词\n",
      "如何用塑料瓶做笛子\t如何用塑料瓶制作笛子\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "嘴里特别臭是怎么回事\t嘴里很臭是怎么回事\t0\treplace:特别(副词)替换为很(副词)，他们的关系是同义词\n",
      "煤气灶自动熄火原因\t燃气灶自动熄火原因\t0\treplace:煤气灶(普通名词)替换为燃气灶(普通名词)，他们的关系是同义词\n",
      "怎么看不到\t怎么看不见\t0\treplace:看不到(普通动词)替换为看不见(普通动词)，他们的关系是同义词\n",
      "airpods pro怎么找\tairpods pro怎么寻找\t0\treplace:找(普通动词)替换为寻找(普通动词)，他们的关系是同义词\n",
      "像什么一样温顺\t像什么一样温驯\t0\treplace:温顺(形容词)替换为温驯(普通名词)，他们的关系是同义词\n",
      "你了解什么游戏\t你知道什么游戏\t0\treplace:了解(普通动词)替换为知道(普通动词)，他们的关系是同义词\n",
      "中国股市类型\t中国股市种类\t0\treplace:类型(普通名词)替换为种类(普通名词)，他们的关系是同义词\n",
      "1万公积金能贷款多少\t1万公积金能贷多少\t0\treplace:贷款(普通动词)替换为贷(普通动词)，他们的关系是同义词\n",
      "开启充电提示音\t打开充电提示音\t0\treplace:开启(普通动词)替换为打开(普通动词)，他们的关系是同义词\n",
      "来大姨妈了能吃中药吗\t来月经了能吃中药吗\t0\treplace:大姨妈(普通名词)替换为月经(普通名词)，他们的关系是同义词\n",
      "如何拆开插座面板\t如何拆插座面板\t0\treplace:拆开(普通动词)替换为拆(普通动词)，他们的关系是同义词\n",
      "右手中指无名指发麻\t右手中指无名指麻木\t0\treplace:发麻(普通动词)替换为麻木(形容词)，他们的关系是同义词\n",
      "老毛桃安装iso\t老毛桃安装iso文件\t0\treplace:iso(普通名词)替换为iso文件(其他专名)，他们的关系是同义词\n",
      "增加免疫的药物\t增加免疫的药\t0\treplace:药物(普通名词)替换为药(普通名词)，他们的关系是同义词\n",
      "为什么玩游戏老是闪退\t为什么玩游戏频繁闪退\t0\treplace:老是(副词)替换为频繁(副形词)，他们的关系是同义词\n",
      "最近觉得很困\t最近感觉很困\t0\treplace:觉得(普通动词)替换为感觉(普通动词)，他们的关系是同义词\n",
      "怎么画艾蒿\t怎么画艾草\t0\treplace:艾蒿(普通名词)替换为艾草(普通名词)，他们的关系是同义词\n",
      "茄子怎么存储\t茄子怎么贮存\t0\treplace:存储(普通动词)替换为贮存(普通动词)，他们的关系是同义词\n",
      "停车告示怎么写\t停车通告怎么写\t0\treplace:告示(普通名词)替换为通告(普通名词)，他们的关系是同义词\n",
      "是什么东西\t是啥东西\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "来了月经可以吃韭菜吗\t来了例假可以吃韭菜吗\t0\treplace:月经(普通名词)替换为例假(普通名词)，他们的关系是同义词\n",
      "身高会遗传吗\t个子会遗传吗\t0\treplace:身高(普通名词)替换为个子(普通名词)，他们的关系是同义词\n",
      "虎牌是什么牌子\t虎牌是什么牌\t0\treplace:牌子(普通名词)替换为牌(普通名词)，他们的关系是同义词\n",
      "来生理期可以吃感冒药吗\t来月经可以吃感冒药吗\t0\treplace:生理期(普通名词)替换为月经(普通名词)，他们的关系是同义词\n",
      "视频流量怎么赚钱\t视频流量怎么挣钱\t0\treplace:赚钱(普通动词)替换为挣钱(普通动词)，他们的关系是同义词\n",
      "小孩打呼噜的原因及治疗方法\t小孩打鼾的原因及治疗方法\t0\treplace:打呼噜(普通动词)替换为打鼾(普通动词)，他们的关系是同义词\n",
      "藕尖的作法\t藕尖的做法\t0\treplace:作法(普通名词)替换为做法(普通名词)，他们的关系是同义词\n",
      "失业金累计可以领多少个月\t失业金总共可以领多少个月\t0\treplace:累计(动副词)替换为总共(副词)，他们的关系是同义词\n",
      "你妈多大了\t你妈妈多大了\t0\treplace:妈(普通名词)替换为妈妈(普通名词)，他们的关系是同义词\n",
      "梦见谈合约\t梦见谈合同\t0\treplace:合约(普通名词)替换为合同(普通名词)，他们的关系是同义词\n",
      "形容鸟儿的诗句\t形容鸟儿的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "例假和怀孕初期症状\t月经和怀孕初期症状\t0\treplace:例假(普通名词)替换为月经(普通名词)，他们的关系是同义词\n",
      "你闺蜜是哪个\t你闺蜜是谁\t0\treplace:哪个(代词)替换为谁(代词)，他们的关系是同义词\n",
      "如何描写水蜜桃\t如何形容水蜜桃\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "你是什么样子的\t你是啥样子的\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "关于摆渡人的诗句\t关于摆渡人的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "如何改变小布的声音\t怎么改变小布的声音\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "大便酸臭是什么原因\t粪便酸臭是什么原因\t0\treplace:大便(普通名词)替换为粪便(普通名词)，他们的关系是同义词\n",
      "形容误解别人的成语\t形容误会别人的成语\t0\treplace:误解(普通动词)替换为误会(普通动词)，他们的关系是同义词\n",
      "数学中元素的概念\t数学中元素的定义\t0\treplace:概念(普通名词)替换为定义(普通名词)，他们的关系是同义词\n",
      "回力标怎么做?\t回力标怎么制作?\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "相知的唯美句子\t相识的唯美句子\t0\treplace:相知(普通动词)替换为相识(普通动词)，他们的关系是同义词\n",
      "照片尺寸标准\t照片大小标准\t0\treplace:尺寸(普通名词)替换为大小(普通名词)，他们的关系是同义词\n",
      "郭璞的著作\t郭璞的作品\t0\treplace:著作(普通名词)替换为作品(普通名词)，他们的关系是同义词\n",
      "鼻孔里面有个疙瘩\t鼻腔里面有个疙瘩\t0\treplace:鼻孔(普通名词)替换为鼻腔(普通名词)，他们的关系是同义词\n",
      "二手发电机多少钱一台\t二手电机多少钱一台\t0\treplace:发电机(普通名词)替换为电机(普通名词)，他们的关系是同义词\n",
      "怎样减肚子上的脂肪\t怎样减肚子上的油\t0\treplace:脂肪(普通名词)替换为油(普通名词)，他们的关系是同义词\n",
      "中国移动怎么修改月结日\t中国移动怎么改月结日\t0\treplace:修改(普通动词)替换为改(普通动词)，他们的关系是同义词\n",
      "虾怎么去味\t虾子怎么去味\t0\treplace:虾(普通名词)替换为虾子(普通名词)，他们的关系是同义词\n",
      "玩手机拇指痛\t玩手机拇指疼\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "金山嘴渔村可以钓鱼吗\t金山嘴渔村可以垂钓吗\t0\treplace:钓鱼(普通动词)替换为垂钓(普通动词)，他们的关系是同义词\n",
      "割包好处和坏处举荐 强生联系\t割包好处和坏处推荐 强生联系\t0\treplace:举荐(普通动词)替换为推荐(普通动词)，他们的关系是同义词\n",
      "喜鹊的言语\t喜鹊的语言\t0\treplace:言语(普通名词)替换为语言(普通名词)，他们的关系是同义词\n",
      "形容声音开心的成语\t形容声音高兴的成语\t0\treplace:开心(形容词)替换为高兴(形容词)，他们的关系是同义词\n",
      "小乔 扮演者\t小乔 演员\t0\treplace:扮演者(普通名词)替换为演员(普通名词)，他们的关系是同义词\n",
      "怎么做冰块不容易融化\t怎么做冰块不容易化\t0\treplace:融化(普通动词)替换为化(普通动词)，他们的关系是同义词\n",
      "公共关系的发源地\t公共关系的源头\t0\treplace:发源地(普通名词)替换为源头(普通名词)，他们的关系是同义词\n",
      "没有来学校英语\t没来学校英语\t0\treplace:没有(普通动词)替换为没(普通动词)，他们的关系是同义词\n",
      "怀孕为什么不能戴首饰\t孕妇为什么不能戴首饰\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "形容一个人善于思考\t描述一个人善于思考\t0\treplace:形容(普通动词)替换为描述(普通动词)，他们的关系是同义词\n",
      "北极蛤怎么读\t北极蛤怎么念\t0\treplace:读(普通动词)替换为念(普通动词)，他们的关系是同义词\n",
      "清凉油可以摸肚脐吗\t清凉油可以摸肚脐眼吗\t0\treplace:肚脐(普通名词)替换为肚脐眼(普通名词)，他们的关系是同义词\n",
      "总感觉心脏难受\t总觉得心脏难受\t0\treplace:感觉(普通动词)替换为觉得(普通动词)，他们的关系是同义词\n",
      "百家乐结果\t百家乐结局\t0\treplace:结果(普通名词)替换为结局(普通名词)，他们的关系是同义词\n",
      "怎样形容气氛\t怎样形容氛围\t0\treplace:气氛(普通名词)替换为氛围(普通名词)，他们的关系是同义词\n",
      "谁建造了长城\t谁建造了万里长城\t0\treplace:长城(地名)替换为万里长城(地名)，他们的关系是同义词\n",
      "鲨鱼怕水母吗\t鲨鱼害怕水母吗\t0\treplace:怕(普通动词)替换为害怕(普通动词)，他们的关系是同义词\n",
      "榴莲没开可以放冰箱吗\t榴莲没有开可以放冰箱吗\t0\treplace:没(普通动词)替换为没有(普通动词)，他们的关系是同义词\n",
      "早上起来吸烟头晕\t早上起来抽烟头晕\t0\treplace:吸烟(普通动词)替换为抽烟(普通动词)，他们的关系是同义词\n",
      "经常放屁是什么病\t常常放屁是什么病\t0\treplace:经常(副词)替换为常常(副词)，他们的关系是同义词\n",
      "我们作为中国人而自豪英语\t我们作为中国人而骄傲英语\t0\treplace:自豪(形容词)替换为骄傲(形容词)，他们的关系是同义词\n",
      "月经稀少怎么治疗\t月经稀少怎么治\t0\treplace:治疗(普通动词)替换为治(普通动词)，他们的关系是同义词\n",
      "怎么能让孩子喜欢阅读\t怎么能让小孩喜欢阅读\t0\treplace:孩子(普通名词)替换为小孩(普通名词)，他们的关系是同义词\n",
      "咳嗽嗓子哑\t咳嗽嗓子沙哑\t0\treplace:哑(形容词)替换为沙哑(形容词)，他们的关系是同义词\n",
      "你喜欢运动吗\t你爱运动吗\t0\treplace:喜欢(普通动词)替换为爱(普通动词)，他们的关系是同义词\n",
      "如何拆开插座面板\t如何拆卸插座面板\t0\treplace:拆开(普通动词)替换为拆卸(普通动词)，他们的关系是同义词\n",
      "孕妇能吃橘子吗晚期\t孕妇能吃桔子吗晚期\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "欧式眉毛在纸上的画法\t欧式眉在纸上的画法\t0\treplace:眉毛(普通名词)替换为眉(普通名词)，他们的关系是同义词\n",
      "你这是什么意思\t你这是啥意思\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "毒品的危害\t毒品的为害\t0\treplace:危害(名动词)替换为为害(名动词)，他们的关系是同义词\n",
      "拇指外翻会疼吗\t拇指外翻会疼痛吗\t0\treplace:疼(形容词)替换为疼痛(形容词)，他们的关系是同义词\n",
      "新生儿眼眶发黑\t新生儿眼窝发黑\t0\treplace:眼眶(普通名词)替换为眼窝(普通名词)，他们的关系是同义词\n",
      "类似翩翩起舞\t类似跳舞\t0\treplace:翩翩起舞(普通动词)替换为跳舞(名动词)，他们的关系是同义词\n",
      "面颊突出面相\t脸颊突出面相\t0\treplace:面颊(普通名词)替换为脸颊(普通名词)，他们的关系是同义词\n",
      "4维彩超分辨男女准吗\t4维彩超分辨男女准确吗\t0\treplace:准(形容词)替换为准确(形容词)，他们的关系是同义词\n",
      "小孩经常咳嗽\t孩子经常咳嗽\t0\treplace:小孩(普通名词)替换为孩子(普通名词)，他们的关系是同义词\n",
      "苗木的种类\t苗子的种类\t0\treplace:苗木(普通名词)替换为苗子(普通名词)，他们的关系是同义词\n",
      "你要什么呢\t你要啥呢\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "有关感恩的歌曲\t关于感恩的歌曲\t0\treplace:有关(普通动词)替换为关于(介词)，他们的关系是同义词\n",
      "怀孕初期可以吃橘子吗\t怀孕初期可以吃桔子吗\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "比较赚钱的证书\t比较挣钱的证书\t0\treplace:赚钱(普通动词)替换为挣钱(普通动词)，他们的关系是同义词\n",
      "孙悟空十分顽皮一会儿什么一会儿什么一会儿什么\t孙悟空十分调皮一会儿什么一会儿什么一会儿什么\t0\treplace:顽皮(形容词)替换为调皮(形容词)，他们的关系是同义词\n",
      "怀孕听的歌\t孕妇听的歌\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "麦克风无法开启\t麦克风无法打开\t0\treplace:开启(普通动词)替换为打开(普通动词)，他们的关系是同义词\n",
      "月经是褐色的怎么回事\t例假是褐色的怎么回事\t0\treplace:月经(普通名词)替换为例假(普通名词)，他们的关系是同义词\n",
      "小心的英语怎么读?\t小心的英语怎么念?\t0\treplace:读(普通动词)替换为念(普通动词)，他们的关系是同义词\n",
      "画商保险箱密码\t画商保险柜密码\t0\treplace:保险箱(普通名词)替换为保险柜(普通名词)，他们的关系是同义词\n",
      "孕妇能否吃鹅蛋\t孕妇可不可以吃鹅蛋\t0\treplace:能否(普通动词)替换为可不可以(普通动词)，他们的关系是同义词\n",
      "凄凉的诗歌\t凄惨的诗歌\t0\treplace:凄凉(形容词)替换为凄惨(形容词)，他们的关系是同义词\n",
      "崴脚意味着什么\t崴脚意味什么\t0\treplace:意味着(普通动词)替换为意味(普通名词)，他们的关系是同义词\n",
      "知乎如何发表问题\t知乎如何发布问题\t0\treplace:发表(普通动词)替换为发布(普通动词)，他们的关系是同义词\n",
      "亚历山大的父亲是谁\t亚历山大的爸爸是谁\t0\treplace:父亲(普通名词)替换为爸爸(普通名词)，他们的关系是同义词\n",
      "抽导尿管痛吗\t抽导尿管疼吗\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "牛顿的品格\t牛顿的品德\t0\treplace:品格(普通名词)替换为品德(普通名词)，他们的关系是同义词\n",
      "你爸妈叫什么\t你爸妈叫啥\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "痛风可不可以吃海带\t痛风可不可吃海带\t0\treplace:可以(普通动词)替换为可(普通动词)，他们的关系是同义词\n",
      "拉肚子可以吃橘子吗\t拉肚子可以吃桔子吗\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "涨肚子怎么办\t胀肚子怎么办\t0\treplace:涨(普通动词)替换为胀(普通动词)，他们的关系是同义词\n",
      "手脚发麻是什么原因\t手脚麻痹是什么原因\t0\treplace:发麻(普通动词)替换为麻痹(形容词)，他们的关系是同义词\n",
      "舌根上的味蕾是品尝什么味道的\t舌根上的味蕾是尝什么味道的\t0\treplace:品尝(普通动词)替换为尝(普通动词)，他们的关系是同义词\n",
      "目光和眼神的区别\t眼光和眼神的区别\t0\treplace:目光(普通名词)替换为眼光(普通名词)，他们的关系是同义词\n",
      "你会一直在吗\t你能一直在吗\t0\treplace:会(普通动词)替换为能(普通动词)，他们的关系是同义词\n",
      "你会哄我开心吗\t你能哄我开心吗\t0\treplace:会(普通动词)替换为能(普通动词)，他们的关系是同义词\n",
      "开宾馆赚钱吗\t开招待所赚钱吗\t0\treplace:宾馆(普通名词)替换为招待所(普通名词)，他们的关系是同义词\n",
      "怎么制作会飞的鸟\t怎么制作会飞的小鸟\t0\treplace:鸟(普通名词)替换为小鸟(普通名词)，他们的关系是同义词\n",
      "孩子不掉牙是什么原因\t小孩不掉牙是什么原因\t0\treplace:孩子(普通名词)替换为小孩(普通名词)，他们的关系是同义词\n",
      "我感觉这个名字不好听\t我觉得这个名字不好听\t0\treplace:感觉(普通动词)替换为觉得(普通动词)，他们的关系是同义词\n",
      "迷你世界如何做娃娃机\t迷你世界如何制作娃娃机\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "怀孕九周可以做阴超吗\t孕九周可以做阴超吗\t0\treplace:怀孕(普通动词)替换为孕(普通动词)，他们的关系是同义词\n",
      "什么中药可以治疗哮喘\t什么中药可以治疗气喘\t0\treplace:哮喘(普通名词)替换为气喘(普通名词)，他们的关系是同义词\n",
      "那你研究出来了吗\t那你钻研出来了吗\t0\treplace:研究(普通动词)替换为钻研(普通动词)，他们的关系是同义词\n",
      "孕妇腹部运动\t怀孕腹部运动\t0\treplace:孕妇(普通名词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "水印怎么修改时间\t水印怎么改时间\t0\treplace:修改(普通动词)替换为改(普通动词)，他们的关系是同义词\n",
      "为什么手机wlan打不开\t为什么手机无线网打不开\t0\treplace:wlan(人名)替换为无线网(副形词)，他们的关系是同义词\n",
      "颅脑损伤的定义\t颅脑损伤的概念\t0\treplace:定义(普通名词)替换为概念(普通名词)，他们的关系是同义词\n",
      "关于梦瑶的诗句\t关于梦瑶的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "女人可以承受多少次\t女性可以承受多少次\t0\treplace:女人(普通名词)替换为女性(普通名词)，他们的关系是同义词\n",
      "新生儿可以喝七星茶\t婴儿可以喝七星茶\t0\treplace:新生儿(普通名词)替换为婴儿(普通名词)，他们的关系是同义词\n",
      "饵料品牌排行榜\t鱼饵品牌排行榜\t0\treplace:饵料(普通名词)替换为鱼饵(普通名词)，他们的关系是同义词\n",
      "湿疹能吃橘子吗\t湿疹能吃桔子吗\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "人一般多少个牙\t人一般多少个牙齿\t0\treplace:牙(普通名词)替换为牙齿(普通名词)，他们的关系是同义词\n",
      "金鱼吊兰怎么栽培\t金鱼吊兰怎么培植\t0\treplace:栽培(普通动词)替换为培植(普通动词)，他们的关系是同义词\n",
      "唱个好听的歌\t唱个好听的歌曲\t0\treplace:歌(普通名词)替换为歌曲(普通名词)，他们的关系是同义词\n",
      "菠萝蜜几月成熟\t菠萝蜜几月熟\t0\treplace:成熟(形容词)替换为熟(形容词)，他们的关系是同义词\n",
      "梦到很漂亮的风景\t梦到很好看的风景\t0\treplace:很漂亮(形容词)替换为很好看(形容词)，他们的关系是同义词\n",
      "孕10个月\t怀孕10个月\t0\treplace:孕(普通动词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "直播间夸大哥的话\t直播间夸奖大哥的话\t0\treplace:夸(普通动词)替换为夸奖(普通动词)，他们的关系是同义词\n",
      "如何开启隐藏功能\t怎么开启隐藏功能\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "怀孕身上好痒\t孕妇身上好痒\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "小黄鞋怎么洗\t小黄鞋怎么清洗\t0\treplace:洗(普通动词)替换为清洗(普通动词)，他们的关系是同义词\n",
      "直播怎么关弹幕\t直播怎么关闭弹幕\t0\treplace:关(普通动词)替换为关闭(普通动词)，他们的关系是同义词\n",
      "搬家告示怎么写\t搬家通告怎么写\t0\treplace:告示(普通名词)替换为通告(普通名词)，他们的关系是同义词\n",
      "人一辈子活多少分钟\t人一生活多少分钟\t0\treplace:一辈子(数量词)替换为一生(普通名词)，他们的关系是同义词\n",
      "喝酒会推迟例假吗\t喝酒会推迟月经吗\t0\treplace:例假(普通名词)替换为月经(普通名词)，他们的关系是同义词\n",
      "电脑怎么开启青少年模式\t电脑怎么打开青少年模式\t0\treplace:开启(普通动词)替换为打开(普通动词)，他们的关系是同义词\n",
      "来例假可以吃甘草片吗\t来月经可以吃甘草片吗\t0\treplace:例假(普通名词)替换为月经(普通名词)，他们的关系是同义词\n",
      "黄金怎么验真伪\t金子怎么验真伪\t0\treplace:黄金(普通名词)替换为金子(普通名词)，他们的关系是同义词\n",
      "0除以0等于几\t0除以0等于多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "小肚子胀是怎么回事\t小肚子鼓胀是怎么回事\t0\treplace:胀(普通动词)替换为鼓胀(名动词)，他们的关系是同义词\n",
      "红旗h7油箱盖怎么开启\t红旗h7油箱盖怎么打开\t0\treplace:开启(普通动词)替换为打开(普通动词)，他们的关系是同义词\n",
      "印痕是什么\t痕迹是什么\t0\treplace:印痕(普通名词)替换为痕迹(普通名词)，他们的关系是同义词\n",
      "男孩特别依赖妈妈怎么办\t男孩太依赖妈妈怎么办\t0\treplace:特别(副词)替换为太(副词)，他们的关系是同义词\n",
      "油漆和漆料的配比\t漆和漆料的配比\t0\treplace:油漆(普通名词)替换为漆(普通名词)，他们的关系是同义词\n",
      "张杰她老婆是谁\t张杰他老婆是谁\t0\treplace:她(代词)替换为他(代词)，他们的关系是同义词\n",
      "如何清理瓷砖缝隙\t如何清理瓷砖缝\t0\treplace:缝隙(普通名词)替换为缝(普通名词)，他们的关系是同义词\n",
      "描写春天空气清新的句子\t形容春天空气清新的句子\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "牙龈老出血怎么回事\t牙龈老流血怎么回事\t0\treplace:出血(普通动词)替换为流血(普通动词)，他们的关系是同义词\n",
      "古代为什么学六艺\t古代为什么学习六艺\t0\treplace:学(普通动词)替换为学习(普通动词)，他们的关系是同义词\n",
      "阴历1948年\t农历1948年\t0\treplace:阴历(普通名词)替换为农历(普通名词)，他们的关系是同义词\n",
      "材料科学与工程的定义\t材料科学与工程的概念\t0\treplace:定义(普通名词)替换为概念(普通名词)，他们的关系是同义词\n",
      "自行车很难踩怎么办\t单车很难踩怎么办\t0\treplace:自行车(普通名词)替换为单车(普通名词)，他们的关系是同义词\n",
      "如何进行长截屏\t怎么进行长截屏\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "脖子两边肿\t颈部两边肿\t0\treplace:脖子(普通名词)替换为颈部(普通名词)，他们的关系是同义词\n",
      "最搞笑的公司名字\t最搞笑的公司名\t0\treplace:名字(普通名词)替换为名(普通名词)，他们的关系是同义词\n",
      "月子期间外出\t月子期间出门\t0\treplace:外出(普通动词)替换为出门(普通动词)，他们的关系是同义词\n",
      "中医如何治疗脑供血不足\t中医如何治脑供血不足\t0\treplace:治疗(普通动词)替换为治(普通动词)，他们的关系是同义词\n",
      "什么是友情\t什么是友谊\t0\treplace:友情(普通名词)替换为友谊(普通名词)，他们的关系是同义词\n",
      "怀孕多久不可以平躺睡觉\t怀孕多久不可以平躺睡\t0\treplace:睡觉(普通动词)替换为睡(普通动词)，他们的关系是同义词\n",
      "借记卡没有激活\t借记卡没激活\t0\treplace:没有(普通动词)替换为没(普通动词)，他们的关系是同义词\n",
      "行李箱怎么洗里面\t行李箱怎么清洗里面\t0\treplace:洗(普通动词)替换为清洗(普通动词)，他们的关系是同义词\n",
      "简单又好看的书怎么画\t简单又漂亮的书怎么画\t0\treplace:好看(形容词)替换为漂亮(形容词)，他们的关系是同义词\n",
      "电脑图标太小\t电脑图标很小\t0\treplace:太(副词)替换为很(副词)，他们的关系是同义词\n",
      "大姨妈推迟半个月怎么回事\t大姨妈延后半个月怎么回事\t0\treplace:推迟(普通动词)替换为延后(普通动词)，他们的关系是同义词\n",
      "山东好玩的地方\t山东有意思的地方\t0\treplace:好玩(形容词)替换为有意思(形容词)，他们的关系是同义词\n",
      "宫外孕一般多久会出血\t宫外孕一般多久会流血\t0\treplace:出血(普通动词)替换为流血(普通动词)，他们的关系是同义词\n",
      "说话嘴歪怎么回事\t说话嘴斜怎么回事\t0\treplace:歪(普通动词)替换为斜(普通动词)，他们的关系是同义词\n",
      "银行卡烂了怎么办\t银行卡坏了怎么办\t0\treplace:烂(形容词)替换为坏(普通动词)，他们的关系是同义词\n",
      "肚子下面很痛怎么回事\t肚子下面很疼怎么回事\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "如何清理手机垃圾\t怎么清理手机垃圾\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "成都市2019年平均收入\t成都市2019年人均收入\t0\treplace:平均(形容词)替换为人均(普通动词)，他们的关系是同义词\n",
      "变压器负荷怎么计算\t变压器负载怎么计算\t0\treplace:负荷(普通名词)替换为负载(普通动词)，他们的关系是同义词\n",
      "这附近哪有酒店\t这附近哪有宾馆\t0\treplace:酒店(普通名词)替换为宾馆(普通名词)，他们的关系是同义词\n",
      "模拟位置对微信没用\t模拟位置对微信无效\t0\treplace:没用(普通动词)替换为无效(普通动词)，他们的关系是同义词\n",
      "莴苣还叫什么\t莴笋还叫什么\t0\treplace:莴苣(其他专名)替换为莴笋(普通名词)，他们的关系是同义词\n",
      "无格式文本\t无格式公文\t0\treplace:文本(普通名词)替换为公文(普通名词)，他们的关系是同义词\n",
      "养生堂维生素e是哪里生产的\t养生堂维生素e是哪里产的\t0\treplace:生产(普通动词)替换为产(普通动词)，他们的关系是同义词\n",
      "吃鸡怎么看不到敌人\t吃鸡怎么看不见敌人\t0\treplace:看不到(普通动词)替换为看不见(普通动词)，他们的关系是同义词\n",
      "怎么抠图片上的字\t怎么抠图上的字\t0\treplace:图片(普通名词)替换为图(普通名词)，他们的关系是同义词\n",
      "如何插文献\t如何插入文献\t0\treplace:插(普通动词)替换为插入(普通动词)，他们的关系是同义词\n",
      "虎什么什么咽成语\t虎什么什么吞成语\t0\treplace:咽(普通动词)替换为吞(普通动词)，他们的关系是同义词\n",
      "梦见捡小孩\t梦见捡到小孩\t0\treplace:捡(普通动词)替换为捡到(普通动词)，他们的关系是同义词\n",
      "照片增加水印软件\t照片添加水印软件\t0\treplace:增加(普通动词)替换为添加(普通动词)，他们的关系是同义词\n",
      "身体老是发麻\t身体老是麻木\t0\treplace:发麻(普通动词)替换为麻木(形容词)，他们的关系是同义词\n",
      "身体透支过度\t身体透支超负荷\t0\treplace:过度(形容词)替换为超负荷(名动词)，他们的关系是同义词\n",
      "商标添加小类需要多久\t商标增加小类需要多久\t0\treplace:添加(普通动词)替换为增加(普通动词)，他们的关系是同义词\n",
      "猫猫可以上高铁吗\t猫咪可以上高铁吗\t0\treplace:猫猫(普通名词)替换为猫咪(普通名词)，他们的关系是同义词\n",
      "宋丹丹儿媳妇叫什么\t宋丹丹儿媳叫什么\t0\treplace:儿媳妇(普通名词)替换为儿媳(普通名词)，他们的关系是同义词\n",
      "查询表怎么做\t查询表怎么制作\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "熊为什么这么傻\t熊为什么这么笨\t0\treplace:傻(形容词)替换为笨(形容词)，他们的关系是同义词\n",
      "小轿车属于几类车\t小轿车属几类车\t0\treplace:属于(普通动词)替换为属(普通动词)，他们的关系是同义词\n",
      "如何做网页广告\t如何制作网页广告\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "挣不到钱怎么办\t赚不到钱怎么办\t0\treplace:挣(普通动词)替换为赚(普通动词)，他们的关系是同义词\n",
      "梦见死去姑父\t梦见死去姑夫\t0\treplace:姑父(普通名词)替换为姑夫(普通名词)，他们的关系是同义词\n",
      "中科院在哪个城市\t中国科学院在哪个城市\t0\treplace:中科院(机构名)替换为中国科学院(机构名)，他们的关系是同义词\n",
      "组长申请书怎么写\t小组长申请书怎么写\t0\treplace:组长(普通名词)替换为小组长(普通名词)，他们的关系是同义词\n",
      "怎么增加门禁卡\t怎么添加门禁卡\t0\treplace:增加(普通动词)替换为添加(普通动词)，他们的关系是同义词\n",
      "这个手机是OPPO几\t这个手机是OPPO多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "化妆师可以遮住纹身吗\t化妆师可以遮掉纹身吗\t0\treplace:遮住(普通动词)替换为遮掉(普通动词)，他们的关系是同义词\n",
      "怎么做简单的盲盒教程\t怎么制作简单的盲盒教程\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "回族人死后怎么下葬\t回族人死后怎么安葬\t0\treplace:下葬(普通动词)替换为安葬(普通动词)，他们的关系是同义词\n",
      "宝宝高热物理降温方法\t宝宝高烧物理降温方法\t0\treplace:高热(形容词)替换为高烧(普通名词)，他们的关系是同义词\n",
      "治疗中风的方剂\t治疗中风的药方\t0\treplace:方剂(普通名词)替换为药方(普通名词)，他们的关系是同义词\n",
      "梦见打仗自己到处躲藏\t梦见打仗自己到处躲\t0\treplace:躲藏(普通动词)替换为躲(普通动词)，他们的关系是同义词\n",
      "如何取生锈的螺丝\t如何取生锈的螺丝钉\t0\treplace:螺丝(普通名词)替换为螺丝钉(普通名词)，他们的关系是同义词\n",
      "安全校园手抄报内容 小学生\t平安校园手抄报内容 小学生\t0\treplace:安全(形容词)替换为平安(形容词)，他们的关系是同义词\n",
      "怎么吃都感觉吃不饱\t怎么吃都觉得吃不饱\t0\treplace:感觉(普通动词)替换为觉得(普通动词)，他们的关系是同义词\n",
      "小蚂蚁你怎么啦加标点\t小蚂蚁你怎么啦加标点符号\t0\treplace:标点(普通名词)替换为标点符号(普通名词)，他们的关系是同义词\n",
      "怎么减少肝脏脂肪\t怎么减肝脏脂肪\t0\treplace:减少(普通动词)替换为减(普通动词)，他们的关系是同义词\n",
      "我们要去哪\t我们要去哪里\t0\treplace:哪(代词)替换为哪里(代词)，他们的关系是同义词\n",
      "轻度肺气肿能治好吗\t轻微肺气肿能治好吗\t0\treplace:轻度(形容词)替换为轻微(形容词)，他们的关系是同义词\n",
      "玻璃器皿怎么包装\t玻璃器皿怎么打包\t0\treplace:包装(普通动词)替换为打包(普通动词)，他们的关系是同义词\n",
      "艾滋病会通过唾液传染吗\t爱滋病会通过唾液传染吗\t0\treplace:艾滋病(其他专名)替换为爱滋病(其他专名)，他们的关系是同义词\n",
      "白磷的化学式怎么写\t白磷的化学方程式怎么写\t0\treplace:化学式(普通名词)替换为化学方程式(其他专名)，他们的关系是同义词\n",
      "一躺下来肚子就痛\t一躺下来肚子就疼\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "我度过了一个忙碌的周末用英语怎么说\t我度过了一个繁忙的周末用英语怎么说\t0\treplace:忙碌(形容词)替换为繁忙(形容词)，他们的关系是同义词\n",
      "用雨做比喻句\t用雨造比喻句\t0\treplace:做(普通动词)替换为造(普通动词)，他们的关系是同义词\n",
      "怎样学才能提高成绩\t怎样学习才能提高成绩\t0\treplace:学(普通动词)替换为学习(普通动词)，他们的关系是同义词\n",
      "胎儿什么时候入盆\t胚胎什么时候入盆\t0\treplace:胎儿(普通名词)替换为胚胎(普通名词)，他们的关系是同义词\n",
      "炸鸡腿凉了能吃吗\t炸鸡腿冷了能吃吗\t0\treplace:凉(形容词)替换为冷(形容词)，他们的关系是同义词\n",
      "倒数三十分钟\t倒计时三十分钟\t0\treplace:倒数(普通动词)替换为倒计时(普通动词)，他们的关系是同义词\n",
      "你害怕老婆吗\t你怕老婆吗\t0\treplace:害怕(普通动词)替换为怕(普通动词)，他们的关系是同义词\n",
      "佩戴象牙有什么讲究\t带象牙有什么讲究\t0\treplace:佩戴(普通动词)替换为带(普通动词)，他们的关系是同义词\n",
      "我想就寝可以吗\t我想睡觉可以吗\t0\treplace:就寝(普通动词)替换为睡觉(普通动词)，他们的关系是同义词\n",
      "怀孕16周肚皮痒\t孕16周肚皮痒\t0\treplace:怀孕(普通动词)替换为孕(普通动词)，他们的关系是同义词\n",
      "你感觉肖战怎么样\t你觉得肖战怎么样\t0\treplace:感觉(普通动词)替换为觉得(普通动词)，他们的关系是同义词\n",
      "怎么训练龟\t怎么训练乌龟\t0\treplace:龟(普通名词)替换为乌龟(普通名词)，他们的关系是同义词\n",
      "认主人的龟\t认识主人的龟\t0\treplace:认(普通动词)替换为认识(普通动词)，他们的关系是同义词\n",
      "怀孕能吃多宝鱼吗\t孕妇能吃多宝鱼吗\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "少华的诗句\t少华的诗\t0\treplace:诗句(普通名词)替换为诗(普通名词)，他们的关系是同义词\n",
      "来月经可以吃正气水吗\t来大姨妈可以吃正气水吗\t0\treplace:月经(普通名词)替换为大姨妈(普通名词)，他们的关系是同义词\n",
      "肖战喜欢谁\t肖战爱谁\t0\treplace:喜欢(普通动词)替换为爱(普通动词)，他们的关系是同义词\n",
      "生理期可以吃橘子吗\t大姨妈可以吃橘子吗\t0\treplace:生理期(普通名词)替换为大姨妈(普通名词)，他们的关系是同义词\n",
      "食品添加剂概念\t食品添加剂定义\t0\treplace:概念(普通名词)替换为定义(普通名词)，他们的关系是同义词\n",
      "怀孕9个月引产\t孕9个月引产\t0\treplace:怀孕(普通动词)替换为孕(普通动词)，他们的关系是同义词\n",
      "怀孕不吃饿吃了胀怎么回事\t孕妇不吃饿吃了胀怎么回事\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "梦见别人送我豆油\t梦见别人给我豆油\t0\treplace:送(普通动词)替换为给(普通动词)，他们的关系是同义词\n",
      "世界上最吓人的恐怖片叫什么名字\t世界上最可怕的恐怖片叫什么名字\t0\treplace:吓人(形容词)替换为可怕(形容词)，他们的关系是同义词\n",
      "哪个方位属火\t哪个方向属火\t0\treplace:方位(普通名词)替换为方向(普通名词)，他们的关系是同义词\n",
      "抒发爱情的诗句\t表述爱情的诗句\t0\treplace:抒发(普通动词)替换为表述(普通动词)，他们的关系是同义词\n",
      "怎么查看固态硬盘大小\t怎么查固态硬盘大小\t0\treplace:查看(普通动词)替换为查(普通动词)，他们的关系是同义词\n",
      "圆柱怎么计算面积\t圆柱怎么算面积\t0\treplace:计算(普通动词)替换为算(普通动词)，他们的关系是同义词\n",
      "微信怎么查聊天记录\t微信怎么查聊天纪录\t0\treplace:记录(普通名词)替换为纪录(普通名词)，他们的关系是同义词\n",
      "魔鬼害怕什么东西\t魔鬼怕什么东西\t0\treplace:害怕(普通动词)替换为怕(普通动词)，他们的关系是同义词\n",
      "脖子肌肉钙化\t颈部肌肉钙化\t0\treplace:脖子(普通名词)替换为颈部(普通名词)，他们的关系是同义词\n",
      "怎样快速缓解痛经\t怎样快速解决痛经\t0\treplace:缓解(普通动词)替换为解决(普通动词)，他们的关系是同义词\n",
      "脱发挂什么科\t脱发挂什么课\t0\treplace:科(普通名词)替换为课(普通名词)，他们的关系是同义词\n",
      "形容天空漂亮的诗句\t形容天空很漂亮的诗句\t0\treplace:漂亮(形容词)替换为很漂亮(形容词)，他们的关系是同义词\n",
      "中国有多少所大学\t中国有多少所高等学校\t0\treplace:大学(普通名词)替换为高等学校(普通名词)，他们的关系是同义词\n",
      "手指上有小疙瘩\t手指头上有小疙瘩\t0\treplace:手指(普通名词)替换为手指头(普通名词)，他们的关系是同义词\n",
      "怎么寻找在火车上遇到的人\t怎么找在火车上遇到的人\t0\treplace:寻找(普通动词)替换为找(普通动词)，他们的关系是同义词\n",
      "梦见吃橘子\t梦见吃桔子\t0\treplace:橘子(普通名词)替换为桔子(普通名词)，他们的关系是同义词\n",
      "午宴几点开始\t午饭几点开始\t0\treplace:午宴(普通名词)替换为午饭(普通名词)，他们的关系是同义词\n",
      "嗓子突然哑了是怎么回事\t嗓子突然嘶哑了是怎么回事\t0\treplace:哑(普通动词)替换为嘶哑(普通动词)，他们的关系是同义词\n",
      "骨质疏松太严重怎么办\t骨质疏松很严重怎么办\t0\treplace:太(副词)替换为很(副词)，他们的关系是同义词\n",
      "人参的作用\t人参的功效\t0\treplace:作用(普通名词)替换为功效(普通名词)，他们的关系是同义词\n",
      "怎样才能免费获取吃鸡皮肤\t怎样才能免费获得吃鸡皮肤\t0\treplace:获取(普通动词)替换为获得(普通动词)，他们的关系是同义词\n",
      "面团发酵失败怎么办\t面包发酵失败怎么办\t0\treplace:面团(普通名词)替换为面包(普通名词)，他们的关系是同义词\n",
      "描写广西山水的诗句\t形容广西山水的诗句\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "头神经痛怎么缓解\t头神经痛怎么解决\t0\treplace:缓解(普通动词)替换为解决(普通动词)，他们的关系是同义词\n",
      "孕妇吃什么补铁\t怀孕吃什么补铁\t0\treplace:孕妇(普通名词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "孕一个月可以吃小龙虾吗\t怀孕一个月可以吃小龙虾吗\t0\treplace:孕(普通动词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "你是什么时候出生的\t你是什么时候诞生的\t0\treplace:出生(普通动词)替换为诞生(普通动词)，他们的关系是同义词\n",
      "消瘦的原因有哪些\t削瘦的原因有哪些\t0\treplace:消瘦(形容词)替换为削瘦(形容词)，他们的关系是同义词\n",
      "关于写云的句子\t关于写云彩的句子\t0\treplace:云(普通名词)替换为云彩(普通名词)，他们的关系是同义词\n",
      "抽烟为什么会头晕\t吸烟为什么会头晕\t0\treplace:抽烟(普通动词)替换为吸烟(名动词)，他们的关系是同义词\n",
      "掺四字成语\t混杂四字成语\t0\treplace:掺(普通动词)替换为混杂(普通动词)，他们的关系是同义词\n",
      "支付宝如何分身\t支付宝怎么分身\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "没食欲恶心\t无食欲恶心\t0\treplace:没(普通动词)替换为无(普通动词)，他们的关系是同义词\n",
      "焖烧杯用途\t焖烧杯作用\t0\treplace:用途(普通名词)替换为作用(普通名词)，他们的关系是同义词\n",
      "公办幼儿园归什么部门管\t公立幼儿园归什么部门管\t0\treplace:公办(形容词)替换为公立(形容词)，他们的关系是同义词\n",
      "血糖高的人能吃橘子吗\t血糖高的人能吃桔子吗\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "土豆的栽培\t马铃薯的栽培\t0\treplace:土豆(普通名词)替换为马铃薯(普通名词)，他们的关系是同义词\n",
      "怀孕能不能喝玉米须水\t孕妇能不能喝玉米须水\t0\treplace:怀孕(名动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "蔬菜干的热量高吗\t蔬菜干的热量大吗\t0\treplace:高(形容词)替换为大(形容词)，他们的关系是同义词\n",
      "怎样做脱骨鸡爪\t怎样制作脱骨鸡爪\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "与人说话的书籍\t与人说话的书\t0\treplace:书籍(普通名词)替换为书(普通名词)，他们的关系是同义词\n",
      "做梦经常梦到同一个人\t做梦时常梦到同一个人\t0\treplace:经常(副词)替换为时常(副词)，他们的关系是同义词\n",
      "分手后心态\t分手后心情\t0\treplace:心态(普通名词)替换为心情(普通名词)，他们的关系是同义词\n",
      "坏了的水果\t烂了的水果\t0\treplace:坏(形容词)替换为烂(形容词)，他们的关系是同义词\n",
      "拉肚子能不能吃橘子\t拉肚子能不能吃桔子\t0\treplace:橘子(普通名词)替换为桔子(普通名词)，他们的关系是同义词\n",
      "需要后下的药物是\t需要后下的药是\t0\treplace:药物(普通名词)替换为药(普通名词)，他们的关系是同义词\n",
      "十大污软件\t十大污点软件\t0\treplace:污(普通名词)替换为污点(普通名词)，他们的关系是同义词\n",
      "月息三厘五是多少\t月利率三厘五是多少\t0\treplace:月息(普通名词)替换为月利率(其他专名)，他们的关系是同义词\n",
      "中国哪个地方盛产美女\t中国哪个地方产美女\t0\treplace:盛产(普通动词)替换为产(普通动词)，他们的关系是同义词\n",
      "默网名是什么意思\t静默网名是什么意思\t0\treplace:默(副词)替换为静默(形容词)，他们的关系是同义词\n",
      "多高兴啊补充句子\t多开心啊补充句子\t0\treplace:高兴(形容词)替换为开心(形容词)，他们的关系是同义词\n",
      "测有机物相对分子质量的方法\t测量有机物相对分子质量的方法\t0\treplace:测(普通动词)替换为测量(普通动词)，他们的关系是同义词\n",
      "天窗遮阳板怎么拆卸\t天窗遮阳板怎么拆\t0\treplace:拆卸(普通动词)替换为拆(普通动词)，他们的关系是同义词\n",
      "客流量怎么形容\t客流量怎么描述\t0\treplace:形容(普通动词)替换为描述(普通动词)，他们的关系是同义词\n",
      "户口本姓名可以更改吗\t户口本姓名可以改吗\t0\treplace:更改(普通动词)替换为改(普通动词)，他们的关系是同义词\n",
      "描写埙的诗句\t形容埙的诗句\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "姓张的富豪\t姓张的有钱人\t0\treplace:富豪(普通名词)替换为有钱人(普通名词)，他们的关系是同义词\n",
      "当兵体格检查标准\t入伍体格检查标准\t0\treplace:当兵(普通动词)替换为入伍(普通动词)，他们的关系是同义词\n",
      "吃了米非司酮片会拉肚子吗\t吃了米非司酮片会腹泻吗\t0\treplace:拉肚子(普通动词)替换为腹泻(普通动词)，他们的关系是同义词\n",
      "腹泻吃什么药好得快\t拉稀吃什么药好得快\t0\treplace:腹泻(普通动词)替换为拉稀(普通动词)，他们的关系是同义词\n",
      "小孩子怎么做\t小孩子怎么造\t0\treplace:做(普通动词)替换为造(普通动词)，他们的关系是同义词\n",
      "摆地摊能赚钱嘛\t摆地摊能挣钱嘛\t0\treplace:赚钱(普通动词)替换为挣钱(普通动词)，他们的关系是同义词\n",
      "recite怎么读\trecite怎么念\t0\treplace:读(普通动词)替换为念(普通动词)，他们的关系是同义词\n",
      "word简历模板怎么添加下一页\tword简历模板怎么增加下一页\t0\treplace:添加(普通动词)替换为增加(普通动词)，他们的关系是同义词\n",
      "什么动物会变性\t啥动物会变性\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "手机号能转换归属地吗\t手机号能换归属地吗\t0\treplace:转换(普通动词)替换为换(普通动词)，他们的关系是同义词\n",
      "双手突然发麻\t两手突然发麻\t0\treplace:双手(普通名词)替换为两手(普通名词)，他们的关系是同义词\n",
      "算年龄的方法\t计算年龄的方法\t0\treplace:算(普通动词)替换为计算(名动词)，他们的关系是同义词\n",
      "小布开启静音模式\t小布打开静音模式\t0\treplace:开启(普通动词)替换为打开(普通动词)，他们的关系是同义词\n",
      "月经经常推迟不来什么原因\t月经常常推迟不来什么原因\t0\treplace:经常(副词)替换为常常(副词)，他们的关系是同义词\n",
      "经常腹泻是什么原因\t经常拉肚是什么原因\t0\treplace:腹泻(普通动词)替换为拉肚(普通动词)，他们的关系是同义词\n",
      "怎么查看股票佣金\t怎么查股票佣金\t0\treplace:查看(普通动词)替换为查(普通动词)，他们的关系是同义词\n",
      "正确佩戴口罩的方式\t正确配戴口罩的方式\t0\treplace:佩戴(普通动词)替换为配戴(普通动词)，他们的关系是同义词\n",
      "描写环境很安静\t形容环境很安静\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "形容船只很多\t形容船很多\t0\treplace:船只(普通名词)替换为船(普通名词)，他们的关系是同义词\n",
      "你真名叫什么\t你真名叫啥\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "头孢氨苄片治疗扁桃体发炎吗\t头孢氨苄片治扁桃体发炎吗\t0\treplace:治疗(普通动词)替换为治(普通动词)，他们的关系是同义词\n",
      "上海市老年津贴标准\t上海市老年补贴标准\t0\treplace:津贴(普通名词)替换为补贴(名动词)，他们的关系是同义词\n",
      "微信收到的图片不清楚\t微信收的图片不清楚\t0\treplace:收到(普通动词)替换为收(普通动词)，他们的关系是同义词\n",
      "开启应用分屏\t打开应用分屏\t0\treplace:开启(普通动词)替换为打开(普通动词)，他们的关系是同义词\n",
      "剖腹产痛吗\t剖腹产疼吗\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "微信怎样查看绿码\t微信怎样查绿码\t0\treplace:查看(普通动词)替换为查(普通动词)，他们的关系是同义词\n",
      "word目录页码格式怎么修改\tword目录页码格式怎么改\t0\treplace:修改(普通动词)替换为改(普通动词)，他们的关系是同义词\n",
      "洋桔梗几月种植\t洋桔梗几月种\t0\treplace:种植(普通动词)替换为种(普通动词)，他们的关系是同义词\n",
      "什么最宝贵\t什么最可贵\t0\treplace:宝贵(形容词)替换为可贵(形容词)，他们的关系是同义词\n",
      "6个半月宝宝频繁夜醒\t6个半月宝宝总是夜醒\t0\treplace:频繁(副形词)替换为总是(副词)，他们的关系是同义词\n",
      "你要怎么样\t你要怎样\t0\treplace:怎么样(代词)替换为怎样(代词)，他们的关系是同义词\n",
      "形容语言质朴的成语\t形容语言朴素的成语\t0\treplace:质朴(形容词)替换为朴素(形容词)，他们的关系是同义词\n",
      "描写有恒心的句子\t形容有恒心的句子\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "修改时间的指令\t修改时间的命令\t0\treplace:指令(普通名词)替换为命令(普通名词)，他们的关系是同义词\n",
      "快手删了粉丝怎么恢复\t快手删除了粉丝怎么恢复\t0\treplace:删(普通动词)替换为删除(普通动词)，他们的关系是同义词\n",
      "咳分为几种\t咳嗽分为几种\t0\treplace:咳(普通动词)替换为咳嗽(名动词)，他们的关系是同义词\n",
      "oppor15换个电池多少钱\toppor15换个电池多钱\t0\treplace:多少(代词)替换为多(形容词)，他们的关系是同义词\n",
      "左肾盂无回声\t左肾无回声\t0\treplace:肾盂(普通名词)替换为肾(普通名词)，他们的关系是同义词\n",
      "橘子的升糖指数是多少\t桔子的升糖指数是多少\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "负一减一等于几\t负一减一等于多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "榛子怎么拼\t榛怎么拼\t0\treplace:榛子(普通名词)替换为榛(普通名词)，他们的关系是同义词\n",
      "黄山玉石价格\t黄山玉价格\t0\treplace:玉石(普通名词)替换为玉(普通名词)，他们的关系是同义词\n",
      "很漂亮的小鸟怎么画\t好看的小鸟怎么画\t0\treplace:很漂亮(形容词)替换为好看(形容词)，他们的关系是同义词\n",
      "女孩下面毛多\t女生下面毛多\t0\treplace:女孩(普通名词)替换为女生(普通名词)，他们的关系是同义词\n",
      "你有什么遗憾\t你有哪些遗憾\t0\treplace:什么(代词)替换为哪些(代词)，他们的关系是同义词\n",
      "小女孩有疝气吗\t女童有疝气吗\t0\treplace:小女孩(普通名词)替换为女童(普通名词)，他们的关系是同义词\n",
      "最贵的中药材\t最贵的中药\t0\treplace:中药材(普通名词)替换为中药(普通名词)，他们的关系是同义词\n",
      "伸懒腰肚脐疼\t伸懒腰肚脐眼疼\t0\treplace:肚脐(普通名词)替换为肚脐眼(普通名词)，他们的关系是同义词\n",
      "两腿膝盖内侧疼\t两腿膝盖内侧疼痛\t0\treplace:疼(形容词)替换为疼痛(形容词)，他们的关系是同义词\n",
      "髋骨疼痛的原因\t髋骨疼的原因\t0\treplace:疼痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "小建中汤的作用\t小建中汤的功能\t0\treplace:作用(普通名词)替换为功能(普通名词)，他们的关系是同义词\n",
      "含羞草的幼苗是什么样的\t含羞草的苗是什么样的\t0\treplace:幼苗(普通名词)替换为苗(普通名词)，他们的关系是同义词\n",
      "水瓶座有什么特点\t水瓶座有哪些特点\t0\treplace:什么(代词)替换为哪些(代词)，他们的关系是同义词\n",
      "来例假可以跑步吗\t来经期可以跑步吗\t0\treplace:例假(普通名词)替换为经期(普通名词)，他们的关系是同义词\n",
      "怎样挑梭子蟹\t怎样选梭子蟹\t0\treplace:挑(普通动词)替换为选(普通动词)，他们的关系是同义词\n",
      "眼睛进沙子怎么办\t眼睛进砂子怎么办\t0\treplace:沙子(普通名词)替换为砂子(人名)，他们的关系是同义词\n",
      "没有abs的摩托车\t没abs的摩托车\t0\treplace:没有(普通动词)替换为没(普通动词)，他们的关系是同义词\n",
      "肩部疼痛是什么原因\t肩部疼是什么原因\t0\treplace:疼痛(名形词)替换为疼(形容词)，他们的关系是同义词\n",
      "京东售后太慢\t京东售后很慢\t0\treplace:太(副词)替换为很(副词)，他们的关系是同义词\n",
      "孩子喜欢摆东西\t小孩喜欢摆东西\t0\treplace:孩子(普通名词)替换为小孩(普通名词)，他们的关系是同义词\n",
      "手机邮箱怎么做表格\t手机邮箱怎么制作表格\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "避孕套尺寸怎么看\t安全套尺寸怎么看\t0\treplace:避孕套(普通名词)替换为安全套(普通名词)，他们的关系是同义词\n",
      "孩子的出生证怎么办\t小孩的出生证怎么办\t0\treplace:孩子(普通名词)替换为小孩(普通名词)，他们的关系是同义词\n",
      "学习通下载的图书在哪\t学习通下载的书籍在哪\t0\treplace:图书(普通名词)替换为书籍(普通名词)，他们的关系是同义词\n",
      "修改符号的好处\t修改符号的作用\t0\treplace:好处(普通名词)替换为作用(普通名词)，他们的关系是同义词\n",
      "怀孕会老想睡觉吗\t孕妇会老想睡觉吗\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "例假黑少怎么回事\t月经黑少怎么回事\t0\treplace:例假(普通名词)替换为月经(普通名词)，他们的关系是同义词\n",
      "折衣服不皱的方法\t叠衣服不皱的方法\t0\treplace:折(普通动词)替换为叠(普通动词)，他们的关系是同义词\n",
      "你觉得作为辅导老师最重要的是什么\t你认为作为辅导老师最重要的是什么\t0\treplace:觉得(普通动词)替换为认为(普通动词)，他们的关系是同义词\n",
      "那你的名字叫什么\t那你的名字叫啥\t0\treplace:什么(代词)替换为啥(代词)，他们的关系是同义词\n",
      "例假不调的原因\t经期不调的原因\t0\treplace:例假(普通名词)替换为经期(普通名词)，他们的关系是同义词\n",
      "孕妇能吃橘子吗\t孕妇能吃桔子吗\t0\treplace:橘子(其他专名)替换为桔子(普通名词)，他们的关系是同义词\n",
      "拔牙后痛怎么办\t拔牙后疼怎么办\t0\treplace:痛(副形词)替换为疼(普通动词)，他们的关系是同义词\n",
      "你为什么是仙女\t你为什么是美女\t0\treplace:仙女(普通名词)替换为美女(普通名词)，他们的关系是同义词\n",
      "你的祖先是谁\t你的祖宗是谁\t0\treplace:祖先(普通名词)替换为祖宗(普通名词)，他们的关系是同义词\n",
      "燕子怎么画又简单又好看\t燕子怎么画又简单又漂亮\t0\treplace:好看(形容词)替换为漂亮(形容词)，他们的关系是同义词\n",
      "鸟用什么辅助呼吸\t鸟类用什么辅助呼吸\t0\treplace:鸟(普通名词)替换为鸟类(普通名词)，他们的关系是同义词\n",
      "理发店开张广告宣传语\t美发店开张广告宣传语\t0\treplace:理发店(普通名词)替换为美发店(普通名词)，他们的关系是同义词\n",
      "祭奠去世的人用什么花\t祭去世的人用什么花\t0\treplace:祭奠(普通动词)替换为祭(普通动词)，他们的关系是同义词\n",
      "dh代表什么意思\tdh表示什么意思\t0\treplace:代表(普通动词)替换为表示(普通动词)，他们的关系是同义词\n",
      "眼睛痛用什么滴眼液\t眼睛疼用什么滴眼液\t0\treplace:痛(副形词)替换为疼(形容词)，他们的关系是同义词\n",
      "妹妹的孩子怎么称呼我\t妹妹的孩子怎么叫我\t0\treplace:称呼(普通动词)替换为叫(普通动词)，他们的关系是同义词\n",
      "开关面板种类\t开关面板分类\t0\treplace:种类(普通名词)替换为分类(普通动词)，他们的关系是同义词\n",
      "女人喝什么茶治疗便秘\t女人喝什么茶治便秘\t0\treplace:治疗(普通动词)替换为治(普通动词)，他们的关系是同义词\n",
      "哪个国家湖泊最多\t哪个国家湖最多\t0\treplace:湖泊(普通名词)替换为湖(普通名词)，他们的关系是同义词\n",
      "丙二酸二乙酯的化学式\t丙二酸二乙酯的分子式\t0\treplace:化学式(普通名词)替换为分子式(普通名词)，他们的关系是同义词\n",
      "艹凡怎么念\t艹凡怎么读\t0\treplace:念(普通动词)替换为读(普通动词)，他们的关系是同义词\n",
      "怎么用手机更改路由器名称\t怎么用手机改路由器名称\t0\treplace:更改(普通动词)替换为改(普通动词)，他们的关系是同义词\n",
      "月经能喝咖啡吗\t经期能喝咖啡吗\t0\treplace:月经(普通名词)替换为经期(普通名词)，他们的关系是同义词\n",
      "小肚子右边靠近胯骨按压疼\t小肚子右边靠近胯骨压疼\t0\treplace:按压(普通动词)替换为压(普通动词)，他们的关系是同义词\n",
      "finland怎么读\tfinland怎么念\t0\treplace:读(普通动词)替换为念(普通动词)，他们的关系是同义词\n",
      "女性自强的诗句\t女性自强不息的诗句\t0\treplace:自强(形容词)替换为自强不息(普通动词)，他们的关系是同义词\n",
      "描写一个人独处的诗句\t形容一个人独处的诗句\t0\treplace:描写(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "仙人球冻软了还能活吗\t仙人掌冻软了还能活吗\t0\treplace:仙人球(普通名词)替换为仙人掌(其他专名)，他们的关系是同义词\n",
      "微信收款怎么搞\t微信收款怎么做\t0\treplace:搞(普通动词)替换为做(普通动词)，他们的关系是同义词\n",
      "46除以二等于几\t46除以二等于多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "孕四个月肚子鼓包是胎动吗\t怀孕四个月肚子鼓包是胎动吗\t0\treplace:孕(名动词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "面色分为几种\t脸色分为几种\t0\treplace:面色(普通名词)替换为脸色(普通名词)，他们的关系是同义词\n",
      "老年人总觉得自己有病怎么办\t老年人总认为自己有病怎么办\t0\treplace:觉得(普通动词)替换为认为(普通动词)，他们的关系是同义词\n",
      "例假多长时间一次\t生理期多长时间一次\t0\treplace:例假(普通名词)替换为生理期(普通名词)，他们的关系是同义词\n",
      "感受器类型\t感受器种类\t0\treplace:类型(普通名词)替换为种类(普通名词)，他们的关系是同义词\n",
      "起了的奶粉能放多久\t开了的奶粉能放多久\t0\treplace:起(普通动词)替换为开(普通动词)，他们的关系是同义词\n",
      "孕妇初期不可以吃的东西\t怀孕初期不可以吃的东西\t0\treplace:孕妇(普通名词)替换为怀孕(名动词)，他们的关系是同义词\n",
      "拆除违建标语\t拆除违建口号\t0\treplace:标语(普通名词)替换为口号(普通名词)，他们的关系是同义词\n",
      "整容去哪里学习\t整容去哪里学\t0\treplace:学习(普通动词)替换为学(普通动词)，他们的关系是同义词\n",
      "哺乳期腋下有肿块\t哺乳期腋下有疙瘩\t0\treplace:肿块(普通名词)替换为疙瘩(普通名词)，他们的关系是同义词\n",
      "丼字怎么读\t丼字怎么念\t0\treplace:读(普通动词)替换为念(普通动词)，他们的关系是同义词\n",
      "人的五种需求层次\t人的五种需要层次\t0\treplace:需求(普通名词)替换为需要(普通动词)，他们的关系是同义词\n",
      "狮子座明天运势\t狮子座明日运势\t0\treplace:明天(时间)替换为明日(时间)，他们的关系是同义词\n",
      "准确数的定义\t准确数的概念\t0\treplace:定义(普通名词)替换为概念(普通名词)，他们的关系是同义词\n",
      "橡皮怎么描述\t橡皮怎么形容\t0\treplace:描述(普通动词)替换为形容(普通动词)，他们的关系是同义词\n",
      "起重机最大起吊重量\t吊车最大起吊重量\t0\treplace:起重机(普通名词)替换为吊车(普通名词)，他们的关系是同义词\n",
      "巴西位于热带吗\t巴西在热带吗\t0\treplace:位于(普通动词)替换为在(介词)，他们的关系是同义词\n",
      "左炔诺孕酮片吃完能喝水吗\t左炔诺孕酮片吃了能喝水吗\t0\treplace:完(普通动词)替换为了(助词)，他们的关系是同义词\n",
      "新课程倡导的师生关系\t新课程提倡的师生关系\t0\treplace:倡导(普通动词)替换为提倡(普通动词)，他们的关系是同义词\n",
      "抽血后运动\t抽血之后运动\t0\treplace:后(方位名词)替换为之后(方位名词)，他们的关系是同义词\n",
      "怎么切换语音助手的声音\t怎么更改语音助手的声音\t0\treplace:切换(普通动词)替换为更改(普通动词)，他们的关系是同义词\n",
      "主动的动字怎么写\t自动的动字怎么写\t0\treplace:主动(形容词)替换为自动(形容词)，他们的关系是同义词\n",
      "家庭成员老公称谓怎么填写\t家庭成员老公称谓怎么填\t0\treplace:填写(普通动词)替换为填(普通动词)，他们的关系是同义词\n",
      "女生怎样追直男\t女生怎样追求直男\t0\treplace:追(普通动词)替换为追求(普通动词)，他们的关系是同义词\n",
      "天津下雨了吗\t天津市下雨了吗\t0\treplace:天津(地名)替换为天津市(地名)，他们的关系是同义词\n",
      "大拇指指甲周围红肿\t大拇指指甲盖周围红肿\t0\treplace:指甲(普通名词)替换为指甲盖(普通名词)，他们的关系是同义词\n",
      "人体正常体温是多少\t人体正常气温是多少\t0\treplace:体温(普通名词)替换为气温(普通名词)，他们的关系是同义词\n",
      "激起购物欲的颜色\t刺激购物欲的颜色\t0\treplace:激起(普通动词)替换为刺激(普通动词)，他们的关系是同义词\n",
      "如何长截屏\t怎么长截屏\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "如何分辨工业酒精和食用酒精\t如何辨别工业酒精和食用酒精\t0\treplace:分辨(普通动词)替换为辨别(普通动词)，他们的关系是同义词\n",
      "形容手漂亮的四字成语\t形容手好看的四字成语\t0\treplace:漂亮(形容词)替换为好看(形容词)，他们的关系是同义词\n",
      "如何克制不玩手机\t如何自制不玩手机\t0\treplace:克制(普通动词)替换为自制(普通动词)，他们的关系是同义词\n",
      "吃完香蕉后多久可以吃红薯\t吃了香蕉后多久可以吃红薯\t0\treplace:完(普通动词)替换为了(助词)，他们的关系是同义词\n",
      "最凄凉的二胡曲\t最悲的二胡曲\t0\treplace:凄凉(形容词)替换为悲(形容词)，他们的关系是同义词\n",
      "怀孕羊水的多少和什么有关\t孕妇羊水的多少和什么有关\t0\treplace:怀孕(普通动词)替换为孕妇(普通名词)，他们的关系是同义词\n",
      "口腔溃疡一直流口水怎么办\t口腔溃疡一直流涎怎么办\t0\treplace:流口水(普通动词)替换为流涎(普通动词)，他们的关系是同义词\n",
      "月经期间可以洗澡吗\t月经期间可以沐浴吗\t0\treplace:洗澡(普通动词)替换为沐浴(普通动词)，他们的关系是同义词\n",
      "vivo手机来电拒接怎么取消\tvivo手机来电拒绝怎么取消\t0\treplace:拒接(普通动词)替换为拒绝(普通动词)，他们的关系是同义词\n",
      "侄子侄女的英语\t侄儿侄女的英语\t0\treplace:侄子(普通名词)替换为侄儿(普通名词)，他们的关系是同义词\n",
      "好看的卡片形状\t漂亮的卡片形状\t0\treplace:好看(形容词)替换为漂亮(形容词)，他们的关系是同义词\n",
      "肩背麻木是什么原因\t肩背麻是什么原因\t0\treplace:麻木(形容词)替换为麻(普通名词)，他们的关系是同义词\n",
      "读过的书籍\t读过的书\t0\treplace:书籍(普通名词)替换为书(普通名词)，他们的关系是同义词\n",
      "孕28周发烧怎么办\t怀孕28周发烧怎么办\t0\treplace:孕(普通动词)替换为怀孕(普通动词)，他们的关系是同义词\n",
      "用什么相机拍照清晰\t用什么相机拍照清楚\t0\treplace:清晰(形容词)替换为清楚(形容词)，他们的关系是同义词\n",
      "绿豆糕的做法\t绿豆糕的作法\t0\treplace:做法(普通名词)替换为作法(普通名词)，他们的关系是同义词\n",
      "有关生活的励志语录\t关于生活的励志语录\t0\treplace:有关(普通动词)替换为关于(介词)，他们的关系是同义词\n",
      "肚子一收缩就痛\t肚子一收缩就疼\t0\treplace:痛(形容词)替换为疼(形容词)，他们的关系是同义词\n",
      "二零等于几\t二零等于多少\t0\treplace:几(数量词)替换为多少(代词)，他们的关系是同义词\n",
      "设置语音提示\t设置语音提醒\t0\treplace:提示(名动词)替换为提醒(名动词)，他们的关系是同义词\n",
      "花和尚是谁的绰号?\t花和尚是谁的外号?\t0\treplace:绰号(普通名词)替换为外号(普通名词)，他们的关系是同义词\n",
      "怎么做水肺药水\t怎么制作水肺药水\t0\treplace:做(普通动词)替换为制作(普通动词)，他们的关系是同义词\n",
      "哪个月最少\t哪个月最短\t0\treplace:最少(形容词)替换为最短(形容词)，他们的关系是同义词\n",
      "菊花作用是什么\t菊花功能是什么\t0\treplace:作用(普通名词)替换为功能(普通名词)，他们的关系是同义词\n",
      "金麟岂是池中物的诗\t金麟岂是池中物的诗句\t0\treplace:诗(普通名词)替换为诗句(普通名词)，他们的关系是同义词\n",
      "如何开启root权限\t怎么开启root权限\t0\treplace:如何(代词)替换为怎么(代词)，他们的关系是同义词\n",
      "神经病应该吃什么药\t精神病应该吃什么药\t0\treplace:神经病(普通名词)替换为精神病(普通名词)，他们的关系是同义词\n",
      "网站怎么填写\t网站怎么填\t0\treplace:填写(普通动词)替换为填(普通动词)，他们的关系是同义词\n",
      "和平精英实名认证怎么修改QQ\t和平精英实名认证怎么改QQ\t0\treplace:修改(普通动词)替换为改(普通动词)，他们的关系是同义词\n",
      "拍照功能\t照相功能\t0\treplace:拍照(名动词)替换为照相(名动词)，他们的关系是同义词\n",
      "月经期能吃桔子吗\t月经期能吃橘子吗\t0\treplace:桔子(普通名词)替换为橘子(其他专名)，他们的关系是同义词\n",
      "甲亢吃药会胖吗\t甲亢吃药会瘦吗\t1\treplace:胖(形容词)替换为瘦(形容词)，他们的关系是反义词\n",
      "怎么追一个比自己小的男生\t怎么追一个比自己大的男生\t1\treplace:小(形容词)替换为大(形容词)，他们的关系是反义词\n",
      "身子特别短的狗\t身子特别长的狗\t1\treplace:短(形容词)替换为长(形容词)，他们的关系是反义词\n",
      "梦见手机坏了\t梦见手机好了\t1\treplace:坏(形容词)替换为好(形容词)，他们的关系是反义词\n",
      "晚上喝酸奶会胖吗\t晚上喝酸奶会瘦吗\t1\treplace:胖(形容词)替换为瘦(形容词)，他们的关系是反义词\n",
      "审核凭证相关说法错误的是( )\t审核凭证相关说法正确的是( )\t1\treplace:错误(形容词)替换为正确(形容词)，他们的关系是反义词\n",
      "属于深感觉检查的是\t属于浅感觉检查的是\t1\treplace:深(副词)替换为浅(形容词)，他们的关系是反义词\n",
      "快的的英文是什么\t慢的的英文是什么\t1\treplace:快(形容词)替换为慢(形容词)，他们的关系是反义词\n",
      "相对评价的特点\t绝对评价的特点\t1\treplace:相对(副词)替换为绝对(副词)，他们的关系是反义词\n",
      "阳历11月6是什么星座的呀？\t阴历11月6是什么星座的呀？\t1\treplace:阳历(普通名词)替换为阴历(普通名词)，他们的关系是反义词\n",
      "身份证年龄怎么改小\t身份证年龄怎么改大\t1\treplace:小(形容词)替换为大(形容词)，他们的关系是反义词\n",
      "统计字符数量\t统计字符串数量\t1\treplace:字符(普通名词)替换为字符串(普通名词)，他们的关系是反义词\n",
      "阳历七月初九是什么星座\t阴历七月初九是什么星座\t1\treplace:阳历(普通名词)替换为阴历(普通名词)，他们的关系是反义词\n",
      "新生儿老是吐奶怎么回事\t新生儿偶尔吐奶怎么回事\t1\treplace:老是(副词)替换为偶尔(副词)，他们的关系是反义词\n",
      "形容女生个子矮的词语\t形容女生个子高的词语\t1\treplace:矮(形容词)替换为高(形容词)，他们的关系是反义词\n",
      "角的大小与什么无关与什么有关\t角的大小与什么有关与什么有关\t1\treplace:无关(普通动词)替换为有关(普通动词)，他们的关系是反义词\n",
      "怎么才能长胖\t怎么才能长瘦\t1\treplace:胖(形容词)替换为瘦(形容词)，他们的关系是反义词\n",
      "北京朝阳区离天安门远吗\t北京朝阳区离天安门近吗\t1\treplace:远(形容词)替换为近(形容词)，他们的关系是反义词\n",
      "少的 英语\t老的 英语\t1\treplace:少(形容词)替换为老(形容词)，他们的关系是反义词\n",
      "什么油脂肪含量最低\t什么油脂肪含量最高\t1\treplace:最低(形容词)替换为最高(形容词)，他们的关系是反义词\n",
      "焦距越大越好吗\t焦距越小越好吗\t1\treplace:大(形容词)替换为小(形容词)，他们的关系是反义词\n",
      "华南植物园几点关门\t华南植物园几点开门\t1\treplace:关门(普通动词)替换为开门(普通动词)，他们的关系是反义词\n",
      "老是干咳嗽是什么原因\t偶尔干咳嗽是什么原因\t1\treplace:老是(副词)替换为偶尔(副词)，他们的关系是反义词\n",
      "嘴唇太厚可以整吗\t嘴唇太薄可以整吗\t1\treplace:厚(形容词)替换为薄(形容词)，他们的关系是反义词\n",
      "阳历6月份出生的是什么星座\t阴历6月份出生的是什么星座\t1\treplace:阳历(普通名词)替换为阴历(普通名词)，他们的关系是反义词\n",
      "职高都教什么\t职高都学什么\t1\treplace:教(普通动词)替换为学(普通动词)，他们的关系是反义词\n",
      "关于热的诗句\t关于冷的诗句\t1\treplace:热(名形词)替换为冷(形容词)，他们的关系是反义词\n",
      "二手房淡季是哪几个月\t二手房旺季是哪几个月\t1\treplace:淡季(普通名词)替换为旺季(普通名词)，他们的关系是反义词\n",
      "婴儿指甲发白怎么回事\t婴儿指甲发黑怎么回事\t1\treplace:白(形容词)替换为黑(形容词)，他们的关系是反义词\n",
      "怎么买电影票\t怎么卖电影票\t1\treplace:买(普通动词)替换为卖(普通动词)，他们的关系是反义词\n",
      "普通近义词是什么 标准答案\t珍贵近义词是什么 标准答案\t1\treplace:普通(形容词)替换为珍贵(形容词)，他们的关系是反义词\n",
      "晚什么结构\t早什么结构\t1\treplace:晚(时间)替换为早(形容词)，他们的关系是反义词\n",
      "1990年2月7日是什么星座阳历\t1990年2月7日是什么星座阴历\t1\treplace:阳历(普通名词)替换为阴历(普通名词)，他们的关系是反义词\n",
      "广阔的反义词是什么\t狭窄的反义词是什么\t1\treplace:广阔(形容词)替换为狭窄(形容词)，他们的关系是反义词\n",
      "科威特穷吗\t科威特富吗\t1\treplace:穷(形容词)替换为富(形容词)，他们的关系是反义词\n",
      "心跳过快是怎么回事\t心跳过慢是怎么回事\t1\treplace:快(形容词)替换为慢(形容词)，他们的关系是反义词\n",
      "哪个网站买书便宜\t哪个网站卖书便宜\t1\treplace:买(普通动词)替换为卖(普通动词)，他们的关系是反义词\n",
      "形容富庶的诗词\t形容贫穷的诗词\t1\treplace:富庶(形容词)替换为贫穷(形容词)，他们的关系是反义词\n",
      "宝宝老是干恶心怎么回事\t宝宝偶尔干恶心怎么回事\t1\treplace:老是(副词)替换为偶尔(副词)，他们的关系是反义词\n",
      "新生儿老是吐奶正常吗\t新生儿偶尔吐奶正常吗\t1\treplace:老是(副词)替换为偶尔(副词)，他们的关系是反义词\n",
      "早上吃什么饭\t晚上吃什么饭\t1\treplace:早上(时间)替换为晚上(时间)，他们的关系是反义词\n",
      "好老师的特点\t坏老师的特点\t1\treplace:好(形容词)替换为坏(形容词)，他们的关系是反义词\n",
      "感觉嗓子有异物老是咳嗽\t感觉嗓子有异物偶尔咳嗽\t1\treplace:老是(副词)替换为偶尔(副词)，他们的关系是反义词\n",
      "脚趾甲发白怎么治\t脚趾甲发黑怎么治\t1\treplace:白(名形词)替换为黑(名形词)，他们的关系是反义词\n",
      "难什么成语大全\t易什么成语大全\t1\treplace:难(形容词)替换为易(副形词)，他们的关系是反义词\n",
      "胖的英语反义词是什么\t瘦的英语反义词是什么\t1\treplace:胖(形容词)替换为瘦(形容词)，他们的关系是反义词\n",
      "亮度亮一点\t亮度暗一点\t1\treplace:亮(形容词)替换为暗(形容词)，他们的关系是反义词\n",
      "吃活血化瘀的药会瘦吗\t吃活血化瘀的药会胖吗\t1\treplace:瘦(形容词)替换为胖(形容词)，他们的关系是反义词\n",
      "脚指甲变白怎么回事\t脚指甲变黑怎么回事\t1\treplace:白(形容词)替换为黑(形容词)，他们的关系是反义词\n",
      "小布称怎么组词\t称怎么组词\t1\t[('称', '组词')]\t[('称', '组词')]\n",
      "叮嘱的叮怎么组词\t小布叮怎么组词\t0\t[('叮', '组词')]\t[('叮', '组词')]\n",
      "目怎么组词\t眼目的目怎么组词\t0\t[('目', '组词')]\t[('目', '组词')]\n",
      "翠怎么组词\t翠鸟的翠怎么组词\t0\t[('翠', '组词')]\t[('翠', '组词')]\n",
      "秦的秦怎么组词\t秦淮的秦怎么组词\t0\t[('秦', '组词')]\t[('秦', '组词')]\n",
      "规则的则怎么组词\t选择的则怎么组词\t0\t[('则', '组词')]\t[('则', '组词')]\n",
      "九州生气恃风雷的事怎么组词\t是风雷的事怎么组词\t1\t[('事', '组词')]\t[('事', '组词')]\n",
      "浑浊的浊可以组什么词\t苔藓的苔可以组什么词\t0\t('浑浊', '浊')\t('苔藓', '苔')\n",
      "学习的习都可以组什么词\t学习的习可以组什么词\t0\t('学习', '习')\t('学习', '习')\n",
      "规则的则怎么组词\t规则的则组词\t0\t('规则', '则')\t('规则', '则')\n",
      "遵从的遵可以组什么词\t遵循的遵可以组什么词\t1\t('遵从', '遵')\t('遵循', '遵')\n",
      "国际的际可以组什么词\t国际的际怎么组词\t1\t('国际', '际')\t('国际', '际')\n",
      "玲珑的玲还能组什么词\t玲珑的珑还能组什么词\t0\t('玲珑', '玲')\t('玲珑', '珑')\n",
      "付出的付还可以组什么词\t支付的付还可以组什么词\t0\t('付出', '付')\t('支付', '付')\n",
      "美美丽的美的组词\t美美好的美的组词\t0\t('美美丽', '美')\t('美美好', '美')\n",
      "蜘蛛的蜘还可以组什么词\t蜘蛛的蜘还能组什么词\t1\t('蜘蛛', '蜘')\t('蜘蛛', '蜘')\n",
      "努力的努字还能组什么词\t努力的努字能组什么词\t1\t('努力', '努')\t('努力', '努')\n",
      "煤气的煤组词\t煤气罐的煤组词\t1\t('煤气', '煤')\t('煤气罐', '煤')\n",
      "茉莉的茉可以组什么词\t茉莉的莉能组什么词\t0\t('茉莉', '茉')\t('茉莉', '莉')\n",
      "翠绿的翠怎么组词\t翠绿的翠组词\t1\t('翠绿', '翠')\t('翠绿', '翠')\n",
      "悄悄的悄可以组什么词\t悄悄的悄能组什么词\t1\t('悄悄', '悄')\t('悄悄', '悄')\n",
      "喝水的喝可以组什么词\t喝水的喝能组什么词\t1\t('喝水', '喝')\t('喝水', '喝')\n",
      "清除的除怎么组词\t清除的除组词\t0\t('清除', '除')\t('清除', '除')\n",
      "响声的响怎么组词\t响声的响能组什么词\t1\t('响声', '响')\t('响声', '响')\n",
      "朴实的朴可以组什么词\t朴素的朴可以组什么词\t0\t('朴实', '朴')\t('朴素', '朴')\n",
      "唐代的唐字组词\t汉唐的唐怎么组词\t0\t('唐代', '唐')\t('汉唐', '唐')\n",
      "背书的背还能组什么词\t背诵的背还能组什么词\t0\t('背书', '背')\t('背诵', '背')\n",
      "响声的响组词\t响声的响能组什么词\t0\t('响声', '响')\t('响声', '响')\n",
      "瘦很瘦的瘦怎么组词\t胖很胖的胖怎么组词\t0\t('瘦很瘦', '瘦')\t('胖很胖', '胖')\n",
      "吞咽的吞可以组什么词\t喉咙的喉可以组什么词\t0\t('吞咽', '吞')\t('喉咙', '喉')\n",
      "朋友的朋怎么组词\t笑呵呵的呵可以组什么词\t0\t('朋友', '朋')\t('笑呵呵', '呵')\n",
      "秦的秦怎么组词\t秦淮的秦怎么组词\t1\t('秦', '秦')\t('秦淮', '秦')\n",
      "里面的里怎么组词\t里面的里组词\t0\t('里面', '里')\t('里面', '里')\n",
      "疑问的问还能组什么词\t疑问的问能组什么词\t0\t('疑问', '问')\t('疑问', '问')\n",
      "打球的打的组词怎么写\t打球的打组词怎么写\t1\t('打球', '打')\t('打球', '打')\n",
      "姿态的姿还可以组什么词\t姿态的姿可以组什么词\t1\t('姿态', '姿')\t('姿态', '姿')\n",
      "瀑布的瀑组词\t玫瑰的玫组词\t0\t('瀑布', '瀑')\t('玫瑰', '玫')\n",
      "愣住的愣怎么组词\t愣住的愣组词\t1\t('愣住', '愣')\t('愣住', '愣')\n",
      "呵呵的呵组词\t掩护的掩组词\t0\t('呵呵', '呵')\t('掩护', '掩')\n",
      "眼睛的睛可以组什么词\t眼睛的睛还可以组什么词\t0\t('眼睛', '睛')\t('眼睛', '睛')\n",
      "牡丹的牡怎么组词\t牡丹的牡组词\t1\t('牡丹', '牡')\t('牡丹', '牡')\n",
      "存在的在组词\t还在的在组词\t0\t('存在', '在')\t('还在', '在')\n",
      "粮食的粮怎么组词\t细菌的菌怎么组词\t0\t('粮食', '粮')\t('细菌', '菌')\n",
      "post2.py:683: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  ~data.text_a.str.contains('(多音字|读音|怎么读|啥意思)'))].iterrows():\n",
      "企业帐户怎么开通\t企业账户怎么开通\t1\n",
      "小腹坠胀怎么回事\t小腹赘胀怎么回事\t1\n",
      "肝功能挂什么科\t肝工能挂什么科\t0\n",
      "如何注册微信号\t如和注册微信号\t0\n",
      "支原体感染传染吗\t支原体感染传染嘛\t1\n",
      "什么是硬下疳\t什么是硬下甘\t0\n",
      "嘴巴周围长痘\t嘴吧周围长痘\t0\n",
      "怎么去螨虫\t怎么去满虫\t0\n",
      "蓝牙音箱什么牌子最好\t蓝牙音响什么牌子最好\t0\n",
      "经期可以喝红酒吗\t经期可以何红酒吗\t0\n",
      "阿迪达斯的标志\t阿迪达斯得标志\t0\n",
      "西葫芦怎么做好吃\t西胡芦怎么做好吃\t0\n",
      "日元兑人民币汇率今日\t日元对人民币汇率今日\t1\n",
      "你他妈是什么意思\t你她妈是什么意思\t0\n",
      "中国出名的民宿\t中国著名的民宿\t0\n",
      "眼睛有血丝是怎么回事\t眼睛有血丝是怎麼回事\t0\n",
      "膏药贴多久\t膏药铁多久\t0\n",
      "荨麻疹能用盐水洗吗\t荨麻疹能用盐水洗么\t0\n",
      "后背疼是怎么回事\t后北疼是怎么回事\t0\n",
      "乙型肝炎表面抗体阳性是什么意思\t乙性肝炎表面抗体阳性是什么意思\t0\n",
      "天花是水痘吗\t天花是水痘么\t0\n",
      "拔罐起水泡是什么原因\t拔罐七水泡是什么原因\t0\n",
      "吃什么长卵泡\t吃什么张卵泡\t0\n",
      "肠胃炎会发烧吗\t肠胃炎会发烧嘛\t1\n",
      "拉肚子可以喂母乳吗\t拉肚子可以喂母乳么\t0\n",
      "月经期可以吃逍遥丸吗\t月经期可以吃逍遥丸么\t0\n",
      "身上有红点是怎么回事\t身上有红点是怎么会事\t0\n",
      "鱼刺卡在喉咙怎么办\t鱼刺恰在喉咙怎么办\t1\n",
      "孕期能吃烧烤吗\t孕期能吃烧烤嘛\t0\n",
      "老人补钙哪个牌子好\t老人补钙那个牌子好\t0\n",
      "糖尿病能吃苹果吗\t塘尿病能吃苹果吗\t0\n",
      "内分泌失调怎么检查\t内分泌时调怎么检查\t1\n",
      "cad如何调线型\tcad如何调线形\t1\n",
      "产妇能吃菠萝蜜吗\t产妇能吃波萝蜜吗\t0\n",
      "脉搏85正常吗\t脉博85正常吗\t0\n",
      "周公解梦梦见蛇\t周工解梦梦见蛇\t1\n",
      "鼻咽癌可以治愈吗\t鼻咽癌可以治愈么\t0\n",
      "便秘会便血吗\t便秘会便血嘛\t0\n",
      "新生儿打嗝怎么办\t新生儿打嗝怎么半\t0\n",
      "2月27日是什么星座\t2月27日是什么星坐\t1\n",
      "脸上毛孔大怎么办\t脸上毛空大怎么办\t0\n",
      "绝经前的症状\t绝经前的证状\t1\n",
      "社区戒毒期限\t社区解毒期限\t1\n",
      "什么情况下需要做胃镜\t什么情况下需要作胃镜\t0\n",
      "什么东西补肾\t什么东西布肾\t0\n",
      "手腕酸痛是怎么回事\t手湾酸痛是怎么回事\t0\n",
      "怀孕可以吃提子吗\t怀孕可以吃提子么\t1\n",
      "来月经能喝酒吗\t来月经能和酒吗\t0\n",
      "碘伏涂伤口疼吗\t碘伏图伤口疼吗\t1\n",
      "牙齿疼怎么办\t芽齿疼怎么办\t0\n",
      "灰指甲传染吗\t灰指甲转染吗\t0\n",
      "心脏不好吃什么\t心脏不好吃什药\t1\n",
      "如何恢复视力\t如何会复视力\t1\n",
      "蒲公英能降血压吗\t蒲公英能将血压吗\t0\n",
      "来例假可以拔牙吗\t来历假可以拔牙吗\t0\n",
      "咽炎吃什么药效果最好\t咽严吃什么药效果最好\t0\n",
      "黑头怎么去掉\t黒头怎么去掉\t1\n",
      "最强nba钻石艾弗森怎么加点\t最强nba钻石艾佛森怎么加点\t1\n",
      "包皮龟头炎\t包皮鬼头炎\t0\n",
      "湿疹可以吃生蚝吗\t湿疹可以吃生蚝嘛\t0\n",
      "大便带血是怎么回事\t大变带血是怎么回事\t0\n",
      "小孩出水痘怎么办\t小孩出水逗怎么办\t0\n",
      "胆囊炎可以吃红薯吗\t胆囊炎可以吃红薯嘛\t0\n",
      "经常口腔溃疡是什么原因\t经长口腔溃疡是什么原因\t0\n",
      "怎样去除眼袋\t怎样去处眼袋\t0\n",
      "苏打水有什么作用\t苏大水有什么作用\t0\n",
      "手机刷机怎么刷\t手机耍机怎么刷\t0\n",
      "孕妇可以吃核桃吗\t孕妇可以吃核桃嘛\t0\n",
      "孕妇能吃卤肉吗\t孕妇能吃卤肉么\t0\n",
      "豆芽的营养价值\t豆芽得营养价值\t0\n",
      "脸形胖的适合什么发型\t脸型胖的适合什么发型\t1\n",
      "宝宝几个月翻身\t宝宝几个月反身\t1\n",
      "枸杞泡水喝有什么好处\t苟杞泡水喝有什么好处\t0\n",
      "月经期间怎么减肥\t月经其间怎么减肥\t0\n",
      "苹果云端在哪里登录\t苹果云端在哪里登陆\t1\n",
      "你是机器人么\t你是机器人吗\t1\n",
      "如何治疗荨麻疹\t如何治疗寻麻疹\t0\n",
      "平行四边形的面积公式是什么\t平行四边行的面积公式是什么\t0\n",
      "词藻华丽的近义词\t辞藻华丽的近义词\t1\n",
      "喝柠檬水有什么好处\t和柠檬水有什么好处\t1\n",
      "拉肚子可以吃西瓜吗\t拉肚子可以吃西瓜么\t0\n",
      "人流后可以吃水果吗\t人流厚可以吃水果吗\t0\n",
      "怎么去除扁平疣\t怎么去除扁平尤\t0\n",
      "小孩腹泻吃什么药好得快\t小孩腹泻吃什么药好的快\t0\n",
      "乙肝会传染吗\t乙肝会传染么\t0\n",
      "儿童流鼻血是什么原因\t儿童留鼻血是什么原因\t0\n",
      "支气管炎传染吗\t支气管炎传染嘛\t1\n",
      "心肌缺血的症状\t心肌缺血得症状\t0\n",
      "高血压可以坐飞机吗\t高血压可以坐飞机嘛\t0\n",
      "1安培等于多少库仑\t1安培等于多少库伦\t0\n",
      "咖啡能加红茶吗\t咖啡能加红茶吗\t1\n",
      "我国的四大发明是什么\t我国的四大发名是什么\t0\n",
      "急性白血病有哪些症状\t急性白血病有那些症状\t0\n",
      "月经提前半个月正常吗\t月经提前半个月正常么\t0\n",
      "喝头孢能喝酒吗\t和头孢能喝酒吗\t0\n",
      "乙型肝炎表面抗体阳性是什么意思\t已型肝炎表面抗体阳性是什么意思\t0\n",
      "家常菜都有哪些\t家常菜都有那些\t0\n",
      "脂肪肝可以吃生蚝吗\t脂肪肝可以吃生蚝么\t0\n",
      "豆浆会发胖吗\t豆浆会发胖么\t1\n",
      "阿长与山海经滴主要内容是什么\t阿长与山海经的主要内容是什么\t0\n",
      "牌照能换吗\t牌照能换嘛\t0\n",
      "人流后多久可以洗澡\t人流厚多久可以洗澡\t0\n",
      "吃什么补气血\t吃什么布气血\t0\n",
      "孕妇可以吃鸭血吗\t孕妇可以吃鸭血么\t0\n",
      "空腹可以吃香蕉吗\t空腹可以吃香蕉嘛\t1\n",
      "先有鸡还是先有蛋\t先右鸡还是先有蛋\t1\n",
      "月经期能喝柠檬水吗\t月经期能喝宁檬水吗\t0\n",
      "哺乳期能吃马齿苋吗\t哺乳期能吃马齿苋嘛\t0\n",
      "豆浆补羊水吗\t豆浆补羊水妈\t0\n",
      "慢性阑尾炎需要手术吗\t慢性阑尾炎需要手术嘛\t0\n",
      "怀孕能吃鲍鱼吗\t怀孕能吃鲍鱼么\t0\n",
      "打狂犬疫苗注意事项\t大狂犬疫苗注意事项\t0\n",
      "荨麻疹能吃姜\t寻麻疹能吃姜\t0\n",
      "今天是什么节日\t今天是什麼节日\t0\n",
      "早上空腹可以吃苹果吗\t早上空复可以吃苹果吗\t0\n",
      "阿迪达斯的标志\t啊迪达斯的标志\t1\n",
      "怎么分辨公鸭母鸭\t怎么分辩公鸭母鸭\t0\n",
      "血液粘稠吃什么药\t血液沾稠吃什么药\t1\n",
      "猝死的前兆是什么\t促死的前兆是什么\t0\n",
      "月经前几天白带会增多吗\t月经前几天白带会增多么\t1\n",
      "带状疱疹会自愈吗\t带状泡疹会自愈吗\t1\n",
      "过敏性鼻炎可以根治吗\t过敏性鼻炎可以根治么\t0\n",
      "阿斯匹林作用\t阿司匹林作用\t0\n",
      "早上空腹喝蜂蜜水好吗\t早上空腹和蜂蜜水好吗\t0\n",
      "不锈钢锅可以熬中药吗\t不绣钢锅可以熬中药吗\t1\n",
      "什么是内分泌失调\t什么是内分必失调\t0\n",
      "中暑会拉肚子吗\t中暑会啦肚子吗\t0\n",
      "韩语姐姐怎么说\t汉语姐姐怎么说\t0\n",
      "宝宝咳嗽流鼻涕怎么办\t宝宝咳嗽留鼻涕怎么办\t0\n",
      "乳房疼是怎么回事\t乳房疼是怎么回是\t0\n",
      "来月经可以运动吗\t来月经可以运动么\t1\n",
      "唾液可以传播艾滋病吗\t唾液可以传播爱滋病吗\t0\n",
      "喉咙痛流鼻涕吃什么药\t喉咙痛留鼻涕吃什么药\t0\n",
      "腿疼是什么原因\t腿疼是什么愿因\t0\n",
      "孝感哪个厂工资高\t孝感那个厂工资高\t0\n",
      "怀孕了还会来月经吗\t怀孕了还回来月经吗\t0\n",
      "茭头炒肉的做法\t荞头炒肉的做法\t0\n",
      "吃什么能提高免疫力\t吃什么能提高勉疫力\t1\n",
      "来月经能吃生蚝吗\t来月经能吃生蚝么\t1\n",
      "月经来了可以洗头吗\t月经来了可以洗头么\t0\n",
      "熬夜喝什么好\t敖夜喝什么好\t0\n",
      "黄瓜片敷脸有什么好处\t黄瓜片肤脸有什么好处\t0\n",
      "手术后能吃海鲜吗\t手术后能吃海鲜嘛\t0\n",
      "大姨妈期间可以拔牙吗\t大姨妈期间可以拔牙嘛\t0\n",
      "开塞露怎么用\t凯塞露怎么用\t0\n",
      "妊娠糖尿病能吃什么水果\t任娠糖尿病能吃什么水果\t0\n",
      "甲硝唑栓的作用与用途\t甲硝坐栓的作用与用途\t0\n",
      "怀孕能吃黄桃罐头吗\t怀孕能吃黄桃罐头嘛\t1\n",
      "烧心是怎么回事\t烧心是怎么会事\t0\n",
      "戴避孕套会怀孕吗\t带避孕套会怀孕吗\t0\n",
      "大便不成型\t大便不成性\t1\n",
      "吃李子会胖吗\t吃李子会胖么\t0\n",
      "哺乳期可以吃阿莫西林胶囊吗\t哺乳期可以吃啊莫西林胶囊吗\t0\n",
      "孕妇什么时候开始补钙\t孕服什么时候开始补钙\t1\n",
      "交感神经型颈椎病症状\t交感神经型颈椎病证状\t0\n",
      "来例假能洗澡吗\t来例假能洗澡么\t1\n",
      "右下腹是什么器官\t又下腹是什么器官\t0\n",
      "请假条的格式\t请加条的格式\t0\n",
      "熬夜有什么危害\t熬夜有什么威害\t0\n",
      "逍遥丸什么时候吃好\t消遥丸什么时候吃好\t1\n",
      "体检前可以抽烟吗\t体检前可以抽烟么\t1\n",
      "感冒可以吃生蚝吗\t感冒可以吃生蚝么\t0\n",
      "淤血淤青怎么消除\t瘀血淤青怎么消除\t0\n",
      "梭子蟹孕妇能吃吗\t梭子蟹孕妇能吃么\t1\n",
      "脚底出汗是什么原因\t脚底出汉是什么原因\t1\n",
      "社区戒毒期限\t社区介毒期限\t1\n",
      "地板砖什么样的好\t底板砖什么样的好\t0\n",
      "白矾的功效与作用\t百矾的功效与作用\t1\n",
      "肠胃炎的症状\t长胃炎的症状\t0\n",
      "脚底板痒是怎么回事\t脚底版痒是怎么回事\t0\n",
      "荨麻疹是什么症状\t荨麻诊是什么症状\t0\n",
      "膝盖痛是什么原因\t息盖痛是什么原因\t0\n",
      "经期能喝菊花茶吗\t经期能和菊花茶吗\t0\n",
      "宝宝缺钙的表现\t宝宝确钙的表现\t0\n",
      "萨达姆是哪国的\t撒达姆是哪国的\t0\n",
      "来例假能喝中药\t来历假能喝中药\t0\n",
      "做完人流可以吃巧克力吗\t做完人流可以吃巧克力么\t1\n",
      "甲状腺结节能吃海带吗\t甲状腺结节能给海带吗\t0\n",
      "心率不齐的症状\t心率不齐得症状\t1\n",
      "怀孕肚子胀怎么回事\t怀孕肚子涨怎么回事\t1\n",
      "慢性胃炎能根治吗\t慢性胃炎能根治嘛\t0\n",
      "小儿急性喉炎吃什么药\t小二急性喉炎吃什么药\t0\n",
      "月经期可以喝益母草吗\t月经期可以喝益母草嘛\t1\n",
      "脑梗塞病人吃什么食物好\t脑更塞病人吃什么食物好\t1\n",
      "快来月经体温会升高吗\t快来月经体温会升高嘛\t0\n",
      "幽门螺旋杆菌的三联疗法\t幽门螺旋杆菌的三连疗法\t0\n",
      "糖尿病人可以吃银耳吗\t糖尿病人可以吃银耳嘛\t0\n",
      "例假前白带会增多吗\t例假前白带会增多嘛\t0\n",
      "我国汛期最长的河流\t我过汛期最长的河流\t0\n",
      "尿毒症的症状有哪些\t尿毒症的症状有那些\t0\n",
      "慢性咽炎会自己好吗\t慢性咽炎会自己好嘛\t0\n",
      "脚底长水泡是什么原因\t脚底长水疱是什么原因\t0\n",
      "淋巴严重吗\t淋巴严重么\t0\n",
      "怀孕可以吃麻油吗\t怀孕可以吃麻油么\t0\n",
      "小腹胀痛是怎么回事\t小腹长痛是怎么回事\t0\n",
      "结节是肿瘤吗\t结节事肿瘤吗\t0\n",
      "吃什么增强免疫力\t吃什么增强勉疫力\t0\n",
      "写字的正确笔画\t写字的正确笔划\t0\n",
      "拔智齿脸会变小吗\t拔智齿脸会变小么\t0\n",
      "大便黑是怎么回事\t大便黒是怎么回事\t0\n",
      "脚底长鸡眼怎么办\t角底长鸡眼怎么办\t0\n",
      "哪里批发服装最便宜\t那里批发服装最便宜\t1\n",
      "慢性胃炎可以吃鱼子吗\t慢性胃炎可以吃鱼籽吗\t1\n",
      "咳嗽吃什么\t咳嗽给什么\t1\n",
      "拉肚子会头晕吗\t拉肚子会头晕嘛\t0\n",
      "右腹部疼痛\t又腹部疼痛\t0\n",
      "学生什么时候放假\t学生什么时侯放假\t1\n",
      "哺乳期可以喝板蓝根吗\t哺乳期可以喝板蓝根嘛\t0\n",
      "吃榴莲上火吗\t吃榴莲上火么\t0\n",
      "艺伎线条多少钱\t艺妓线条多少钱\t0\n",
      "苹果手机通讯录怎么批量删除\t苹果手机通迅录怎么批量删除\t0\n",
      "泰迪可以吃米饭吗\t泰迪可以吃米饭嘛\t0\n",
      "悲恸近义词\t悲痛近义词\t1\n",
      "月经期间能拔牙吗\t月经其间能拔牙吗\t1\n",
      "怀孕能喝咖啡吗\t怀孕能和咖啡吗\t0\n",
      "下腹痛怎么回事\t下复痛怎么回事\t0\n",
      "枸杞子的功效与作用\t苟杞子的功效与作用\t1\n",
      "孩子脸上有白斑是怎么回事\t孩子脸上有白班是怎么回事\t0\n",
      "颈椎痛怎么缓解\t劲椎痛怎么缓解\t0\n",
      "又人工服务吗\t由人工服务吗\t1\n",
      "肚子痛拉肚子怎么办\t肚子痛啦肚子怎么办\t0\n",
      "叶绍翁是哪个朝代的\t叶少翁是哪个朝代的\t0\n",
      "盆腔积液是什么\t盆腔积夜是什么\t0\n",
      "国内航班要护照吗\t国内航班要护照嘛\t0\n",
      "尿毒症有什么症状\t尿毒证有什么症状\t0\n",
      "伦敦以什么出名\t伦敦以什么著名\t0\n",
      "胃病能治好吗\t胃病能治好么\t0\n",
      "近视眼会得老花眼吗\t近视眼会得老花眼么\t0\n",
      "慢性肾炎会遗传吗\t慢性肾炎会遗传么\t0\n",
      "胃炎可以喝酸奶吗\t胃炎可以喝酸奶么\t0\n",
      "双氧水洗耳朵\t双阳水洗耳朵\t0\n",
      "世界上最小的国家\t事界上最小的国家\t0\n",
      "如何注销微信号\t如何注销微信好\t0\n",
      "双侧肾盂未见明显分离是什么意思\t双测肾盂未见明显分离是什么意思\t1\n",
      "大便频繁是怎么回事\t大便频烦是怎么回事\t0\n",
      "人参的功效\t人参得功效\t0\n",
      "核磁共振影响怀孕吗\t核磁共振影响怀孕嘛\t0\n",
      "红细胞计数偏高是什么原因\t红细胞记数偏高是什么原因\t1\n",
      "怎么看苹果手机真假\t怎么看平果手机真假\t0\n",
      "老虎狮子谁厉害\t老虎狮子谁历害\t0\n",
      "泌尿结石吃什么可以排石\t秘尿结石吃什么可以排石\t1\n",
      "绿豆解药吗\t绿豆接药吗\t1\n",
      "怎么去黑头\t怎要去黑头\t0\n",
      "经常放屁是什么原因\t经常放屁是什么愿因\t1\n",
      "膝盖可以拔罐吗\t膝盖可以拔罐嘛\t1\n",
      "做胃镜需要空腹吗\t作胃镜需要空腹吗\t0\n",
      "流产后几天可以出门\t留产后几天可以出门\t1\n",
      "心率不齐严重吗\t心率不齐严重嘛\t0\n",
      "消防拴漏水\t消防栓漏水\t1\n",
      "胆汁反流性胃炎的症状\t胆汁返流性胃炎的症状\t0\n",
      "长期大便不成形是什么原因\t长期大便不成型是什么原因\t0\n",
      "孕妇可以吃辣椒吗\t孕妇可以吃辣椒嘛\t0\n",
      "怀孕初期吃什么好\t坏孕初期吃什么好\t1\n",
      "湿热体质怎么调理\t湿热体制怎么调理\t1\n",
      "月经期可以运动吗\t月经期可以运动么\t0\n",
      "鼻窦炎的症状有哪些\t鼻窦炎得症状有哪些\t0\n",
      "眼睛的英文是什么\t眼镜的英文是什么\t0\n",
      "怀孕一定会孕吐吗\t怀孕一定会孕吐嘛\t0\n",
      "肠胃炎吃什么药\t常胃炎吃什么药\t0\n",
      "喝牛奶腹泻\t和牛奶腹泻\t1\n",
      "带状疱疹的症状\t带状疱疹的正状\t0\n",
      "中暑会拉肚子吗\t中暑会拉肚子么\t0\n",
      "无花果糖尿病人能吃吗\t无花果糖尿并人能吃吗\t0\n",
      "前列腺增生有什么症状\t前列腺增生有什么症壮\t0\n",
      "孩子上火流鼻血怎么办\t孩子上火留鼻血怎么办\t1\n",
      "测血糖需要空腹吗\t侧血糖需要空腹吗\t1\n",
      "产妇能吃茄子吗\t产妇能吃茄子么\t1\n",
      "坐月子可以吃花菜吗\t坐月子可以吃花菜么\t0\n",
      "今天属什么生肖\t今天数什么生肖\t0\n",
      "蒲公英泡水喝的功效\t朴公英泡水喝的功效\t0\n",
      "怎样才能让腿变细\t怎样才能让退变细\t1\n",
      "排卵期有几天\t排卵期又几天\t1\n",
      "孕妇可以喝金银花茶吗\t孕妇可以喝紧银花茶吗\t0\n",
      "息屏时间\t熄屏时间\t1\n",
      "怀孕可以吃乳酸菌素片吗\t怀孕可以吃乳酸菌素片么\t1\n",
      "车架号是什么\t车加号是什么\t0\n",
      "经常喝柠檬蜂蜜水好吗\t经常喝柠檬蜂蜜水好么\t0\n",
      "怀孕能吃冷面吗\t怀孕能吃冷面么\t0\n",
      "每天大便三次正常吗\t每天大便三次正常么\t1\n",
      "肩周炎看哪个科室\t肩周炎看那个科室\t1\n",
      "坐飞机能带充电宝吗\t做飞机能带充电宝吗\t0\n",
      "腹腔淋巴结肿大的症状\t腹腔淋巴结肿大的证状\t1\n",
      "大三阳是什么\t大三样是什么\t1\n",
      "喝蜂蜜水能减肥吗\t喝蜂密水能减肥吗\t0\n",
      "山药的功效与作用\t山药的功效与做用\t1\n",
      "白内障怎么治疗\t百内障怎么治疗\t0\n",
      "黑豆的功效与作用\t黑豆的功效与做用\t0\n",
      "肌肉腿怎么瘦\t肌肉腿怎么收\t1\n",
      "六类网线的标识\t六类网线的标志\t0\n",
      "新生儿打嗝怎么办\t心生儿打嗝怎么办\t1\n",
      "卖零食赚钱吗\t卖零食赚钱么\t0\n",
      "达克宁治脚气吗\t达客宁治脚气吗\t0\n",
      "高血压怎么治疗\t高血压怎么治辽\t0\n",
      "社保局周末上班吗\t社保局周末上班么\t0\n",
      "甲状腺结节钙化是怎么回事\t甲状腺结节丐化是怎么回事\t1\n",
      "real原声技术哪样\treal原生技术哪样\t1\n",
      "丙肝会传染吗\t丙肝会传染嘛\t1\n",
      "铁皮石斛的功效与作用\t铁皮石胡的功效与作用\t1\n",
      "梅毒的症状有哪些\t梅毒的症状有那些\t0\n",
      "洛阳晚上哪里好玩\t洛阳晚上那里好玩\t0\n",
      "痛风不能吃哪些食物\t痛风不能吃那些食物\t0\n",
      "好听的英文名字\t好听的英问名字\t0\n",
      "肾结石可以喝红茶吗\t肾结石可以和红茶吗\t0\n",
      "赞美教室的句子\t赞美教师的句子\t1\n",
      "甲状腺结节可以吃燕窝吗\t甲状腺结节可以吃燕窝嘛\t0\n",
      "膀胱炎的症状\t膀胱炎的证状\t0\n",
      "白癜风怎么治疗\t白电风怎么治疗\t0\n",
      "薏米的功效与作用\t苡米的功效与作用\t0\n",
      "孕妇可以吃板栗吗\t孕妇可以吃板栗嘛\t0\n",
      "解脲支原体阳性好治吗\t解脲支原体阳性好治么\t1\n",
      "怀孕会犯困吗\t怀孕回犯困吗\t0\n",
      "背诵有什么好处\t背诵有什么好处\t1\n",
      "脚趾甲有瘀血怎么办\t脚趾甲有淤血怎么办\t0\n",
      "来月经可以喝蜂蜜水吗\t来月经可以喝蜂密水吗\t1\n",
      "怎样排肝毒\t怎样拍肝毒\t0\n",
      "跳绳能减肥吗\t跳绳能减肥嘛\t0\n",
      "老是放屁是怎么回事\t老是放屁是怎麼回事\t1\n",
      "8月27日是什么星座\t8月27日是什么星坐\t0\n",
      "房性早搏是怎么回事\t房行早搏是怎么回事\t0\n",
      "孕妇可以吃甜瓜吗\t孕妇可以吃甜瓜嘛\t0\n",
      "芦荟可以直接擦脸吗\t芦会可以直接擦脸吗\t0\n",
      "腺肌症能怀孕吗\t腺肌症能怀孕嘛\t0\n",
      "幽门螺旋杆菌会传染吗\t由门螺旋杆菌会传染吗\t1\n",
      "吃完榴莲不能吃什么\t吃完榴连不能吃什么\t0\n",
      "喝藿香正气水能喝酒吗\t和藿香正气水能喝酒吗\t0\n",
      "带状疱疹是怎么引起的\t带壮疱疹是怎么引起的\t0\n",
      "大便出血是怎么回事\t大变出血是怎么回事\t0\n",
      "乙型肝炎表面抗体呈阳性是什么意思\t乙型肝炎表面抗体成阳性是什么意思\t0\n",
      "来例假可以吃榴莲吗\t来历假可以吃榴莲吗\t1\n",
      "右胸口疼是怎么回事\t友胸口疼是怎么回事\t1\n",
      "怎么测怀孕\t怎么册怀孕\t1\n",
      "莲子孕妇可以吃吗\t莲子孕妇可以吃么\t0\n",
      "前列腺炎吃什么药\t前列线炎吃什么药\t1\n",
      "霉菌性阴道炎\t霉菌行阴道炎\t0\n",
      "细辛的功效与作用\t细心的功效与作用\t0\n",
      "哮喘能根治吗\t哮喘能跟治吗\t0\n",
      "怎么去除狐臭\t怎麼去除狐臭\t0\n",
      "脂肪肝是什么症状\t脂肪肝是什么证状\t0\n",
      "杨幂和刘恺威真的复合了吗\t杨幂和刘凯威真的复合了吗\t1\n",
      "韩国化妆品有哪些品牌\t韩国化妆品有那些品牌\t0\n",
      "无线鼠标没反应\t无限鼠标没反应\t0\n",
      "膝盖痛怎么回事\t膝盖痛怎么会事\t0\n",
      "怀孕初期可以吃牛油果吗\t怀孕初期可以吃牛油果么\t0\n",
      "历史朝代表\t历时朝代表\t1\n",
      "桥本氏甲减会遗传吗\t桥本氏甲减会遗传么\t0\n",
      "做血管造影要多少钱\t作血管造影要多少钱\t1\n",
      "颈椎病会引起头痛吗\t颈椎病会引起头痛嘛\t0\n",
      "什么是寒性体质\t什么事寒性体质\t0\n",
      "怀孕多久可以药流\t怀孕多久可以药留\t0\n",
      "腰肌劳损怎么治疗\t腰肌劳损怎么治辽\t1\n",
      "白花蛇舌草功效与作用\t白花蛇蛇草功效与作用\t0\n",
      "扁桃体发炎化脓吃什么药\t扁桃体发炎化浓吃什么药\t0\n",
      "毕业赠言给老师的\t毕业增言给老师的\t0\n",
      "怎么才能长高\t怎麼才能长高\t0\n",
      "孕妇可以吃鸡胗吗\t孕妇可以吃鸡胗么\t1\n",
      "郑爽张翰结婚了吗\t郑爽张翰结婚了么\t0\n",
      "痘坑痘印怎么修复\t都坑痘印怎么修复\t0\n",
      "胃肠功能紊乱的症状\t胃肠工能紊乱的症状\t0\n",
      "戴牙套要多少费用\t带牙套要多少费用\t1\n",
      "家长意见和建议\t家长意见和建意\t1\n",
      "菠菜和鸡蛋能一起吃吗\t波菜和鸡蛋能一起吃吗\t0\n",
      "手被油烫了怎么办\t手背油烫了怎么办\t1\n",
      "如何治疗打呼噜\t如何治疗大呼噜\t0\n",
      "希腊属于哪个州\t希腊属于那个州\t0\n",
      "怀孕能吃消炎药嘛\t怀孕能吃消炎药吗\t1\n",
      "结婚祝贺词\t结婚祝合词\t0\n",
      "怎么通过随心贴登陆别人账号\t怎么通过随心贴登录别人账号\t1\n",
      "肚子大怎么减\t肚子打怎么减\t0\n",
      "怀孕初期白带多是怎么回事\t怀孕出期白带多是怎么回事\t0\n",
      "容易出汗怎么办\t容易出汗怎么半\t0\n",
      "四川在哪个地震带\t四川在那个地震带\t0\n",
      "经期前体温会升高吗\t经期前体温会升高么\t1\n",
      "热敷消肿吗\t热敷消肿嘛\t1\n",
      "发烧可以吹空调吗\t发烧可以吹空调么\t1\n",
      "晚上咳嗽厉害怎么办\t晚上咳嗽历害怎么办\t0\n",
      "孕妇可以吃海带吗\t孕妇可以吃海带么\t1\n",
      "月经后几天容易怀孕\t月精后几天容易怀孕\t0\n",
      "心血管堵塞\t新血管堵塞\t0\n",
      "不吃米饭只吃菜能瘦吗\t不吃米饭只吃菜能瘦么\t0\n",
      "脚底脱皮怎么办\t脚底脱皮怎么半\t0\n",
      "血糖偏高怎么办\t血唐偏高怎么办\t0\n",
      "皮肤过敏的症状\t皮肤过敏的正状\t0\n",
      "尿液有泡沫是怎么回事\t尿液有泡末是怎么回事\t1\n",
      "子宫切除有什么影响\t自宫切除有什么影响\t1\n",
      "晚上吃苹果好吗\t晚上吃苹果好嘛\t1\n",
      "陕西和四川有多远\t山西和四川有多远\t0\n",
      "转氨酶高有什么症状\t转氨酶高有什么证状\t0\n",
      "神经衰弱的症状\t神经衰弱的整状\t0\n",
      "痛经可以吃止疼药吗\t痛经可以吃止疼药么\t1\n",
      "喝豆浆有什么好处\t和豆浆有什么好处\t0\n",
      "吃减肥药会反弹吗\t吃减肥药会反弹么\t0\n",
      "痛风能吃虾皮吗\t痛风能吃虾皮么\t0\n",
      "安阳有那些县\t安阳有哪些县\t1\n",
      "别人欠钱不还怎么办\t别人歉钱不还怎么办\t0\n",
      "月经期可以泡脚吗\t月经期可以泡脚么\t0\n",
      "哺乳期可以拔罐吗\t哺乳期可以拔罐嘛\t0\n",
      "卡莎哪个皮肤\t卡沙哪个皮肤\t0\n",
      "老是放臭屁是怎么回事\t老是防臭屁是怎么回事\t0\n",
      "月经推迟吃什么药\t月经退迟吃什么药\t1\n",
      "来大姨妈能洗头吗\t来大姨妈能洗头么\t0\n",
      "抑郁症如何治疗\t抑郁正如何治疗\t0\n",
      "电饼铛哪个牌子好\t电饼挡哪个牌子好\t0\n",
      "如何戴假发\t如何带假发\t1\n",
      "乳腺增生能不能吃蜂蜜\t乳腺增升能不能吃蜂蜜\t1\n",
      "长治市二甲医院有那些\t长治市二甲医院有哪些\t1\n",
      "柳州到兖州火车时刻表\t柳州到广州火车时刻表\t0\n",
      "膝关节韧带损伤\t膝关节忍带损伤\t0\n",
      "湿疹可以吃苦瓜吗\t湿疹可以吃苦瓜嘛\t0\n",
      "来大姨妈能洗头吗\t来大姨妈能洗头嘛\t1\n",
      "怎样清洗羽绒服\t怎样请洗羽绒服\t0\n",
      "哪个星座男人最好\t那个星座男人最好\t1\n",
      "宝宝拉肚子能吃酸奶吗\t宝宝拉肚子能吃酸奶嘛\t0\n",
      "精油可以去痘印吗\t精油可以去痘印嘛\t0\n",
      "手脱皮怎么回事\t手脱皮怎么会事\t1\n",
      "宝宝一直流鼻涕怎么办\t宝宝一直留鼻涕怎么办\t1\n",
      "六味地黄丸怎么样\t六位地黄丸怎么样\t0\n",
      "感冒喝什么药\t感冒和什么药\t0\n",
      "高血压能吃带鱼吗\t高血压能吃带鱼么\t0\n",
      "糖尿病能治好吗\t糖尿病能治好么\t1\n",
      "金毛能吃菠萝吗\t金毛能吃菠萝么\t0\n",
      "银行卡怎么激活\t银行卡怎么几活\t0\n",
      "肾虚脱发怎么治疗\t肾虚脱发怎么治辽\t0\n",
      "糖尿病患者可以吃火龙果吗\t糖尿病患者可以吃火龙果嘛\t1\n",
      "贫血怎么办\t贫血怎么半\t0\n",
      "表示风的词语\t表是风的词语\t1\n",
      "女性更年期年龄\t女姓更年期年龄\t0\n",
      "端午节的习俗\t端午节的习素\t1\n",
      "吃橘子会回奶吗\t吃桔子会回奶吗\t1\n",
      "这是什么型号的\t这是什么性号的\t0\n",
      "肝硬化晚期症状\t肝硬化晚期正状\t0\n",
      "来月经可以喝蜂蜜水吗\t来月经可以喝蜂蜜水么\t1\n",
      "多囊卵巢综合征好治吗\t多囊卵巢综合征好治么\t0\n",
      "糖尿病患者可以吃火龙果吗\t糖尿病患者可以吃火龙果么\t1\n",
      "孕妇可以吃鸭肉吗\t孕妇可以吃鸭肉嘛\t0\n",
      "月经期间可以打消炎针吗\t月经其间可以打消炎针吗\t1\n",
      "打嗝怎么治\t打嗝怎么制\t0\n",
      "苹果手机怎么设置来电铃声\t平果手机怎么设置来电铃声\t0\n",
      "痛风能吃冰淇淋吗\t通风能吃冰淇淋吗\t0\n",
      "科目三考什么\t科目三考十么\t0\n",
      "什么叫其它事业单位\t什么叫其他事业单位\t1\n",
      "水浒传作者\t水浒转作者\t0\n",
      "来月经可以吃叶酸吗\t来月经可以吃叶酸么\t1\n",
      "月经期能吃西瓜吗\t月经期能吃西瓜嘛\t1\n",
      "做完人流可以敷面膜吗\t做完人流可以敷面膜嘛\t0\n",
      "牛奶可以和鸡蛋一起吃吗\t牛奶可以和鸡蛋一起吃么\t1\n",
      "蜂蜜的功效与作用\t蜂密的功效与作用\t1\n",
      "痔疮吃什么药好得快\t痔疮吃什么药好的快\t0\n",
      "脸上长斑怎么处理\t脸上长班怎么处理\t0\n",
      "怀孕第一个月有什么反应\t怀孕第一个月有什么反映\t0\n",
      "来月经可以喝豆浆吗\t来月经可以喝豆江吗\t0\n",
      "血压低是贫血吗\t血压低是贫血嘛\t1\n",
      "地中海贫血\t地种海贫血\t1\n",
      "手爆皮是怎么回事\t手报皮是怎么回事\t0\n",
      "吃什么补肾虚\t吃什么不肾虚\t0\n",
      "经期能吃菠萝蜜吗\t经期能吃菠萝密吗\t0\n",
      "玻尿酸一针多少钱\t玻尿酸一阵多少钱\t0\n",
      "高蛋白食物有哪些\t高蛋白食物有那些\t1\n",
      "哺乳期能吃茄子吗\t补乳期能吃茄子吗\t0\n",
      "月经可以吃红枣吗\t月经可以吃红枣嘛\t1\n",
      "拔罐拔出水泡怎么办\t拔管拔出水泡怎么办\t0\n",
      "补气血的药有哪些\t补气血的药有那些\t0\n",
      "外阴瘙痒用什么药好\t外因瘙痒用什么药好\t0\n",
      "梦见别人作手术\t梦见别人做手术\t0\n",
      "肾功能检查有哪些项目\t肾公能检查有哪些项目\t0\n",
      "做完人流多久复查\t昨完人流多久复查\t0\n",
      "脚气会传染到手上吗\t脚气会传染到手上嘛\t0\n",
      "梅尼埃病是什么病\t梅尼挨病是什么病\t1\n",
      "最好的避孕方法\t最好得避孕方法\t0\n",
      "排卵期胸会胀痛吗\t排卵期胸会胀痛么\t0\n",
      "孩子驼背如何矫正\t孩子驼背如何纠正\t0\n",
      "硫酸钙是沉淀吗\t硫酸钙是沉淀嘛\t0\n",
      "种植牙多少钱一颗\t种植牙多少钱一科\t0\n",
      "怎么变得高情商\t怎么变的高情商\t0\n",
      "照样子写词语\t朝样子写词语\t0\n",
      "脂肪肝可以吃猪肝吗\t脂肪肝可以吃猪肝么\t0\n",
      "下雨天可以艾灸吗\t下雨天可以艾灸么\t1\n",
      "糖尿病能喝无糖可乐吗\t糖尿病能喝无糖可乐么\t0\n",
      "孕晚期能吃冰棍吗\t孕晚期能吃冰棍么\t0\n",
      "孕妇能用皮炎平吗\t孕妇能用皮炎平么\t0\n",
      "艾滋病的传播途径有哪些\t艾滋病的传播途径有那些\t0\n",
      "水泡型脚气怎么办\t水泡性脚气怎么办\t0\n",
      "肺上有结节\t肺上有结界\t0\n",
      "刚来完月经是安全期吗\t刚来完月经是安全期嘛\t1\n",
      "发芽大蒜能吃吗\t发芽大蒜能吃么\t1\n",
      "被蜜蜂蛰了怎么处理\t被密蜂蛰了怎么处理\t1\n",
      "小孩补什么钙好\t小孩补什么盖好\t1\n",
      "孕妇吃葡萄干好吗\t孕妇吃葡萄干好么\t0\n",
      "10到30之间的合数\t10到30之间的合数\t1\n",
      "新生儿打嗝怎么回事\t新生儿打隔怎么回事\t0\n",
      "梦到自己被狗咬\t梦到自己备狗咬\t0\n",
      "孕初期可以吃榴莲吗\t孕初期可以吃榴莲么\t0\n",
      "纸船怎么折\t只船怎么折\t0\n",
      "梦见鞋跟断了\t梦见鞋根断了\t0\n",
      "葵花籽致癌吗\t葵花籽治癌吗\t0\n",
      "水痘结痂几天能掉\t水痘结痂几天能钓\t0\n",
      "治湿疹的药膏\t制湿疹的药膏\t0\n",
      "如何去除牙结石\t如何去除牙洁石\t0\n",
      "新生儿睡觉不踏实\t新声儿睡觉不踏实\t1\n",
      "一岁宝宝可以吃榴莲吗\t一岁宝宝可以吃榴莲嘛\t1\n",
      "胃食管反流吃什么药\t胃食馆反流吃什么药\t0\n",
      "包皮红肿怎么回事\t包皮红重怎么回事\t0\n",
      "乳腺结节需要手术吗\t乳腺结节须要手术吗\t1\n",
      "梦见已故的亲人\t梦见一故的亲人\t0\n",
      "肾结石面粉类可以吃吗\t肾结石面粉类可以吃嘛\t0\n",
      "手被辣椒辣了怎么办\t手被辣椒辣了怎么半\t0\n",
      "咳嗽能游泳吗\t咳嗽能游泳嘛\t0\n",
      "怎么去除黑眼圈\t怎么去处黑眼圈\t1\n",
      "葫芦的功效与作用\t葫芦的工效与作用\t0\n",
      "经期喝红糖水好吗\t经期和红糖水好吗\t1\n",
      "孕妇可以吃火腿肠吗\t孕妇可以吃火腿肠嘛\t0\n",
      "子宫肌瘤能吃鸡肉吗\t子宫几瘤能吃鸡肉吗\t0\n",
      "仓鼠吃大米吗\t仓鼠吃大米么\t1\n",
      "中国古代的文房四宝是什么\t中国古代的文防四宝是什么\t1\n",
      "怎么还原魔方\t怎么还原摩方\t1\n",
      "米黄色裤子配什么上衣\t米黄色裤子陪什么上衣\t1\n",
      "水果什么时候吃最好\t水果什么时侯吃最好\t0\n",
      "奶粉过期还能喝吗\t奶粉过期还能喝么\t1\n",
      "慢性浅表性胃炎伴糜烂\t慢性浅表性胃炎半糜烂\t0\n",
      "什么的波纹\t什么地波纹\t0\n",
      "坐月子能不能吃方便面\t做月子能不能吃方便面\t1\n",
      "环保手抄报内容\t环保手抄包内容\t0\n",
      "心堵的慌是怎么回事\t心堵得慌是怎么回事\t0\n",
      "碳酸钠是什么\t炭酸钠是什么\t0\n",
      "甲状腺手术后多久恢复\t甲状腺手术后多久回复\t0\n",
      "怀孕可以吃苹果吗\t怀孕可以吃苹果么\t0\n",
      "拔罐出水泡是怎么回事\t拔罐出水疱是怎么回事\t0\n",
      "已婚妇女戒指戴哪个手指\t已婚妇女戒指带哪个手指\t0\n",
      "心脏彩超多少钱\t心赃彩超多少钱\t0\n",
      "淋巴在哪个位置\t淋巴在那个位置\t0\n",
      "脸上长了脂肪粒怎么办\t脸上张了脂肪粒怎么办\t1\n",
      "支原体感染是什么意思\t支愿体感染是什么意思\t1\n",
      "尿浑浊是什么原因\t尿昏浊是什么原因\t1\n",
      "慢性荨麻疹吃什么好\t慢性寻麻疹吃什么好\t0\n",
      "过敏性鼻炎怎么治\t过敏星鼻炎怎么治\t0\n",
      "怎样申请微信号\t怎样身请微信号\t0\n",
      "荨麻疹能吃橙子吗\t寻麻疹能吃橙子吗\t0\n",
      "什么是更年期\t什麼是更年期\t0\n",
      "倒瓜子脸适合什么发型\t到瓜子脸适合什么发型\t1\n",
      "猫能吃鸡皮吗\t猫能吃鸡皮嘛\t0\n",
      "低回声是什么意思\t低回升是什么意思\t0\n",
      "白化病是遗传病吗\t白化病是遗传病嘛\t1\n",
      "心肌酶高怎么办\t心机酶高怎么办\t0\n",
      "股骨头坏死怎么治\t股骨头坏死怎么制\t1\n",
      "孕妇吃紫薯好吗\t孕妇吃紫薯好嘛\t0\n",
      "下颌骨错位\t下颌角错位\t0\n",
      "滴虫性阴道炎的症状\t滴虫性阴道炎的证状\t0\n",
      "甲状腺旁腺瘤严重吗\t甲状腺旁线瘤严重吗\t0\n",
      "减肥可以吃牛油果吗\t减肥可以吃牛油果嘛\t0\n",
      "偏头痛是什么原因\t翩头痛是什么原因\t0\n",
      "移动好还是联通好\t移动号还是联通好\t0\n",
      "小腿酸痛是什么原因\t小退酸痛是什么原因\t0\n",
      "甲亢会遗传吗\t甲亢回遗传吗\t0\n",
      "阑尾炎手术后可以吃蛋糕吗\t阑尾炎手术后可以吃蛋糕嘛\t0\n",
      "上腹胀是什么原因\t上腹帐是什么原因\t0\n",
      "怎么数胎动\t怎么书胎动\t0\n",
      "什么时候开学\t甚么时候开学\t0\n",
      "蒲公英的功效与作用\t蒲公英的工效与作用\t1\n",
      "孕妇能吃牛油果吗\t孕妇能吃牛油果妈\t1\n",
      "孕妇可以喝咖啡吗\t孕妇可以和咖啡吗\t1\n",
      "外阴瘙痒用什么药\t外阴瘙痒用什么要\t0\n",
      "咳嗽可以吃香瓜吗\t咳嗽可以吃香瓜么\t1\n",
      "怀孕初期可以吃李子吗\t怀孕初期可以吃李子嘛\t0\n",
      "分数怎么化成小数\t分数怎么划成小数\t0\n",
      "人流要做多久的月子\t人流要坐多久的月子\t0\n",
      "虎皮鹦鹉能吃大米吗\t虎皮鹦鹉能吃大米么\t0\n",
      "肩周炎怎么治疗\t见周炎怎么治疗\t0\n",
      "垃圾桶怎么折\t垃圾筒怎么折\t0\n",
      "小腿酸胀是怎么回事\t小腿酸帐是怎么回事\t0\n",
      "中联重科董事长是谁\t中联重科懂事长是谁\t0\n",
      "甲状腺球蛋白偏高\t甲状腺求蛋白偏高\t0\n",
      "萝卜樱怎么做好吃\t萝卜婴怎么做好吃\t1\n",
      "出名风水大师\t著名风水大师\t0\n",
      "甲状腺癌能吃豆制品吗\t甲壮腺癌能吃豆制品吗\t0\n",
      "精英律师带的表\t精英律师戴的表\t0\n",
      "怀孕初期出血\t怀孕出期出血\t0\n",
      "菠萝和鸡蛋能一起吃吗\t菠萝和鸡蛋能一起吃么\t1\n",
      "王健林哪里人\t王健林那里人\t1\n",
      "宽带密码怎么查\t宽带蜜码怎么查\t0\n",
      "益母草的功效与作用\t一母草的功效与作用\t1\n",
      "吃避孕药还会怀孕吗\t吃避孕要还会怀孕吗\t0\n",
      "梦遗正常吗\t梦遗正常么\t0\n",
      "艾灸可以天天灸吗\t艾灸可以天天灸嘛\t1\n",
      "坐骨神经痛吃什么药\t坐骨神精痛吃什么药\t0\n",
      "小孩长痱子怎么办\t小孩涨痱子怎么办\t1\n",
      "肚子胀是什么原因\t肚子帐是什么原因\t0\n",
      "孕妇可以吃烧仙草吗\t孕妇可以吃烧仙草嘛\t1\n",
      "脚底长鸡眼\t脚底张鸡眼\t1\n",
      "乙肝能自愈吗\t乙肝能自愈嘛\t0\n",
      "怎么在微信上卖东西\t怎么在微信上买东西\t0\n",
      "一直拉肚子是怎么回事\t一只拉肚子是怎么回事\t0\n",
      "无线路由器忘记密码怎么办\t无限路由器忘记密码怎么办\t0\n",
      "喉咙有痰怎么办\t喉咙有痰怎么半\t0\n",
      "运动可以减肥吗\t运动可以减肥么\t0\n",
      "尿道疼痛是什么原因\t尿道疼痛是甚么原因\t0\n",
      "翻山越岭什么生肖\t翻山越领什么生肖\t0\n",
      "新生儿打嗝怎么办\t新生儿打隔怎么办\t0\n",
      "什么是肠胃炎\t什么事肠胃炎\t0\n",
      "牙周炎吃什么药\t牙周炎吃什么要\t0\n",
      "什么是癔症\t什么事癔症\t0\n",
      "怀孕初期可以吃生蚝吗\t怀孕初期可以吃生蚝么\t1\n",
      "胃胀气怎么回事\t胃帐气怎么回事\t1\n",
      "六味地黄丸哪个牌子好\t六味地黄丸那个牌子好\t0\n",
      "女人会的疝气吗\t女人会得疝气吗\t0\n",
      "孕妇可以吃荠菜吗\t孕妇可以吃荠菜嘛\t0\n",
      "蜂蜜水什么时候喝好\t蜂蜜水什么时候和好\t0\n",
      "肠梗阻怎么治疗\t肠耿阻怎么治疗\t1\n",
      "浙江省会在哪里\t浙江省会在那里\t0\n",
      "办健康证需要空腹吗\t班健康证需要空腹吗\t0\n",
      "眼睛流泪怎么治\t眼睛流泪怎么制\t0\n",
      "吃了不消化怎么办\t吃了不消话怎么办\t0\n",
      "标志英语单词\t标识英语单词\t0\n",
      "月经期可以吃阿胶吗\t月经期可以吃阿胶嘛\t0\n",
      "水浒传作者\t水浒穿作者\t1\n",
      "痛风可以喝豆奶吗\t通风可以喝豆奶吗\t0\n",
      "怀孕能吃甲鱼吗\t怀孕能吃甲鱼么\t1\n",
      "肾炎严重吗\t肾炎严重嘛\t0\n",
      "胃溃疡什么症状\t胃溃阳什么症状\t0\n",
      "孕妇可以吃香菇吗\t孕妇可以吃香菇么\t0\n",
      "怀孕能吃橄榄菜吗\t怀孕能吃橄榄菜嘛\t0\n",
      "吃头孢可以喝啤酒吗\t吃头孢可以和啤酒吗\t0\n",
      "怎样排除体内湿毒\t怎样排出体内湿毒\t0\n",
      "现在什么电视剧好看\t先在什么电视剧好看\t1\n",
      "哺乳期可以烫发吗\t哺乳期可以汤发吗\t0\n",
      "关节响是怎么回事\t关结响是怎么回事\t1\n",
      "浅滋暗长的意思\t潜滋暗长的意思\t0\n",
      "色弱可以考驾照吗\t色弱可以考驾照么\t0\n",
      "女性内分泌失调吃什么药\t女姓内分泌失调吃什么药\t1\n",
      "肠胃炎可以吃水果吗\t肠胃炎可以吃水果嘛\t1\n",
      "藕尖的作法\t藕尖的做法\t1\n",
      "面瘫怎样按摩\t面滩怎样按摩\t1\n",
      "脚踝骨疼是怎么回事\t脚怀骨疼是怎么回事\t0\n",
      "胸闷胸痛怎么办\t胸闷熊痛怎么办\t1\n",
      "查乙肝五项需要空腹吗\t差乙肝五项需要空腹吗\t1\n",
      "来月经可以吃火龙果吗\t来月经可以吃火龙果嘛\t0\n",
      "胃疼喝蜂蜜水有用吗\t胃疼和蜂蜜水有用吗\t0\n",
      "心率不齐怎么办\t心律不齐怎么办\t1\n",
      "经期可以喝逍遥丸吗\t经期可以和逍遥丸吗\t0\n",
      "花呗账单怎么删除\t花呗张单怎么删除\t0\n",
      "转氨酶高的原因\t转安酶高的原因\t0\n",
      "注意力不集中\t主意力不集中\t0\n",
      "狐臭遗传吗\t狐臭遗传么\t0\n",
      "怎么使胸变大\t怎么是胸变大\t1\n",
      "安眠药药店能买到吗\t安眠药药店能买到嘛\t1\n",
      "心率慢是什么原因\t心律慢是什么原因\t0\n",
      "年青有为的意思\t年轻有为的意思\t0\n",
      "拉肚子能吃橘子吗\t拉肚子能吃橘子么\t0\n",
      "豆腐怎么做好吃\t豆腐怎么作好吃\t1\n",
      "甲状腺结节能吃海参吗\t甲状腺结节能吃海参么\t1\n",
      "手机通讯录如何备份\t手机通迅录如何备份\t1\n",
      "爱心怎么折\t爱心怎么哲\t0\n",
      "中药有副作用吗\t中药有副作用嘛\t0\n",
      "唑疮怎么治\t唑创怎么治\t0\n",
      "怀孕能吃牛肉吗\t怀孕能吃牛肉妈\t1\n",
      "孕妇可以吃生蚝吗\t孕妇可以吃生蚝妈\t1\n",
      "助理工程师有什么用\t助力工程师有什么用\t0\n",
      "面膜过敏怎么办\t面莫过敏怎么办\t0\n",
      "宫颈癌四价疫苗价格\t宫颈癌四家疫苗价格\t1\n",
      "戴隐形眼镜可以睡午觉吗\t带隐形眼镜可以睡午觉吗\t1\n",
      "鸡蛋豆浆能一起吃吗\t鸡蛋豆浆能一起吃么\t1\n",
      "为什么老是拉肚子\t为什么老是啦肚子\t1\n",
      "慢性胃炎能喝酸奶吗\t慢性胃炎能喝酸奶嘛\t1\n",
      "便秘吃什么\t便秘吃什药\t0\n",
      "感冒吃什么水果好\t感帽吃什么水果好\t0\n",
      "我在马路边捡到一分钱\t我在吗路边捡到一分钱\t0\n",
      "哪一种减肥药效果好\t那一种减肥药效果好\t0\n",
      "百度在哪里提问\t百度在那里提问\t1\n",
      "脚上起小水泡是怎么回事\t脚上气小水泡是怎么回事\t0\n",
      "牙齿有裂纹怎么办\t牙齿又裂纹怎么办\t1\n",
      "紧张血压会高吗\t紧张血压会高么\t1\n",
      "来月经能吃葡萄吗\t来月经能吃葡萄嘛\t0\n",
      "心脏病人可以坐飞机吗\t心脏病人可以做飞机吗\t0\n",
      "银耳的功效与作用\t银儿的功效与作用\t0\n",
      "痛风可以吃毛豆吗\t痛风可以吃毛豆嘛\t1\n",
      "两边肋骨痛是什么原因\t两边勒骨痛是什么原因\t0\n",
      "避孕药怎么吃\t毕孕药怎么吃\t1\n",
      "下奶的食物有哪些\t下奶的实物有哪些\t1\n",
      "丰胸的食物和水果\t丰胸得食物和水果\t0\n",
      "湿疹是什么引起的\t湿诊是什么引起的\t1\n",
      "口臭是怎么回事\t口臭是怎么会事\t1\n",
      "什么人不适合吃芒果\t什么人不适合吃忙果\t0\n",
      "感冒了能吃冰激凌吗\t感冒了能吃冰激凌么\t0\n",
      "胃糜烂有哪些症状\t胃糜烂有那些症状\t0\n",
      "肾结石吃什么好\t肾结实吃什么好\t1\n",
      "哺乳期能吃大蒜吗\t补乳期能吃大蒜吗\t0\n",
      "来月经可以吃韭菜吗\t来月经可以吃韭菜么\t0\n",
      "血压140正常吗\t血压140正常嘛\t0\n",
      "心率正常范围\t心律正常范围\t0\n",
      "蒲公英泡水喝的功效\t普公英泡水喝的功效\t0\n",
      "正常心率是多少\t正长心率是多少\t0\n",
      "女的被男的叉什么感觉\t女的被男的插什么感觉\t1\n",
      "猕猴桃会上火吗\t弥猴桃会上火吗\t0\n",
      "相知的唯美句子\t相识的唯美句子\t1\n",
      "手指关节痛怎么治疗\t手只关节痛怎么治疗\t1\n",
      "孕期血糖高能吃红薯吗\t孕期血糖高能吃红薯嘛\t0\n",
      "电脑开不了机\t点脑开不了机\t0\n",
      "网上兼职是真的吗\t网上兼职是真的么\t0\n",
      "怀孕能吃生蚝吗\t怀孕能吃生蚝么\t0\n",
      "鼻孔里面有个疙瘩\t鼻腔里面有个疙瘩\t1\n",
      "宝宝拉肚子能吃酸奶吗\t宝宝拉肚子能吃酸奶么\t0\n",
      "下奶的食物有哪些\t下奶的食物有那些\t1\n",
      "微信转账多久到账\t微信转帐多久到账\t0\n",
      "癣会传染吗\t显会传染吗\t1\n",
      "新生儿鼻子不通气怎么办\t新生二鼻子不通气怎么办\t0\n",
      "哺乳期可以吃薏米吗\t哺乳期可以吃薏米么\t0\n",
      "研究生期间算工龄吗\t研究生期间算工龄么\t0\n",
      "支付宝如何解绑手机号\t支付宝如何解邦手机号\t0\n",
      "血小板低的症状\t血小板低得症状\t1\n",
      "怀孕一个月可以药流吗\t怀孕一个月可以药流么\t0\n",
      "带状疱疹会自愈吗\t带状疱疹回自愈吗\t0\n",
      "怀孕能涂口红吗\t怀孕能涂口红么\t0\n",
      "闲鱼的名字可以改吗\t咸鱼的名字可以改吗\t0\n",
      "眼睛腿怎么调最合适\t眼镜腿怎么调最合适\t1\n",
      "糖尿病人能吃桃子吗\t塘尿病人能吃桃子吗\t1\n",
      "2006年是闰哪个月\t2006年是润哪个月\t0\n",
      "茄子会回奶吗\t茄子会回奶嘛\t0\n",
      "罗密欧与茱莉叶钢琴曲教程\t罗密欧与朱丽叶钢琴曲教程\t1\n",
      "被虫子咬了起水泡\t被虫子咬了起水疱\t0\n",
      "臀部疼痛是什么原因\t屯部疼痛是什么原因\t0\n",
      "枸杞红枣泡水喝的功效\t狗杞红枣泡水喝的功效\t1\n",
      "如何有效祛除蟑螂\t如何有效去除蟑螂\t0\n",
      "骨裂和骨折的区别\t股裂和骨折的区别\t0\n",
      "吃太胀了怎么办\t吃太涨了怎么办\t1\n",
      "白癜风会传染吗\t白癜风会传然吗\t0\n",
      "怎么练出腹肌\t怎么连出腹肌\t0\n",
      "淘宝买家客服\t淘宝卖家客服\t0\n",
      "硫磺皂洗脸好吗\t流磺皂洗脸好吗\t0\n",
      "眼睛下面骨头疼\t眼镜下面骨头疼\t0\n",
      "脚趾头痒是怎么回事\t脚只头痒是怎么回事\t0\n",
      "心脏早搏的药\t心脏早博的药\t0\n",
      "心急吃不了热豆腐\t心极吃不了热豆腐\t0\n",
      "精索静脉曲张怎么治疗\t精缩静脉曲张怎么治疗\t1\n",
      "为什么会长痤疮\t为什么会张痤疮\t1\n",
      "胃炎有什么症状\t胃炎有什么证状\t1\n",
      "经常放屁好不好\t经长放屁好不好\t0\n",
      "经常感冒是怎么回事\t经长感冒是怎么回事\t1\n",
      "大雁为什么要飞到南方过冬\t大眼为什么要飞到南方过冬\t0\n",
      "猫能吃方便面吗\t猫能吃方便面嘛\t0\n",
      "口臭怎么办\t口臭怎么半\t0\n",
      "骨密度检查多少钱\t骨蜜度检查多少钱\t1\n",
      "怀孕初期可以吃火龙果吗\t怀孕初期可以吃火龙果嘛\t1\n",
      "隔夜豆浆能喝吗\t隔夜豆浆能喝么\t0\n",
      "怎样申请微信号\t怎样伸请微信号\t0\n",
      "静脉曲张有哪些危害\t静脉曲张有那些危害\t1\n",
      "火龙果孕妇可以吃吗\t火龙果孕妇可以吃嘛\t1\n",
      "星海音乐学院好吗\t星海音乐学院好么\t0\n",
      "长期坐着腰疼怎么办\t长期做着腰疼怎么办\t0\n",
      "实用新型和外观设计专利权的期限\t使用新型和外观设计专利权的期限\t1\n",
      "喝啤酒上火吗\t和啤酒上火吗\t1\n",
      "霉菌阴道炎\t霉菌阴到炎\t0\n",
      "多囊卵巢能怀孕吗\t多囊乱巢能怀孕吗\t1\n",
      "吃完饭可以吃水果吗\t吃完饭可以吃水果嘛\t0\n",
      "激光能去雀斑吗\t激光能去雀斑么\t1\n",
      "母亲节是哪一天\t母情节是哪一天\t0\n",
      "打嗝是什么原因引起的\t大嗝是什么原因引起的\t0\n",
      "怀孕能喝苹果醋吗\t怀孕能喝苹果醋么\t0\n",
      "肾结石可以吃橘子吗\t肾结石可以吃橘子么\t0\n",
      "芒果湿热吗\t芒果是热吗\t0\n",
      "护士转行可以做什么\t护士转型可以做什么\t1\n",
      "一直打嗝怎么办\t一直大嗝怎么办\t0\n",
      "月经来可以汗蒸吗\t月经来可以汗蒸嘛\t0\n",
      "牛奶和榴莲能一起吃吗\t牛奶和榴莲能一起吃么\t0\n",
      "肝不好有哪些症状\t肝不好有哪些症壮\t0\n",
      "红薯长芽了还能吃吗\t红薯长芽了还能吃嘛\t0\n",
      "孩子感冒流鼻涕怎么办\t孩子感冒留鼻涕怎么办\t0\n",
      "催月经来的方法\t崔月经来的方法\t0\n",
      "嗓子哑怎么办\t嗓子哑怎么班\t0\n",
      "痛风能治断根吗\t痛风能治段根吗\t0\n",
      "绿豆汤怎么煮\t绿豆汤怎么住\t0\n",
      "剖腹产多久可以洗澡\t剖复产多久可以洗澡\t1\n",
      "来月经能吃火龙果吗\t来月经能吃火龙果么\t1\n",
      "头部伽玛刀十大副作用\t头部伽马刀十大副作用\t1\n",
      "你是oppo是吗\t你是oppo什么\t0\n",
      "类风湿能治愈吗\t类风湿能治愈么\t0\n",
      "被蜜蜂蛰了有后遗症吗\t被蜜蜂蜇了有后遗症吗\t0\n",
      "尿道炎吃什么药\t尿导炎吃什么药\t0\n",
      "耳朵痒是怎么回事\t儿朵痒是怎么回事\t1\n",
      "甲状腺结节有什么症状\t甲装腺结节有什么症状\t0\n",
      "哺乳期感冒可以喂奶吗\t哺乳期感冒可以喂奶嘛\t0\n",
      "做月子可以吃螃蟹吗\t做月子可以吃螃蟹嘛\t0\n",
      "补血的药物有哪些\t补血得药物有哪些\t0\n",
      "记忆力差怎么办\t记意力差怎么办\t1\n",
      "孕妇能吃橘子吗晚期\t孕妇能吃桔子吗晚期\t1\n",
      "橄榄油的功效与作用\t敢榄油的功效与作用\t1\n",
      "肚脐眼痛是怎么回事\t肚齐眼痛是怎么回事\t1\n",
      "一边乳房痛\t一遍乳房痛\t1\n",
      "手上长水泡怎么办\t手上张水泡怎么办\t0\n",
      "哺乳期可以喝酸奶吗\t哺乳期可以和酸奶吗\t1\n",
      "毒品的危害\t毒品的为害\t1\n",
      "手机号码注销了微信怎么登陆\t手机号码注销了微信怎么登录\t0\n",
      "脂肪肝能吃鸡肉吗\t脂肪肝能吃鸡肉嘛\t0\n",
      "打嗝放屁是怎么回事\t大嗝放屁是怎么回事\t0\n",
      "怀孕可以吃芋头吗\t怀孕可以吃芋头么\t0\n",
      "怎样去皱纹\t怎样去绉纹\t1\n",
      "阜阳属于哪里\t阜阳属于那里\t1\n",
      "买理财产品有风险吗\t卖理财产品有风险吗\t0\n",
      "吃葡萄上火吗\t吃葡萄上火么\t0\n",
      "柠檬水可以美白吗\t柠檬水可以美白么\t0\n",
      "尿道感染吃什么消炎药\t尿到感染吃什么消炎药\t0\n",
      "低血压症状\t低血压证状\t0\n",
      "糖尿病人可以吃莲藕吗\t糖尿病人可以吃连藕吗\t1\n",
      "什么食物含叶酸\t什么食物喊叶酸\t0\n",
      "眼睛冒绿光\t眼镜冒绿光\t0\n",
      "被蜱虫咬了有什么症状\t被脾虫咬了有什么症状\t0\n",
      "白化病是遗传病吗\t白化病是遗传病么\t0\n",
      "小儿脾胃虚弱怎么调理\t小二脾胃虚弱怎么调理\t0\n",
      "喝蜂蜜水减肥吗\t喝蜂蜜水减肥嘛\t0\n",
      "经期可以吃什么水果\t经期可以吃什麼水果\t0\n",
      "磷酸奥司他韦颗粒是消炎药吗\t磷酸奥司他韦颗粒是消炎药么\t0\n",
      "甲状腺结节\t甲状腺结洁\t0\n",
      "人流后能吃葡萄吗\t人流后能吃葡萄嘛\t0\n",
      "法令纹怎么去除\t法令纹怎么祛除\t1\n",
      "灰黄霉素的副作用\t灰黄梅素的副作用\t1\n",
      "孕妇能吃蒲地蓝消炎口服液吗\t孕妇能吃蒲地兰消炎口服液吗\t0\n",
      "怎么去水肿\t怎么取水肿\t0\n",
      "神经官能症的治疗\t神经管能症的治疗\t0\n",
      "失眠吃什么\t失眠吃什药\t0\n",
      "荨麻疹可以吃鸡翅吗\t寻麻疹可以吃鸡翅吗\t0\n",
      "心情烦躁不安怎么办\t心情烦燥不安怎么办\t1\n",
      "吃黄瓜可以减肥吗\t吃黄瓜可以减肥嘛\t1\n",
      "背上长痘痘\t辈上长痘痘\t0\n",
      "身上长猴子是什么原因\t身上涨猴子是什么原因\t0\n",
      "艾灸后多久可以洗澡\t艾灸厚多久可以洗澡\t1\n",
      "世界又变得大了起来是什么歌\t世界又变的大了起来是什么歌\t0\n",
      "血清阳性是什么意思\t血青阳性是什么意思\t1\n",
      "针灸的原理是什么\t针灸得原理是什么\t0\n",
      "肝炎的早期症状\t肝炎的早起症状\t0\n",
      "霍金得的什么病\t霍金德的什么病\t0\n",
      "室性早搏算不算心脏病\t室性早博算不算心脏病\t0\n",
      "胃食管反流不能吃什么\t胃食管返流不能吃什么\t1\n",
      "菠萝蜜吃了上火吗\t菠萝蜜吃了上火嘛\t0\n",
      "怎么治好荨麻疹\t怎么治好寻麻疹\t1\n",
      "刷牙时牙龈出血怎么办\t刷牙是牙龈出血怎么办\t0\n",
      "员工请假条怎么写\t员工清假条怎么写\t1\n",
      "怀孕可以吃当归吗\t怀孕可以吃档归吗\t1\n",
      "来月经能吃辣吗\t来月经能吃辣嘛\t0\n",
      "什么的月光\t什么得月光\t0\n",
      "怀孕初期可以吃橘子吗\t怀孕初期可以吃桔子吗\t1\n",
      "嘴唇发紫是什么原因\t最唇发紫是什么原因\t0\n",
      "网上定火车票怎么取票\t网上订火车票怎么取票\t1\n",
      "走之旁汉字\t走之旁汉子\t0\n",
      "燕麦回奶吗\t燕麦回奶嘛\t0\n",
      "小孩皮肤有红斑\t小孩皮肤有红斑\t1\n",
      "关于书的名言\t关于书的明言\t1\n",
      "三点双眼皮是永久的吗\t三点双眼皮是永久的么\t1\n",
      "奥得力是什么意思\t奥得利是什么意思\t1\n",
      "没意义的工作\t无意义的工作\t1\n",
      "心脏早搏是怎么引起的\t心脏早博是怎么引起的\t1\n",
      "宝宝肠炎怎么办\t宝宝肠严怎么办\t1\n",
      "空腹跑步好吗\t空腹跑步好么\t1\n",
      "来大姨妈可以吃西瓜吗\t来大姨妈可以吃西瓜么\t0\n",
      "哺乳期可以喝酵素吗\t哺乳期可以喝酵素么\t1\n",
      "输卵管通而不畅怎么办\t输卵管通儿不畅怎么办\t0\n",
      "胃不好可以吃葡萄吗\t胃不好可以吃葡萄么\t1\n",
      "空腹可以喝柠檬蜂蜜水吗\t空复可以喝柠檬蜂蜜水吗\t0\n",
      "中暑了吃什么药\t中署了吃什么药\t0\n",
      "丙氨酸转氨酶偏高是什么原因\t丙氨酸转安酶偏高是什么原因\t1\n",
      "梦到自己被狗咬\t梦到自己背狗咬\t0\n",
      "感冒了鼻子不通气怎么办\t感冒了鼻子不痛气怎么办\t0\n",
      "什么电视剧好看\t是么电视剧好看\t0\n",
      "朱元漳为什么要大杀功臣\t朱元璋为什么要大杀功臣\t0\n",
      "戴避孕套会怀孕吗\t戴避孕套会怀孕么\t1\n",
      "被马蜂蛰了怎么处理\t被马蜂折了怎么处理\t0\n",
      "什么是皮肤病\t什么事皮肤病\t1\n",
      "孕妇能吃阿莫西林胶囊吗\t孕妇能吃啊莫西林胶囊吗\t0\n",
      "白带带血丝是什么原因\t百带带血丝是什么原因\t1\n",
      "空腹喝牛奶好吗\t空服喝牛奶好吗\t0\n",
      "中国哪个男明星最帅\t中国那个男明星最帅\t1\n",
      "南瓜怎么做好吃\t难瓜怎么做好吃\t0\n",
      "快递能寄液体吗\t快递能寄液体么\t0\n",
      "枸杞怎么保存\t苟杞怎么保存\t0\n",
      "一型糖尿病和二型糖尿病的区别\t一性糖尿病和二型糖尿病的区别\t1\n",
      "怀孕能吃鹅蛋吗\t怀孕能吃鹅蛋嘛\t1\n",
      "尖锐湿疣传播途径\t尖锐湿疣传播途经\t0\n",
      "肺里有结节\t肺里有结结\t1\n",
      "湿疹能吃红枣吗\t湿疹能吃红枣嘛\t1\n",
      "查艾滋病挂什么科\t查爱滋病挂什么科\t0\n",
      "血肌酐正常值\t雪肌酐正常值\t0\n",
      "附近有什么好吃的\t附近由什么好吃的\t0\n",
      "来月经时腰疼\t来月经是腰疼\t0\n",
      "手指上长小水泡\t手指上张小水泡\t0\n",
      "功能性消化不良怎么治\t功能性销化不良怎么治\t0\n",
      "拉肚子可以吃橘子吗\t拉肚子可以吃桔子吗\t1\n",
      "脚趾麻木是怎么回事\t脚止麻木是怎么回事\t1\n",
      "小孩上吐下泻\t小孩上吐下泄\t0\n",
      "变异型哮喘\t变异性哮喘\t0\n",
      "什么冰箱好\t什么冰箱号\t0\n",
      "涨肚子怎么办\t胀肚子怎么办\t1\n",
      "体温计要量多久\t体温计要两多久\t0\n",
      "来月经能练瑜伽吗\t来月经能练瑜伽么\t0\n",
      "哺乳期可以吃巧克力吗\t补乳期可以吃巧克力吗\t0\n",
      "肠梗阻怎么治疗\t肠梗组怎么治疗\t0\n",
      "什么是窦性心动过速\t什么事窦性心动过速\t0\n",
      "白癜风会遗传吗\t白店风会遗传吗\t0\n",
      "手机wps下划线怎么打出来\t手机wps下滑线怎么打出来\t0\n",
      "哪种猫好养\t那种猫好养\t1\n",
      "孕妇可以吃提子吗\t孕妇可以吃提子么\t1\n",
      "静脉曲张怎么治\t静迈曲张怎么治\t0\n",
      "乳腺增生吃什么药\t乳线增生吃什么药\t0\n",
      "浩在五行中属什么\t昊在五行中属什么\t1\n",
      "月经推迟多久能测出怀孕\t月经推迟多久能侧出怀孕\t0\n",
      "甲状腺肿大的症状\t甲状腺肿大得症状\t0\n",
      "喝什么可以去湿气\t和什么可以去湿气\t0\n",
      "糖尿病人能喝玉米粥吗\t糖尿病人能喝玉米粥么\t1\n",
      "郎朗为什么出名\t朗朗为什么出名\t1\n",
      "胃炎吃什么\t胃炎吃什药\t0\n",
      "来月经可以健身吗\t来月经可以健身嘛\t1\n",
      "人生是什么\t认生是什么\t0\n",
      "频发室性早搏三联律\t频发室性早搏三联率\t0\n",
      "接吻能不能减肥\t结吻能不能减肥\t1\n",
      "老是拉肚子是怎么回事\t老是垃肚子是怎么回事\t0\n",
      "脚背痒是怎么回事\t教背痒是怎么回事\t0\n",
      "吃中药可以吃芒果吗\t吃中药可以吃芒果么\t0\n",
      "怀孕怎么分辨男女\t怀孕怎么分变男女\t0\n",
      "乌兰图雅的老公是谁\t乌蓝图雅的老公是谁\t0\n",
      "乳腺癌有哪些症状\t乳线癌有哪些症状\t0\n",
      "黑枸杞的功效与作用\t黑枸杞得功效与作用\t0\n",
      "自的行书怎么写\t紫的行书怎么写\t0\n",
      "头皮上长痘痘是怎么回事\t头皮上涨痘痘是怎么回事\t1\n",
      "肝脏血管瘤注意什么\t肝脏血官瘤注意什么\t0\n",
      "带状泡疹最佳治疗方法\t带壮泡疹最佳治疗方法\t1\n",
      "现在做什么行业最挣钱\t现在做什么行也最挣钱\t1\n",
      "孕妇可以吃冰激凌吗\t孕妇可以吃冰激凌妈\t1\n",
      "冠心病症状\t冠新病症状\t1\n",
      "湿气重喝什么茶好\t湿气中喝什么茶好\t0\n",
      "坐骨结节滑囊炎的症状\t坐股结节滑囊炎的症状\t0\n",
      "拉肚子吃什么药\t拉度子吃什么药\t0\n",
      "哪个牌子拖把好\t那个牌子拖把好\t0\n",
      "电热水器哪个牌子好\t店热水器哪个牌子好\t0\n",
      "指南针是哪个国家发明的\t指南针是那个国家发明的\t0\n",
      "腰间盘突出手术多少钱\t腰肩盘突出手术多少钱\t1\n",
      "长期吃安眠药\t常期吃安眠药\t0\n",
      "孕妇可以吃烧仙草吗\t孕妇可以吃烧鲜草吗\t1\n",
      "脚气水泡怎么治疗\t脚气水疱怎么治疗\t1\n",
      "脚痒脱皮起水疱是怎么回事\t脚痒脱皮起水泡是怎么回事\t1\n",
      "喝完酒能洗澡吗\t喝完就能洗澡吗\t0\n",
      "暗度陈仓的上一句\t暗渡陈仓的上一句\t0\n",
      "熬夜喝什么好\t熬夜和什么好\t0\n",
      "孕妇能吃玉米吗\t孕妇能吃玉米嘛\t0\n",
      "蛋白质食物有哪些\t蛋白质食物有那些\t0\n",
      "怎么查电话号码归属地\t怎么差电话号码归属地\t1\n",
      "左肺上叶小结节\t左肺上页小结节\t0\n",
      "佛山到桂林货车\t佛山到桂林火车\t0\n",
      "怎样在网上赚钱\t怎样在往上赚钱\t1\n",
      "慢性浅表性胃炎伴糜烂\t漫性浅表性胃炎伴糜烂\t0\n",
      "烫伤了怎么办\t烫伤了怎么半\t0\n",
      "头发干枯毛躁怎么办\t头发干枯毛燥怎么办\t1\n",
      "咳嗽吃什么药好的快\t咳嗽吃什么药好得快\t1\n",
      "做仰卧起坐能减肥吗\t做仰卧起座能减肥吗\t0\n",
      "解脲支原体阳性怎么办\t解尿支原体阳性怎么办\t1\n",
      "来月经能喝茶吗\t来月经能喝茶么\t1\n",
      "降尿酸的药有哪些\t降尿酸的要有哪些\t0\n",
      "为什么会长智齿\t为什么会章智齿\t0\n",
      "舌头起泡怎么办\t舌头气泡怎么办\t0\n",
      "月经期间可以健身吗\t月经期间可以建身吗\t1\n",
      "痔疮一般长在哪里\t痔疮一般长在那里\t0\n",
      "修正带坏了怎么修\t修整带坏了怎么修\t0\n",
      "怀孕能吃鳝鱼吗\t怀孕能吃鳝鱼嘛\t0\n",
      "烂脚丫怎么治\t滥脚丫怎么治\t1\n",
      "低血糖吃什么\t低血糖吃什药\t0\n",
      "减肥可以吃火锅吗\t减肥可以吃火锅么\t0\n",
      "低血压吃什么好得快\t低血压吃什么好的快\t0\n",
      "小便时尿道刺痛是怎么回事\t小便是尿道刺痛是怎么回事\t1\n",
      "拉肚子能吃什么\t垃肚子能吃什么\t0\n",
      "经期能喝玫瑰花茶吗\t经期能喝玫瑰花茶嘛\t1\n",
      "微信零钱通和支付宝余额宝哪个收益高\t微信零钱痛和支付宝余额宝哪个收益高\t0\n",
      "空腹吃水果好吗\t空腹吃水果好么\t0\n",
      "燃气灶打不着火是什么原因\t然气灶打不着火是什么原因\t0\n",
      "黑枸杞有什么作用\t黑狗杞有什么作用\t0\n",
      "武大郎那里人\t武大郎哪里人\t0\n",
      "胃不好能喝茶叶吗\t胃不好能和茶叶吗\t1\n",
      "肌张力低的表现\t其张力低的表现\t0\n",
      "感冒喉咙痛吃什么药好\t感冒吼咙痛吃什么药好\t0\n",
      "怀孕能吃生鱼片吗\t怀孕能吃生鱼片嘛\t1\n",
      "来月经可以吃生蚝吗\t来月经可以吃生蚝么\t1\n",
      "便秘会导致痔疮吗\t便秘会导致痔疮么\t0\n",
      "宝宝喉咙有痰怎么办\t宝宝吼咙有痰怎么办\t0\n",
      "乙肝小三阳会传染吗\t乙干小三阳会传染吗\t0\n",
      "食管癌遗传吗\t食管癌移传吗\t0\n",
      "颈椎变形怎么办\t颈椎变型怎么办\t1\n",
      "脖子上有结节怎么办\t脖子上有结界怎么办\t0\n",
      "黑咖啡可以减肥吗\t黑咖啡可以减肥么\t0\n",
      "胃疼可以吃水果吗\t胃疼可以吃水果嘛\t1\n",
      "气缸垫有哪些类型\t汽缸垫有哪些类型\t1\n",
      "哮喘病的症状\t哮喘病的证状\t0\n",
      "女性尿结石的症状\t女姓尿结石的症状\t0\n",
      "湿疹能吃橘子吗\t湿疹能吃桔子吗\t1\n",
      "来大姨妈可以吃香蕉吗\t来大姨吗可以吃香蕉吗\t1\n",
      "什么的目光\t什么得目光\t0\n",
      "杜甫诗怎么写\t杜甫是怎么写\t0\n",
      "脚跟痛如何治疗\t脚根痛如何治疗\t0\n",
      "肺结核有什么症状\t肺结核有什么症壮\t1\n",
      "来例假可以吃橘子吗\t来例假可以吃橘子么\t0\n",
      "怎样消除打嗝\t怎样消除打隔\t1\n",
      "世界上真的有龙吗?\t世界上真的有龙嘛?\t0\n",
      "大便次数多怎么回事\t大便此数多怎么回事\t0\n",
      "肩膀痛是什么原因\t肩旁痛是什么原因\t1\n",
      "白癜风能吃竹笋吗\t白癜风能吃竹笋么\t0\n",
      "感冒嗓子哑\t感冒桑子哑\t0\n",
      "过敏性皮炎能吃牛肉吗\t过敏性皮炎能吃牛肉么\t1\n",
      "返流性食道炎\t返流行食道炎\t0\n",
      "脚趾甲变黑怎么办\t脚指甲变黑怎么办\t0\n",
      "经期可以喝桂圆红枣茶吗\t经期可以喝桂圆红枣茶嘛\t1\n",
      "您好在么\t您好在嘛\t1\n",
      "手上起水泡是怎么回事\t收上起水泡是怎么回事\t0\n",
      "茶叶蛋的营养价值\t茶业蛋的营养价值\t0\n",
      "泡脚可以去湿气吗\t泡脚可以去湿气嘛\t0\n",
      "哺乳期能吃松花蛋吗\t哺乳期能吃松花蛋么\t0\n",
      "结扎手术多少钱\t接扎手术多少钱\t0\n",
      "淋病梅毒早期症状\t淋病梅毒早起症状\t0\n",
      "白醋可以洗脸吗\t白醋可以洗脸么\t1\n",
      "智齿没长出来能拔吗\t智齿没长出来能拔么\t1\n",
      "新鲜百合怎么吃\t新鲜白合怎么吃\t0\n",
      "食物中毒的症状\t食物中毒得症状\t0\n",
      "右边腰疼是什么原因\t右边要疼是什么原因\t1\n",
      "坐骨神经痛症状\t坐骨神经痛证状\t0\n",
      "如何锻炼腰腹力量\t如何锻练腰腹力量\t1\n",
      "怎样制作圆锥\t怎样制做圆锥\t0\n",
      "经常用开塞露有什么副作用\t经常用开赛露有什么副作用\t0\n",
      "拔一颗牙多少钱\t拔一棵牙多少钱\t0\n",
      "睡觉流口水是怎么回事\t睡觉流口水是怎么回是\t0\n",
      "乳腺看什么科\t乳线看什么科\t0\n",
      "怎样教宝宝说话\t怎样交宝宝说话\t0\n",
      "下肢静脉曲张的治疗\t下支静脉曲张的治疗\t1\n",
      "吃坏肚子怎么办\t吃坏肚子怎么半\t1\n",
      "吃什么能降血糖\t吃什么能将血糖\t0\n",
      "月经期可以敷面膜吗\t月经期可以肤面膜吗\t0\n",
      "怀孕能吃蚬子吗\t怀孕能吃蚬子么\t1\n",
      "卵巢多囊综合症能怀孕吗\t卵巢多囊综合证能怀孕吗\t0\n",
      "黄疸型肝炎能治好吗\t黄疸性肝炎能治好吗\t1\n",
      "来例假可以喝酸奶吗\t来例假可以喝酸奶么\t0\n",
      "左手发麻怎么回事\t左手发麻怎么会事\t0\n",
      "电蚊香对孕妇有影响吗\t电文香对孕妇有影响吗\t1\n",
      "月经期间可以吃雪蛤吗\t月经期间可以吃雪蛤嘛\t0\n",
      "跑步腿会粗吗\t跑步腿会粗嘛\t0\n",
      "成龙带的什么眼镜\t成龙戴的什么眼镜\t0\n",
      "皮肤发痒怎么回事\t皮夫发痒怎么回事\t1\n",
      "电动牙刷要用牙膏吗\t电动牙刷要用牙膏么\t0\n",
      "喝什么茶排毒\t和什么茶排毒\t0\n",
      "舞蹈的种类\t舞蹈得种类\t0\n",
      "我的世界怎么去天堂\t我的世界怎么去天唐\t0\n",
      "牙齿有裂痕是什么原因\t牙齿有列痕是什么原因\t0\n",
      "雷克萨斯产自哪个国家\t雷克萨斯产自那个国家\t1\n",
      "胃病能吃桑椹吗\t胃病能吃桑葚吗\t1\n",
      "眼睛有红血丝怎么办\t眼精有红血丝怎么办\t0\n",
      "刮痧多久刮一次\t刮痧多久挂一次\t1\n",
      "宝宝发烧能吹风扇吗\t宝宝发烧能吹凤扇吗\t0\n",
      "手脱皮是怎么回事\t收脱皮是怎么回事\t1\n",
      "血小板增多症\t血小板赠多症\t1\n",
      "京东优惠卷怎么兑换\t京东优惠劵怎么兑换\t0\n",
      "绍兴有哪些高中\t绍兴有那些高中\t0\n",
      "消逝的光芒怎么丢炸弹\t消失的光芒怎么丢炸弹\t0\n",
      "岔气怎么办\t岔气怎么版\t1\n",
      "信用卡哪个银行的最好\t信用卡那个银行的最好\t0\n",
      "水状白带是怎么回事\t水壮白带是怎么回事\t0\n",
      "晚上喝牛奶会长高吗\t晚上和牛奶会长高吗\t1\n",
      "朱德是那里人\t朱徳是那里人\t0\n",
      "灰指甲传染吗\t灰之甲传染吗\t0\n",
      "蔓越莓的功效与作用\t蔓越莓得功效与作用\t1\n",
      "避孕药安全吗\t比孕药安全吗\t0\n",
      "玻璃体混浊会导致失明吗\t玻璃体浑浊会导致失明吗\t0\n",
      "如何让胸变大\t如何让熊变大\t0\n",
      "喉咙痛喝什么好\t喉咙痛和什么好\t0\n",
      "喝酒就拉肚子是怎么回事\t喝酒酒拉肚子是怎么回事\t0\n",
      "乙肝有哪些症状\t艺肝有哪些症状\t1\n",
      "吃苦瓜减肥吗\t吃苦瓜减肥嘛\t0\n",
      "尿道炎是怎么引起的\t尿到炎是怎么引起的\t1\n",
      "心脏早搏如何治疗\t心脏早博如何治疗\t0\n",
      "月经期能吃芒果吗\t月经期能吃忙果吗\t0\n",
      "牙齿痛怎么办\t牙吃痛怎么办\t1\n",
      "湿气重吃什么好\t湿气重吃什药好\t1\n",
      "我的世界怎么去天堂\t我的世界怎麼去天堂\t1\n",
      "喝阿莫西林能喝酒吗\t喝啊莫西林能喝酒吗\t0\n",
      "小孩能吃榴莲吗\t小孩能吃榴莲嘛\t0\n",
      "崩漏是什么\t崩露是什么\t0\n",
      "月经推迟一天能测出怀孕吗\t月经退迟一天能测出怀孕吗\t1\n",
      "经常胃胀是什么原因\t经常胃帐是什么原因\t1\n",
      "狗粮猫能吃吗\t狗粮猫能吃么\t1\n",
      "清华大学的校训是什么\t清华大学的教训是什么\t0\n",
      "静脉曲张早期症状\t静脉曲张早起症状\t0\n",
      "初至天目双清庄记\t处至天目双清庄记\t0\n",
      "肾的生理功能是什么\t肾的生里功能是什么\t0\n",
      "新生儿可以喝葡萄糖吗\t新生儿可以和葡萄糖吗\t0\n",
      "西瓜工会排名\t西瓜公会排名\t1\n",
      "农村户口可以买社保吗\t农村户口可以买社保么\t1\n",
      "脂肪肝可以当兵吗\t脂肪肝可以当兵么\t0\n",
      "怎样去除眼袋\t怎样去出眼袋\t1\n",
      "肾炎的症状\t肾炎得症状\t0\n",
      "宁波属于哪个市\t宁波属于那个市\t0\n",
      "嗓子有痰怎么办\t嗓子又痰怎么办\t1\n",
      "怀孕能不能泡温泉\t怀孕能不能跑温泉\t1\n",
      "孕妇可以喝可乐吗\t孕妇可以喝可乐嘛\t0\n",
      "甲状腺结节的危害\t甲状腺结节的威害\t0\n",
      "厦门地理位置\t厦门地里位置\t0\n",
      "小儿打呼噜是病吗\t小二打呼噜是病吗\t0\n",
      "感冒咳嗽晚上咳得厉害\t感冒咳嗽晚上咳的厉害\t1\n",
      "盆腔炎吃什么药\t盆腔严吃什么药\t1\n",
      "得了癌症怎么办\t的了癌症怎么办\t1\n",
      "心脏病的早期症状有哪些\t心脏病的早期症状有那些\t1\n",
      "拉肚子喝藿香正气水管用吗\t拉肚子和藿香正气水管用吗\t0\n",
      "晚上睡觉磨牙是什么原因\t晚上睡觉模牙是什么原因\t0\n",
      "张杰她老婆是谁\t张杰他老婆是谁\t1\n",
      "脂肪肝怎么治\t脂方肝怎么治\t0\n",
      "慢性咽炎的症状\t慢性咽严的症状\t1\n",
      "舌苔厚腻是怎么回事\t舌态厚腻是怎么回事\t0\n",
      "小孩换牙是全换吗\t小孩换牙是全换么\t0\n",
      "半边头痛是怎么回事\t办边头痛是怎么回事\t0\n",
      "激光祛斑疼吗\t激光祛斑疼嘛\t0\n",
      "无痛胃镜是怎么麻醉的\t无痛胃经是怎么麻醉的\t0\n",
      "孕妇能吃蛏子吗\t孕妇能吃蛏子么\t0\n",
      "尿道感染是怎么引起的\t尿道感染是怎么引起得\t0\n",
      "dc家居是品牌吗\tdc家具是品牌吗\t1\n",
      "慢性肝病传染吗\t慢性肝病传染么\t0\n",
      "尖锐湿疣症状\t尖锐湿尤症状\t0\n",
      "结婚证能补办吗\t结婚证能补办么\t0\n",
      "近视眼怎么恢复视力\t近视眼怎么回复视力\t0\n",
      "黄体破裂严重吗\t黄体破裂严重嘛\t0\n",
      "减肥期间可以吃凉面吗\t减肥期间可以吃凉面嘛\t0\n",
      "掉头发是什么原因\t掉头发是什么愿因\t0\n",
      "被猫咬了要打针吗\t背猫咬了要打针吗\t1\n",
      "肺部结节严重吗\t肺布结节严重吗\t1\n",
      "哺乳期能拔智齿吗\t哺乳期能拔智齿嘛\t0\n",
      "拉黑色大便怎么回事\t拉黑色大变怎么回事\t0\n",
      "胃不好可以吃桃胶吗\t胃不好可以吃桃胶嘛\t0\n",
      "脚底长刺猴怎么治\t脚底长刺瘊怎么治\t1\n",
      "北京的区号\t北京得区号\t1\n",
      "中兴通讯怎么样\t中兴通迅怎么样\t1\n",
      "脚跟痛是什么原因\t脚根痛是什么原因\t0\n",
      "密集恐惧症怎么治疗\t密极恐惧症怎么治疗\t0\n",
      "糖尿病可以吃面食吗\t糖尿病可以吃面食么\t1\n",
      "前额胀痛是什么原因\t前额帐痛是什么原因\t0\n",
      "月经期间可以喝绿茶吗\t月经期间可以和绿茶吗\t0\n",
      "在阳光下屏幕太暗\t在阳光下屏幕泰安\t0\n",
      "皮肤黄怎么变白\t皮服黄怎么变白\t0\n",
      "经期能喝茶吗\t经期能和茶吗\t0\n",
      "芦荟胶的功效与作用\t芦荟交的功效与作用\t1\n",
      "女生下面流水怎么回事\t女生下面留水怎么回事\t0\n",
      "两对半是什么\t两队半是什么\t0\n",
      "痛风能吃馒头吗\t痛风能吃馒头嘛\t0\n",
      "口腔溃疡吃什么好\t口腔溃疡吃什药好\t0\n",
      "咽炎会咳嗽吗\t咽炎会咳嗽妈\t0\n",
      "怎么网上订机票\t怎么网上定机票\t0\n",
      "膝盖痛是什么原因\t希盖痛是什么原因\t1\n",
      "甲状腺结节有哪些症状\t甲状腺结结有哪些症状\t0\n",
      "电脑开不了机\t电脑开不了记\t1\n",
      "什么的原野\t什么地原野\t1\n",
      "把什么比作什么\t把什么比做什么\t0\n",
      "血糖高的症状\t血糖高德症状\t0\n",
      "强直性脊椎炎的症状\t强直性脊椎严的症状\t0\n",
      "双相情感障碍有哪些临床表现\t双向情感障碍有哪些临床表现\t1\n",
      "梦见被鬼追杀\t梦见背鬼追杀\t0\n",
      "血糖高能吃西瓜吗\t血唐高能吃西瓜吗\t0\n",
      "吃完药能喝牛奶吗\t吃完药能和牛奶吗\t0\n",
      "怎么去除地板上的乳胶漆\t怎么祛除地板上的乳胶漆\t0\n",
      "感冒喉咙痛吃什么药好\t感帽喉咙痛吃什么药好\t0\n",
      "晒伤了怎么办\t晒伤了怎么半\t0\n",
      "尿路感染会低烧吗\t尿路感染会低烧嘛\t1\n",
      "怀孕可以吃咸鱼吗\t怀孕可以吃咸鱼嘛\t1\n",
      "羊奶和牛奶哪个好\t羊奶和牛奶那个好\t0\n",
      "孕妇小便混浊\t孕妇小便浑浊\t0\n",
      "阳虚怎么治疗\t阳需怎么治疗\t0\n",
      "泡疹的症状\t泡诊的症状\t0\n",
      "c30怎么登录\tc30怎么登陆\t0\n",
      "来月经可以吃海鲜吗\t来月经可以吃海鲜嘛\t1\n",
      "小孩子可以喝蜂蜜吗\t小孩子可以和蜂蜜吗\t0\n",
      "痔疮的危害\t痔疮得危害\t0\n",
      "简笔画怎么画\t简笔画怎么花\t0\n",
      "额头和下巴长痘是什么原因\t额头和下巴长豆是什么原因\t1\n",
      "扁桃体肿大分度\t扁桃体重大分度\t1\n",
      "肺上有结节\t肺上又结节\t1\n",
      "怎么教孩子画画\t怎么教孩子画花\t0\n",
      "甲状腺结节是什么\t甲状线结节是什么\t0\n",
      "艾灸盒怎么用\t艾久盒怎么用\t1\n",
      "怀孕初期可以吃辣条吗\t怀孕初期可以吃辣条嘛\t1\n",
      "全麦面包能减肥吗\t全麦面包能减肥嘛\t1\n",
      "大便变细是怎么回事\t大便便细是怎么回事\t1\n",
      "怀孕初期可以吃大蒜吗\t怀孕初期可以吃大蒜嘛\t0\n",
      "什么的翅膀\t什么的翅胖\t1\n",
      "幽门螺旋杆菌高温能杀死吗\t优门螺旋杆菌高温能杀死吗\t0\n",
      "四维彩超有必要做吗\t四维彩超有必要做么\t0\n",
      "做心电图多少钱\t作心电图多少钱\t1\n",
      "肺水肿严重吗\t肺水肿严重么\t0\n",
      "孕妇可以喝蜂蜜柚子茶吗\t孕妇可以喝蜂密柚子茶吗\t0\n",
      "来例假能喝酒吗\t来例假能喝酒嘛\t0\n",
      "乳胶枕头有味道吗\t乳胶枕头有味道么\t1\n",
      "耳朵后面长疙瘩\t耳朵后面长疙搭\t1\n",
      "戴cb锁的危害\t带cb锁的危害\t1\n",
      "胆固醇高能吃鸡蛋吗\t胆固醇高能吃鸡蛋嘛\t0\n",
      "吃烧烤会胖吗\t吃烧烤会胖嘛\t0\n",
      "痛风能喝绿豆汤吗\t痛风能喝绿豆汤嘛\t0\n",
      "心血管堵塞\t心学管堵塞\t0\n",
      "术后可以吃牛肉吗\t术后可以吃牛肉么\t1\n",
      "手上长鸡眼怎么办\t手上长几眼怎么办\t0\n",
      "处女膜没破会怀孕吗\t处女膜没破会怀孕嘛\t0\n",
      "新疆著名旅游景点\t新疆出名旅游景点\t0\n",
      "来月经腰痛\t来月经要痛\t1\n",
      "白带异常怎么办\t百带异常怎么办\t0\n",
      "梦到掉牙齿\t梦到掉牙吃\t1\n",
      "正常人心率是多少\t正常人心律是多少\t1\n",
      "激光去痣多少钱\t激光取痣多少钱\t0\n",
      "东南西北怎么折\t动南西北怎么折\t0\n",
      "希腊属于哪个州\t希腊属于哪个洲\t0\n",
      "避孕套带反了会怀孕吗\t避孕套带反了会怀孕嘛\t0\n",
      "你是男的么\t你是男的吗\t1\n",
      "血糖高可以吃玉米吗\t血糖高可以吃玉米嘛\t1\n",
      "经常流鼻血是什么原因\t经常留鼻血是什么原因\t0\n",
      "淋巴细胞偏低\t琳巴细胞偏低\t0\n",
      "吸奶器可以开奶吗\t吸奶器可以开奶么\t0\n",
      "月经量少影响怀孕吗\t月经亮少影响怀孕吗\t0\n",
      "艾滋病有治愈的吗\t艾滋病有治愈的么\t0\n",
      "来月经可以吃乌鸡白凤丸吗\t来月经可以吃乌鸡白风丸吗\t1\n",
      "先涂防晒霜还是隔离霜\t先图防晒霜还是隔离霜\t1\n",
      "爱默生是哪国人\t艾默生是哪国人\t0\n",
      "孕妇糖尿病对胎儿有什么影响\t孕妇唐尿病对胎儿有什么影响\t1\n",
      "孕妇可以吃银耳吗\t孕妇可以吃银耳么\t0\n",
      "肺结节是怎么回事\t肺结接是怎么回事\t1\n",
      "慢性胃炎可以吃苹果吗\t漫性胃炎可以吃苹果吗\t1\n",
      "怀孕肚子硬吗\t怀孕肚子硬么\t0\n",
      "病毒性感冒怎么好的快\t病毒性感冒怎么好得快\t0\n",
      "糖尿病人能吃花生吗\t塘尿病人能吃花生吗\t0\n",
      "关于红军长征的诗\t关于红军长征的事\t0\n",
      "橱柜柜体用什么材料\t厨柜柜体用什么材料\t1\n",
      "不射进去会怀孕吗\t不射进去回怀孕吗\t0\n",
      "月经期可以吃苦瓜吗\t月经期可以吃苦瓜嘛\t1\n",
      "纸船怎么折\t纸船怎么者\t1\n",
      "三十七度一算发烧吗\t三十七度一算发烧么\t1\n",
      "刘亚的拼音\t刘娅的拼音\t1\n",
      "芒果吃了会上火吗\t芒果吃了会上火嘛\t1\n",
      "女人吃榴莲有什么好处\t女人吃榴莲又什么好处\t0\n",
      "头孢是消炎药吗\t头胞是消炎药吗\t1\n",
      "拔火罐可以减肥吗\t拔火罐可以减肥么\t1\n",
      "高血压能吃苦瓜吗\t高血压能吃苦瓜嘛\t0\n",
      "检查艾滋病多久出结果\t检查爱滋病多久出结果\t0\n",
      "霉菌性阴道炎怎么治疗\t霉菌性阴道炎怎么治了\t0\n",
      "结扎后能恢复吗\t结扎后能恢复么\t1\n",
      "膝盖疼是怎么回事\t膝盖疼是怎么会事\t0\n",
      "鼻炎会引起耳鸣吗\t鼻炎会引起耳鸣么\t0\n",
      "经期可以喝中药吗\t经期可以喝中药么\t0\n",
      "结肠炎有那些症状\t结肠炎有那些正状\t1\n",
      "即可以组什么词\t既可以组什么词\t0\n",
      "小孩流口水是什么原因\t小孩留口水是什么原因\t0\n",
      "华为怎么给苹果无线充电\t华为怎么给苹果无限充电\t0\n",
      "同型半胱氨酸偏高\t同性半胱氨酸偏高\t0\n",
      "网上怎么选车牌号\t往上怎么选车牌号\t1\n",
      "梦见死去姑父\t梦见死去姑夫\t1\n",
      "胆汁反流性胃炎的症状\t胆汁反流性胃炎的证状\t0\n",
      "咽喉癌的早期症状\t咽喉癌的早起症状\t0\n",
      "坐月子能吃甜瓜吗\t坐月子能吃田瓜吗\t1\n",
      "专心地看是什么词语\t专心的看是什么词语\t0\n",
      "石家庄是几线城市\t石家庄是几线成市\t0\n",
      "补血的药物有哪些\t补血的药物有那些\t0\n",
      "孕妇夏天可以吃冰淇淋吗\t孕妇夏天可以吃冰淇淋嘛\t0\n",
      "动感单车减肥效果好吗\t动敢单车减肥效果好吗\t0\n",
      "增强记忆力的食物\t增强计忆力的食物\t0\n",
      "甲状腺结节是怎么回事\t甲状腺结结是怎么回事\t1\n",
      "感冒能吃葡萄吗\t感冒能吃葡萄嘛\t1\n",
      "竖折折钩怎么写\t竖折折勾怎么写\t0\n",
      "小孩得了荨麻疹怎么办\t小孩得了寻麻疹怎么办\t1\n",
      "照片改背景颜色\t照片该背景颜色\t1\n",
      "隐适美价格\t隐世美价格\t1\n",
      "嗓子卡东西了怎么办\t嗓子恰东西了怎么办\t1\n",
      "瘦脸仪有用吗\t瘦脸仪有用么\t0\n",
      "中暑的急救方法\t重暑的急救方法\t0\n",
      "姜和白醋能去斑吗\t姜和白醋能祛斑吗\t0\n",
      "肾炎能吃豆制品吗\t肾炎能吃豆制品嘛\t1\n",
      "大便不成形是怎么回事\t大便不成行是怎么回事\t0\n",
      "手搓冰粉的做法\t手挫冰粉的做法\t0\n",
      "莲耦怎么做才好吃\t莲藕怎么做才好吃\t1\n",
      "中考400分能上高中吗\t中考400分能上高中嘛\t1\n",
      "荨麻疹可以吃红薯吗\t荨麻疹可以吃红薯么\t1\n",
      "关节松动术的适应证\t关节松动术的适应症\t1\n",
      "怀孕初期症状\t怀孕初七症状\t1\n",
      "爱情是什么\t爱情是十么\t0\n",
      "脚后跟疼是什么原因\t脚后跟疼是什么愿因\t0\n",
      "拉肚子可以喝咖啡吗\t拉肚子可以喝咖啡嘛\t0\n",
      "黑枸杞孕妇能吃吗\t黑枸杞孕妇能吃么\t0\n",
      "甲状腺球蛋白抗体高怎么办\t甲状腺秋蛋白抗体高怎么办\t0\n",
      "孕酮低吃什么\t孕酮滴吃什么\t0\n",
      "眼线怎么画\t眼线怎么话\t0\n",
      "心梗的症状有哪些症状\t心埂的症状有哪些症状\t0\n",
      "大乐透什么时候开奖\t大乐头什么时候开奖\t0\n",
      "打嗝怎么治\t大嗝怎么治\t0\n",
      "游泳可以减肥吗\t游泳可以减肥么\t0\n",
      "舌苔有裂纹是怎么回事\t舌台有裂纹是怎么回事\t0\n",
      "咸鱼卖东西靠谱吗?\t闲鱼卖东西靠谱吗?\t1\n",
      "坐月子可以吃红枣么\t做月子可以吃红枣么\t1\n",
      "花儿为什么那么红\t花儿未什么那么红\t0\n",
      "淋巴结发炎怎么办\t淋巴杰发炎怎么办\t0\n",
      "回首掏出处\t回手掏出处\t1\n",
      "被开水烫伤起泡怎么办\t被开水汤伤起泡怎么办\t0\n",
      "三视图怎么画\t三视图怎么花\t1\n",
      "仰卧起坐能减肚子吗\t仰卧起做能减肚子吗\t0\n",
      "不睡枕头好吗\t不睡枕头好嘛\t0\n",
      "六味地黄丸和逍遥丸可以一起吃吗\t六味地黄丸和消遥丸可以一起吃吗\t0\n",
      "成都好玩的地方\t成都好玩得地方\t0\n",
      "小三阳会传染吗\t小三阳会转染吗\t1\n",
      "a72支持面容解锁吗\ta72支持面容解锁码\t0\n",
      "抽完血能洗澡吗\t抽完血能洗澡嘛\t1\n",
      "哺乳期可以打乙肝疫苗吗\t哺乳期可以打乙肝疫苗嘛\t0\n",
      "无花果的功效\t无花果的公效\t0\n",
      "玫瑰花茶的功效与作用\t玫瑰花茶得功效与作用\t0\n",
      "血糖偏高怎么办\t雪糖偏高怎么办\t0\n",
      "甲状腺球蛋白抗体高是怎么回事\t甲壮腺球蛋白抗体高是怎么回事\t0\n",
      "治咳嗽的水果\t治咳嗽得水果\t0\n",
      "法制是什么\t法治是什么\t1\n",
      "补中益气丸的功效\t补中益气丸的工效\t0\n",
      "舌苔白是怎么回事\t舌台白是怎么回事\t0\n",
      "男生头发怎么长的快\t男生头发怎么长得快\t0\n",
      "晚上不吃饭可以吗\t晚上不吃饭可以嘛\t0\n",
      "人流挂哪个科\t人流挂那个科\t1\n",
      "经期可以吃感冒药吗\t经期可以吃感冒药么\t0\n",
      "孕妇能吃干贝吗\t孕妇能吃干贝么\t0\n",
      "明星人气榜投票\t名星人气榜投票\t1\n",
      "哺乳期可以吃燕窝吗\t哺乳期可以吃燕窝么\t1\n",
      "什么是细菌性阴道炎\t什么事细菌性阴道炎\t1\n",
      "被蚂蚁咬了怎么办\t被蚂蚁咬了怎么半\t0\n",
      "怀孕会尿频吗\t怀孕回尿频吗\t1\n",
      "月经推迟的危害\t月经推迟得危害\t1\n",
      "身上长水泡是怎么回事\t身上张水泡是怎么回事\t1\n",
      "拔火罐可以去湿气吗\t把火罐可以去湿气吗\t0\n",
      "开塞露可以擦脸吗\t开塞路可以擦脸吗\t1\n",
      "神经衰弱有哪些症状\t神经衰弱有那些症状\t0\n",
      "大便解不出来怎么办\t打便解不出来怎么办\t0\n",
      "小孩脸上有白斑\t小孩连上有白斑\t0\n",
      "艾滋病会通过唾液传染吗\t爱滋病会通过唾液传染吗\t1\n",
      "糖尿病人可以吃辣椒吗\t唐尿病人可以吃辣椒吗\t0\n",
      "胳膊麻木怎么回事\t胳膊麻木怎么会事\t1\n",
      "苦瓜的功效有哪些\t苦瓜的功效有那些\t1\n",
      "坐月子可以吃藕粉吗\t坐月子可以吃藕粉嘛\t0\n",
      "现在做什么小吃赚钱\t现在坐什么小吃赚钱\t1\n",
      "诺氟沙星治疗拉肚子吗\t诺氟沙星治疗拉肚子么\t0\n",
      "伊可尔治疗扁平疣\t伊可儿治疗扁平疣\t0\n",
      "感冒咳嗽可以吃蛋糕吗\t感冒咳嗽可以吃蛋糕么\t1\n",
      "鱿鱼怎么做\t鱿鱼怎么作\t0\n",
      "微信聊天记录怎么备份\t威信聊天记录怎么备份\t0\n",
      "腿酸是怎么回事\t腿酸是怎么会事\t0\n",
      "哺乳期可以吃桃子吗\t哺乳期可以吃桃子妈\t0\n",
      "券养的意思\t劵养的意思\t0\n",
      "喜帖街的歌词\t喜贴街的歌词\t0\n",
      "怀孕初期有什么反应\t怀孕初期有什么反映\t0\n",
      "震楼器会影响楼下吗\t振楼器会影响楼下吗\t0\n",
      "常吃六味地黄丸的好处\t长吃六味地黄丸的好处\t0\n",
      "王俊凯在重庆哪里\t王俊凯在重庆那里\t0\n",
      "羊奶粉好还是牛奶粉好\t养奶粉好还是牛奶粉好\t1\n",
      "喉咙痛可以吃橘子吗\t喉咙痛可以吃橘子嘛\t0\n",
      "月经期可以减肥吗\t月经期可以减肥么\t0\n",
      "如何治疗荨麻疹\t如何治疗荨麻诊\t0\n",
      "火龙果可以减肥吗\t火笼果可以减肥吗\t0\n",
      "近视眼贴有用吗\t近视眼贴有用么\t0\n",
      "梅花什么时候开\t梅花什么时候凯\t0\n",
      "放屁臭是什么原因\t防屁臭是什么原因\t0\n",
      "哪些食物含维生素d\t哪些食物含微生素d\t0\n",
      "后背疼挂什么科\t后辈疼挂什么科\t0\n",
      "滑膜炎的症状\t滑么炎的症状\t1\n",
      "甲状腺病传染吗\t甲壮腺病传染吗\t0\n",
      "聚鑫是什么意思\t聚心是什么意思\t0\n",
      "孕妇能吃黄桃吗\t孕妇能吃黄桃嘛\t0\n",
      "狗狗能吃橘子吗\t狗狗能吃橘子么\t0\n",
      "柯基能吃桃吗\t柯基能吃桃么\t0\n",
      "甲醛有气味吗\t甲荃有气味吗\t1\n",
      "发烧可以开空调吗\t发烧可以开空调嘛\t0\n",
      "杭州哪里有摩托车卖\t杭州哪里有摩托车买\t0\n",
      "种植牙能用多久\t种值牙能用多久\t1\n",
      "九连籽的功效\t九连子的功效\t0\n",
      "忧郁症的表现\t忧郁症得表现\t0\n",
      "做唐筛要空腹吗\t做唐筛要空腹么\t0\n",
      "牛仔裤怎么洗不褪色\t牛仔裤怎么冼不褪色\t1\n",
      "小孩能刮痧吗\t小孩能刮痧嘛\t1\n",
      "什么食物降血糖\t什么食物绛血糖\t1\n",
      "a92s支持面部解锁嘛\ta92s支持面部解锁码\t0\n",
      "拉屎拉不出来怎么办\t拉屎啦不出来怎么办\t0\n",
      "大便不成形次数多是什么原因\t大便不成型次数多是什么原因\t0\n",
      "来月经可以喝红枣水吗\t来月经可以和红枣水吗\t0\n",
      "甲状腺结节有什么症状\t甲状腺结节有什么证状\t1\n",
      "怀孕能吃茭白吗\t怀孕能吃茭白么\t1\n",
      "好听的女生英文名\t好听得女生英文名\t0\n",
      "怎么卸假睫毛\t怎么卸甲睫毛\t0\n",
      "新生儿黄疸值多少正常\t新生儿黄疸直多少正常\t1\n",
      "什么是附件炎\t什么事附件炎\t1\n",
      "吃降压药能喝酒吗\t吃降压药能喝酒么\t0\n",
      "鲜鲍鱼怎么做好吃\t先鲍鱼怎么做好吃\t0\n",
      "鬼压床是怎么回事\t鬼押床是怎么回事\t0\n",
      "牙齿痛的睡不着怎么办\t牙齿痛得睡不着怎么办\t1\n",
      "脖子涨痛是怎么回事\t脖子胀痛是怎么回事\t0\n",
      "小孩打喷嚏流鼻涕吃什么药\t小孩打喷涕流鼻涕吃什么药\t0\n",
      "教师资格证有有效期吗\t教师资格证有有效期么\t0\n",
      "肚子上的赘肉怎么减\t肚子上的坠肉怎么减\t1\n",
      "鼻窦炎能治吗\t鼻窦炎能治么\t0\n",
      "血糖高可以吃红薯吗\t血糖高可以吃红署吗\t1\n",
      "经常打嗝是怎么回事\t经常打隔是怎么回事\t0\n",
      "防溢乳垫有用吗\t防溢乳垫有用么\t0\n",
      "怎样去除老年斑\t怎样去除老年版\t0\n",
      "小三阳和大三阳哪个严重\t小三阳和大三阳那个严重\t1\n",
      "小孩可以吃芒果吗\t小孩可以吃芒果么\t1\n",
      "哺乳期可以喝蒲公英颗粒吗\t哺乳期可以喝蒲公英颗粒么\t1\n",
      "氯化钾注射液可以口服吗\t氯化钾注射夜可以口服吗\t0\n",
      "嘴巴周围长痘\t嘴巴周围张痘\t1\n",
      "什么是心脏早搏\t什么是心脏早博\t1\n",
      "月经推迟十几天正常吗\t月经推迟十几天正常嘛\t0\n",
      "师傅的师傅叫什么\t师傅得师傅叫什么\t1\n",
      "喝什么粥养胃\t喝什么州养胃\t0\n",
      "红霉素软膏的作用\t红霉素软高的作用\t1\n",
      "怎样剪腿上的肉\t怎样减腿上的肉\t0\n",
      "腰疼是怎么回事\t腰疼事怎么回事\t1\n",
      "什么是艾滋病\t什麼是艾滋病\t0\n",
      "微波炉可以考披萨吗\t微波炉可以考披萨么\t1\n",
      "肉苁蓉怎么泡酒\t肉苁蓉怎么炮酒\t0\n",
      "孕妇可以吃泡面吗\t孕妇可以吃泡面妈\t1\n",
      "左上腹疼痛\t左上复疼痛\t0\n",
      "微信如何升级\t微信如何生级\t1\n",
      "神经性耳聋可以治愈吗\t神经性耳聋可以治愈嘛\t0\n",
      "什么是维生素c\t什么是微生素c\t0\n",
      "白带是排卵吗\t白带是排卵嘛\t1\n",
      "怀孕能吃大蒜吗\t怀孕能吃大蒜么\t0\n",
      "怀孕能吃橘子吗\t怀孕能吃橘子么\t0\n",
      "血糖高的人可以吃红薯吗\t血糖高的人可以吃红薯么\t1\n",
      "圣诞节礼物\t圣诞接礼物\t0\n",
      "痛风能吃橙子吗\t痛风能吃橙子么\t0\n",
      "怎么买电影票\t怎么卖电影票\t0\n",
      "节育环哪种最好\t节育环那种最好\t0\n",
      "来月经可以喝酸奶吗\t来月经可以和酸奶吗\t1\n",
      "孕妇可以戴隐形眼镜吗\t孕妇可以带隐形眼镜吗\t0\n",
      "微信怎么查聊天记录\t微信怎么查聊天纪录\t1\n",
      "乙肝小三阳传染吗\t乙肝小三阳传染么\t0\n",
      "中国前十大上市公司\t中国前十大上市公司\t1\n",
      "单字名字女\t单子名字女\t0\n",
      "内分泌失调怎么调理\t内分秘失调怎么调理\t1\n",
      "最小公倍数怎么求\t最小公倍数怎么球\t0\n",
      "人的正常体温是多少\t人的正尝体温是多少\t1\n",
      "英语日常用语\t英语日常用于\t1\n",
      "子宫疼怎么回事\t字宫疼怎么回事\t1\n",
      "脱发挂什么科\t脱发挂什么课\t1\n",
      "免疫球蛋白多少钱一针\t免疫求蛋白多少钱一针\t0\n",
      "心脏主要由什么细胞构成\t心脏主要有什么细胞构成\t0\n",
      "坐飞机耳朵痛怎么办\t做飞机耳朵痛怎么办\t0\n",
      "苹果手机怎么格式化\t苹果手机怎么各式化\t1\n",
      "空腹血糖正常值范围\t空服血糖正常值范围\t0\n",
      "怎么下载手机银行\t怎么下栽手机银行\t0\n",
      "肩膀长痘痘是什么原因\t肩膀张痘痘是什么原因\t0\n",
      "艾滋病的症状\t艾滋病的政状\t0\n",
      "颈部淋巴结肿大\t颈不淋巴结肿大\t0\n",
      "大肠息肉严重吗\t大肠息肉严重么\t0\n",
      "洗牙的好处\t洗呀的好处\t0\n",
      "梦见吃橘子\t梦见吃桔子\t1\n",
      "莓菌性阴炎怎么根冶\t莓菌性阴炎怎么跟冶\t1\n",
      "人为什么会做梦\t仁为什么会做梦\t0\n",
      "机器人怎么做\t机气人怎么做\t0\n",
      "吃烧烤会胖吗\t吃烧烤会胖么\t1\n",
      "人体正常体温是多少\t人体正长体温是多少\t1\n",
      "世界上最小的国家是哪个国家\t世界上最小的国家是那个国家\t1\n",
      "南通市在哪个省\t南通市在那个省\t0\n",
      "说话结巴怎么办\t说话结吧怎么办\t1\n",
      "怀孕为什么会流血\t怀孕为什么会留血\t0\n",
      "修眉的注意事项\t绣眉的注意事项\t0\n",
      "菱形块怎么切\t菱形快怎么切\t0\n",
      "闭合性粉刺怎么治疗\t闭和性粉刺怎么治疗\t0\n",
      "怀男孩的症状\t怀男孩的证状\t0\n",
      "怀孕可以吃豆腐吗\t怀孕可以吃豆腐嘛\t1\n",
      "来姨妈可以吃芒果吗\t来姨妈可以吃芒果么\t0\n",
      "眼睛有红血丝怎么回事\t眼精有红血丝怎么回事\t1\n",
      "哪里有免费电影\t那里有免费电影\t1\n",
      "孕妇可以拔罐吗\t孕妇可以拔罐妈\t1\n",
      "输尿管末端结石好排吗\t输尿管末端结石好牌吗\t1\n",
      "怀孕初期白带多吗\t怀孕初期白带多么\t0\n",
      "感冒能吃芒果吗\t感冒能吃芒果么\t0\n",
      "汽车坐垫什么牌子好\t汽车做垫什么牌子好\t0\n",
      "经期可以吃芒果吗\t经起可以吃芒果吗\t0\n",
      "什么的波纹\t什么得波纹\t0\n",
      "痛风可以吃海鲜吗\t痛风可以吃海鲜么\t1\n",
      "拔罐起泡是怎么回事\t拔管起泡是怎么回事\t1\n",
      "乳房疼是怎么回事\t乳妨疼是怎么回事\t1\n",
      "眼霜的作用\t眼霜的做用\t1\n",
      "怎样消除黑眼圈\t怎样消出黑眼圈\t0\n",
      "孕妇能吃茶叶蛋吗\t孕妇能吃茶叶蛋嘛\t0\n",
      "脱式计算是什么\t脱式记算是什么\t0\n",
      "冷冻鳕鱼的做法\t冷冻雪鱼的做法\t1\n",
      "人有多少颗牙齿\t人有多少克牙齿\t0\n",
      "新疆最出名的沙漠\t新疆最著名的沙漠\t0\n",
      "孕妇可以吃辣条吗早期\t孕妇可以吃辣条么早期\t1\n",
      "牙疼怎么治\t牙疼怎麼治\t0\n",
      "脚底板痒是什么原因\t脚地板痒是什么原因\t0\n",
      "小儿肺炎有哪些症状\t小儿肺炎有那些症状\t1\n",
      "湿疹与痱子的区别\t湿诊与痱子的区别\t1\n",
      "经期能艾灸吗\t经期能艾灸么\t0\n",
      "怀孕可以吃冰淇淋吗\t怀孕可以吃冰淇淋嘛\t0\n",
      "虚幻缥缈的意思\t虚幻飘渺的意思\t0\n",
      "补缴住房公积金可以贷款吗\t补交住房公积金可以贷款吗\t1\n",
      "梦见自己生孩子\t梦见自几生孩子\t0\n",
      "解脲脲原体会自愈吗\t解脲脲原体会自愈么\t1\n",
      "作信封的方法\t做信封的方法\t1\n",
      "唐嫣哪里人\t唐嫣那里人\t0\n",
      "公积金可以取吗?\t公基金可以取吗?\t0\n",
      "背上长痘痘的原因\t背上张痘痘的原因\t1\n",
      "荨麻疹的原因\t荨麻疹得原因\t0\n",
      "怀孕肚子胀怎么回事\t怀孕肚子帐怎么回事\t0\n",
      "哪些昆虫是害虫\t那些昆虫是害虫\t1\n",
      "中考让带手表吗\t中考让戴手表吗\t0\n",
      "吃红糖会发胖吗\t吃红唐会发胖吗\t0\n",
      "长智齿疼怎么办\t张智齿疼怎么办\t1\n",
      "驼背怎么矫正\t驮背怎么矫正\t0\n",
      "腰压迫神经怎么治疗\t腰压破神经怎么治疗\t1\n",
      "拉肚子可以吃蛋吗\t拉肚子可以吃蛋嘛\t0\n",
      "什么是心率不齐\t什么事心率不齐\t0\n",
      "月子可以吃桃子吗\t月子可以吃桃子妈\t0\n",
      "脸上长斑是什么原因\t脸上张斑是什么原因\t0\n",
      "带状疱疹的症状\t带壮疱疹的症状\t0\n",
      "杜甫著名的诗\t杜甫出名的诗\t0\n",
      "经期能拔牙吗\t经期能拔牙嘛\t0\n",
      "其可以组什么词\t既可以组什么词\t0\n",
      "猫一年生几胎\t猫一年生几台\t0\n",
      "红色经典书籍\t红色精典书籍\t0\n",
      "没食欲恶心\t无食欲恶心\t1\n",
      "猪肝怎么炒好吃\t猪肝怎么抄好吃\t1\n",
      "老烂腿怎么治\t老烂腿怎麼治\t0\n",
      "几何体是什么\t几和体是什么\t0\n",
      "怀孕可以吃黄豆吗\t怀孕可以吃黄豆么\t0\n",
      "喝奶茶失眠怎么办\t和奶茶失眠怎么办\t1\n",
      "哺乳期可以喝绿豆汤吗\t哺乳期可以喝绿豆汤么\t0\n",
      "血糖高的人能吃橘子吗\t血糖高的人能吃桔子吗\t1\n",
      "血压140正常吗\t血压140正常么\t1\n",
      "慢性萎缩性胃炎症状\t慢性萎缩性胃炎证状\t0\n",
      "手机听筒声音小怎么办\t手机听桶声音小怎么办\t0\n",
      "感冒药饭前吃还是饭后吃\t感冒药饭钱吃还是饭后吃\t0\n",
      "坐月子可以吃饼干吗\t坐月子可以吃饼干么\t0\n",
      "微信号怎么注销\t微信号怎么注消\t0\n",
      "怀孕能用花露水吗\t怀孕能用花露水嘛\t0\n",
      "微信怎么删除好友\t微信怎么珊除好友\t0\n",
      "糖尿病可以吃木瓜吗\t糖尿病可以吃木瓜么\t0\n",
      "喝咖啡能减肥吗\t和咖啡能减肥吗\t1\n",
      "落枕脖子疼怎么办\t洛枕脖子疼怎么办\t1\n",
      "揉腹部的正确方法\t揉腹补的正确方法\t0\n",
      "胃肠感冒吃什么药\t胃肠感冒吃什么要\t0\n",
      "冰点脱毛永久吗\t冰点脱毛永久么\t0\n",
      "宝宝贫血有什么症状\t宝宝贫血有什么证状\t1\n",
      "早餐卖什么赚钱\t早餐买什么赚钱\t0\n",
      "孕妇可以做足疗吗\t孕妇可以做足疗嘛\t1\n",
      "土豆属于发物吗\t土豆属于发物嘛\t1\n",
      "肝火旺怎么治\t肝火望怎么治\t1\n",
      "怀孕初期能吃方便面吗\t怀孕初期能吃方便面么\t1\n",
      "朱茵结婚了吗\t朱茵结婚了么\t0\n",
      "生理期能喝茶吗\t生理期能喝茶嘛\t0\n",
      "不管是什么都往嘴里添\t不管是什么都往嘴里填\t0\n",
      "经常腹泻是怎么回事\t经常复泻是怎么回事\t1\n",
      "北京站在哪个区\t北京站在那个区\t0\n",
      "怀孕可以吃麻油吗\t怀孕可以吃麻油嘛\t0\n",
      "治疗胃病的药\t治疗胃病的要\t0\n",
      "月经期间可以喝蜂蜜吗\t月经期间可以和蜂蜜吗\t0\n",
      "刚怀孕会尿频吗\t刚怀孕会尿频么\t0\n",
      "淋巴结肿大严重吗\t淋巴节肿大严重吗\t0\n",
      "脸上长脂肪粒怎么回事\t脸上张脂肪粒怎么回事\t1\n",
      "尖锐湿疣如何治疗\t尖锐湿尤如何治疗\t0\n",
      "白癜风能根治吗\t白癜风能根治嘛\t0\n",
      "体检抽血可以喝水吗\t体检抽血可以喝水么\t1\n",
      "三角形的周长怎么求\t三角型的周长怎么求\t0\n",
      "吃橙子会胖吗\t吃橙子会胖么\t0\n",
      "胆囊炎可以喝牛奶吗\t胆囊炎可以和牛奶吗\t0\n",
      "有胃病能喝酸奶吗\t有胃病能喝酸奶么\t0\n",
      "隔离的做用\t隔离的作用\t1\n",
      "孕妇可以吃鸭肉吗\t孕妇可以吃鸭肉么\t0\n",
      "拉肚子能不能吃橘子\t拉肚子能不能吃桔子\t1\n",
      "怎样改转述句\t怎样改传述句\t0\n",
      "石英砂用途\t石英沙用途\t1\n",
      "每天早上喝蜂蜜水好吗\t每天早上和蜂蜜水好吗\t0\n",
      "胃不好能吃西瓜吗\t胃不好能吃西瓜么\t1\n",
      "尿道感染怎么治\t尿到感染怎么治\t1\n",
      "做蛋糕用什么面粉\t坐蛋糕用什么面粉\t0\n",
      "格力售后服务电话\t格立售后服务电话\t0\n",
      "那里有二手摩托车买\t那里有二手摩托车卖\t0\n",
      "肚子胀胀的怎么回事\t肚子涨涨的怎么回事\t0\n",
      "大便拉不出来怎么办\t大便垃不出来怎么办\t0\n",
      "右脚大拇指发麻\t右脚大母指发麻\t0\n",
      "达克宁治龟头炎吗\t达克宁治鬼头炎吗\t0\n",
      "上吐下泻肚子疼吃什么药\t上吐下泄肚子疼吃什么药\t1\n",
      "孕后期可以吃冰淇淋吗\t孕后期可以吃冰淇淋嘛\t0\n",
      "儿童可以喝蜂蜜水吗\t儿童可以喝蜂蜜水嘛\t0\n",
      "糖尿病早期症状\t糖尿病早期症壮\t0\n",
      "怀孕可以吃豆芽吗\t怀孕可以吃豆芽么\t0\n",
      "澳元兑人民币汇率趋势\t澳元对人民币汇率趋势\t1\n",
      "如何申请微信号\t如和申请微信号\t1\n",
      "孕妇能吃韭菜吗\t孕夫能吃韭菜吗\t1\n",
      "什么是天堂\t什么事天堂\t0\n",
      "怀孕初期可以吃火锅嘛\t怀孕初期可以吃火锅吗\t0\n",
      "长辈过生日送什么花\t长背过生日送什么花\t0\n",
      "得了脂肪肝怎么办\t的了脂肪肝怎么办\t0\n",
      "手上长鸡眼\t手上张鸡眼\t0\n",
      "坐月子能做面膜吗\t做月子能做面膜吗\t0\n",
      "拔智齿脸会变小吗\t拔智齿脸会变小嘛\t1\n",
      "晚上咳的厉害是怎么回事\t晚上咳得厉害是怎么回事\t0\n",
      "月经推迟两天正常吗\t月经推迟两天正常么\t0\n",
      "长针眼怎么办\t张针眼怎么办\t0\n",
      "蜂巢怎么吃\t蜂巢怎麼吃\t0\n",
      "深海鱼油的功效与作用\t深海鱼尤的功效与作用\t0\n",
      "怀孕能吃香蕉吗\t怀孕能吃香蕉嘛\t0\n",
      "网上怎么定汽车票\t网上怎么顶汽车票\t0\n",
      "正常视力是多少\t正常视里是多少\t0\n",
      "流鼻涕咳嗽\t留鼻涕咳嗽\t0\n",
      "小孩剪什么发型好看\t小孩减什么发型好看\t0\n",
      "蒲公英能长期喝吗\t蒲公英能长期喝么\t0\n",
      "怎么改无线网密码\t怎么改无限网密码\t0\n",
      "嗜酸性粒细胞偏高\t是酸性粒细胞偏高\t1\n",
      "六味地黄丸有副作用吗\t六味地黄丸有副作用嘛\t0\n",
      "带状泡疹最佳治疗方法\t带状疱疹最佳治疗方法\t0\n",
      "怀孕能吃原荽吗\t怀孕能吃园荽吗\t0\n",
      "怀孕能吃面包吗\t怀孕能吃面包么\t0\n",
      "拉肚子可以吃火龙果吗\t拉肚子可以吃火龙果么\t0\n",
      "孕妇能吃皮皮虾吗\t孕妇能吃皮皮虾么\t1\n",
      "感冒吃什么药\t敢冒吃什么药\t1\n",
      "广西有那些好的大专\t广西有那些好的大专\t1\n",
      "感冒发烧能吃橙子吗\t感冒发烧能吃橙子么\t0\n",
      "脑供血不足怎么办\t脑供血不足怎么半\t0\n",
      "交通安全手抄报内容\t交通安全收抄报内容\t1\n",
      "耳朵后面长了个小疙瘩\t耳朵后面涨了个小疙瘩\t1\n",
      "现在什么行业好做\t现在什麼行业好做\t0\n",
      "脂肪肝有什么症状\t脂防肝有什么症状\t0\n",
      "新生儿肺炎的症状有哪些\t新生儿肺炎的症状有那些\t1\n",
      "生肖三合是什么意思\t生肖三和是什么意思\t1\n",
      "甲状腺结节\t甲状线结节\t1\n",
      "孕妇可以吃川贝炖雪梨吗\t孕妇可以吃川北炖雪梨吗\t1\n",
      "甲状腺结节需要手术吗\t甲状腺结结需要手术吗\t1\n",
      "鲜胚移植后几天着床\t鲜配移植后几天着床\t0\n",
      "你会吐位情况吗\t你会吐胃情况吗\t0\n",
      "孕妇可以喝红糖水吗\t孕妇可以和红糖水吗\t0\n",
      "有几种荨麻疹\t有几种寻麻疹\t1\n",
      "怀不了孕做哪些检查\t怀不了孕做那些检查\t0\n",
      "长寿花的花期是什么时候\t长寿花的花季是什么时候\t0\n",
      "怎样会怀孕\t怎样回怀孕\t0\n",
      "拉不出来屎怎么办\t拉不出来时怎么办\t0\n",
      "体检前可以喝水吗\t体检前可以喝水嘛\t0\n",
      "怎么删除淘宝订单\t怎么删除淘宝定单\t0\n",
      "怎样预防新生儿黄疸\t怎样预防新生儿黄胆\t0\n",
      "玻尿酸多少钱一只\t玻尿酸多少钱一直\t0\n",
      "眼睛充血用什么眼药水\t眼睛冲血用什么眼药水\t0\n",
      "白癜风会痒吗\t白癜风回痒吗\t0\n",
      "什么样的嘴巴\t什么样的嘴吧\t0\n",
      "带套不会怀孕吧\t戴套不会怀孕吧\t0\n",
      "头发有头皮屑怎么办\t头发又头皮屑怎么办\t0\n",
      "怎么治口臭\t怎么只口臭\t1\n",
      "蚕的生长过程\t蚕的生长过成\t1\n",
      "肝火旺盛吃什么药\t肝火旺胜吃什么药\t0\n",
      "妊娠糖尿病可以喝纯牛奶吗\t妊娠糖尿病可以喝纯牛奶嘛\t1\n",
      "神经炎是什么症状\t神精炎是什么症状\t0\n",
      "拔火罐可以减肥吗\t拔火罐可以减肥嘛\t1\n",
      "怀孕初期能吃榴莲吗\t怀孕初期能吃榴莲么\t0\n",
      "阑尾炎手术后吃什么好\t兰尾炎手术后吃什么好\t1\n",
      "偏头痛是什么原因\t片头痛是什么原因\t0\n",
      "子宫内膜多厚会来月经\t子宫内膜多厚回来月经\t0\n",
      "喝红茶上火吗\t和红茶上火吗\t0\n",
      "经常头痛是什么原因\t经常头痛是什么愿因\t0\n",
      "菊花的功效与作用\t菊花得功效与作用\t1\n",
      "奥美拉唑饭前吃还是饭后吃\t奥美啦唑饭前吃还是饭后吃\t1\n",
      "尿酸高能吃生蚝吗\t尿酸高能吃生蚝么\t1\n",
      "脚痒脱皮是什么原因\t脚痒拖皮是什么原因\t0\n",
      "舌头有裂纹是怎么回事\t舌头有列纹是怎么回事\t0\n",
      "微信密码忘记了怎么办\t薇信密码忘记了怎么办\t1\n",
      "内分泌失调是什么症状\t内分泌失调是什么证状\t0\n",
      "正确佩戴口罩的方式\t正确配戴口罩的方式\t1\n",
      "甲亢不能吃什么\t甲抗不能吃什么\t0\n",
      "肠胃炎能吃橙子吗\t肠胃炎能吃橙子么\t0\n",
      "射进去一次会怀孕吗\t射进去一次会怀孕么\t1\n",
      "孕妇可以吃草莓吗\t孕妇可以吃草莓么\t1\n",
      "皮肤过敏痒怎么办\t皮服过敏痒怎么办\t0\n",
      "小肚子胀怎么回事\t小肚子涨怎么回事\t0\n",
      "肝脾不和的症状\t肝脾不合的症状\t0\n",
      "跳成语接龙开头的成语\t超成语接龙开头的成语\t0\n",
      "经常抠鼻子有什么坏处\t经常扣鼻子有什么坏处\t0\n",
      "哺乳期吃什么好\t捕乳期吃什么好\t1\n",
      "喝咖啡对月经有影响吗\t和咖啡对月经有影响吗\t0\n",
      "怀孕可以喝养乐多吗\t怀孕可以喝养乐多嘛\t0\n",
      "下眼眶疼是怎么回事\t下眼框疼是怎么回事\t1\n",
      "例假能喝咖啡吗\t例假能喝咖啡嘛\t0\n",
      "月经前白带会多吗\t月经前白带会多么\t1\n",
      "尖锐湿疣怎么得的\t尖锐湿疣怎么得得\t0\n",
      "来例假能喝茶吗\t来例假能喝茶嘛\t0\n",
      "胃炎可以喝红糖水吗\t胃炎可以和红糖水吗\t0\n",
      "刚出生的婴儿打嗝怎么办\t刚出生的婴儿打隔怎么办\t0\n",
      "蟑螂会咬人吗\t蟑螂回咬人吗\t0\n",
      "怀孕可以吃零食吗\t怀孕可以吃零食么\t0\n",
      "吃黄瓜可以减肥吗\t吃黄瓜可以减肥么\t0\n",
      "大脑供血不足的症状\t打脑供血不足的症状\t1\n",
      "地中海贫血\t地重海贫血\t0\n",
      "颈椎病怎样治疗\t颈椎病怎样制疗\t0\n",
      "感冒对体检有影响吗\t感冒对体检有影响么\t1\n",
      "什么是定向流量\t什麼是定向流量\t1\n",
      "哺乳期感冒可以喝板蓝根吗\t哺乳期感冒可以和板蓝根吗\t0\n",
      "孕妇可以吃土豆吗\t孕妇可以吃土豆嘛\t1\n",
      "香蕉和酸奶可以一起吃吗\t香焦和酸奶可以一起吃吗\t0\n",
      "孕妇喝纯牛奶好吗\t孕妇喝纯牛奶好嘛\t0\n",
      "太阳穴长痘怎么回事\t太阳穴长痘怎么会事\t0\n",
      "怀孕初期能喝姜糖水吗\t怀孕初期能喝姜汤水吗\t0\n",
      "坐月子能吃李子吗\t坐月子能吃李子嘛\t0\n",
      "哪个网站买书便宜\t哪个网站卖书便宜\t0\n",
      "慢性胃炎怎么调理\t慢行胃炎怎么调理\t0\n",
      "你有喜欢的人么\t你有喜欢的人吗\t1\n",
      "孕妇能喝椰子汁吗\t孕妇能喝椰子汁么\t0\n",
      "排卵期一般几天\t排卵期一半几天\t1\n",
      "如何用黏土自制起泡胶\t如何用粘土自制起泡胶\t1\n",
      "手脱皮是什么原因\t手拖皮是什么原因\t0\n",
      "吃了头孢喝酒会怎么样\t吃了头孢和酒会怎么样\t1\n",
      "来例假腰疼是怎么回事\t来历假腰疼是怎么回事\t0\n",
      "充电宝要托运吗\t充电宝要托运么\t0\n",
      "妊娠糖尿病可以吃小米粥吗\t妊娠糖尿病可以吃小米粥嘛\t0\n",
      "妊娠糖尿病可以吃南瓜吗\t妊娠糖尿病可以吃南瓜嘛\t0\n",
      "氯化钠是不是生理盐水\t录化钠是不是生理盐水\t0\n",
      "盆腔积液是怎么引起的\t喷腔积液是怎么引起的\t0\n",
      "小布丁雪糕的做法\t小不丁雪糕的做法\t0\n",
      "左胸疼是怎么回事\t昨胸疼是怎么回事\t0\n",
      "幼儿急疹可以出门吗\t幼儿急疹可以出门么\t1\n",
      "脾虚湿气重吃什么药\t脾需湿气重吃什么药\t1\n",
      "经期可以吃感冒药吗\t经期可以吃感冒药嘛\t1\n",
      "带状疱疹严重吗\t带状疱疹严重嘛\t1\n",
      "痛经能喝红糖水吗\t痛经能和红糖水吗\t0\n",
      "生理期可以喝红糖水吗\t生理期可以喝红糖水么\t1\n",
      "巧影怎么扣图\t巧影怎么抠图\t0\n",
      "咽喉滤泡增生怎么治疗\t咽后滤泡增生怎么治疗\t0\n",
      "生理期可以吃什么水果\t生理期可以吃什麼水果\t1\n",
      "月经期间可以吃山竹吗\t月经其间可以吃山竹吗\t0\n",
      "咳嗽怎样好得快\t咳嗽怎样好的快\t0\n",
      "中暑会肚子疼吗\t中暑会肚子疼么\t1\n",
      "艾滋病潜伏期能查出来吗\t艾滋病潜伏期能查出来么\t0\n",
      "眼睛混浊是什么原因\t眼睛浑浊是什么原因\t0\n",
      "贾玲多少岁了\t嘉玲多少岁了\t1\n",
      "做引产疼吗\t做引产疼嘛\t0\n",
      "橘子的升糖指数是多少\t桔子的升糖指数是多少\t1\n",
      "来月经可以泡脚吗\t来月经可以跑脚吗\t0\n",
      "葡萄的功效\t葡萄的公效\t0\n",
      "湿气重的症状有哪些\t湿气中的症状有哪些\t1\n",
      "王健林哪里人\t王建林哪里人\t0\n",
      "眼睛黄是什么原因\t眼镜黄是什么原因\t0\n",
      "咳嗽可以喝豆浆吗\t咳嗽可以喝豆浆嘛\t0\n",
      "怎么去除痘印\t怎么去处痘印\t1\n",
      "考试作弊打一数学名词\t考试做弊打一数学名词\t0\n",
      "食言了是什么意思\t失言了是什么意思\t0\n",
      "开塞露有副作用吗\t开塞露有副作用嘛\t0\n",
      "电热毯有辐射吗\t电热毯有辐射么\t1\n",
      "西瓜皮可以生吃吗\t西瓜皮可以生吃么\t0\n",
      "吃什么药来月经\t吃什么要来月经\t0\n",
      "布艺沙发哪个品牌好\t布艺沙发那个品牌好\t0\n",
      "精囊炎有哪些症状\t精囊炎有那些症状\t0\n",
      "有痰咳不出来吃什么药\t有谈咳不出来吃什么药\t0\n",
      "经期可以吃芒果吗\t经期可以吃芒果么\t0\n",
      "经常做梦是什么原因\t经常坐梦是什么原因\t1\n",
      "桔子糖分高吗\t桔子糖份高吗\t1\n",
      "黄体酮和地屈孕酮片的区别\t黄体酮和地区孕酮片的区别\t0\n",
      "三角形的周长公式\t三角形得周长公式\t1\n",
      "神经性头痛怎么治疗\t神精性头痛怎么治疗\t0\n",
      "八个月的宝宝发烧怎么办\t八个月得宝宝发烧怎么办\t0\n",
      "哺乳期能喝菊花茶吗\t哺乳期能喝菊花茶嘛\t0\n",
      "戴牙套怎么刷牙\t带牙套怎么刷牙\t1\n",
      "微信密码忘记了怎么办\t微信蜜码忘记了怎么办\t0\n",
      "肾结石能吃豆芽吗\t肾结石能吃豆牙吗\t0\n",
      "颈椎病的症状有哪些\t颈椎病的证状有哪些\t1\n",
      "艾灸能天天做吗\t艾灸能天天做么\t0\n",
      "鼻窦炎的症状\t鼻逗炎的症状\t0\n",
      "甲亢的早期症状\t甲亢的早起症状\t0\n",
      "恶性肿瘤是癌症吗\t恶性肿瘤是癌症嘛\t0\n",
      "耳朵流水怎么办\t耳多流水怎么办\t1\n",
      "和乙肝患者共用碗筷会传染吗\t和乙肝患者公用碗筷会传染吗\t1\n",
      "女生做什么工作比较好\t女生坐什么工作比较好\t0\n",
      "哺乳期能吃米线吗\t哺乳期能吃米线嘛\t0\n",
      "抑郁症能治愈吗\t抑郁证能治愈吗\t0\n",
      "怎样正确的刷牙\t怎样正确地刷牙\t1\n",
      "大便出血怎么办\t大便初血怎么办\t0\n",
      "唇炎怎么治\t唇炎怎么吃\t0\n",
      "蛋白质高的食物有哪些\t蛋白质高的实物有哪些\t0\n",
      "马克思和恩格斯是哪国人\t马克思和恩格斯是那国人\t1\n",
      "什么食物含锌\t什么实物含锌\t0\n",
      "阿胶小孩可以吃吗\t阿娇小孩可以吃吗\t1\n",
      "输卵管堵塞会宫外孕吗\t输卵管堵塞会宫外孕嘛\t1\n",
      "粽子怎么做的?\t棕子怎么做的?\t0\n",
      "支付宝如何充值\t支付宝如何冲值\t0\n",
      "康妇消炎栓为什么是直肠给药\t康复消炎栓为什么是直肠给药\t0\n",
      "眼睛进沙子怎么办\t眼睛进砂子怎么办\t1\n",
      "怎样恢复眼睛视力\t怎样回复眼睛视力\t0\n",
      "如何让胸变小\t如何让凶变小\t0\n",
      "月经淋漓不尽怎么办\t月经淋离不尽怎么办\t1\n",
      "滑石粉的功效与作用\t华石粉的功效与作用\t0\n",
      "怎样去疤痕\t怎样去巴痕\t0\n",
      "偏头痛是怎么引起的\t偏头痛是怎么引起得\t1\n",
      "眼睛里进东西了怎么办\t眼睛里今东西了怎么办\t0\n",
      "草珊瑚的功效与作用\t草珊湖的功效与作用\t0\n",
      "做肠镜需要多长时间\t做肠境需要多长时间\t1\n",
      "抑郁症怎么治疗\t意郁症怎么治疗\t0\n",
      "炉石传说哪些牌可以分解\t炉石传说那些牌可以分解\t0\n",
      "刺激性食物有哪些\t刺激性食物有那些\t0\n",
      "中国最穷的县\t中国最穷得县\t0\n",
      "什么叫定向流量\t什么教定向流量\t0\n",
      "水痘和疱疹的区别\t水逗和疱疹的区别\t0\n",
      "胃肠功能紊乱的症状\t胃肠功能稳乱的症状\t0\n",
      "月经后几天是排卵期\t月经后几天是拍卵期\t0\n",
      "小儿肠胃炎\t小儿常胃炎\t0\n",
      "酵素可以减肥吗\t酵素可以减肥嘛\t1\n",
      "元曲四大家之首是谁\t元曲四大家之手是谁\t0\n",
      "泰迪能吃豌豆吗\t泰迪能吃豌豆么\t1\n",
      "脚后跟长骨刺怎么办\t脚后跟涨骨刺怎么办\t0\n",
      "孕妇可以吃提子吗\t孕妇可以吃提子嘛\t0\n",
      "骶1隐性脊椎裂\t骶1隐形脊椎裂\t0\n",
      "妇科纳囊是什么病\t妇科那囊是什么病\t1\n",
      "什么是光子嫩肤\t什么事光子嫩肤\t1\n",
      "大蛇丸死了吗\t大蛇丸死了么\t0\n",
      "荨麻疹不能吃什么\t寻麻疹不能吃什么\t0\n",
      "热感冒可以喝姜汤吗\t热感冒可以喝姜汤嘛\t0\n",
      "什么情况下需要根管治疗\t什么情况下需要跟管治疗\t0\n",
      "什么时候用have\t什么时侯用have\t0\n",
      "避孕套有保质期吗\t避孕套有保质期么\t1\n",
      "三围是哪三围\t三位是哪三围\t0\n",
      "专心的看叫什么视\t专心的看叫什么是\t1\n",
      "怀孕会犯困吗\t怀孕会犯困么\t0\n",
      "月经不调怎么办\t月经不条怎么办\t0\n",
      "经常放屁是怎么回事\t经常放屁事怎么回事\t0\n",
      "奥美拉唑饭前吃还是饭后吃\t奥美垃唑饭前吃还是饭后吃\t0\n",
      "颈椎退行性变如何治疗\t颈椎推行性变如何治疗\t0\n",
      "月经来了能吃芒果吗\t月经来了能吃茫果吗\t0\n",
      "植物神经功能紊乱有哪些症状\t植物神精功能紊乱有哪些症状\t0\n",
      "晚上跑步能减肥吗\t晚上跑不能减肥吗\t0\n",
      "额头下巴长痘痘是什么原因\t额头下巴涨痘痘是什么原因\t1\n",
      "安卓手机语音怎么设置\t安卓手机语言怎么设置\t0\n",
      "骨质疏松的症状\t骨质疏松得症状\t0\n",
      "妊娠糖尿病可以喝绿豆汤吗\t妊娠糖尿病可以喝绿豆汤么\t1\n",
      "来月经可以喝奶茶吗\t来月经可以喝奶茶嘛\t0\n",
      "梨花什么颜色\t梨花是么颜色\t0\n",
      "茄子会回奶吗\t茄子会回奶么\t1\n",
      "黑芝麻的功效与作用\t嘿芝麻的功效与作用\t1\n",
      "什么浏览器好用\t什么流览器好用\t1\n",
      "山西应急厅厅长\t陕西应急厅厅长\t0\n",
      "肺部有结节严重吗\t肺不有结节严重吗\t1\n",
      "额头长痘痘是什么原因\t额头张痘痘是什么原因\t0\n",
      "尿频尿急是怎么回事\t尿濒尿急是怎么回事\t0\n",
      "宫颈癌前期有什么症状\t宫颈癌前期有什么证状\t0\n",
      "深蹲可以减肥吗\t深蹲可以减肥嘛\t0\n",
      "忽如一夜春风来千树万树梨花开是哪个季节\t呼如一夜春风来千树万树梨花开是哪个季节\t0\n",
      "豆浆能隔夜喝吗\t豆浆能隔夜喝嘛\t0\n",
      "孕妇能吃橘子吗\t孕妇能吃桔子吗\t1\n",
      "母亲节什么时候\t母亲杰什么时候\t0\n",
      "糖尿病患者可以喝豆浆吗\t糖尿病患者可以和豆浆吗\t1\n",
      "痔疮可以吃鸡肉吗\t痔疮可以吃鸡肉嘛\t1\n",
      "狂犬病传播途径\t狂犬病传播途经\t0\n",
      "怎样会导致不孕\t怎样会导至不孕\t0\n",
      "可以找公司代缴社保吗\t可以找公司代交社保吗\t1\n",
      "什么软件充话费最便宜\t什么软件冲话费最便宜\t0\n",
      "荨麻疹会不会传染\t荨麻诊会不会传染\t0\n",
      "淋巴瘤有什么症状\t淋巴瘤有什么证状\t0\n",
      "肩周炎的症状\t肩周炎的正状\t0\n",
      "拔智齿后多久可以吃东西\t把智齿后多久可以吃东西\t0\n",
      "蜂蜜对胃好吗\t蜂蜜对胃好嘛\t1\n",
      "肾癌的症状\t肾癌得症状\t0\n",
      "肾阴虚吃什么药\t肾阴虚吃什么要\t1\n",
      "盐酸普萘洛尔片的作用\t盐酸普奈洛尔片的作用\t0\n",
      "哺乳期发烧可以打针吗\t哺乳期发烧可以打针嘛\t1\n",
      "感冒能吃芒果吗\t感冒能吃芒果嘛\t0\n",
      "小三阳能治好吗\t小三阳能只好吗\t0\n",
      "三七是田七吗\t三七是田七么\t0\n",
      "一次就会怀孕吗\t一次就会怀孕么\t1\n",
      "什么是注册资本\t什么事注册资本\t0\n",
      "奥美拉唑是饭前吃还是饭后吃\t奥美拉唑是饭钱吃还是饭后吃\t0\n",
      "腰肌劳损有哪些症状\t腰肌老损有哪些症状\t0\n",
      "远志的功效与作用\t远制的功效与作用\t0\n",
      "脚磨起泡了怎么办\t脚磨气泡了怎么办\t0\n",
      "舌头俩侧发麻\t舌头两侧发麻\t1\n",
      "骨折可以吃生蚝吗\t骨折可以吃生蚝么\t0\n",
      "滑石粉能吃吗\t滑石粉能吃嘛\t0\n",
      "子宫肌瘤能吃燕窝吗\t子宫肌瘤能吃燕窝么\t1\n",
      "前列腺炎的治疗方法\t前列腺炎得治疗方法\t1\n",
      "湿热吃什么药\t湿热吃什么药\t1\n",
      "湿疹怎么办\t湿诊怎么办\t0\n",
      "经期能喝柠檬水吗\t经期能喝拧檬水吗\t0\n",
      "做散瞳对眼睛有伤害吗\t做散童对眼睛有伤害吗\t1\n",
      "霉菌性阴道炎能怀孕吗\t霉菌性阴道炎能怀孕嘛\t0\n",
      "柠檬泡水功效\t宁檬泡水功效\t0\n",
      "甲状腺回声不均匀是什么意思\t甲状腺回升不均匀是什么意思\t1\n",
      "公主连接母猪石怎么得\t公主连结母猪石怎么得\t1\n",
      "玫瑰代表着什么意思\t玫瑰带表着什么意思\t0\n",
      "胰腺炎的症状有哪些\t胰腺炎的症状有那些\t0\n",
      "民政局星期六上班吗\t民政局星期六上班嘛\t0\n",
      "下巴长粉刺的原因\t下巴张粉刺的原因\t0\n",
      "腿部肌肉酸痛\t腿不肌肉酸痛\t1\n",
      "男孩子起什么名字好听\t男孩子启什么名字好听\t0\n",
      "专心的看叫什么视\t专心地看叫什么视\t0\n",
      "取环多久可以怀孕\t去环多久可以怀孕\t1\n",
      "活血化瘀的药有哪些\t活血化瘀的要有哪些\t0\n",
      "小鸟叼生日\t小鸟刁生日\t1\n",
      "猫为什么舔爪子\t猫为什么添爪子\t1\n",
      "脚背痛是不是痛风\t脚背痛是不是通风\t0\n",
      "梭子蟹孕妇能吃吗\t梭子蟹孕妇能吃嘛\t0\n",
      "肠胃不好能喝蜂蜜吗\t肠胃不好能和蜂蜜吗\t0\n",
      "脚趾发麻怎么办\t脚指发麻怎么办\t0\n",
      "手麻是怎么回事\t手麻是怎么会事\t0\n",
      "人为什么要睡觉\t人为什么要谁觉\t0\n",
      "孕晚期能吃花甲吗\t孕晚期能吃花甲么\t0\n",
      "八万日元等于多少人民币\t八百日元等于多少人民币\t1\n",
      "接吻会怀孕吗\t接吻会怀孕么\t0\n",
      "大拇指腱鞘炎的治疗\t大姆指腱鞘炎的治疗\t0\n",
      "糖尿病人可以吃地瓜吗\t糖尿病人可以吃地瓜嘛\t0\n",
      "拉的黑色的屎怎么回事\t拉的黑色的是怎么回事\t0\n",
      "胆结石可以吃鸭蛋吗\t胆结石可以吃鸭蛋么\t1\n",
      "晚上吃梨好吗\t晚上吃黎好吗\t0\n",
      "胸口闷怎么回事\t胸口闷怎么会事\t0\n",
      "一直拉稀怎么回事\t一只拉稀怎么回事\t0\n",
      "身上长猴子怎么去掉\t身上长瘊子怎么去掉\t0\n",
      "腹泻可以喝蜂蜜水吗\t腹泻可以喝蜂蜜水么\t0\n",
      "月经期间能运动吗\t月经期间能运动么\t0\n",
      "拔完牙多久可以喝水\t把完牙多久可以喝水\t0\n",
      "肠炎的症状有哪些\t肠炎的症状有那些\t0\n",
      "小腿胀痛怎么办\t小腿张痛怎么办\t0\n",
      "心颤是怎么回事\t心战是怎么回事\t0\n",
      "怀孕胸会变大吗\t怀孕胸会变大嘛\t0\n",
      "怀孕可以吃白木耳吗\t怀孕可以吃白木耳么\t0\n",
      "怀孕可以吃无花果干吗\t怀孕可以吃无花果干嘛\t0\n",
      "髋关节积液的治疗方法\t宽关节积液的治疗方法\t0\n",
      "白蛋白偏高\t白蛋百偏高\t0\n",
      "痛风能吃芋头吗\t痛风能吃芋头嘛\t1\n",
      "容易怀孕吗\t容易怀孕嘛\t1\n",
      "脑梗能吃海参吗\t脑梗能吃海参么\t0\n",
      "东革阿里的功效与作用\t东格阿里的功效与作用\t0\n",
      "双肺纹理增多紊乱\t双肺文理增多紊乱\t1\n",
      "南州是什么地方\t南洲是什么地方\t0\n",
      "小米粥糖分高吗?\t小米粥糖份高吗?\t0\n",
      "尿液发红怎么办\t尿夜发红怎么办\t0\n",
      "心率不齐的危害\t心律不齐的危害\t0\n",
      "跑完步能喝水吗\t跑完不能喝水吗\t0\n",
      "乳腺增生能吃燕窝吗\t乳腺增生能吃燕窝么\t0\n",
      "脚浮肿怎么办\t脚俘肿怎么办\t1\n",
      "如何申请小号\t如何申清小号\t1\n",
      "骨髓移植活得最长的人\t骨髓移植活的最长的人\t0\n",
      "如何收缩毛孔\t如何收索毛孔\t0\n",
      "医用外科口罩一次能戴多久\t医用外科口罩一次能带多久\t1\n",
      "怎样去除眼袋\t怎样取除眼袋\t0\n",
      "坐月子拉肚子怎么办\t座月子拉肚子怎么办\t0\n",
      "前列腺增生吃什么药\t前裂腺增生吃什么药\t0\n",
      "糖尿病可以吃胡萝卜吗\t糖尿病可以吃胡罗卜吗\t0\n",
      "子宫肌瘤可以吃燕窝吗\t子宫肌瘤可以吃燕窝嘛\t0\n",
      "沉香的功效与作用\t沉香得功效与作用\t0\n",
      "泌乳素高怎么办\t必乳素高怎么办\t0\n",
      "酸奶什么时候喝最好\t酸奶什么时侯喝最好\t1\n",
      "比熊能吃红薯吗\t比熊能吃红薯么\t0\n",
      "咳嗽能吃水果吗\t咳嗽能吃水果嘛\t1\n",
      "喝完酒能洗澡吗\t喝完酒能洗澡嘛\t0\n",
      "小腿肚抽筋怎么回事\t小腿杜抽筋怎么回事\t0\n",
      "哺乳期能吃奥美拉唑吗\t哺乳期能吃奥美拉唑嘛\t0\n",
      "肝痛是在哪个位置\t肝痛是在那个位置\t1\n",
      "来月经可以喝豆浆吗\t来月经可以和豆浆吗\t0\n",
      "肠胃炎吃什么好\t肠胃炎吃什药好\t0\n",
      "拉肚子可以吃酸奶吗\t拉肚子可以吃酸奶么\t1\n",
      "孕晚期能吃雪糕吗\t孕晚期能吃雪糕嘛\t1\n",
      "脑梗塞的症状有哪些\t脑梗赛的症状有哪些\t0\n",
      "怎么在微店上买东西\t怎么在微店上卖东西\t0\n",
      "肠胃炎可以吃橘子吗\t肠胃炎可以吃桔子吗\t1\n",
      "新生儿为什么老打嗝\t新生儿为什么老打隔\t0\n",
      "胸闷气短是怎么回事\t凶闷气短是怎么回事\t1\n",
      "腹泻能吃橙子吗\t腹泻能吃橙子嘛\t0\n",
      "胃不好能喝红茶吗\t胃不好能和红茶吗\t1\n",
      "苹果手机怎么改字体\t苹果手机怎么改自体\t1\n",
      "糖尿病吃什么蔬菜好\t糖尿病吃什么蔬才好\t0\n",
      "鼻塞流鼻涕吃什么药\t鼻赛流鼻涕吃什么药\t0\n",
      "咳嗽可以吃冰淇淋吗\t咳嗽可以吃冰淇淋么\t0\n",
      "痛风能吃甲鱼吗\t痛风能吃甲鱼嘛\t1\n",
      "额头上长小疙瘩\t额头上张小疙瘩\t0\n",
      "水浒传作者\t谁浒传作者\t1\n",
      "小肚子疼是怎么回事\t小度子疼是怎么回事\t0\n",
      "怎样调节内分泌失调\t怎样调解内分泌失调\t1\n",
      "结石不能吃什么\t节石不能吃什么\t1\n",
      "为什么手机收不到验证码\t为什么手机收不到验正码\t1\n",
      "慢性咽炎吃什么药\t慢性咽炎吃什么要\t0\n",
      "跑步能减肥吗\t跑不能减肥吗\t0\n",
      "耳朵里长痘痘是怎么回事\t耳朵里张痘痘是怎么回事\t1\n",
      "睡觉磨牙是什么原因\t谁觉磨牙是什么原因\t1\n",
      "益母草的功效与作用\t益母草的工效与作用\t1\n",
      "老烂腿怎么治\t老兰腿怎么治\t0\n",
      "不停打嗝怎么办\t不挺打嗝怎么办\t0\n",
      "养猫需要打疫苗吗\t养猫需要打疫苗嘛\t0\n",
      "怀孕可以吃苹果吗\t怀孕可以吃苹果嘛\t1\n",
      "艾滋病的前期症状\t爱滋病的前期症状\t1\n",
      "妊娠糖尿病能吃菠萝吗\t妊娠糖尿病能吃菠萝么\t1\n",
      "皮肤癌有哪些症状\t皮肤癌有那些症状\t0\n",
      "如何取消分隔符\t如何取消分格符\t0\n",
      "湿热型体质如何调理\t湿热性体质如何调理\t0\n",
      "大便排不出来怎么办\t大便拍不出来怎么办\t1\n",
      "肾结石患者可以吃南瓜吗\t肾结石患者可以吃南瓜么\t1\n",
      "孕晚期可以吃冰淇淋吗\t孕晚起可以吃冰淇淋吗\t0\n",
      "盐城盛产盐吗\t盐城生产盐吗\t1\n",
      "胃里反酸水\t胃里范酸水\t1\n",
      "失眠怎么办\t失眠怎麼办\t0\n",
      "吃避孕药会流血吗\t吃避孕药会留血吗\t0\n",
      "乙型肝炎表面抗体阳性是什么意思\t乙行肝炎表面抗体阳性是什么意思\t1\n",
      "高蛋白食物有哪些\t高蛋百食物有哪些\t0\n",
      "肾结石可以吃红薯吗\t肾结石可以吃红薯嘛\t0\n",
      "怀孕可以吃莴笋吗\t怀孕可以吃窝笋吗\t0\n",
      "孕妇为什么会孕吐\t孕妇为什么回孕吐\t0\n",
      "喝蜂蜜上火吗\t喝蜂蜜上火嘛\t1\n",
      "蜜蜂蛰了怎么处理\t蜜峰蛰了怎么处理\t0\n",
      "筋断了吃什么好得快\t筋断了吃什么好的快\t1\n",
      "卫星锅分辨率\t卫星锅分辩率\t1\n",
      "哺乳期可以吃板蓝根颗粒吗\t哺乳期可以吃板蓝根颗粒么\t1\n",
      "产妇可以吃什么零食\t产妇可以吃什么零时\t1\n",
      "人流后多久来月经\t人流后多久莱月经\t0\n",
      "中暑的症状\t种暑的症状\t1\n",
      "粮票值钱吗\t粮票值钱么\t0\n",
      "芦荟可以直接涂在脸上吗\t芦会可以直接涂在脸上吗\t0\n",
      "激光手术疼吗\t激光手术疼嘛\t0\n",
      "十边形内角和\t十边型内角和\t1\n",
      "纯碱作洗涤剂的原理\t纯碱做洗涤剂的原理\t1\n",
      "怀孕可以吃棒冰吗\t怀孕可以吃棒冰嘛\t0\n",
      "什么是康复治疗\t什么是康复制疗\t0\n",
      "分数是小数吗\t分数是小数么\t0\n",
      "糖尿病可以吃核桃吗\t唐尿病可以吃核桃吗\t1\n",
      "荨麻疹吃什么药\t寻麻疹吃什么药\t0\n",
      "茄子怎样做好吃\t茄子怎样作好吃\t0\n",
      "民政局有哪些部门\t民政局有那些部门\t1\n",
      "蜂蜜水什么时候喝好\t风蜜水什么时候喝好\t0\n",
      "足跟滑囊炎怎么治疗\t足根滑囊炎怎么治疗\t1\n",
      "男性尿血是怎么回事\t男姓尿血是怎么回事\t0\n",
      "哪些人不适合吃蜂蜜\t那些人不适合吃蜂蜜\t1\n",
      "喝阿莫西林能喝酒吗\t喝阿莫西林能喝酒么\t1\n",
      "老式显微镜有收藏的吗\t老式显微镜有收藏的吗\t1\n",
      "戴避孕套会怀孕吗\t待避孕套会怀孕吗\t0\n",
      "哺乳期可以吃葡萄吗\t哺乳期可以吃葡萄么\t0\n",
      "淋巴结怎么治疗\t淋吧结怎么治疗\t0\n",
      "视神经萎缩\t视神精萎缩\t0\n",
      "菠萝上火吗\t菠萝上火嘛\t0\n",
      "怀孕初期会头晕吗\t怀孕初期会头晕么\t1\n",
      "怎么叠爱心\t怎么碟爱心\t0\n",
      "做什么生意最赚钱\t作什么生意最赚钱\t0\n",
      "干眼症如何治疗\t干眼证如何治疗\t0\n",
      "肠胃不好怎么调理\t肠胃不好怎么调里\t0\n",
      "来月经可以吃西洋参吗\t来月经可以吃西洋参么\t1\n",
      "宫腔积液吃什么药\t宫腔积夜吃什么药\t0\n",
      "胃不好能吃水果吗\t胃不好能吃水果么\t1\n",
      "坐骨神经痛是怎么回事\t做骨神经痛是怎么回事\t0\n",
      "高血压可以吃黄瓜吗\t高血压可以吃黄瓜嘛\t0\n",
      "怀孕可以吃提子吗\t怀孕可以吃提子嘛\t1\n",
      "心脏供血不足怎么调理\t心脏共血不足怎么调理\t1\n",
      "人为什么要睡觉\t仁为什么要睡觉\t0\n",
      "血氧饱和度正常值是多少\t血养饱和度正常值是多少\t1\n",
      "鼻孔里面结痂怎么办\t鼻腔里面结痂怎么办\t1\n",
      "海参小孩可以吃吗\t海参小孩可以吃么\t1\n",
      "怎样除口臭\t怎样处口臭\t0\n",
      "电池会爆炸吗\t电池会爆炸么\t0\n",
      "学习英语的软件\t学习英语得软件\t0\n",
      "血压低吃什么药好\t血压地吃什么药好\t0\n",
      "减肥晚上可以吃橙子吗\t减肥晚上可以吃橙子么\t0\n",
      "如何祛草莓印\t如何去草莓印\t0\n",
      "背痛是什么原因\t背痛是什麼原因\t0\n",
      "生姜发芽还能吃吗\t生姜发芽还能吃么\t1\n",
      "什么是肺结节\t什么是肺结结\t1\n",
      "肾结石能吃橘子吗\t肾结石能吃橘子么\t1\n",
      "吃蜂蜜有什么好处\t吃风蜜有什么好处\t0\n",
      "慢性宫颈炎怎么治\t曼性宫颈炎怎么治\t0\n",
      "怀孕初期可以吃火鸡面吗\t怀孕初期可以吃火鸡面嘛\t1\n",
      "流产后可以喝红糖水吗\t流产后可以和红糖水吗\t0\n",
      "慢性咽炎的症状\t慢性咽炎的证状\t0\n",
      "阿里巴巴如何开店\t啊里巴巴如何开店\t1\n",
      "转基因食品有哪些\t转基因食品有那些\t0\n",
      "酷暑难挡是什么意思\t酷暑难当是什么意思\t1\n",
      "什么的枫叶\t什么得枫叶\t0\n",
      "吗丁啉治胃炎吗\t吗丁啉治胃炎么\t0\n",
      "绿豆糕的做法\t绿豆糕的作法\t1\n",
      "如何补气血\t入何补气血\t0\n",
      "乳腺结节是乳腺增生吗\t乳腺结节是乳腺增生么\t0\n",
      "伤口化脓怎么处理\t伤口化浓怎么处理\t0\n",
      "被狗咬了怎么办\t备狗咬了怎么办\t0\n",
      "烂嘴角是怎么回事\t烂嘴角是怎么会事\t0\n",
      "白带多是怎么回事\t白带多是怎么会事\t0\n",
      "什么的迎春花\t什么地迎春花\t0\n",
      "胃恶心想吐\t为恶心想吐\t0\n",
      "坐久了腰疼是怎么回事\t做久了腰疼是怎么回事\t1\n",
      "怀孕初期可以吃枣吗\t怀孕初期可以吃枣嘛\t0\n",
      "九一年属什么\t九壹年属什么\t0\n",
      "微波炉能做披萨吗\t微波炉能做披萨么\t1\n",
      "如何提高心理素质\t如何提高心里素质\t0\n",
      "放疗可以报销吗\t放疗可以报销么\t1\n",
      "甲亢能治愈吗\t甲亢能治愈嘛\t1\n",
      "副乳怎么消除才正确\t附乳怎么消除才正确\t1\n",
      "党员有哪些权利\t党员有那些权利\t1\n",
      "哪些动物是气象员\t那些动物是气象员\t0\n",
      "农村户口可以买社保吗\t农村户口可以买社保嘛\t0\n",
      "如何查询自己的手机号\t如何查寻自己的手机号\t0\n",
      "怎么申请支付宝账号\t怎么申请支付宝帐号\t0\n",
      "温州市有哪些区\t温州市有那些区\t0\n",
      "感冒喝什么汤好\t感冒和什么汤好\t0\n",
      "伊利纯牛奶好吗\t伊利纯牛奶好么\t0\n",
      "黄芩的功效与作用\t黄芩的功效与做用\t0\n",
      "消化不良可以吃香蕉吗\t消化不良可以吃香蕉嘛\t0\n",
      "薄荷的功效与作用\t薄荷的功效与做用\t0\n",
      "喉咙痒咳嗽怎么办\t候咙痒咳嗽怎么办\t0\n",
      "过渡性是什么意思\t过度性是什么意思\t0\n",
      "月经期能吃桔子吗\t月经期能吃橘子吗\t1\n",
      "刘晓燕哪里人\t刘小燕哪里人\t0\n",
      "post2.py:688: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (~data.text_a.str.contains('(多音字|读音|啥意思)')) &\n",
      "post2.py:689: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  (~data.text_b.str.contains('(多音字|读音|啥意思)')),\n",
      "change cnt : 2085\n",
      "save sum 16991\n"
     ]
    }
   ],
   "source": [
    "!python post2.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
